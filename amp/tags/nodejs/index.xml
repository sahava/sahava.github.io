<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Nodejs on Simo Ahava's blog</title><link>https://www.simoahava.com/amp/tags/nodejs/</link><description>Recent content in Nodejs on Simo Ahava's blog</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 31 Dec 2018 11:14:06 +0200</lastBuildDate><atom:link href="https://www.simoahava.com/amp/tags/nodejs/index.xml" rel="self" type="application/rss+xml"/><item><title>Scrape The URLs Of A Domain And Write The Results To BigQuery</title><link>https://www.simoahava.com/amp/google-cloud/scrape-domain-and-write-results-to-bigquery/</link><pubDate>Mon, 31 Dec 2018 11:14:06 +0200</pubDate><guid>https://www.simoahava.com/amp/google-cloud/scrape-domain-and-write-results-to-bigquery/</guid><description>&lt;p>In my intense love affair with the &lt;a href="https://cloud.google.com/">Google Cloud Platform&lt;/a>, I&amp;rsquo;ve never felt more inspired to write content and try things out. After starting with a &lt;a href="https://www.simoahava.com/amp/analytics/install-snowplow-on-the-google-cloud-platform/">Snowplow Analytics setup guide&lt;/a>, and continuing with a &lt;a href="https://www.simoahava.com/amp/google-cloud/lighthouse-bigquery-google-cloud-platform/">Lighthouse audit automation tutorial&lt;/a>, I&amp;rsquo;m going to show you yet another cool thing you can do with GCP.&lt;/p>


 &lt;a href="https://www.simoahava.com/amp/images/2018/12/bigquery-status-codes.jpg" title="BigQuery status codes">
 
 &lt;amp-img src="https://www.simoahava.com/amp/images/2018/12/bigquery-status-codes.jpg" layout="responsive" alt="BigQuery status codes" height="501" width="981">&lt;/amp-img>
 
 &lt;/a>
 

&lt;p>In this guide, I&amp;rsquo;ll show you how to use an &lt;a href="https://github.com/yujiosaka/headless-chrome-crawler">open-source web crawler&lt;/a> running in a &lt;a href="https://cloud.google.com/compute/">Google Compute Engine&lt;/a> virtual machine (VM) instance to scrape all the internal and external links of a given domain, and write the results into a &lt;a href="https://cloud.google.com/bigquery/">BigQuery table&lt;/a>. With this setup, you can audit and monitor the links in any website, looking for bad status codes or missing titles, and fix them to improve your site&amp;rsquo;s logical architecture.&lt;/p></description></item><item><title>Audit Multiple Sites With Lighthouse And Write Results To BigQuery</title><link>https://www.simoahava.com/amp/google-cloud/lighthouse-bigquery-google-cloud-platform/</link><pubDate>Tue, 18 Dec 2018 09:03:08 +0200</pubDate><guid>https://www.simoahava.com/amp/google-cloud/lighthouse-bigquery-google-cloud-platform/</guid><description>&lt;p>&lt;a href="https://cloud.google.com/">Google Cloud Platform&lt;/a> is very, very cool. It&amp;rsquo;s a fully capable, enterprise-grade, scalable cloud ecosystem which lets even total novices get started with building their first cloud applications. I wrote a long guide for installing &lt;a href="https://www.simoahava.com/amp/analytics/install-snowplow-on-the-google-cloud-platform/">Snowplow on the GCP&lt;/a>, and you might want to read that if you want to see how you can build your own analytics tool using some nifty open-source modules.&lt;/p>
&lt;p>But this guide will not be about &lt;a href="https://snowplowanalytics.com/">Snowplow&lt;/a>. Rather, it will tackle Google&amp;rsquo;s own open-source performance audit tool: &lt;a href="https://developers.google.com/web/tools/lighthouse/">Lighthouse&lt;/a>.&lt;/p></description></item><item><title>Google Analytics Client ID In AMP Pages</title><link>https://www.simoahava.com/amp/analytics/google-analytics-client-id-amp-pages/</link><pubDate>Mon, 14 Nov 2016 08:59:32 +0000</pubDate><guid>https://www.simoahava.com/amp/analytics/google-analytics-client-id-amp-pages/</guid><description>&lt;p>This article is a collaboration between Simo and &lt;a href="https://www.bounteous.com/insights/author/danwilkerson/">Dan Wilkerson&lt;/a>. Dan&amp;rsquo;s one of the smartest analytics developers out there, and he&amp;rsquo;s already contributed a great &lt;a href="https://www.simoahava.com/amp/gtm-tips/using-document-write-safely-gtm-tags/">#GTMTips guest post&lt;/a>. It&amp;rsquo;s great to have him back here sharing his insight on working with &lt;a href="https://www.ampproject.org/">Accelerated Mobile Pages&lt;/a> (AMP).&lt;/p>
&lt;p>So, we&amp;rsquo;re back on AMP! Simo wrote a long, sprawling &lt;a href="https://www.simoahava.com/amp/analytics/accelerated-mobile-pages-via-google-tag-manager/">AMP for Google Tag Manager guide&lt;/a> a while ago, and Dan has also contributed to the space with his guide for &lt;a href="https://www.bounteous.com/insights/2015/12/08/google-analytics-using-amp/">AMP and Google Analytics&lt;/a>. Both of these guides touched upon a subject that might be one of the reasons to stay away from AMP for now: Client ID matching across AMP, your regular website, and any caches or CDNs that serve the AMP version.&lt;/p></description></item></channel></rss>