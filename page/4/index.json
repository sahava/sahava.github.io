[
{
	"uri": "https://www.simoahava.com/analytics/format-value-option-in-google-tag-manager-variables/",
	"title": "#GTMTips: Format Value Option In Google Tag Manager Variables",
	"tags": ["google tag manager", "variable", "format value", "gtmtips"],
	"description": "The new Format Value option in Google Tag Manager variables lets you modify the output of GTM&#39;s variables dynamically, without needing to resort to Custom JavaScript.",
	"content": " A very recent addition to Google Tag Manager is the Format Value option in all of GTM\u0026rsquo;s variables. With Format Value, you can modify the output of the variable with a number of pre-defined transformations.\nThis is extremely handy, because you no longer need to create Custom JavaScript variables whose sole purpose of existence it to change the output of other variables to lowercase, or to change undefined values to fallback strings (e.g. (not set)).\nTip 88: Format Value option in GTM\u0026rsquo;s Variables   When you create or modify any variable in GTM, you now see a new option at the bottom of the configuration screen. The option is titled Format Value. By expanding it, you will see the following options:\n Change Case to\u0026hellip; - This lets you change the case of the string output of the variable to either lowercase or UPPERCASE.\n Convert null to\u0026hellip; - With this, you can convert null values to some other string (by typing text directly into the field), or you can have null output fall back to another variable by picking it from the variable selector.\n Convert undefined to\u0026hellip; - Same as with null, you can now have undefined values fall back to strings or the returned value of other variables.\n Convert true to\u0026hellip; - Same as above, except now you can convert Boolean true to a string or the returned value of some other variable.\n Convert false to\u0026hellip; - Same as above, except now you can convert Boolean false to a string or the returned value of some other variable.\n  So how is this useful? Well, take the Case conversion as an example. By forcing the variable output to lowercase, for example, you can normalize all the following strings:\n\u0026quot;I love GTM\u0026quot;, \u0026quot;i LoVe gTM\u0026quot;, \u0026quot;I LOVE GTM\u0026quot;.\nWith Case conversion set to Lowercase, the output of all the three strings above would be \u0026quot;i love gtm\u0026quot;.\nNormalization is absolutely vital in tools such as Google Analytics, which treat each case format of any string as unique and distinct from the others.\nBeing able to convert falsy values such as undefined, null and false to string representations is handy, too, since you can now use something like \u0026quot;N/A\u0026quot; or \u0026quot;(not set)\u0026quot; to represent situations where the variable did not return a proper value. Again, in Google Analytics this is relevant, because GA drops undefined fields from hits.\nThe Format Value option is a very useful addition to Google Tag Manager\u0026rsquo;s arsenal. I only hope the number of available formatting options is increased in the future, perhaps even allowing us to write simple anonymous functions directly in the UI through which each varible output is passed.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/tracking-cross-domain-iframes-upgraded-solution/",
	"title": "Tracking Cross-domain Iframes - Upgraded Solution",
	"tags": ["google tag manager", "customtask", "universal analytics", "cross-domain", "iframe"],
	"description": "An upgraded solution (using customTask) to tracking iframes cross-domain when using Google Tag Manager and Google Analytics.",
	"content": " Some years ago, I wrote a post on how to track cross-domain iframes when using Google Tag Manager and Google Analytics. That solution relied on hitCallback to decorate the iframe, and now that I look back on it, it has its shortcomings.\nFor one, the older solution used hitCallback which, while being reliable in that Google Analytics has definitely loaded with the linker plugin when the method is called, doesn\u0026rsquo;t take into account the possible race condition of the script running before the iframe has been loaded.\nAn additional problem was that the older solution simply grabbed the linker from the first Google Analytics tracker object on the page. But this might not be the one we want to use for the cross-domain tracking.\n  In this solution, we\u0026rsquo;ll use the wonderful customTask to decorate the target iframe. The customTask leverages a setInterval() script which polls the page periodically until the target iframe is found or a timeout is reached.\n  Naturally, this script has been added to my customTask Builder tool.\nThe customTask itself This is what the customTask looks like. To deploy it, make sure you read the instructions in the customTask Builder tool before copy-pasting the required code into your page JavaScript (if using the Universal Analytics on-page snippet) or a Custom JavaScript variable (if using Google Tag Manager).\nfunction() { var iframeDecorator = { selector: \u0026#39;iframe#decorateMe\u0026#39;, attempts: 10, intervalMs: 1000, useAnchor: false }; // DO NOT EDIT ANYTHING BELOW THIS LINE  var globalSendHitTaskName = \u0026#39;_ga_originalSendHitTask\u0026#39;; return function(customTaskModel) { window[globalSendHitTaskName] = window[globalSendHitTaskName] || customTaskModel.get(\u0026#39;sendHitTask\u0026#39;); var tempFieldObject, dimensionIndex, count, ga, tracker, decorateTimer, decorateIframe, iframe; if (typeof iframeDecorator === \u0026#39;object\u0026#39; \u0026amp;\u0026amp; typeof iframeDecorator.selector === \u0026#39;string\u0026#39; \u0026amp;\u0026amp; typeof iframeDecorator.attempts === \u0026#39;number\u0026#39; \u0026amp;\u0026amp; typeof iframeDecorator.intervalMs === \u0026#39;number\u0026#39;) { count = 0; ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; tracker = ga.getByName(customTaskModel.get(\u0026#39;name\u0026#39;)); decorateIframe = function() { iframe = document.querySelector(iframeDecorator.selector); if (iframe !== null \u0026amp;\u0026amp; /[?\u0026amp;]_ga=/.test(iframe.src)) { window.clearInterval(decorateTimer); return; } if (iframe === null) { count += 1; if (count === iframeDecorator.attempts) { window.clearInterval(decorateTimer); } return; } window.clearInterval(decorateTimer); iframe.src = (new window.gaplugins.Linker(tracker)).decorate(iframe.src, iframeDecorator.useAnchor); }; decorateTimer = window.setInterval(decorateIframe, iframeDecorator.intervalMs); } }; }  To begin with, make sure to edit the configuration object iframeDecorator. Set the parameters to their correct values.\n   Parameter Example value Description     selector \u0026quot;#decorateMe\u0026quot; String with the CSS selector that matches the iframe you want to decorate.   attempts 10 Number denoting how many times the page is polled for the iframe until the script stops trying.   intervalMs 1000 Milliseconds between each attempt to find the iframe on the page.   useAnchor false Whether to use a hash (#) instead of a URL query parameter to append the linker parameter to the iframe src.    Once you\u0026rsquo;ve edited these, you\u0026rsquo;ll need to add this customTask to your trackers or tags.\nMake sure to add this customTask to a hit or tag that fires after (or shortly before) the iframe element has been added to the page. The script has a timeout which is attempts * intervalMs milliseconds, so if the script doesn\u0026rsquo;t find the iframe by this timeout, the script will no longer poll the page, and the iframe will remain undecorated.\nFor example, if the iframe is in the page HTML template itself, it\u0026rsquo;s typically enough to add this customTask to the Page View hit that fires as soon as the page starts to load (so All Pages trigger in GTM, or the on-page snippet if using Universal Analytics).\nBut if the iframe is added in a modal upon the click of a button, for example, you\u0026rsquo;ll want to fire a Google Analytics hit with that click, and then make sure to include this customTask in the hit.\nHow it works When the hit to Google Analytics is generated, this customTask repeatedly asks the page: \u0026ldquo;Is there an iframe that matches the given CSS selector?\u0026rdquo;. If this iframe is found before the timeout (attempts * intervalMs), then the iframe path is decorated with the cross-domain linker parameter.\nThis, in turn, means that when the page within the iframe loads, the URL of the page will have the _ga= cross-domain linker parameter, which is then utilized by the first tag that fires in the iframe with the allowLinker flag set to true.\nCaveats Note that this only decorates the iframe src path. This is the only thing you can do from the source site, so if it doesn\u0026rsquo;t work, you\u0026rsquo;re out of luck with this solution. Some iframes might introduce a redirect when the original src is loaded, which often eliminates the query parameter from the URL. If this is the case, you can try setting the useAnchor parameter to true, which might be more resilient to redirects.\n If you\u0026rsquo;re interested in a viable alternative to the linker parameter, take a look at the postMessage API introduced in this great article by Dan Wilkerson from LunaMetrics.\n Be wary, also, that this customTask uses the cookie configuration of the hit that the customTask was added to. So if this hit has an exceptional cookie configuration, it\u0026rsquo;s possible the linker is built with the wrong Client ID.\nIn other words, make sure you are aware of any modifications to the default cookie settings in the tracker, hit or tag to which the customTask is added.\nThere is no real penalty to adding this customTask directly to the tracker or all your Universal Analytics tags. If the iframe already has a cross-domain parameter in the src value, the script simply stops attempting to decorate the iframe.\nSummary This is an alternative approach to my original solution of using hitCallback to decorate the iframe. In my humble opinion, I think this customTask wipes the floor with my original idea, so I\u0026rsquo;m fully recommending using this instead.\nMy feelings on iframes haven\u0026rsquo;t really changed since writing the original article, so I\u0026rsquo;ll just include the relevant excerpt here for you to sympathize with.\n  If you want to vent, please let me know what you think about iframes in the comments of this article.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/create-and-update-google-analytics-session-timeout-cookie/",
	"title": "Create And Update Google Analytics Session Timeout Cookie",
	"tags": ["google tag manager", "google analytics", "customtask", "session"],
	"description": "With this customTask trick, you can create a cookie which mimics Google Analytics&#39; session timeout. This cookie is refreshed with every valid hit, and can be used to detect active/inactive sessions in the browser.",
	"content": " In Google Analytics, the concept of a session is the key aggregation unit of all the data you work with. It\u0026rsquo;s so central to all the key metrics you use (Conversion Rate, Bounce Rate, Session Duration, Landing Page), and yet there\u0026rsquo;s an underlying complexity that I\u0026rsquo;m pretty certain is unrecognized by many of GA\u0026rsquo;s users. And yet, since this idea of a session is so focal to GA (to the point of being overbearing), it\u0026rsquo;s annoying that the browser isn\u0026rsquo;t privy to any of the sessionization parameters that Google Analytics applies to the hits sent from the browser to its servers.\nWell, to rectify this, I\u0026rsquo;ve written a very simple customTask solution, which basically mimics the session timeout (30 minutes by default) in a browser cookie. You can use this cookie for a number things, such as preventing event hits from being dispatched if the session has timed out, or for turning these event hits into non-interactive hits.\n  Naturally, I have also updated my guide to customTask as well as my customTask Builder tool with this trick, so you can start using it with all the other cool customTask tricks out there!\nThe customTask code Here\u0026rsquo;s what the customTask method looks like:\nvar _customTask = function() { // Update expiresMs to be the number of milliseconds when the cookie should expire.  // Update domain to match the parent domain of your website.  var updateSessionCookie = { expiresMs: 1000*60*30, domain: \u0026#39;mydomain.com\u0026#39; }; // DO NOT EDIT ANYTHING BELOW THIS LINE  var globalSendHitTaskName = \u0026#39;_ga_originalSendHitTask\u0026#39;; return function(customTaskModel) { window[globalSendHitTaskName] = window[globalSendHitTaskName] || customTaskModel.get(\u0026#39;sendHitTask\u0026#39;); customTaskModel.set(\u0026#39;sendHitTask\u0026#39;, function(sendHitTaskModel) { var originalSendHitTaskModel = sendHitTaskModel, originalSendHitTask = window[globalSendHitTaskName]; var hitType, nonInteraction, d; try { originalSendHitTask(sendHitTaskModel); // updateSessionCookie  if (typeof updateSessionCookie === \u0026#39;object\u0026#39; \u0026amp;\u0026amp; updateSessionCookie.hasOwnProperty(\u0026#39;expiresMs\u0026#39;) \u0026amp;\u0026amp; updateSessionCookie.hasOwnProperty(\u0026#39;domain\u0026#39;)) { hitType = sendHitTaskModel.get(\u0026#39;hitType\u0026#39;); nonInteraction = sendHitTaskModel.get(\u0026#39;nonInteraction\u0026#39;); if (nonInteraction !== true \u0026amp;\u0026amp; (hitType === \u0026#39;pageview\u0026#39; || hitType === \u0026#39;event\u0026#39;)) { d = new Date(); d.setTime(d.getTime() + updateSessionCookie.expiresMs); document.cookie = \u0026#39;_session_\u0026#39; + sendHitTaskModel.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;=true; expires=\u0026#39; + d.toUTCString() + \u0026#39;; path=/; domain=\u0026#39; + updateSessionCookie.domain; } } // /updateSessionCookie  } catch(e) { originalSendHitTask(originalSendHitTaskModel); } }); }; };  If you\u0026rsquo;re using Google Tag Manager, copy-paste that into a Custom JavaScript variable, and then change the first line to function() { and remove the very last character of the code block (the final semicolon). Then, add it as a new Field to Set in your Google Analytics tag settings.\nif you\u0026rsquo;re using Google Analytics, you need to run this JavaScript before the Google Analytics snippet, and then when creating the tracker modify it to:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-XXXXX-Y\u0026#39;); ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, _customTask); // \u0026lt;-- Add this ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;);  This customTask should be added to all the tags and hits that you want to have an impact on the session refresh. Basically, it should fire with all your pageviews and events, since those are the two that keep the session alive.\nHow it works Any tag or hit that uses this customTask will now run some extra code when the hit has been sent to Google Analytics. The code checks whether the hit was interactive (since non-interactive hits don\u0026rsquo;t keep a session alive) and whether it was an event or pageview (since those are the two hits that keep a session alive).\nIn both these conditions are true, a cookie named _session_UA-XXXXX-Y is created (or updated if it already exists) with an expiration set to whatever you configured as the value of the expiresMs property in the beginning of the code block.\nIn other words, you will now have a cookie which, if it exists, means there is most likely an active session in Google Analytics. I say \u0026ldquo;most likely\u0026rdquo;, because there are many ways that sessions can be broken off even before the timeout expires.\nThis cookie is a reasonable abstraction of the session timeout schema in Google Analytics. It\u0026rsquo;s not perfect, but it gives you an idea.\nThings you can do with it Well, the easiest thing is to use it to prevent Events from firing if the session cookie doesn\u0026rsquo;t exist. Why? Because it\u0026rsquo;s tiresome having sessions that only have events. Even though there\u0026rsquo;s really no problem with having events fire before pageviews (even if all the documentation tries to tell you otherwise), there\u0026rsquo;s a risk you\u0026rsquo;ll have sessions that only have events.\nThose sessions will be marred with the ugly (not set) Landing Page, because Google Analytics is tyrannical in demanding sessions to always include a pageview (I have no idea why).\nSo, in Google Tag Manager, you could do this by first creating a 1st Party Cookie variable for the session cookie. Remember to change the \u0026ldquo;UA-XXXXXX-Y\u0026rdquo; to whatever the tracking ID is for the property whose session timeout you are monitoring.\n  Then, create a new Custom Event trigger which checks if this cookie has the value true:\n  Now, any tag you add this trigger to as an exception will not fire if the session has timed out.\nThis is pretty brutal - you\u0026rsquo;re not sending event hits to GA because you\u0026rsquo;re afraid they\u0026rsquo;ll create orphaned sessions. It\u0026rsquo;s a valid fear to have with GA\u0026rsquo;s sessionization schema, but it might be overkill.\nSo another option is to turn all event hits into non-interactive hits, because these don\u0026rsquo;t increment the session counts or dimensions in your data set, but the data is still collected.\nTo do this, you need a Custom JavaScript variable that looks like this:\nfunction() { return {{UA-XXXXX-Y session}} !== \u0026#39;true\u0026#39;; }  This JavaScript returns false if the session is active, and true if there is no active session. By adding this to the Non-Interaction field in your Event tags, the hit will be non-interactive if there is no active session.\nYou could even modify the customTask to do this logic for you. Within the customTask method, just after try {, you could do something like this (you\u0026rsquo;ll need the 1st Party Cookie for this):\ntry { // ADD THIS  if ({{UA-XXXXX-Y session}} !== \u0026#39;true\u0026#39; \u0026amp;\u0026amp; sendHitTaskModel.get(\u0026#39;hitType\u0026#39;) === \u0026#39;event\u0026#39; \u0026amp;\u0026amp; sendHitTaskModel.get(\u0026#39;nonInteraction\u0026#39;) !== true) { return; } // UP TO HERE  originalSendHitTask(sendHitTaskModel); ... }  This addition prevents the hit from being fired (and the cookie from being created/updated) if the session is not alive and the hit is an interactive event. For all other hit types, the hit gets sent and the cookie gets created. This way you don\u0026rsquo;t need to mess with triggers - you can have customTask do all the legwork for you.\nSummary This customTask trick can be used to bring some insight into the browser whether or not a session is currently active in Google Analytics.\nIt\u0026rsquo;s not perfect, since sessionization depends on so many things (of which a multitude happens in the bowel\u0026rsquo;s of GA\u0026rsquo;s processing servers), but it can be used as an indication of whether or not there\u0026rsquo;s an active session.\nThis solution is also not necessary, especially if you use BigQuery. The raw data you collect from the site is useful and valid even if there\u0026rsquo;s no pageview initiating a session. So make sure you have a use case for this before taking the plunge.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/introducing-customtask-builder/",
	"title": "#GTMTips: Introducing The customTask Builder",
	"tags": ["google tag manager", "gtmtips", "customtask", "tools"],
	"description": "Introducing the customTask Builder tool, with which you can generate the JavaScript necessary to build a Google Analytics customTask script.",
	"content": " One of the coolest features of Google Analytics and, as a consequence, Google Tag Manager is customTask. It\u0026rsquo;s a method you can use to add and execute code as the hit to Google Analytics is being generated.\nI\u0026rsquo;ve written A LOT about customTask, and much of the feedback I\u0026rsquo;ve received has been around the question of how to combine all these different tricks into one customTask script. The problem is, you see, that a tag or hit can only have one customTask script attached to it, so the code within must combine all the different tricks I\u0026rsquo;ve been writing about over the past months.\nTo help with the pain of programming, I wrote a tool which you can find behind this link. Here\u0026rsquo;s a short introduction to it.\nTip 87: Introducing the customTask Builder Tool   The tool itself is fairly simple. You just select the customTask features you want to utilize in the script, and it then generates the JavaScript block that you\u0026rsquo;ll then need to edit to change the default values to something meaningful.\nAt this point, head on over to the customTask Builder Tool itself, and read the instructions within. Be sure to read my guide on customTask to understand what customTask is and why it may be useful to you.\nAnd keep checking the tool at regular intervals. I\u0026rsquo;ll be updating it as I come up with new ideas for the wonderful feature that customTask is.\n"
},
{
	"uri": "https://www.simoahava.com/tools/customtask-builder/",
	"title": "customTask Builder",
	"tags": [],
	"description": "",
	"content": " You can use the customTask Builder tool to create a customTask script. customTask is a method of the Google Analytics library, which lets you run JavaScript code when the hit request to Google Analytics is being built.\n Click here to jump directly to the tool.\n This is very useful for a number of reasons, and I recommend you read customTask - The Guide before doing anything with the tool.\nThe tool automatically builds the necessary JavaScript, avoiding any potential conflicts that the overlapping methods might introduce otherwise.\nWhen you add individual features to the script by selecting items in the table, you\u0026rsquo;ll see how the final script is modified accordingly.\nWhen you are satisfied with the result, select all the text within the white code box. You can also click the Copy to clipboard button to automatically copy the code to your clipboard.\nGeneral deployment instructions Upon adding individual items to the script, you\u0026rsquo;ll notice that the first lines of the script contain default values that you\u0026rsquo;ll need to modify. For example, when adding the Client ID as a Custom Dimension item, you\u0026rsquo;ll see these lines added to the code:\n// clientIdIndex: The Custom Dimension index to where you want to send the visitor\u0026#39;s Client ID. // https://bit.ly/2Ms0ZcC var clientIdIndex = 1;  The value 1 is just a default value - you\u0026rsquo;ll need to change this to the Custom Dimension index you have created in Google Analytics for this specific purpose.\nThus after copy-pasting the code into place, make sure you edit all the default values with the actual values you want to configure the items with. Otherwise you will run into severe data quality issues.\nDeployment with Google Tag Manager If you are using Google Tag Manager, you need to copy-paste the code into a Custom JavaScript variable, and modify the first line by removing the var _customTask = part like this:\n// OLD, CHANGE THIS: var _customTask = function() { // NEW, TO THIS: function() {  The second change you need to do is remove the semi-colon at the very end of the code block. In other words, remove the very last character of the entire code block, which should be a semi-colon ;.\nOnce you\u0026rsquo;re done modifying the default values, save the variable with the name {{customTask}} or something similar and descriptive.\nThen, in your Google Analytics Settings variable, go to Fields to set, and add a new field:\nField name: customTask\nValue: {{customTask}}\nIf you\u0026rsquo;re not using a Google Analytics Settings variable, you need to click Enable overriding settings in this tag in all the Google Analytics tags where you want to add this customTask as a field, and make the same change directly to the tag itself.\nDeployment with analytics.js With the regular (legacy) Universal Analytics library, you first need to make sure the variable is written into memory, so in the site JavaScript (or page template), make sure the code in the code box below is executed before any Google Analytics commands are run.\nThen, when you want to invoke this customTask in your trackers, find where you are creating the tracker and make the following change:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;); ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, _customTask()); // \u0026lt;-- Add this right after creating the tracker  ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;);  The customTask Builder tool    Click to select which feature(s) to include     Client ID as a Custom Dimension   Hit Type as a Custom Dimension   Payload Length as a Custom Dimension   Remove Custom Definitions from Page Speed Timing Hits   Copy Hits to Multiple Properties   Remove PII from Hits   Copy Hits to Snowplow Collector Endpoint   Update Session Cookie   Decorate Cross-domain Iframes    Copy to clipboard   div#customTaskWrapper { padding: 10px; border: 1px dotted; border-radius: 5px; background: #f7f7ff; } button#copy { border: 2px solid #ccc; background: #eee; font-size: 1em; margin-top: 10px; } pre#result { white-space: pre-wrap; font-size: 0.8em; padding: 5px; background: #fff; line-height: 1.5em; margin-top: 0px; border: 2px solid #ccc; } div#customTaskWrapper table { border-bottom: 2px solid #909ba2; margin-top: 0; } td[data-customtask-id] { cursor: pointer; } td[data-customtask-selected=\"true\"] { background: #d6ffc1 !important; }   (function() { var customTaskItems = document.querySelectorAll('[data-customtask-id]'); var copyBtn = document.querySelector('#copy'); var rowsInCode = { cid: [7,8,9,10,62,63,64,65,66,67], ht: [11,12,13,14,68,69,70,71,72,73], pl: [15,16,17,18,142,143,144,145,146,147,148,149,150], rcd: [19,20,21,22,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88], dh: [23,24,25,26,166,167,168,169,170,171,172,173,174,175,176], pr: [27,28,29,30,31,32,33,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141], sp: [34,35,36,37,153,154,155,156,157,158,159,160,161,162,163,164,165], sc: [38,39,40,41,42,43,44,177,178,179,180,181,182,183,184,185,186,187,188], id: [45,46,47,48,49,50,51,52,53,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113] }; var result = document.querySelector('#result'); var customTask = [ \"var _customTask = function() {\", \" // customTask Builder by Simo Ahava\", \" //\", \" // More information about customTask: https://www.simoahava.com/analytics/customtask-the-guide/\", \" //\", \" // Change the default values for the settings below.\", \"\", \" // clientIdIndex: The Custom Dimension index to where you want to send the visitor's Client ID.\", \" // https://bit.ly/2Ms0ZcC \", \" var clientIdIndex = 1;\", \"\", \" // hitTypeIndex: The Custom Dimension index to where you want to send the hit type of the request.\", \" // https://bit.ly/2KZqLA9\", \" var hitTypeIndex = 2;\", \"\", \" // payloadLengthIndex: The Custom Dimension index to where you want to send the length of the payload of the request.\", \" // https://bit.ly/2PdhPKM\", \" var payloadLengthIndex = 3;\", \"\", \" // removeCustomDefinitionsFromTimingHits: Set to true if you want to remove Custom Dimensions and Custom Metrics from the page speed timing hit.\", \" // https://bit.ly/2nGzw8T\", \" var removeCustomDefinitionsFromTimingHits = true;\", \"\", \" // duplicateHitToTrackingIds: Array of all Universal Analytics tracking IDs to where you want to duplicate the initial hit.\", \" // https://bit.ly/2MwFGGP\", \" var duplicateHitToTrackingIds = ['UA-12345-1'];\", \"\", \" // piiRegex: Array of {name, regex} objects, where the regular expression matches a pattern you want to replace with [REDACTED name].\", \" // https://bit.ly/2wcJym2\", \" var piiRegex = [{\", \" name: 'EMAIL',\", \" regex: /.{4}@.{4}/g\", \" }];\", \"\", \" // snowplowEndpoint: The Snowplow collector endpoint to which you want to send the GA request hit payload.\", \" // https://bit.ly/2OCBzXc\", \" var snowplowEndpoint = 'https://collector.simoahava.com/';\", \"\", \" // updateSessionCookie: Object which contains both an expiration time (in milliseconds) and domain name.\", \" // https://bit.ly/2wh1xsH\", \" var updateSessionCookie = {\", \" expiresMs: 1000*60*30,\", \" domain: 'mydomain.com'\", \" };\", \"\", \" // iframeDecorator: Configuration object for decorating any iframe with cross-domain parameters when this customTask is run.\", \" // https://bit.ly/2LUoWFf\", \" var iframeDecorator = {\", \" selector: 'iframe#decorateMe',\", \" attempts: 10,\", \" intervalMs: 1000,\", \" useAnchor: false\", \" };\", \"\", \" // DO NOT EDIT ANYTHING BELOW THIS LINE\", \" var globalSendHitTaskName = '_ga_originalSendHitTask';\", \"\", \" return function(customTaskModel) {\", \"\", \" window[globalSendHitTaskName] = window[globalSendHitTaskName] || customTaskModel.get('sendHitTask');\", \" var tempFieldObject, dimensionIndex, count, ga, tracker, decorateTimer, decorateIframe, iframe;\", \"\", \" // clientIdIndex\", \" if (typeof clientIdIndex === 'number') {\", \" customTaskModel.set('dimension' + clientIdIndex, customTaskModel.get('clientId'));\", \" }\", \" // /clientIdIndex\", \"\", \" // hitTypeIndex\", \" if (typeof hitTypeIndex === 'number') {\", \" customTaskModel.set('dimension' + hitTypeIndex, customTaskModel.get('hitType'));\", \" }\", \" // /hitTypeIndex\", \"\", \" // removeCustomDefinitionsFromTimingHits\", \" if (typeof removeCustomDefinitionsFromTimingHits === 'boolean' \u0026\u0026 removeCustomDefinitionsFromTimingHits === true) {\", \" if (customTaskModel.get('hitType') === 'timing') {\", \" tempFieldObject = {};\", \" dimensionIndex = 1;\", \" while (dimensionIndex !== 201) {\", \" tempFieldObject['dimension' + dimensionIndex] = undefined;\", \" tempFieldObject['metric' + dimensionIndex] = undefined;\", \" dimensionIndex++;\", \" }\", \" customTaskModel.set(tempFieldObject)\", \" }\", \" }\", \" // /removeCustomDefinitionsFromTimingHits\", \"\", \" // iframeDecorator\", \" if (typeof iframeDecorator === 'object' \u0026\u0026 typeof iframeDecorator.selector === 'string' \u0026\u0026 typeof iframeDecorator.attempts === 'number' \u0026\u0026 typeof iframeDecorator.intervalMs === 'number') {\", \" count = 0;\", \" ga = window[window['GoogleAnalyticsObject']];\", \" tracker = ga.getByName(customTaskModel.get('name'));\", \" decorateIframe = function() {\", \" iframe = document.querySelector(iframeDecorator.selector);\", \" if (iframe !== null \u0026\u0026 /[?\u0026]_ga=/.test(iframe.src)) {\", \" window.clearInterval(decorateTimer);\", \" return;\", \" }\", \" if (iframe === null) {\", \" count += 1;\", \" if (count === iframeDecorator.attempts) {\", \" window.clearInterval(decorateTimer);\", \" }\", \" return;\", \" }\", \" window.clearInterval(decorateTimer);\", \" iframe.src = (new window.gaplugins.Linker(tracker)).decorate(iframe.src, iframeDecorator.useAnchor);\", \" };\", \" decorateTimer = window.setInterval(decorateIframe, iframeDecorator.intervalMs);\", \" }\", \" // /iframeDecorator\", \"\", \" customTaskModel.set('sendHitTask', function(sendHitTaskModel) {\", \"\", \" var originalSendHitTaskModel = sendHitTaskModel,\", \" originalSendHitTask = window[globalSendHitTaskName];\", \"\", \" var hitPayload, hitPayloadParts, param, val, regexI, trackingId, snowplowVendor, snowplowVersion, snowplowPath, request, originalTrackingId, hitType, nonInteraction, d;\", \"\", \" try {\", \" // piiRegex\", \" if (typeof piiRegex !== 'undefined' \u0026\u0026 piiRegex.length) {\", \" hitPayloadParts = sendHitTaskModel.get('hitPayload').split('\u0026');\", \" for (regexI = 0; regexI  Summary I hope you find this tool useful. I will try to update it as I come up with new customTask ideas, which seems to be quite often.\nPlease let me know in the comments if you are having trouble using the tool, or if you have new customTask ideas in mind you\u0026rsquo;d want to include in the tool.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/decorate-links-decorate-forms-tags/",
	"title": "#GTMTips: Decorate Links And Decorate Forms Tag Types",
	"tags": ["google tag manager", "cross-domain tracking", "gtmtips"],
	"description": "Use the Decorate Forms and Decorate Links tag types to cross-domain track only specific link clicks and form submits from your site.",
	"content": " Getting cross-domain tracking right in Google Analytics is difficult. Even if you use Google Tag Manager. There are many known issues when cross-domain tracking iframes, for example.\nGoogle Tag Manager implements the cross-domain tracking plugin quite handily via the Universal Analytics tag template, and often the easiest way to track links and form submits is to use the Auto-Link Domains option, as described in this great series of posts on cross-domain tracking by LunaMetrics.\nHowever, sometimes you want more precision in decorating the URLs. Perhaps you only want to decorate one specific link rather than all links that share the same hostname. Or perhaps you only want to decorate forms when they are submitted by your actual visitors rather than internal users.\nThis is where the quite rare Decorate Links and Decorate Forms Universal Analytics tag types come in handy.\nTip 86: Decorate Links and Decorate Forms tags   The principle is very simple. If you set the Decorate Links tag to fire with a Just Links trigger, then any link click that causes that trigger to go off will be decorated by the tag. Similarly, if you set the Decorate Forms tag to fire with a Form trigger, then any form submit that toggles that trigger will have its destination URL decorated by the tag.\n  For example, if you create a Just Links trigger with the following condition:\nClick URL matches RegEx shop\\.domain\\.com/cart/\nThen any click on a link whose href contains shop.domain.com/cart/ will be decorated with cross-domain parameters. However, unlike the Auto-Link Domains plugin, no other link to shop.domain.com will be decorated.\nThis can be very useful if you want full control over when Client ID information is passed from domain to domain.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/two-simple-data-model-tricks/",
	"title": "#GTMTips: Two Simple Data Model Tricks",
	"tags": ["google tag manager", "gtmtips", "data model"],
	"description": "Two simple tricks to derive powerful functionality from Google Tag Manager&#39;s data model.",
	"content": " One of the more difficult concepts in Google Tag Manager is the data model. In essence, the data model is what Google Tag Manager uses to populate the Data Layer variable. You might be tempted to think that it\u0026rsquo;s the same thing as the dataLayer array, but it\u0026rsquo;s not.\nThe data model is a representation of the keys and values you push into dataLayer. Whenever you push any key into dataLayer, GTM grabs this key and updates the corresponding key in its data model with the new value, or in the case of objects and arrays merges the old and the new value together.\nIn this #GTMTips article, I\u0026rsquo;m completely indebted to Mr. Jethro Nederhof from Snowflake Analytics. He published these two tricks in Measure Slack, and I asked if he\u0026rsquo;s OK that I publish them on my blog. He kindly agreed, which is not suprising, since his generosity also spawned our co-authored article on tracking browsing behavior a few months back.\nTip 85: Two simple data model tricks   Both tips have to do with how the data model processes keys and values pushed into it.\nThe first trick lets you prevent recursive merge from happening (useful on single-page apps where you don\u0026rsquo;t want to persist values pushed in earlier pages, for example).\nThe second trick lets you access what the current state of the data model is. This can be useful for a number of things, but especially if you\u0026rsquo;re debugging your setup it might be useful to see all they keys and values that are currently located in the data model\u0026rsquo;s table.\nTrick 1: Use _clear: true to prevent merging of the keys in the object Let\u0026rsquo;s say you are pushing some product impressions into the dataLayer. The first push looks like this:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ products: [{ sku: \u0026#39;123\u0026#39;, name: \u0026#39;Thick as a Brick\u0026#39; },{ sku: \u0026#39;234\u0026#39;, name: \u0026#39;Aqualung\u0026#39; }] });  At this point, the key products in the data model would have two objects representing the products that were pushed. If you were to create a Data Layer variable for products, that\u0026rsquo;s what you\u0026rsquo;d also get as the return value of the variable.\nThen let\u0026rsquo;s say the user moves to another section of the site without a page load (so it\u0026rsquo;s a single-page app), and on that page there\u0026rsquo;s just one product impression, so the site runs the following code:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ products: [{ sku: \u0026#39;345\u0026#39;, name: \u0026#39;Close to the Edge\u0026#39; }] });  You\u0026rsquo;d expect the data model to now have just one product in the products array, but due to how recursive merge works, the data model looks like this:\n{ products: [{ sku: \u0026#39;345\u0026#39;, name: \u0026#39;Close to the Edge\u0026#39; },{ sku: \u0026#39;234\u0026#39;, name: \u0026#39;Aqualung\u0026#39; }] }  As you can see, the second product of the first push persists, because the new product was simply merged with the old products array.\nAnd here\u0026rsquo;s the tip. To prevent this recursive merge from happening, you need to push the key _clear with the value true in the same object where you push the keys you don\u0026rsquo;t want to merge with their counterparts. So the second push becomes:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ products: [{ sku: \u0026#39;345\u0026#39;, name: \u0026#39;Close to the Edge\u0026#39; }], _clear: true });  So now the key in the products array of the data model only has one object within.\nTrick 2: Get the object representation of the current state of the data model You can always use window.google_tag_manager['GTM-XXXXX'].dataLayer.get(key) to fetch the current value of the given key from the data model. But if you want to get the full contents of the current data model, you need to run the following command:\nvar dataModel = window.google_tag_manager[\u0026#39;GTM-XXXXX\u0026#39;].dataLayer.get({ split: function() { return []; } }); console.table(dataModel);  If you run the command above in the JavaScript console of your browser, you should see a nice table view of the current data model:\n  What a simple way to see what the current state is.\nSummary I\u0026rsquo;ll be the first to admit: these are very technical, niche tricks. You probably won\u0026rsquo;t need them daily, or even monthly, in your implementations.\nHowever, I firmly believe that understanding how the data model works is one of the keys to unlocking Google Tag Manager\u0026rsquo;s real power.\nAnd, again, a huge thanks to Jethro Nederhof for revealing these simple tricks. He gets full credit for the substance of this article.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/get-position-index-of-visible-element/",
	"title": "#GTMTips: Get Position Index Of Visible Element",
	"tags": ["google tag manager", "gtmtips", "element visibility"],
	"description": "Use a Custom JavaScript variable in Google Tag Manager to get the position of the element that became visible, when using the Element Visibility trigger.",
	"content": " It\u0026rsquo;s time for a very simple #GTMTips article (I know, I always write that these are simple tips, but then they escalate into complex behemoths). Today, we\u0026rsquo;ll cover a nifty trick you can use with the Element Visibility trigger in Google Tag Manager. This tip was inspired by a question from Eugen Potlog in the Google Tag Manager Facebook group.\nThe use case is that you have an Element Visibility trigger firing for a number of elements all sharing the same CSS selector. In the image below, I want the visibility trigger to fire when any \u0026lt;h2\u0026gt; header element becomes visibile on the screen. However, I also want to know which one of all those headers caused the trigger to fire. In other words, I want the position of the header; If it\u0026rsquo;s the 5th header from the top, I want to get the number 5 to use in my tags. If it\u0026rsquo;s the first header, I want it to return 1.\nThis is quite easy to do with a Custom JavaScript variable, and below I\u0026rsquo;ll show you how.\nTip 84: Get the position index of the visible element   Here\u0026rsquo;s what the Custom JavaScript variable should look like:\nfunction() { var list = document.querySelectorAll(\u0026#39;h2\u0026#39;), // Make sure this CSS selector matches the one in the trigger  el = {{Click Element}}; return [].indexOf.call(list, el) + 1; }  This makes use of something you might not have thought of before, namely the fact that the built-in variable {{Click Element}} returns the element that caused the Element Visibility trigger to fire. It\u0026rsquo;s a multi-purpose variable in that sense.\nThe script first creates a list of all the possible elements the Element Visibility trigger can fire for, so it\u0026rsquo;s important that the selector argument of document.querySelectorAll(selector) matches the one you use in the Element Visibility trigger. Once the list is created, indexOf() is used against a native array object (because the list returned by querySelectorAll doesn\u0026rsquo;t have the .indexOf() method), and it checks if the list contains the element that fired the trigger.\nIf the list does contain it, the element\u0026rsquo;s position is returned as a positive integer, so the first element on the page would be 1, the second would be 2 and so on. If the element does not match against the list of elements in the variable list, position 0 is returned. This means you have misconfigured the selector(s).\nThis was a simple tip, undoubtedly, but I hope it\u0026rsquo;s useful to some of you!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/tag-sequencing-custom-html-tags/",
	"title": "#GTMTips: Tag Sequencing With Custom HTML Tags",
	"tags": ["google tag manager", "gtmtips", "tag sequencing", "custom html"],
	"description": "This guide shows you how to set up tag sequencing with Custom HTML tags when using Google Tag Manager.",
	"content": " Tag sequencing was introdced to Google Tag Manager in late 2015. Its main purpose was to facilitate the sequential firing of tags that have dependencies with each other. Due to the asynchronous nature of third-party libraries like Google Tag Manager, it\u0026rsquo;s difficult to establish an order of completion with tags that compete for their chance to fire.\nTag sequencing changed this, as it allows you to establish setup and cleanup tags - the former firing before the main tag, and the latter after.\nSetting up tag sequencing is relatively easy, at least once you understand how it works. However, Custom HTML tags have some exceptional behavior, as you need to utilize certain specific commands to signal the sequence once the Custom HTML tag has completed its execution. This #GTMTips article aims to guide you with setting up Custom HTML tags in a tag sequence.\nTip 83: Setting up Custom HTML tags in a tag sequence   Lesson 1: Sequence is managed with the success and failure callbacks The two callbacks, onHtmlSuccess() and onHtmlFailure() are what tag sequencing with Custom HTML tags really pivots around. The first is used to denote a place in the code when the code has finished running successfully, and execution can move to the next tag in the sequence. The second is used to signal when a failure happens, and here execution is also passed to the next tag in the sequence unless it has the failure toggle on:\n  Just to recap (but be sure to read my guide for a more thorough treatment), here\u0026rsquo;s how you would set up a regular Custom HTML tag in a tag sequence, where both success and failure criteria are established.\n NOTE! Remember to enable the Container ID and HTML ID built-in variables for this.\n (function() { var gtm = window.google_tag_manager[{{Container ID}}]; // Required \twindow[\u0026#39;something\u0026#39;] = getSomethingElse(); if (typeof window[\u0026#39;something\u0026#39;] !== \u0026#39;undefined\u0026#39;) { gtm.onHtmlSuccess({{HTML ID}}); // Success, move to next tag  } else { gtm.onHtmlFailure({{HTML ID}}); // Failure, move to next tag unless it has failure toggle on  } })();  Lesson 2: The success and failure callbacks aren\u0026rsquo;t always necessary Here\u0026rsquo;s something I think most guides have missed: you don\u0026rsquo;t need onHtmlSuccess() and onHtmlFailure() in your Custom HTML tag! The web browser executes all the code it finds in a Custom HTML tag from top-to-bottom before moving to the next item in the sequence.\nFor example, if you\u0026rsquo;ve setup the Facebook pixel with Custom HTML tags, you don\u0026rsquo;t need onHtmlSuccess() in the base pixel tag.\n!function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function(){n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)};if(!f._fbq)f._fbq=n; n.push=n;n.loaded=!0;n.version=\u0026#39;2.0\u0026#39;;n.queue=[];t=b.createElement(e);t.async=!0; t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window, document,\u0026#39;script\u0026#39;,\u0026#39;https://connect.facebook.net/en_US/fbevents.js\u0026#39;); fbq(\u0026#39;init\u0026#39;, {{Facebook Pixel ID}}); // The following line is NOT necessary: // window.google_tag_manager[{{Container ID}}].onHtmlSuccess({{HTML ID}});  Why is the last line not necessary? Because GTM would pass execution to the next tag in any case when it reaches the last line of this tag. The web browser runs code synchronously - there\u0026rsquo;s no way it will stop in the middle of this tag and start working on the next tag.\nSo the lesson is:\nIf you have code that is always run from top-to-bottom before moving to the next tag, you don\u0026rsquo;t need onHtmlSuccess() and onHtmlFailure().\nBut, and there\u0026rsquo;s always a \u0026ldquo;but\u0026rdquo;, you\u0026rsquo;ll want to check the next lesson, too.\nLesson 3: If you have onHtmlFailure(), you\u0026rsquo;ll always want to have onHtmlSuccess(), too If you use onHtmlFailure() to signal that at some point in the code an error is met and sequence should not proceed with the next tag (since you have the failure toggle on), you should also add onHtmlSuccess() somewhere in the code.\nThis is because when you use the failure callback, GTM will not automatically proceed to the next tag anymore when it reaches the last line of the Custom HTML tag, even if you have the failure toggle turned off. By using onHtmlFailure(), you are telling Google Tag Manager to wait for either the onHtmlFailure() or onHtmlSuccess() before deciding whether to move to the next tag.\n(function() { var gtm = window.google_tag_manager[{{Container ID}}]; if (true) { console.log(\u0026#39;Worked!\u0026#39;); } else { gtm.onHtmlFailure({{HTML ID}}); } })();  In the above example, sequence will never proceed to the next tag. You have onHtmlFailure() which is never met (because true is always true), but you don\u0026rsquo;t have onHtmlSuccess() anywhere. So only this first tag is run, and the sequence is never continued.\nThis is one way it would work:\nif (true) { console.log(\u0026#39;Worked\u0026#39;); gtm.onHtmlSuccess({{HTML ID}}); } else { gtm.onHtmlFailure({{HTML ID}}); }  This would also work (though it\u0026rsquo;s not a good pattern), if the next tag in the sequence had the failure toggle off:\nif (true) { console.log(\u0026#39;Worked\u0026#39;); gtm.onHtmlFailure({{HTML ID}}); } else { gtm.onHtmlFailure({{HTML ID}}); }  And since it\u0026rsquo;s synchronous code, you can leave both callbacks out, and the sequence will proceed normally after logging Worked to the console in this case, too:\n(function() { if (true) { console.log(\u0026#39;Worked\u0026#39;); } })();  Lesson 4: The callbacks are at their best in asynchronous operations In my view, the purpose of tag sequencing is to establish order when the previous tag has an asynchronous operation. In other words, you want the browser to wait for the operation to complete before telling the next tag to start firing.\nFor example, here we load the jQuery library asynchronously, waiting for it to have completely loaded before moving to the next tag:\n(function() { var gtm = window.google_tag_manager[{{Container ID}}]; var el = document.createElement(\u0026#39;script\u0026#39;); el.async = true; el.src = \u0026#39;https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\u0026#39;; el.addEventListener(\u0026#39;load\u0026#39;, function() { gtm.onHtmlSuccess({{HTML ID}}); }); document.head.appendChild(el); })();  As you can see, onHtmlSuccess() is embedded in the callback of the load listener, which is invoked only after the library has downloaded and the browser has executed the code within.\nSummary Working with Custom HTML tags in a tag sequence has some gotchas you should be aware of, but there\u0026rsquo;s really very little game-breaking. The biggest \u0026ldquo;mistake\u0026rdquo; I see people doing is adding the onHtmlSuccess() callback to the end of a synchronously executed block of code - this is not necessary unless you have onHtmlFailure() somewhere in the code, too.\nI hope that this article has clarified how Custom HTML tags and tag sequencing work together.\nLet me know in the comments if you have futher questions!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/fire-trigger-when-user-about-to-leave-page/",
	"title": "#GTMTips: Fire Trigger When User Is About To Leave The Page",
	"tags": ["google tag manager", "gtmtips", "beforeunload"],
	"description": "Use the &#39;beforeunload&#39; browser event to fire a Google Tag Manager trigger (and tag) when the user is about to leave the page.",
	"content": " One of the great ways to leverage Google Tag Manager in your web analytics tracking is to make use of all the possible custom events that the browser has to offer. One such event is beforeunload. It\u0026rsquo;s dispatched in the browser when the user is about to unload the page. This means, typically, that the user is about to leave the page after clicking a link, or they are about to exit the browser by either closing the tab or the entire window.\nWe can use this event for many things, but in this article I\u0026rsquo;ll show you how to setup the listener, and then use it to send an event to Google Analytics which contains the deepest scroll depth threshold the user crossed on the page. So if they scrolled all the way to 75% of the document, this event would send that threshold to Google Analytics. Why? Because sometimes we simply want to know the farthest the user scrolled to any given page, rather than all the thresholds they crossed on the way there.\nTip 82: Fire a trigger on the beforeunload event   First of all, let\u0026rsquo;s create the event listener for beforeunload, so that the impatient readers can go right ahead and start working on their own solutions around this trigger.\n One important thing to note is that if you use a beforeunload listener, you invalidate the Back-Forward Cache of some browsers (e.g. Firefox). On some websites this might break user experience, so be sure to consult with your developers before implementing this, particularly on pages with forms.\n The tag is a simple Custom HTML tag that fires on the All Pages trigger. Feel free to use a more restrictive trigger, if you want the listener to be active only on specific pages.\nHere are the contents:\n\u0026lt;script\u0026gt; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { window.dataLayer.push({ event: \u0026#39;beforeunload\u0026#39; }); }); \u0026lt;/script\u0026gt; All this tag does is create the listener. The listener has a callback which pushes the beforeunload custom event into dataLayer.\nNow if you go to Preview mode, by clicking a link away from any page, you should just see the beforeunload text appear in the Preview mode event list before you are whisked away. If you see it, it means the listener works.\n  Next thing to do is to create a Custom Event trigger with the following settings:\n  If you add this trigger to a tag, that tag will fire just when the user is about to leave the page.\nSet the transport field in Google Analytics tags Because the trigger fires on the threshold of unloading the page, there is a very real risk that the page is unloaded before the asynchronous request initiated by the tag (firing on the trigger) has time to complete. To let your requests complete in time, you can use the Beacon API - another cool browser feature that\u0026rsquo;s almost essential to web analytics tracking.\nThankfully, if you are using Google Analytics tags, you don\u0026rsquo;t need to build the beacon utility yourself. The Universal Analytics library, analytics.js, has a special field called transport, which you can set to the value beacon in case you want to leverate the Beacon API with your Google Analytics hits.\nTo add this field, either use a Google Analytics Settings variable, or override the settings of your tag. Scroll down to Fields to set, and add a new field:\nField name: transport\nValue: beacon\nWith this setting, the tag now utilizes the Beacon API to dispatch the asynchronous request even if the browser has unloaded the page. The cool thing about this implementation is that if the browser doesn\u0026rsquo;t support this API, the tag automatically falls back to either GET or POST, just like it would normally do.\nOne \u0026ldquo;side effect\u0026rdquo; of using the Beacon API is that the request is automatically turned into a POST request. This means that if you\u0026rsquo;re using the Network tab of your browser\u0026rsquo;s developer tools, the request parameters won\u0026rsquo;t be outlined as nicely as they would with a GET request. For this reason, I strongly recommend you use the Google Analytics Debugger to analyze the requests.\nSend the deepest Scroll Depth threshold To send the deepest (or farthest) the user has scrolled on any given page, you need the following components.\nA Scroll Depth trigger with the thresholds configured\n  Note that you do not need to add this trigger to any tag. Its sole purpose is to push the threshold values into dataLayer.\nA Google Analytics tag which fires on the beforeunload trigger\nThe tag needs to fire on the beforeunload trigger, and it needs to send the value of the {{Scroll Depth Threshold}} Built-in variable to Google Analytics. Don\u0026rsquo;t forget to add the transport field there, too!\n  Again, feel free to add trigger exceptions or to modify the Custom Event trigger to restrict this tag to fire only on relevant pages. It doesn\u0026rsquo;t make sense to collect scrolling data on pages where that information is not relevant.\nSummary Once you\u0026rsquo;ve created the Custom HTML tag for the listener, the Custom Event trigger, the Scroll Depth trigger, and the Google Analytics tag, you\u0026rsquo;re good to go. When the user is about to leave any page, the beforeunload event triggers your Google Analytics tag. This tag grabs the latest value from {{Scroll Depth Threshold}} and sends it with the event to GA.\nSo if the user scrolled all the way down to 70% of the page (if you\u0026rsquo;ve set it up as a vertical threshold in the trigger settings), the value 70 would get sent with the tag.\nThis way you\u0026rsquo;ll preserve your hit quota (remember there\u0026rsquo;s a 500 hits per session limit in Google Analytics), and you\u0026rsquo;ll avoid sending a lot of noisy information about the intermediate thresholds to Google Analytics.\nThe scroll depth trick was just a tangent, though. The beforeunload listener can be used for a million different things, such as form abandonment and content engagement tracking.\nDo you have other cool uses for the beforeunload listener? Let us know in the comments!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-content-security-policy/",
	"title": "#GTMTips: Google Tag Manager Content Security Policy",
	"tags": ["google tag manager", "content security policy", "csp"],
	"description": "Configure the Content Security Policy (CSP) so that Google Tag Manager works on your website.",
	"content": " A Content Security Policy (CSP) is something you\u0026rsquo;ll configure your web server with to add an additional layer of protection, especially from harmful scripts loaded from third-party vendors. Once you have a CSP in place, all resources loaded and executed by the web page need to pass the CSP directives. For Google Tag Manager, this is very relevant. If you have a CSP in place, you will need to modify it so that Google Tag Manager functions properly.\nIn this short article, I\u0026rsquo;ll show you what directives you\u0026rsquo;ll need in place for GTM to work. In addition to the instructions here, I want you to read the excellent LunaMetrics article on the same topic. It isn\u0026rsquo;t comprehensive enough when it comes to GTM (which is why I wrote this article), but it has more information on CSPs in general, and it has instructions on how to get your tags to comply with the CSP as well.\nTip 81: Google Tag Manager Content Security Policy   First, here are a number of symptoms to look for, which might help you detect that you have a CSP issue:\n No debug panel shown even if you are in Preview mode.\n Debug panel shows, but it has no styles (see the image above).\n Google Tag Manager doesn\u0026rsquo;t load, and you see a Content Security Policy error in the JavaScript console.\n    Google Tag Manager requires you to allow a number of things: inline scripts, inline eval() use, and inline styles. Listed below are the modifications you need to make in the Content Security Policy, so that Google Tag Manager works properly both in published containers and in Preview mode.\n Thanks to Wieland Lindenthal for the feedback that helped make the directives below more precise.\n    Directive Comment     script-src 'unsafe-eval' 'unsafe-inline' https://tagmanager.google.com/ https://www.googletagmanager.com/ You need to enable the two listed domains in script-src together with the 'unsafe-inline' and 'unsafe-eval' sources. GTM requires both inline script and eval() to run custom code added by users.   style-src 'unsafe-inline' https://tagmanager.google.com/ https://fonts.googleapis.com/ This directive enables the styles and custom fonts in the GTM debug panel.   img-src 'unsafe-inline' https://ssl.gstatic.com/ This directive loads the Google Tag Manager logo image in debug mode.    The first directive is absolutely necessary, the last two directives are useful but not critical. However, I do recommend including the style-src directive, since it\u0026rsquo;s a pain to work in debug mode without the stylesheet.\nSummary These simple instructions should help you fix your site\u0026rsquo;s CSP so that Google Tag Manager works properly.\nI know you might be wary of adding all these directives, especially since they might introduce issues into your site by being so relaxed. However, Google Tag Manager is a script injector, so it does require elevated privileges to work properly on your site. It\u0026rsquo;s part of the bargain when using a tag management solution.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/automatically-reduce-google-analytics-payload-length/",
	"title": "Automatically Reduce Google Analytics Payload Length",
	"tags": ["google tag manager", "customtask", "google analytics"],
	"description": "Use customTask to automatically reduce the Google Analytics payload length, so that it stays below the maximum of 8192. This is very useful for Enhanced Ecommerce tracking, where payload sizes might grow to be very large.",
	"content": " Here we are, reunited with customTask. This time, we\u0026rsquo;ll put this wonderful mechanism to work for a very, very good cause. One of the lesser known \u0026ldquo;features\u0026rdquo; of Google Analytics is that when the payload size (the request body that is actually sent to Google Analytics with each request) goes past a certain limit, specifically 8192 bytes, the hit is aborted without warning. This can come as a surprise, because there\u0026rsquo;s no indication anywhere in Google Analytics that you are missing hits because of this.\nThe solution? A nice little customTask script, which recursively whittles away parts of the payload until the length is just below the cap.\n  The idea is that you will be able to specify a list of payload parameters to be removed one by one from the payload until the size is safely below the maximum of 8192. First things that will go are some of the default dimensions that no one really uses, such as \u0026lsquo;Java Enabled\u0026rsquo; and \u0026lsquo;Document Encoding\u0026rsquo;. Next, you can list all the Custom Dimensions you want to get rid of, in order of priority.\nFinally, you\u0026rsquo;ll be able to list the Enhanced Ecommerce impression parameters that you want to remove from each impression in the payload. The script will stop as soon as the length is below 8192, so you\u0026rsquo;ll most likely end up with some impressions having more details than others.\nWhy stop at impressions? Because, from experience, that\u0026rsquo;s where most problems lie. It shouldn\u0026rsquo;t be too difficult to customize the script to also include Promotions and even \u0026ldquo;regular\u0026rdquo; Enhanced Ecommerce product objects.\nOnce you\u0026rsquo;ve implemented this in your Enhanced Ecommerce tags, you should never see the following error in the console (if you have Google Analytics Debugger activated, or if you have Universal Analytics running in debug mode):\n  I recommend implementing this customTask together with my solution for sending the payload length as a custom dimension. This way you\u0026rsquo;ll be able to detect if you\u0026rsquo;re approaching the maximum length of the payload with your hits, and you can then proceed to implement this payload length limiter when necessary.\nFor an alternative solution, take a look at this excellent article by the awesome Dan Wilkerson from the equally awesome LunaMetrics blog.\nThe customTask variable To build the customTask, you need to create a new Custom JavaScript variable. Name it something like {{customTask - reduce payload length}}.\n Note! If you already have a customTask implemented in your Enhanced Ecommerce tags, you\u0026rsquo;ll need to combine the code below with the existing customTask script you already have. For tips on how to do this, consult this guide.\n Add the following code into the customTask variable body:\nfunction() { return function(customModel) { // Add any other default parameters you want to strip from the payload  // into this array in order of priority.  // For more details, visit: https://bit.ly/2MOhjBD  var defaultParams = [\u0026#39;\u0026amp;je\u0026#39;, \u0026#39;\u0026amp;de\u0026#39;, \u0026#39;\u0026amp;sd\u0026#39;, \u0026#39;\u0026amp;vp\u0026#39;, \u0026#39;\u0026amp;sr\u0026#39;]; // List the (regular) Custom Dimensions you want to strip from the  // payload in order of priority. Leave the array empty if you don\u0026#39;t  // want to remove Custom Dimensions.  // For more details, visit: https://bit.ly/2MM6O1O  var customDims = [\u0026#39;\u0026amp;cd198\u0026#39;, \u0026#39;\u0026amp;cd199\u0026#39;, \u0026#39;\u0026amp;cd200\u0026#39;]; // List the impression object parameters you want to strip from the  // payload in order of priority. Only list the field specifier, so  // instead of \u0026#39;\u0026amp;il1pi2va\u0026#39;, write \u0026#39;va\u0026#39;, and instead of \u0026#39;\u0026amp;il1pi4cd3\u0026#39;, write  // \u0026#39;cd3\u0026#39;. For more details, visit: https://bit.ly/2KehCHF  var impressions = [\u0026#39;va\u0026#39;, \u0026#39;br\u0026#39;, \u0026#39;ca\u0026#39;, \u0026#39;ps\u0026#39;, \u0026#39;nm\u0026#39;]; // Don\u0026#39;t touch the code below.  var maxLength = 8192, globalSendTaskName = \u0026#39;_\u0026#39; + customModel.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;, originalSendHitTask = window[globalSendTaskName] = window[globalSendTaskName] || customModel.get(\u0026#39;sendHitTask\u0026#39;); customModel.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; // Only log if in analytics debug mode.  var log = function(msg) { if (\u0026#39;dump\u0026#39; in ga) { window.console.log.apply(window.console, [msg]); } }; var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var removeKeys = function(hitPayload, keys) { var key, regex; while(hitPayload.length \u0026gt;= maxLength \u0026amp;\u0026amp; keys.length) { key = keys[0]; log(\u0026#39;--\u0026gt; Removing \u0026#39; + key); regex = new RegExp(key + \u0026#39;=[^\u0026amp;]+\u0026#39;, \u0026#39;gi\u0026#39;); keys.shift(); hitPayload = hitPayload.replace(regex, \u0026#39;\u0026#39;); log(\u0026#39;--\u0026gt; New length: \u0026#39; + hitPayload.length); } return hitPayload; }; var removeImpressions = function(hitPayload, keys) { var key, regex, oldKey; while(hitPayload.length \u0026gt;= maxLength \u0026amp;\u0026amp; keys.length) { if (key !== keys[0]) { key = keys[0]; log(\u0026#39;--\u0026gt; Removing \u0026amp;ilNpiN\u0026#39; + key + \u0026#39; from impression objects\u0026#39;); } regex = new RegExp(\u0026#39;\u0026amp;il\\\\d+pi\\\\d+\u0026#39; + key + \u0026#39;=[^\u0026amp;]+\u0026#39;, \u0026#39;i\u0026#39;); if (!regex.test(hitPayload)) { keys.shift(); } hitPayload = hitPayload.replace(regex, \u0026#39;\u0026#39;); } log(\u0026#39;--\u0026gt; New length: \u0026#39; + hitPayload.length); return hitPayload; }; // If over payload length, remove default parameters.  if (hitPayload.length \u0026gt;= maxLength) { log(\u0026#39;Payload too long (\u0026#39; + hitPayload.length + \u0026#39;), removing default keys...\u0026#39;); hitPayload = removeKeys(hitPayload, defaultParams); } // If over payload length, remove custom dimensions.  if (hitPayload.length \u0026gt;= maxLength) { log(\u0026#39;Payload still too long (\u0026#39; + hitPayload.length + \u0026#39;), removing Custom Dimensions...\u0026#39;); hitPayload = removeKeys(hitPayload, customDims); } // If over payload length, clean up impression objects.  if (hitPayload.length \u0026gt;= maxLength) { log(\u0026#39;Payload still too long (\u0026#39; + hitPayload.length + \u0026#39;), cleaning up Impressions...\u0026#39;); hitPayload = removeImpressions(hitPayload, impressions); } // Send the modified payload.  sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload, true); originalSendHitTask(sendModel); }); }; }  Make sure you edit the defaultParams, customDims, and impressions arrays to include the keys you want to purge from the dataLayer. Note that you will need to list the keys using their Measurement Protocol parameter names rather than what their analytics.js field names are. So instead of 'encoding', for example, you need to use '\u0026amp;de'.\nThe keys I have added to the defaultParams array are:\n   Key Name Description     \u0026amp;je Java Enabled Whether the browser has enabled Java or not.   \u0026amp;de Document Encoding What the character encoding of the current page is (e.g. UTF-8).   \u0026amp;sd Screen Colors The screen color depth (e.g. 24-bits).   \u0026amp;vp Viewport Size The viewable area (in pixels) of the browser or device.   \u0026amp;sr Screen Resolution The screen resolution (in pixels) of the browser or device.    Naturally, you might want to preserve some of these, e.g. \u0026amp;vp or \u0026amp;sr. Feel free to edit the defaultParams array as you see fit.\nWhen adding items to the impressions array, the syntax is slightly more complex. You should only add the actual parameter specifier, which is the key that comes after \u0026amp;ilNpiN. So if the parameter name for Product Impression Variant is \u0026amp;il2pi1va, you\u0026rsquo;d type just 'va' into the array. Or, if you wanted to purge the Product-Scoped Custom Dimension from index 3 from your impression objects, instead of typing '\u0026amp;il1pi1cd3', you\u0026rsquo;d type 'cd3 into the array.\nNote that for defaultParams and customDims you need to type the full parameter name with the leading \u0026amp;.\nAdd the variable to your tag This variable should be added to the tag which sends the Enhanced Ecommerce payload with impression objects to Google Analytics. To add it to the tag, either edit the Google Analytics Settings variable in the impression tag, or add the field directly to the tag.\nBrowse to More Settings -\u0026gt; Fields to set, and add the following field:\nField name: customTask\nValue: {{customTask - reduce payload length}}\nLike so:\n  And that\u0026rsquo;s it for the setup! Now, if your payload is over 8192, the script will first chop out the parameters specified in the defaultParams array. Then it will gobble up the dimensions in the customDims array. Finally, if the payload is STILL too long, it will proceed to clean up your impressions objects by removing the fields listed in impressions one by one, impression by impression.\nHow to debug If you walked through the code, as I\u0026rsquo;m sure you did, you might have noticed how I use a custom method named log() to send some debug data to the console. The thing is, I don\u0026rsquo;t want to pollute the JavaScript console with debug messages when Google Analytics is not in debug mode, so I do a simple check to see if the debug version of analytics.js is loaded:\nif (\u0026#39;dump\u0026#39; in window[\u0026#39;ga\u0026#39;]) {}  Basically, if the global ga object has the method dump, I\u0026rsquo;m assuming the user is using the debug version of analytics.js.\n NOTE! If someone has figured a more robust way to check for the debug version of analytics.js, please let me know! Thank you.\n So, if you want to see debug messages, you can set the library to debug mode by browsing to More Settings -\u0026gt; Advanced Configuration -\u0026gt; Use Debug Version in your Google Analytics tag or Google Analytics Settings variable, and setting it to true. Or, you can use the Google Analytics Debugger browser extension.\nOnce you have the debug library loaded, you can see debug messages such as these if the payload exceeds the maximum length of 8192:\n  In these debug messages you can see how the script walks through your payload, stripping out parameters where necessary.\nSummary I wish analytics.js had a more elegant way of handling payloads that are too large. Just dropping them is slightly overkill, in my opinion. analytics.js could, for example, compile a custom hit to GA when the payload maximum size is breached, and this would turn into a warning or notification in the Google Analytics UI. This way you\u0026rsquo;d at least have a clue that something is amiss.\nSo the customTask solution presented here is, as is typical for scripts that I write, a bandaid for something that will hopefully be remedied natively by the library itself in the future.\nNaturally, the \u0026ldquo;best\u0026rdquo; way to avoid payloads that are too large is to only send relevant data to Google Analytics. In the case of impressions, for example, it doesn\u0026rsquo;t really make sense to send every single impression on the page in one hit. Rather, you\u0026rsquo;d want to only send impressions that the user has actually viewed. Luckily, I might just have a guide coming up that will show you how to track viewed impressions only.\nLet me know in the comments if you find this useful or if you have suggestions for improving the method!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/allow-block-advertising-features-google-analytics/",
	"title": "Allow And Block Advertising Features In Google Analytics",
	"tags": ["google tag manager", "google analytics", "gdpr"],
	"description": "Use the new allowAdFeatures field in Universal Analytics and Google Tag Manager to either allow or block the DoubleClick request. This request is initiated with the Advertising Features setting.",
	"content": " After writing yet another customTask article on how to respect client-side opt-out using Google Analytics and Google Tag Manager, the analytics.js core library was enhanced with a new field that makes it all a lot easier to do. The field, allowAdFeatures, lets you either allow or block the request to DoubleClick that is initiated when Advertising Features have been enabled.\nIn this very short article, I\u0026rsquo;ll quickly show you what the field does and why it\u0026rsquo;s useful.\nAdvertising Features If you go to Google Analytics\u0026rsquo; Property Settings, you can find the relevant toggles under Tracking Info -\u0026gt; Data Collection.\n  When you enable both these toggles, hits collected to this web property on your site will automatically send the advertising hit to the DoubleClick endpoint, too. In other words, the analytics.js library downloaded by the analytics setup on your site (deployed via Universal Analytics, gtag.js, or Google Tag Manager snippets) will automatically be equipped with the necessary tools to perform this redirect. If you want to verify that it\u0026rsquo;s working, you should see the following in the Google Analytics Debugger output in the console:\n  An alternative way to deploy this feature is to load the displayfeatures plugin if using analytics.js:\n... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;); ga(\u0026#39;require\u0026#39;, \u0026#39;displayfeatures\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;);  The require command does the same thing as the Property Setting toggle. The difference is that now you have the option to control whether or not this plugin is loaded.\nThe third way to deploy this feature is to use the respective tag setting in Google Tag Manager:\n  All these settings do the same thing - once a hit is sent to Google Analytics, a request is sent to the DoubleClick server, too, containing information about the user (such as Client ID) and the web property (Property ID). This request is used to build the Demographics and Interests reports and for building remarketing audiences.\nThe new allowAdFeatures field But what if you want to conditionally block the request from being sent? Under GDPR, this might be a very good idea. If the visitor doesn\u0026rsquo;t explicitly opt-in to you aggregating their visit data into DoubleClick servers, you might want to block the request from being sent.\nIn an earlier article, I recommended using customTask for this. However, due to how displayFeaturesTask can\u0026rsquo;t be used to control the plugin / Google Tag Manager tag setting, it turned out to be an inefficient solution.\nLuckily, Google released the allowAdFeatures field, which you can use to conditionally block the DoubleClick request regardless of how it was set up.\nNote that the field can\u0026rsquo;t be used to establish Advertising Features collection. You still need to 1) enable the respective GA Property settings first, OR 2) load the displayfeatures plugin, OR 3) toggle the respective setting in your Google Tag Manager tags. This field simply either allows the request to go through, or blocks it.\nThe default value of the field is true, so if you don\u0026rsquo;t add the field to your setup, the Advertising Features will work regularly, sending the DoubleClick request if necessary. If you set the field to false, the DoubleClick request will be unconditionally blocked on the current page.\nTo use the field in analytics.js, you can do something like this:\n... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;); if (checkUserConsent() === \u0026#39;NO\u0026#39;) { ga(\u0026#39;set\u0026#39;, \u0026#39;allowAdFeatures\u0026#39;, false); } ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); ...  In the example above, if the method checkUserConsent() returns the value 'NO', then Advertising Features will be blocked for this tracker.\nTo use this in Google Tag Manager, you need to go to More Settings -\u0026gt; Fields to Set, and add a new field with:\nField name: allowAdFeatures\nValue: true/false\nNaturally, it\u0026rsquo;s easiest if you use a variable which checks the user consent, and then make sure the variable returns either true or false, depending on whether you want to allow or block the DoubleClick request, respectively.\n  Summary I hope all that made sense. The point of allowAdFeatures is to give you full client-side control over whether or not the DoubleClick request should happen. Due to the flexibility of allowAdFeatures I personally use the following setup:\n Toggle the Remarketing and Advertising Features settings on in Google Analytics / Property Settings / Tracking Info / Data Collection.\n Make sure the Advertising Features selections are disabled in Google Tag Manager tags.\n Use the allowAdFeatures field to conditionally block the Advertising Features if the visitor has not opted in.\n  This, in my experience, is the solution that\u0026rsquo;s easiest to manage.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/13-useful-custom-dimensions-for-google-analytics/",
	"title": "13 Useful Custom Dimensions For Google Analytics",
	"tags": ["google tag manager", "google analytics", "custom dimensions"],
	"description": "Implementation guide for useful Google Analytics Custom Dimensions, such as Hit Type, Session ID, Payload Length, and many more. The guide is for Google Tag Manager.",
	"content": " One of my favorite (and most popular) articles in my blog is Improve Data Collection With Four Custom Dimensions. In that article, I show how you can improve the quality and granularity of your Google Analytics data set with just four Custom Dimensions. The reason I chose the four dimensions (Hit Timestamp, Session ID, Client ID, and User ID) is because I firmly believe that they should be in Google Analytics\u0026rsquo; standard set of dimensions, but for some inexplicable reason they aren\u0026rsquo;t.\n  Since publishing that article three years ago, I have naturally uncovered more of these \u0026ldquo;need-to-have\u0026rdquo; Custom Dimensions, and I\u0026rsquo;ve written a bunch of guides on how to implement them. In this article, I want to pull all of these together into one reference guide, which you can then use to find the relevant information with ease. All of the implementation guides are for Google Tag Manager, but nothing\u0026rsquo;s stopping you from modifying the JavaScript to work with analytics.js or gtag.js.\n1. Improve granularity The first four Custom Dimensions are those introduced in my earlier article. You can follow the link to see more details about the implementation, but some of the solutions below have been updated, so make sure you follow these guides rather than those in the original article.\nThe purpose of these four dimensions is to add more information to Google Analytics data sets about the user journeys that take place on your site. Being able to segment and chop the data on a hit-by-hit basis (Hit Timestamp), group them into sessions (Session ID), sort by GA user (Client ID), and finally analyze cross-device paths (User ID), makes so much sense from an analytics point-of-view. It\u0026rsquo;s amazing that these dimensions are not readily available in Google Analytics\u0026rsquo; data sets. They are available in the BigQuery export\u0026hellip;\n  1.1. Hit Timestamp Original source: Link\nCustom Dimension scope: Hit\nHit Timestamp outputs the local time (i.e. visitor\u0026rsquo;s browser time) of the hit in standardized format. An example would be 2018-05-29T15:04:51.361+03:00 (year-month-dayThour:minutes:seconds.milliseconds timezone_offset). Since it\u0026rsquo;s hit timestamp, it\u0026rsquo;s important that you add this Custom Dimensions to every single Google Analytics tag that fires on your site. Easiest way to do it is to add it to a Google Analytics Settings variable.\nCustom JavaScript variable: {{Hit timestamp}}\nContents:\nfunction() { // Get local time as ISO string with offset at the end  var now = new Date(); var tzo = -now.getTimezoneOffset(); var dif = tzo \u0026gt;= 0 ? \u0026#39;+\u0026#39; : \u0026#39;-\u0026#39;; var pad = function(num) { var norm = Math.abs(Math.floor(num)); return (norm \u0026lt; 10 ? \u0026#39;0\u0026#39; : \u0026#39;\u0026#39;) + norm; }; return now.getFullYear() + \u0026#39;-\u0026#39; + pad(now.getMonth()+1) + \u0026#39;-\u0026#39; + pad(now.getDate()) + \u0026#39;T\u0026#39; + pad(now.getHours()) + \u0026#39;:\u0026#39; + pad(now.getMinutes()) + \u0026#39;:\u0026#39; + pad(now.getSeconds()) + \u0026#39;.\u0026#39; + pad(now.getMilliseconds()) + dif + pad(tzo / 60)  + \u0026#39;:\u0026#39; + pad(tzo % 60); }    1.2. Session ID Original source: Link\nCustom Dimension scope: Session\nSession ID is a random, unique string (GUID) which is scoped to the entire session. This means that all hits of the same session can be queried with the same ID. This, in turn, means that you have a way of aggregating all related hits directly in the data reports, rather than having to infer them using segments, for example.\nYou can add Session ID only to your Page View tag, but there\u0026rsquo;s no harm in including it in every single one of your GA tags. In fact, I actually recommend just adding it to the Google Analytics Settings variable you use for all your tags, because it\u0026rsquo;s possible that not all of your sessions will have a pageview in them (if the session breaks, and a new one starts without reloading a page).\nCustom JavaScript variable: {{Random GUID}}\nContents:\nfunction () { // Public Domain/MIT  var d = new Date().getTime(); if (typeof performance !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; typeof performance.now === \u0026#39;function\u0026#39;){ d += performance.now(); //use high-precision timer if available  } return \u0026#39;xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\u0026#39;.replace(/[xy]/g, function (c) { var r = (d + Math.random() * 16) % 16 | 0; d = Math.floor(d / 16); return (c === \u0026#39;x\u0026#39; ? r : (r \u0026amp; 0x3 | 0x8)).toString(16); }); }    1.3. Client ID Original source: Link\nCustom Dimension scope: User\nClient ID is the anonymous cookie identifier that Google Analytics assigns to every single browser instance of any given web visitor. It\u0026rsquo;s how GA calculates the Users metric in views which don\u0026rsquo;t have the User ID feature enabled (more on this in the next chapter).\nSending the Client ID as a Custom Dimension to Google Analytics is absolutely necessary. It\u0026rsquo;s the only way to get row-by-row reports split by user, and it\u0026rsquo;s the only way to query for data collected from any anonymous user.\nThe Client ID is collected using customTask (guide here), so you do not add it to tags using the Custom Dimensions settings. Instead, you add it to Fields to set -\u0026gt; customTask (see screenshot below). Be sure to read my guide on customTask to understand how this mechanism works.\nCustom JavaScript variable: {{customTask - Client ID}}\nContents:\nfunction() { var clientIdIndex = 3; // Change this number to the actual Custom Dimension index number  return function(model) { model.set(\u0026#39;dimension\u0026#39; + clientIdIndex, model.get(\u0026#39;clientId\u0026#39;)); }; }    1.4. User ID Original source: Link\nCustom Dimension scope: User\nUser ID is an identifier that you have somehow linked to the logged in user. Typically it\u0026rsquo;s a pseudonymized key written into dataLayer using an identifier attached to the user in your CRM or some other server-side user registry.\nBecause there are so many ways to implement User ID, depending on how your backend produces the identifier, I do not have a generic guide on how to generate the value. Thus the instructions below apply only to a very specific use case, where the User ID is written to the dataLayer when the page is loaded. But you could just as well have your web server write the User ID in some other global variable, or even in a browser cookie.\nAlso, because you are collecting data from logged in users, make sure whatever solution you implement is compliant with the privacy legislation and regulations of your region.\nData Layer variable: {{DLV - userId}}\nContents: Data Layer Variable Name - userId\n  2. Good all-around Custom Dimensions The next set of Custom Dimensions are just smart things to add to your data collection. Since they are included in this guide, they aren\u0026rsquo;t queriable by default in GA\u0026rsquo;s reporting interface.\n  2.1. Hit Type Original source: Link\nCustom Dimension scope: Hit\nHit Type tells you explicitly what the type of hit collected in Google Analytics was. So it would be event for Events, pageview for Pageviews, timing for Timing hits, etc. You can use this to build segments (e.g. sessions where the first hit was an event), or to add more granularity to path analysis.\nYou should add the variable to every single Google Analytics tag in your container. The variable needs to be added using customTask. Be sure to read my guide on customTask to understand how this mechanism works.\nCustom JavaScript variable: {{customTask - Hit type}}\nContents:\nfunction() { var hitTypeIndex = 5; // Change this number to the actual Custom Dimension index number  return function(model) { model.set(\u0026#39;dimension\u0026#39; + hitTypeIndex, model.get(\u0026#39;hitType\u0026#39;)); }; }    2.2. Full Referrer Custom Dimension scope: Hit\nFull Referrer is simply the value of document.referrer added as a hit-scoped Custom Dimension to every single Google Analytics tag in your container. This will let you analyze what the previous page of any given hit was. This makes a lot of sense for pageview tracking, and it makes a lot of sense for hits that start sessions, since you can now analyze the referral information for sessions that came via some other source than a referral hit.\nJavaScript variable: {{document.referrer}}\nContents: Global Variable Name - document.referrer\n  2.3. Payload Length Original source: Link\nCustom Dimension scope: Hit\nYou can send the payload length of every single Google Analytics hit by adding this hit-scoped Custom Dimension to every single tag in your container. The idea is that you can monitor if you are approaching the 8192 byte limit, since hits that equal or surpass that limit will not get sent to Google Analytics.\nThe solution is added using customTask. Be sure to read my guide on customTask to understand how this mechanism works.\nCustom JavaScript variable: {{customTask - Hit payload length}}\nContents:\nfunction() { // Change this index to match that of the Custom Dimension you created in GA  var customDimensionIndex = 7; return function(model) { var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; var originalSendHitTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { try { var originalHitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var customDimensionParameter = \u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex; // If hitPayload already has that Custom Dimension, note this in the console and do not overwrite the existing dimension  if (hitPayload.indexOf(customDimensionParameter + \u0026#39;=\u0026#39;) \u0026gt; -1) { console.log(\u0026#39;Google Analytics error: tried to send hit payload length in an already assigned Custom Dimension\u0026#39;); originalSendHitTask(sendModel); } else { // Otherwise add the Custom Dimension to the string  // together with the complete length of the payload  hitPayload += customDimensionParameter + \u0026#39;=\u0026#39;; hitPayload += (hitPayload.length + hitPayload.length.toString().length); sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload, true); originalSendHitTask(sendModel); } } catch(e) { console.error(\u0026#39;Error sending hit payload length to Google Analytics\u0026#39;); sendModel.set(\u0026#39;hitPayload\u0026#39;, originalHitPayload, true); originalSendHitTask(sendModel); } }); }; }    2.4. GTM Container ID Custom Dimension scope: Hit\nThis is another of those no-brainer Custom Dimensions. Sending the Container ID serves multiple purposes: It helps you identify valid hits from spam (particularly spam sent from outside your site), it helps you debug data in a situation where you have more than one container running on the site, and it makes it easy to run parallel installations of Universal Analytics (or Global Site Tag) and Google Tag Manager.\nYou need to activate the Container ID Built-in variable for this. Add the variable to your Google Analytics Settings variable, so that it\u0026rsquo;s added to every single Google Analytics tag in your container.\n  3. Browsing behavior The final set of Custom Dimensions is all about tracking browsing behavior. Follow the link in the previous sentence to read a thorough guide on how and why to track browsing behavior in Google Analytics.\nSuffice to say that by adding these dimensions to your data collection, you can make more sense out of how users navigate to, navigate on, and navigate away from your site. It\u0026rsquo;s finally possible to segment your data based on how your visitors open pages in browser tabs, do they navigate with the browser\u0026rsquo;s Back and Forward buttons, and how many tabs they have open at any given time!\nInstead of adding solution-specific implementation information, please follow the steps in the original guide.\n  3.1. Redirect Count Custom Dimension scope: Hit\nRedirect count is the number of times the initial document request was redirected when the user loaded the current page. There are some inconsistencies here, and I haven\u0026rsquo;t been able to deduce a consistent description of redirectCount behavior. However, if it works as it should, it offers interesting data about how your site responds to requests, especially when combined with organic search traffic, for example.\nData Layer variable: {{DLV - browsingBehavior.redirectCount}}\nContents: Data Layer Variable Name - browsingBehavior.redirectCount\n  3.2. Navigation Type Custom Dimension scope: Hit\nNavigation type means the method of navigating to the current page. This includes values such as NAVIGATE (user wrote the address in the address bar or clicked a link to the current page), RELOAD (user reloaded the page), BACK / FORWARD (user clicked the browser\u0026rsquo;s back or forward buttons) and OTHER (some other way of navigating to the page.\nData Layer variable: {{DLV - browsingBehavior.navigationType}}\nContents: Data Layer Variable Name - browsingBehavior.navigationType\n  3.3. Tab Type Custom Dimension scope: Hit\nTab type indicates whether the page load occurred in a newly open tab, or whether the tab already existed. This is done by storing the current tabId into sessionStorage. If the storage doesn\u0026rsquo;t have the current tab ID, we can deduce that the tab is a new one, since sessionStorage is purged when the tab is closed.\nData Layer variable: {{DLV - browsingBehavior.newTab}}\nContents: Data Layer Variable Name - browsingBehavior.newTab\n  3.4. Tabs Open Custom Dimension scope: Hit\nTabs open returns the number of tabs currently open in the browser. This is based on a count of currently active tab IDs stored in localStorage. This counter isn\u0026rsquo;t 100% reliable, because it relies on a number of moving parts which might not always be in sync. But as an indicator it\u0026rsquo;s very useful, since it tells you how your content is typically being digested.\nData Layer variable: {{DLV - browsingBehavior.tabCount}}\nContents: Data Layer Variable Name - browsingBehavior.tabCount\n  3.5. Tab ID Custom Dimension scope: Hit\nThe final cog in the machine is the ID of the current tab. This is useful in case you want to group hits together by the tab in which they occurred.\nData Layer variable: {{DLV - browsingBehavior.tabId}}\nContents: Data Layer Variable Name - browsingBehavior.tabId\n  4. The customTask variable You might have noticed that a number of the solutions in this guide utilize customTask. I might have recommended you to read my customTask guide, too!\nOne of the things you\u0026rsquo;ll learn in the guide is that you can only have one customTask per tag. That means that if you want to implement all the Custom Dimensions in this article, you will need to combine three different customTask solutions into a single Custom JavaScript variable.\nThis is fairly easy to do, since it\u0026rsquo;s more or less just copy-pasting all the code into one long anonymous function, but I\u0026rsquo;ll show you how to do it nevertheless.\nThis is the Custom JavaScript variable you\u0026rsquo;ll be using:\nfunction() { var clientIdIndex = 3; // Change this number to the index of your Client ID Custom Dimension  var hitTypeIndex = 5; // Change this number to the index of your Hit Type Custom Dimension  var payloadLengthIndex = 7; // Change this number to the index of your Payload Length Custom Dimension  return function(model) { var globalSendTaskName, originalSendHitTask, originalHitPayload, hitPayload, customDimensionParameter; if (typeof clientIdIndex === \u0026#39;number\u0026#39;) { model.set(\u0026#39;dimension\u0026#39; + clientIdIndex, model.get(\u0026#39;clientId\u0026#39;)); } if (typeof hitTypeIndex === \u0026#39;number\u0026#39;) { model.set(\u0026#39;dimension\u0026#39; + hitTypeIndex, model.get(\u0026#39;hitType\u0026#39;)); } if (typeof payloadLengthIndex === \u0026#39;number\u0026#39;) { globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; originalSendHitTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { try { originalHitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); customDimensionParameter = \u0026#39;\u0026amp;cd\u0026#39; + payloadLengthIndex; // If hitPayload already has that Custom Dimension, note this in the console and do not overwrite the existing dimension  if (hitPayload.indexOf(customDimensionParameter + \u0026#39;=\u0026#39;) \u0026gt; -1) { console.log(\u0026#39;Google Analytics error: tried to send hit payload length in an already assigned Custom Dimension\u0026#39;); originalSendHitTask(sendModel); } else { // Otherwise add the Custom Dimension to the string  // together with the complete length of the payload  hitPayload += customDimensionParameter + \u0026#39;=\u0026#39;; hitPayload += (hitPayload.length + hitPayload.length.toString().length); sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload, true); originalSendHitTask(sendModel); } } catch(e) { console.error(\u0026#39;Error sending hit payload length to Google Analytics\u0026#39;); sendModel.set(\u0026#39;hitPayload\u0026#39;, originalHitPayload, true); originalSendHitTask(sendModel); } }); } }; }  If you want to drop any of the three solutions from this customTask, simply remove or comment out the respective var ...Index = N; line. For example, if you don\u0026rsquo;t need to collect the payload length, change the code appropriately:\nfunction() { var clientIdIndex = 3; // Change this number to the index of your Client ID Custom Dimension  var hitTypeIndex = 5; // Change this number to the index of your Hit Type Custom Dimension  // var payloadLengthIndex = 7;  return function(model) { ...  Summary This list of Custom Dimensions is certainly not exhaustive, and I\u0026rsquo;m sure you have other suggestions to what could be considered \u0026ldquo;useful\u0026rdquo;.\nOne thing to keep in mind is the restriction of just 20 available Custom Dimension slots in the free version of Google Analytics. This is very unfortunate, and one of the main gripes I have with GA. So it\u0026rsquo;s very likely you\u0026rsquo;re forced to prioritize just which dimension you\u0026rsquo;ll need to be adding to your data collection. If push comes to shove, I would personally be fine with ignoring the five Browsing Behavior dimensions, and just focus on the 8 dimensions listed first in this article.\nRegardless, I consider these Custom Dimensions to add much-needed granularity to GA data. Many of these dimensions are available by default only in the BigQuery export, which, in turn, is mainly available for Google Analytics 360 customers. So by adding these dimensions to your data set, you are, in a way, actually saving money.\nDo you have some go-to Custom Dimensions you\u0026rsquo;d recommend others add to their data collection right this instant? Let us know in the comments.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/add-hit-type-custom-dimension/",
	"title": "#GTMTips: Add Hit Type As A Custom Dimension",
	"tags": ["google tag manager", "gtmtips", "customtask"],
	"description": "Use customTask in Google Tag Manager to automatically send the hit type of each request as a Custom Dimension to Google Analytics. This introduces an additional level of granularity to your report data.",
	"content": " I\u0026rsquo;ve spent a considerable amount of time talking and writing about how to improve the granularity of your Google Analytics data, especially when using Google Tag Manager. I\u0026rsquo;ve also gone on and on and on (and on) about customTask, which makes adding metadata to the Google Analytics hits dispatched from your website a breeze.\nIn this article, I\u0026rsquo;ll introduce a simple way to add yet another level of detail to your GA hits, using customTask as the method of choice. The piece of data we\u0026rsquo;ll add is the hit type of the hit (e.g. pageview, event, and timing) which, for some ludicrous reason, is not a default dimension available in Google Analytics reports.\nTip 80: Add hit type as a Custom Dimension   Adding hit type as a Custom Dimension is fairly easy, because it\u0026rsquo;s a default field available in the model object that customTask automatically receives as a parameter when executed.\nSo, to start with, create a new Hit-scoped Custom Dimension in your Google Analytics Property Settings. Name it Hit type. Make note of the Index number assigned to the new dimension.\n  Then, in Google Tag Manager, create a new Custom JavaScript variable (or edit your existing customTask variable). Add the following code within:\nfunction() { var hitTypeIndex = 2; return function(model) { model.set(\u0026#39;dimension\u0026#39; + hitTypeIndex, model.get(\u0026#39;hitType\u0026#39;)); }; }  Change the hitTypeIndex variable value from 2 in the example to whatever the index number of your Custom Dimension is.\nFinally, add this variable to all your Google Analytics tags in More Settings / Fields To Set. It\u0026rsquo;s easiest if you just add it to your Google Analytics Settings variable (you are using one, right?). The field name should be customTask, and the value should be the Custom JavaScript variable you just created.\n  Now, every tag that has this field set will send its hit type automatically to Google Analytics as part of the hit payload.\nYou can verify this setup works by using the Google Analytics Debugger browser extension, and checking that the hit type is being sent with the correct Custom Dimension parameter (\u0026amp;cdX, where X is the index number).\n  If you can see that parameter, you\u0026rsquo;ll know everything should be working as intended.\nAnd what can you do with this data, you ask? Well, the most useful (my opinion) application is with segments. You can create Advanced Segments such as the one in the title image of this article to find specific sequences of different hit types, such as sessions where an event preceded a pageview hit.\nOr you can pull the data out using the Reporting API, and use the new Hit type Custom Dimension as an additional level of detail. This is particularly useful when combined with dimensions such as hit timestamp, session ID, and the variety of browsing behavior dimensions introduced in this article.\nLet me know in the comments if you can think of other uses for this data! Always happy to delegate actual analytics work to people wiser than me.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/delay-the-history-change-trigger/",
	"title": "#GTMTips: Delay The History Change Trigger",
	"tags": ["google tag manager", "gtmtips", "history", "spa"],
	"description": "Use a Custom HTML tag to delay the History Change trigger in order to accommodate for single-page frameworks that load the content after the history change event has been pushed.",
	"content": " When working with the analytics of single-page applications (SPA), there are a number of things to pay attention to. For example, you need to make sure that Google Analytics doesn\u0026rsquo;t break your session attribution, and that you are not inadvertently inflating your page speed timing metrics. Actually, there are so many \u0026ldquo;gotchas\u0026rdquo; when it comes to SPA tracking in tools like Google Analytics that you just can\u0026rsquo;t get by with a plug-and-play implementation.\nSee Dan Wilkerson\u0026rsquo;s excellent article, which sums nicely the can of worms involved with tracking an SPA.\nOne of the problems with frameworks that load their content dynamically using JavaScript (e.g. React) is when the history event is dispatched before the content has been loaded or the URL has actually changed.\nThis is problematic, since you might actually want to refer to elements loaded in this dynamic state change in your tags, but because the History Change trigger fires as soon as the event is dispatched, the content might not be there yet when your tags fire.\nSo in this article I\u0026rsquo;ll show a quick and dirty way to delay the trigger, so that your tags don\u0026rsquo;t fire until the page has had time to load the content.\nTip 79: Delay The History Change Trigger   The easy way to do it is to fire a Custom HTML tag with the History Change trigger that is causing problems on your site.\nFirst, make sure you have all the history-related Built-in variables enabled in the container.\nThen, in the Custom HTML tag, add the following code:\n\u0026lt;script\u0026gt; (function() { var timeout = 500; // Milliseconds - change to what you want the timeout to be.  window.setTimeout(function() { window.dataLayer.push({ event: \u0026#39;custom.historyChange\u0026#39;, custom: { historyChangeSource: {{History Source}}, newHistoryState: {{New History State}}, oldHistoryState: {{Old History State}}, newHistoryFragment: {{New History Fragment}}, oldHistoryFragment: {{Old History Fragment}} } }); }, timeout); })(); \u0026lt;/script\u0026gt; As said above, make sure this tag fires on the History Change trigger you want to delay.\nThe Custom HTML tag adds a 500 millisecond delay, after which it pushes a custom event named custom.historyChange into the dataLayer. With this event, five new Data Layer variables are pushed, each with the values from the original History event that triggered the Custom HTML tag in the first place. These new variables are:\n custom.historyChangeSource - the history event that triggered the delay (e.g. pushState or replaceState).\n custom.newHistoryState - the state object set in the history event.\n custom.oldHistoryState - the state object that was overwritten with the new state object.\n custom.newHistoryFragment - the hash fragment set in the history event (e.g. #contactus).\n custom.oldHistoryFragment - the hash fragment that was overwritten with the new hash.\n  Now, create a new Custom Event trigger for event name custom.historyChange, and create Data Layer variables for all of the new custom variables listed above (or at least the ones that make sense in your case). Here\u0026rsquo;s what the trigger and a sample variable would look like:\n  Add the Custom Event trigger to whatever tag you want to fire with the history event, and use the new Data Layer variables where necessary.\nYou might be wondering why rewrite the original Built-in variables into custom Data Layer variables. This is just a precaution. If your site dispatches more than one history event before the 500 millisecond delay is over, then the Built-in variables will always refer to the latest history state, and not the one that was delayed.\nProblem with this approach There\u0026rsquo;s one, potentially big issue with this approach. By firing a Custom HTML tag with every single history event, you are clogging up the document object model of the page, because that gets unloaded when the user navigates away from the page, and not when new content is pulled in. For example, after ten history events, this is what the DOM can end up looking like:\n  The problem with rewriting the DOM so many times is that each new element added forces a re-evaluation of the document object model, and the more items in the DOM, the longer this re-evaluation takes. So the more Custom HTML tags that fire without a page reload or refresh, the more the page performance will suffer.\nPotential solution One potential solution is to use only a single Custom HTML tag, where you overwrite the window.history.pushState and window.history.replaceState methods. The overwritten code should include the delayed dataLayer.push(), and you must pass the arguments to the original window.history.pushState using apply(), unless you want to destroy your site navigation. See here for inspiration.\nBasically, you\u0026rsquo;re writing a custom event listener, but instead of listening for user interactions, you\u0026rsquo;ll be listening for pushState and replaceState events.\nI\u0026rsquo;m not going to write the solution here - it\u0026rsquo;s difficult to write a generic history listener that works with your particular use case. But the Stack Overflow article should help you get started. Just remember to test thoroughly if overwriting basic browser interfaces like the Window History API.\nSummary The trick outlined in this article should really be a temporary solution (as all hacks should). You really ought to talk to your developers and ask them to implement the custom event push directly into whatever JavaScript is handling the route / state changes on the site.\nBy delegating the work to your developers, they can ensure that the dataLayer event is dispatched at the exact right time. Using a delay like the 500 milliseconds of this article is sub-optimal for two reasons:\n It can be too short, meaning the delay goes off, the custom event is pushed, but the transition is still not complete.\n It can be too long, meaning you are wasting time with the trigger, and tracking the page view of each dynamic transition can lag behind the events dispatched with each new bit of content.\n  Regardless, it\u0026rsquo;s a way to make things work, which I guess is a good justification as any for using hacks.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-browsing-behavior-in-google-analytics/",
	"title": "Track Browsing Behavior In Google Analytics",
	"tags": ["google tag manager", "custom dimensions", "google analytics", "navigation"],
	"description": "Add Custom Dimensions for browsing behavior (tabbed browsing, how the user navigated to the current page) in Google Analytics. This guide is for Google Tag Manager users mainly, but can be adapted for other implementation methods, too.",
	"content": " In this article, Jethro Nederhof of Snowflake Analytics fame and I will introduce you to some pretty neat web browser APIs. The purpose of these APIs is to find out more about how the user navigated to the current page, and what\u0026rsquo;s going on with their browser tabs.\n  There are so many things you can do with this new information. You can build proper navigational path reports, rather than rely on the fuzzy and often incoherent flow reports in Google Analytics. You can identify how visitors interact with your content using browser tabs - a crucial bit of information if you want to make heads or tails of Google Analytics\u0026rsquo; time on page metrics, for example. You can see how many redirects were involved in the current navigation action.\nThe origins of this article are in a number of places, including an impromptu challenge thrown by Yehoshua Coren in Twitter (with great contributions from Marek Lecián, too):\nNew #GTM challenge for @SimoAhava . Can you track how many browser tabs I have open on your site right now? ;)\n\u0026mdash; yeh-hoh-SHU-ah🥇 (@AnalyticsNinja) April 12, 2018  However, the main source of inspiration came from Measure Slack, where a similar discussion around tabbed browser was being had:\n  Jethro\u0026rsquo;s idea got the ball rolling in my mind, so I contacted him immediately and asked if he wanted to co-author this article. As it turns out, he\u0026rsquo;d been mulling around lots of different ideas for navigation behavior tracking, so we quickly sketched the outline of this article, and what you are reading now is the final product.\nI consider the enhancements introduced in this article just as necessary as those I introduced way back when in my article Improve Data Collection With Four Custom Dimensions. Once you\u0026rsquo;re done implementing these scripts, I\u0026rsquo;m sure you\u0026rsquo;ll agree.\nAs said, this article is co-authored by Jethro and me. Since I am the editor, all mistakes and errors are entirely my fault, and any snarky comments should be directed at me and not my generous partner in crime (naturally, all snarky comments will be deleted, but I will read them and promise to be insulted).\nYou can skip directly to the Solutions chapter, but I do recommend reading the Theory first. At the very least, make sure you read the Caveats chapter, because there are a couple of gotchas you need to be aware of if implementing this solution.\nAh, damn it. Just read the whole thing, will you?\n1. The why and how (theory) The web, by default, is stateless. Your browsing behavior is confined to the current page only, and it\u0026rsquo;s difficult to programmatically peer into the past (never mind into the future).\nTools like Google Analytics try to make sense of this stateless mess by collecting information in a chronological order. You send a pageview, then you send another pageview. Google Analytics interprets this as navigational behavior where you first viewed the first page and then the second page. Makes sense, right?\nBut what about if you opened the second page in a tab and never even glanced at it? GA still interprets it as a page being viewed.\nWhat about if you reloaded the current page? GA still interprets it as a navigational step.\nWhat about if you pressed the back button of the browser to return to the previous page? Google Analytics makes no distinction - it doesn\u0026rsquo;t know if you clicked a link, typed the URL in the address bar, or used the back button. It\u0026rsquo;s all the same.\n  The flow reports try to make sense of this mess by aligning everything into a navigational pattern (the \u0026ldquo;flow\u0026rdquo;). But the reports are quite difficult to interpret, as they sometimes show sequences that you are certain shouldn\u0026rsquo;t be possible, lack necessary detail, and they don\u0026rsquo;t really give you a robust way to query the information or to build a proper flow report yourself.\nAnd tabbed browsing is still a problem. Each tab initiates a new \u0026ldquo;session\u0026rdquo; in the browser (not to be confused with a Google Analytics session). Thus when GA tries to explain to you that everything is part of a linear navigational flow, the truth is actually more complex: each tab initiates a new branch of navigation!\n  Add to this the fact that in Google Analytics, \u0026ldquo;Referral\u0026rdquo; is a reserved term for campaign attribution. Thus when you are navigating around the site, the referring page is not sent when navigating in-site. This would be really helpful when deciphering navigational paths, since the Previous Page Path dimension does not necessarily represent the previous page viewed (just the previous page for which a pageview was sent). To make some sense out of the mess, sending the referral string in a Custom Dimension is a good practice.\n  There are other, more granular tracking solutions out there, of course. Snowplow, for example, lets you track hit-level data in any way you like. You can include referral information, if you wish. However, since you\u0026rsquo;re approaching Snowplow with the limitations of SQL queries, as soon as the navigation journey starts looping or has multiple pages, the joins you\u0026rsquo;d need to make become frustratingly complex and, as a result, quite unwieldy over large amounts of data.\nSo, we\u0026rsquo;ve had this problem of analytics tools imposing a linear sequence on a non-linear navigational pattern for a couple of decades, ever since tabbed browsing was introduced around the turn of the millennium.\nWhat we\u0026rsquo;re proposing in this article is to add another layer to the taxonomy of Google Analytics\u0026rsquo; rather rigid schema for browsing behavior.\nFROM: Users \u0026gt; Sessions \u0026gt; Hits\nTO: Users \u0026gt; Sessions \u0026gt; Tabs \u0026gt; Hits\nThis browsing behavior would be encoded directly into Custom Dimensions, so you don\u0026rsquo;t have to infer behavior from GA\u0026rsquo;s pageview model - rather, you can query the navigational information directly!\n1.1. The PerformanceNavigation API The API we\u0026rsquo;re going to use to identify browsing behavior is called PerformanceNavigation. It comes with two read-only properties: performance.navigation.type and performance.navigation.redirectCount.\nThe origin story of this API is firmly rooted in the difficulty of measuring performance of any given web page load. Redirects, network lag, and cached resources (locally, server-side, in CDNs) all contribute to the complexity of what the aggregate performance of any given page load is.\n  To help understand this complexity, web browsers implement the PerformanceNavigation API. The two properties exposed by the API can be found under the global window.performance.navigation interface, and they contain the following information:\n   Parameter Detail Description     redirectCount - The number of 3XX HTTP redirects the browser went through when loading the page.   type - An integer representing how the page was loaded.   \u0026nbsp; 0 Normal navigation, typing the URL, clicking a link, opening a bookmark, entering via an app link, etc.   \u0026nbsp; 1 Page was refreshed / reloaded while already open in the browser tab.   \u0026nbsp; 2 The page was retrieved from the browser history by using the Back or Forward button.   \u0026nbsp; 255 Any other way to navigate to the page.    The 255 value is interesting, because it is quite undocumented. In tests, it seems to only emerge with the Firefox browser, when the page goes through a client-side refresh, either using window.location.replace() or \u0026lt;meta name=\u0026quot;refresh\u0026quot;\u0026gt;. Note that this goes against the W3C specification, which clearly states that client-side redirects should be contained within one of the regular navigation types.\nNow, even though we mention how this API was probably conceived to give more information about the performance timing metrics, where it really shines is uncovering the navigational paths the users take through your site.\n1.2. Browser storage Ever since browser tabs were introduced to the delight of site visitors and web browser users, they\u0026rsquo;ve been a source of annoyance for web analysts.\nIn Google Analytics, for example, we simply don\u0026rsquo;t know (by default) what the tab situation is of any given page. We don\u0026rsquo;t know if the page was opened in a new tab, for one, since you can\u0026rsquo;t attach listeners to the right-click context menu, and tracking just middle mouse button clicks doesn\u0026rsquo;t give a comprehensive idea of the scope of the phenomenon.\n  The beauty of web analytics is that when we can\u0026rsquo;t track things directly (whether a user submitted a form, for example), we can track them indirectly (page load of a \u0026ldquo;thank you\u0026rdquo; page). So maybe we can use this same indirect approach with browser tabs, too?\nIf we can assign an identifier to every tab the user opens in the current website, we can identify individual navigation sequences! This can be achieved by checking against a common data store whether the given tab ID exists already, in which case the page load happened in a tab that was already open, and vice versa.\nHowever, thanks again to the statelessness of the web, there is the problem of persistence. We can\u0026rsquo;t simply use a global JavaScript property to store the tab ID, because that gets demolished when the user unloads the page by reloading or navigating to another page.\nCookies and localStorage are \u0026ldquo;too\u0026rdquo; persistent, because they are only reset when they are manually cleared (localStorage) or when they expire (cookies). We only want to store the ID of a tab for as long as that tab exists.\n  Enter sessionStorage! It\u0026rsquo;s a browser storage API that is unique to each tab in your web browser. By storing the tab ID in sessionStorage, we can always check if the tab already has an ID (existing tab), or if we need to generate a new one (new tab).\nCombine this with some localStorage logic, where we keep a running tally of how many tab IDs have been generated, remembering to remove any tab ID once that tab is closed, and we can also get a fairly reliable count of tabs open on your website at any given time.\nSo, now we are getting close to having all the bits and pieces at hand. Once we combine the tabbed browsing metadata with that provided by the PerformanceNavigation API, we can get a nice set of Custom Dimensions that expose a great deal of interesting information about how your visitors navigate your site.\n2. Caveats Oh, there are plenty of caveats. The solutions below rely on a number of fragile components, which can get easily messed up due to how browsers act differently in certain circumstances.\n2.1. Cross-domain browsing If your tracking crosses multiple domains, then each domain will get their own tab ID. That\u0026rsquo;s because sessionStorage and localStorage are confined to the current domain only. And if your current domain sails between HTTP and HTTPS protocols, then those will get their own storages, too. You could fix this by using URL parameters on the domain boundaries to pass the metadata from one domain to the next, but this is something you\u0026rsquo;ll need to figure out by yourself.\n2.2. Firefox and Chrome go rogue An additional point of concern is that Firefox and Chrome do not respect the specification that session cookies and sessionStorage should only exist for as long as the tab is alive. Once the browser is closed, these session stores should be purged.\nOn Chrome and Firefox, however, if you open the browser and you have the Show your windows and tabs from last time (Firefox) or Continue where you left off (Chrome) settings turned on, the session stores are restored, too! So even though the tab did close, by restoring the tab it\u0026rsquo;s as if the tab was never closed.\n  That sucks. Not much we can do about that.\nAlso, and this is interesting, when you do restore tabs or continue where you left off, the browser claims that the navigation type was BACK/FORWARD, meaning it equates restoring tabs with using the back or forward button of the browser.\nThis sucks, too. And there\u0026rsquo;s not much we can do about this, either.\n2.3. Firefox and its client-side refresh dilemma Then there\u0026rsquo;s the problem with Firefox implementing OTHER as the navigation type if a client-side refresh is done. This is unfortunate, but doesn\u0026rsquo;t luckily mess things up too bad, because this behavior is contained within this particular navigation type alone.\nIn addition to all of these, because the whole granularity of distinguishing between BACK and FORWARD needs to be coded using a programmatically maintained path of pages the user has visited, all it takes is for them to manually clear the sessionStorage to break the whole setup (at least, for as long as the tab is open).\n  That\u0026rsquo;s why in the beginning of the solution you have the option of NOT tracking the back and forward button presses with detail. In this case, the string BACK/FORWARD is sent to Google Analytics in case either button is pressed. It\u0026rsquo;s not as detailed but it does still tell you whether the user navigated using these buttons (or, as mentioned above, if the tabs were restored after restarting the browser).\nOur hypothesis is that with more data the averages will converge towards a more reliable dataset. So idiosyncrasies such as tabs being restored or users clearing storage will disappear into the data as more and more page views are accumulated.\n2.4. Browser support There\u0026rsquo;s also the matter of browser support, but unlike some online resources claim, support for PerformanceNavigation is pretty well supported in Chrome and Safari.\n2.5. Single-page apps You could implement this solution for single-page apps, but in that case you should add an additional, custom navigation type called VIRTUAL, or something similar, if the navigation was a single-page transition and not a proper page load.\nDo note that window.performance.navigation.type does not update when the user uses the browser\u0026rsquo;s Back / Forward buttons and the transition is from one single-page app state to another. So you\u0026rsquo;d need to code the logic for Back / Forward use when no page load is recorded.\n3. Solutions OK, let\u0026rsquo;s get to the good stuff! In this chapter, we\u0026rsquo;ll introduce the technical solution in Google Tag Manager (Custom HTML tag) that orchestrates the whole thing. In addition to that, each sub-section will detail how to send the respective piece of information to Google Analytics as a Custom Dimension. Basically, all you\u0026rsquo;ll need to edit is your main Page View tag, since that\u0026rsquo;s the only one that will be sending this data to Google Analytics.\n3.1. The Custom HTML tag First, create a new Custom HTML tag, and add the following code within.\n\u0026lt;script\u0026gt; (function() { // Set to false if you only want to register \u0026#34;BACK/FORWARD\u0026#34;  // if either button was pressed.  var detailedBackForward = true; if (!!window.Storage) { var openTabs = JSON.parse(localStorage.getItem(\u0026#39;_tab_ids\u0026#39;)), tabId = sessionStorage.getItem(\u0026#39;_tab_id\u0026#39;), navPath = JSON.parse(sessionStorage.getItem(\u0026#39;_nav_path\u0026#39;)), curPage = document.location.href, newTab = false, origin = document.location.origin; var tabCount, redirectCount, navigationType, prevInStack, lastInStack, payload; var getBackForwardNavigation = function() { if (detailedBackForward === false) { return \u0026#39;BACK/FORWARD\u0026#39;; } if (navPath.length \u0026lt; 2) { return \u0026#39;FORWARD\u0026#39;; } prevInStack = navPath[navPath.length-2]; lastInStack = navPath[navPath.length-1]; if (prevInStack === curPage || lastInStack === curPage) { return \u0026#39;BACK\u0026#39;; } else { return \u0026#39;FORWARD\u0026#39;; } }; var removeTabOnUnload = function() { var index; // Get the most recent values from storage  openTabs = JSON.parse(localStorage.getItem(\u0026#39;_tab_ids\u0026#39;)); tabId = sessionStorage.getItem(\u0026#39;_tab_id\u0026#39;); if (openTabs !== null \u0026amp;\u0026amp; tabId !== null) { index = openTabs.indexOf(tabId); if (index \u0026gt; -1) { openTabs.splice(index, 1); } localStorage.setItem(\u0026#39;_tab_ids\u0026#39;, JSON.stringify(openTabs)); } }; var generateTabId = function() { // From https://stackoverflow.com/a/8809472/2367037  var d = new Date().getTime(); if (typeof performance !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; typeof performance.now === \u0026#39;function\u0026#39;){ d += performance.now(); //use high-precision timer if available  } return \u0026#39;xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\u0026#39;.replace(/[xy]/g, function (c) { var r = (d + Math.random() * 16) % 16 | 0; d = Math.floor(d / 16); return (c === \u0026#39;x\u0026#39; ? r : (r \u0026amp; 0x3 | 0x8)).toString(16); }); }; var validNavigation = function(type, newTab) { // Return false if new tab and any other navigation type than  // NAVIGATE or OTHER. Otherwise return true.  return !(newTab === true \u0026amp;\u0026amp; (type !== 0 \u0026amp;\u0026amp; type !== 255)); }; if (tabId === null) { tabId = generateTabId(); newTab = true; sessionStorage.setItem(\u0026#39;_tab_id\u0026#39;, tabId); } openTabs = openTabs || []; if (openTabs.indexOf(tabId) === -1) { openTabs.push(tabId); localStorage.setItem(\u0026#39;_tab_ids\u0026#39;, JSON.stringify(openTabs)); } tabCount = openTabs.length; if (!!window.PerformanceNavigation) { navPath = navPath || []; redirectCount = window.performance.navigation.redirectCount; // Only track new tabs if type is NAVIGATE or OTHER  if (validNavigation(window.performance.navigation.type, newTab)) { switch (window.performance.navigation.type) { case 0: navigationType = \u0026#39;NAVIGATE\u0026#39;; navPath.push(curPage); break; case 1: navigationType = \u0026#39;RELOAD\u0026#39;; if (navPath.length === 0 || navPath[navPath.length-1] !== curPage) { navPath.push(curPage); } break; case 2: navigationType = getBackForwardNavigation(); if (navigationType === \u0026#39;FORWARD\u0026#39;) { // Only push if not coming from external domain  if (document.referrer.indexOf(origin) \u0026gt; -1) { navPath.push(curPage); } } else if (navigationType === \u0026#39;BACK\u0026#39;) { // Only remove last if not coming from external domain  if (lastInStack !== curPage) { navPath.pop(); } } else { navPath.push(curPage); } break; default: navigationType = \u0026#39;OTHER\u0026#39;; navPath.push(curPage); } } else { navPath.push(curPage); } sessionStorage.setItem(\u0026#39;_nav_path\u0026#39;, JSON.stringify(navPath)); } window.addEventListener(\u0026#39;beforeunload\u0026#39;, removeTabOnUnload); payload = { tabCount: tabCount, redirectCount: redirectCount, navigationType: navigationType, newTab: newTab === true ? \u0026#39;New\u0026#39; : \u0026#39;Existing\u0026#39;, tabId: tabId }; // Set the data model keys directly so they can be used in the Page View tag  window.google_tag_manager[{{Container ID}}].dataLayer.set(\u0026#39;browsingBehavior\u0026#39;, payload); // Also push to dataLayer  window.dataLayer.push({ event: \u0026#39;custom.navigation\u0026#39;, browsingBehavior: payload }); } })(); \u0026lt;/script\u0026gt;  Do not add any triggers to this tag. Instead, open your Page View tag, and add this Custom HTML tag into its tag sequence by making the Custom HTML tag fire before the Page View tag.\nAccessing GTM\u0026rsquo;s data model directly with dataLayer.set is necessary if you want to modify Data Layer keys within a tag sequence. However, for the sake of transparency, we\u0026rsquo;ll also push a dataLayer object with a custom event (custom.navigation) and the browsing behavior payload.\n  The code in the Custom HTML tag does a number of things.\n It generates a tab ID for the page, which is stored in sessionStorage. If a new tab ID is thus generated, the page is marked as being in a new browser tab. If a tab ID was already in storage, then the page is flagged as being in an existing tab.\n This tab ID is also stored in an array within localStorage, where all tab IDs generated on the site are stored. The length of this array is the count of currently open tabs on the domain.\n If the user leaves the page, or closes the browser tab, or closes the browser, the tab ID is removed from the array in localStorage (thus keeping the count of open tabs accurate).\n If the page was loaded by navigating to the URL, navigation type is set to NAVIGATE, and the current page is pushed into an array representing the navigation path, stored in sessionStorage.\n If the page was reloaded, navigation type is set to RELOAD, and the navigation path is kept as it is.\n If the Back or Forward button was pressed, the script checks if the current page is the penultimate page in the navigation path, in which case navigation type is set to BACK. In other cases, navigation type is set to FORWARD.\n Count of tabs, count of redirects, navigation type, tab ID, and whether the tab was new or existing are all added to Google Tag Manager\u0026rsquo;s data model, so that the Page View tag can grab these values with Data Layer variables.\n  There are some nuances to the steps listed above, mainly to account for edge cases, such as when navigating BACK or FORWARD from an external domain. Even with these precautions, there are situations where the solution will fail (see the Caveats chapter).\nAnd now that we are adding all this information into Data Layer, it\u0026rsquo;s time to pick up the metadata and send it to Google Analytics!\n3.2. Create the Custom Dimensions in Google Analyitcs First, you\u0026rsquo;ll need to create some Custom Dimensions in Google Analytics.\nCreate the following Custom Dimensions in Google Analytics\u0026rsquo; Property Settings, all in hit scope, and make note of the index numbers assigned to them.\n Redirect count\n Navigation type\n Tab type\n Tabs open\n Tab ID    3.3. Create the Data Layer variables in Google Tag Manager Next, create the corresponding Data Layer variables in Google Tag Manager. Here\u0026rsquo;s my setup:\n   Variable name Value for Data Layer Variable name field     {{DLV - browsingBehavior.redirectCount}} browsingBehavior.redirectCount   {{DLV - browsingBehavior.navigationType}} browsingBehavior.navigationType   {{DLV - browsingBehavior.newTab}} browsingBehavior.newTab   {{DLV - browsingBehavior.tabCount}} browsingBehavior.tabCount   {{DLV - browsingBehavior.tabId }} browsingBehavior.tabId    Here\u0026rsquo;s an example of what one of the variables would look like:\n  3.4. Add the Data Layer variables to your Page View tag Now, open the Page View tag which you have already edited for the Tag Sequence stuff in the beginning of this chapter. Either in a Google Analytics Settings variable or by directly editing the tag fields, add the Data Layer variables to their respective indices in the Custom Dimensions list. This is what my setup looks like:\n  3.5. Test it! Now, save the tag, go to Preview mode, and enter your site.\nNote! You can\u0026rsquo;t really use Preview mode to test if the Data Layer variables are populating correctly. Because you are updating the data model in a tag sequence, the method used does not expose the dynamic changes to the Preview mode user interface.\nYou\u0026rsquo;ll need to either look at the Network requests directly, or use a tool such as Google Tag Assistant recordings or Google Analytics Debugger to check if the data is being sent correctly.\nIn any case, if everything is working, then with your Page View tag you should see the Custom Dimensions being populated with the relevant information.\n  3.6. Custom Report in Google Analytics A handy way to pull it all together is to create a Custom Report in Google Analytics with these settings, for example:\n  This report will contain interesting information about how users navigated to the different pages on your site.\n  Couple this with things like Session ID and Hit Timestamp, and you can really start digging into how users move from one page to the other on your site.\n3.7. Other data stores If you\u0026rsquo;ve taken the time to duplicate your Google Analytics data to Snowplow, you\u0026rsquo;ll naturally have access to a far more granular, raw hit stream resource for querying against. For example, here\u0026rsquo;s a simple SQL query output with all the relevant dimensions included:\n  Do note that Snowplow doesn\u0026rsquo;t differentiate between different scopes of Custom Dimensions, since scope is a concept applied in Google Analytics processing. So if you are sending an identifier into a session-scoped Custom Dimension (e.g. Session ID), the hit stream to Snowplow will interpret this as hit-scoped data, and thus the identifier is pretty useless.\n4. Summary First of all, I\u0026rsquo;m hugely indebted to Jethro Nederhof for agreeing to draft this solution with me. I really love the community of analytics developers - seems like everyone is giddy with excitement when figuring out new solutions to age-old questions, and the amount of knowledge being shared across blogs, Slack channels, and social media is a testament to the selflessness of these good men and women.\nIn my humble opinion, anyone interested in proper page navigation analysis should try out this solution. Understanding things like browser tab usage and Back / Forward browsing can help you figure out where the information architecture blind spots of your site are or whether you need to fix the navigation options you offer your visitors, for example.\nBut, as always on this particular blog, this is a technical solution first and foremost. Jethro and I wanted to highlight some cool tricks you can do with the web browser, and we fully expect others to refine these methods even further.\nIt would be cool if the APIs were developed even further, such as by automatically distinguishing between Back and Forward of the browser. Right now, they\u0026rsquo;re bunched together which is why we need the workaround of managing the navigation path in sessionStorage, and that\u0026rsquo;s a fragile solution indeed.\nLet us know in the comments what you think of this trick, and whether you have suggestions on how to improve it!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/notify-page-google-tag-manager-loaded/",
	"title": "#GTMTips: Notify The Page That Google Tag Manager Has Loaded",
	"tags": ["google tag manager", "gtmtips", "container"],
	"description": "Modify the Google Tag Manager container snippet to notify the page that the GTM container library has loaded.",
	"content": " Here\u0026rsquo;s a quick tip in response to a query in Twitter by Riccardo Mares. By making a small change to the Google Tag Manager container snippet, you can have the \u0026lt;script\u0026gt; element generated by the snippet notify the page as soon as the Google Tag Manager library has downloaded.\nHi @SimoAhava is possible in javascript (from the page) to check (or hook) when GTM has been loaded? Thanks.\n\u0026mdash; Merlinox (@merlinox) April 13, 2018  What you do with this information is up to you. If you are working directly with the google_tag_manager interface, for example, it might make sense to not act until the interface has been established.\nTip 78: Notify the page when the GTM container has loaded   You need to add the following code into the container snippet, immediately after the +i+dl; and immediately before the f.parentNode.insertBefore.\nj.addEventListener(\u0026#39;load\u0026#39;, function() { var _ge = new CustomEvent(\u0026#39;gtm_loaded\u0026#39;, { bubbles: true }); d.dispatchEvent(_ge); });  Thus the modified container snippet would look like this:\n(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;https://www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl; j.addEventListener(\u0026#39;load\u0026#39;, function() { var _ge = new CustomEvent(\u0026#39;gtm_loaded\u0026#39;, { bubbles: true }); d.dispatchEvent(_ge); }); f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-XXXXX\u0026#39;);  Now, when the Google Tag Manager container has been downloaded from Google\u0026rsquo;s servers, the load listener will dispatch a new browser event named gtm_loaded.\nIf you want to build a hook for this event, you can use the addEventListener() method, again:\nif (!!window.google_tag_manager) { // Google Tag Manager has already been loaded  doSomethingWith(window.google_tag_manager); } else { window.addEventListener(\u0026#39;gtm_loaded\u0026#39;, function() { // Google Tag Manager has been loaded  doSomethingWith(window.google_tag_manager); }); } \nIn this example, the code first checks if GTM has already been loaded. If it hasn\u0026rsquo;t, it creates a new listener on the window object that waits for the gtm_loaded event to bubble up to it. As soon as the Google Tag Manager library has been downloaded and initialized, the event is dispatched and the listener for gtm_loaded will go off.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/sort-custom-dimensions-by-index-number/",
	"title": "#GTMTips: Sort Custom Dimensions By Index Number",
	"tags": ["google tag manager", "gtmtips", "hack"],
	"description": "With a little JavaScript snippet executed in the browser&#39;s JavaScript console, you can reorder the Custom Dimension fields in your Google Analytics tags within GTM by their index numbers, in ascending order.",
	"content": " Here\u0026rsquo;s a hacky #GTMTips tip for you. Have you ever had a Google Tag Manager container, where you\u0026rsquo;ve been updating your Google Analytics tags over the years? And perhaps these tags (and, today, Google Analytics Settings variables) have been updated with an ever-expanding list of Custom Dimensions? And perhaps this list of Custom Dimensions is sorted willy-nilly, because once you have 50+ rows, it just doesn\u0026rsquo;t seem like a fun thing to do to go over each row and update them so that they are sorted by Custom Dimension index?\nNo worries, then! I have a solution for you. It involves a little JavaScript snippet you need to execute in the web browser\u0026rsquo;s JavaScript console, and it will sort the Custom Dimension fields for you!\nTip 77: Sort Custom Dimensions by index number   Here\u0026rsquo;s what you need to do.\n Browse to your Google Tag Manager container, and open the Google Analytics tag or Google Analytics Settings variable you want to modify.\n Make sure the tag or variable is in edit mode, meaning you can see each field as a text field that you can edit.\n Open the JavaScript console of your browser.\n Copy-paste the following snippet in the JavaScript console, and press enter to run it.\n Save the tag or variable.\n  Here\u0026rsquo;s the snippet, make sure you copy all of it (triple-clicking it should do the job):\nvar el=document.querySelector(\u0026#39;[diff-field$=\u0026#34;customDimensionSection\u0026#34;]\u0026#39;);var rows=el.querySelectorAll(\u0026#34;.simple-table-row[data-ng-repeat]\u0026#34;);var newRows=[];rows.forEach(function(row){var inputIdx=row.querySelectorAll(\u0026#39;input[type=\u0026#34;text\u0026#34;]\u0026#39;)[0];var inputVal=row.querySelectorAll(\u0026#39;input[type=\u0026#34;text\u0026#34;]\u0026#39;)[1];newRows.push({idx:inputIdx.value,val:inputVal.value})});newRows.sort(function(a,b){if(parseInt(a.idx)\u0026gt;parseInt(b.idx)){return 1}if(parseInt(a.idx)\u0026lt;parseInt(b.idx)){return-1}return 0});rows.forEach(function(row,i){var inputIdx=row.querySelectorAll(\u0026#39;input[type=\u0026#34;text\u0026#34;]\u0026#39;)[0];var inputVal=row.querySelectorAll(\u0026#39;input[type=\u0026#34;text\u0026#34;]\u0026#39;)[1];inputIdx.value=newRows[i].idx;inputVal.value=newRows[i].val;inputIdx.dispatchEvent(new Event(\u0026#34;change\u0026#34;));inputVal.dispatchEvent(new Event(\u0026#34;change\u0026#34;))});  Just to clarify, being in edit mode should look like this:\n   And you can open the JavaScript console of you browser handily with a shortcut key combination:\n Chrome  Win: Ctrl + Shift + J Mac: Cmd + Opt + J  Firefox  Win: Ctrl + Shift + K Mac: Cmd + Opt + K  Edge  Win: Ctrl + Shift + J  Internet Explorer  Win: F12, then click on the \u0026ldquo;Console\u0026rdquo; tab  Safari  Mac: Cmd + Opt + C, you need to enable the \u0026ldquo;Show Develop menu in menu bar\u0026rdquo; setting in the Advanced pane of Safari\u0026rsquo;s preferences   The snippet basically rewrites each field in the list of Custom Dimensions so that the rows are in ascending order, sorted by index number of each Custom Dimension.\nIf the snippet stops working, please let me know in the comments below and I will update it.\nNaturally, I am anxiously waiting for sorting of fields to be a built-in feature of the Google Tag Manager UI. But until then, we can hack our way around this limitation.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/send-google-analytics-payload-length-as-custom-dimension/",
	"title": "Send Google Analytics Payload Length As Custom Dimension",
	"tags": ["google tag manager", "google analytics", "customtask"],
	"description": "Send the Google Analytics request payload length as a Custom Dimension of the hit. This way you can monitor if you are approaching the maximum size of the payload.",
	"content": " Maybe you knew this, maybe you didn\u0026rsquo;t, but requests sent from your website (or app) to Google Analytics have a maximum size. Or, more specifically, the payload size (meaning the actual content body of the request) has a maximum.\nThis maximum size of the payload is 8192 bytes. This means, basically, that the entire parameter string sent to Google Analytics servers can be no longer than 8192 characters in length. The thing is, if the payload exceeds this, Google Analytics simply drops the hit. There\u0026rsquo;s no warning, no error, nothing. The hit just doesn\u0026rsquo;t get sent. If you are running the Google Analytics debugger browser extension, you can actually see a warning when the payload size is exceeded:\n  If you see this warning, it means that the hit was aborted due to exceeding the 8192 length of the payload.\n Note that if you are using Measurement Protocol to directly send data to Google Analytics, this size limitation applies to the POST request body. If you are sending the data with a GET request, the maximum size of the entire /collect URL is 8000 bytes.\n Anyway, in this article I\u0026rsquo;ll show you how to send the payload size (or at least a very close approximation thereof) as a Custom Dimension to Google Analytics with each hit. That way you\u0026rsquo;ll be able to check if you are approaching this limitation, and thus you can take precautions to avoid exceeding the maximum size. We\u0026rsquo;ll get things done with customTask (what else?) and Google Tag Manager.\n UPDATE: Check out Angela Grammatas\u0026rsquo; excellent article on the very same topic. She uses a slightly different tactic, appending the data in the buildHitTask, which works just as well.\n IMPORTANT REQUEST Before I get started, I have a request to make. Some time ago, I was contacted by someone (Googler, I think), who shared with me a similar solution. For the life of me, I can\u0026rsquo;t find this communication anywhere, because I don\u0026rsquo;t even remember what medium I was contacted over (I\u0026rsquo;ve gone through my mailbox to no avail).\nThis solution was definitely inspired by this person\u0026rsquo;s idea, so I want to give credit where credit is due. So, if you remember approaching me with a solution you used to work on that did something similar, please be in touch and I will update this article with my thanks for your inspirational example.\nSend the hit payload length using customTask If you don\u0026rsquo;t know what customTask is, please check out my guide on the topic. In a nutshell, customTask lets you modify, among other things, the request sent to Google Analytics before it is sent, adding information dynamically to the payload. This information could be anything from a PII-purged payload to the Client ID.\ncustomTask works with a Custom JavaScript variable. To send the hit payload length as a Custom Dimension, you\u0026rsquo;ll first need to create a new hit-scoped Custom Dimension in Google Analytics admin. Once you\u0026rsquo;ve created it, make note of the index assigned to the new dimension.\n  Then, in Google Tag Manager, create a new Custom JavaScript variable. Name it something descriptive, e.g. customTask - hit payload length. This is what you should add within:\nfunction() { // Change this index to match that of the Custom Dimension you created in GA  var customDimensionIndex = 10; return function(model) { var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; var originalSendHitTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { try { var originalHitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var customDimensionParameter = \u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex; // If hitPayload already has that Custom Dimension, note this in the console and do not overwrite the existing dimension  if (hitPayload.indexOf(customDimensionParameter + \u0026#39;=\u0026#39;) \u0026gt; -1) { console.log(\u0026#39;Google Analytics error: tried to send hit payload length in an already assigned Custom Dimension\u0026#39;); originalSendHitTask(sendModel); } else { // Otherwise add the Custom Dimension to the string  // together with the complete length of the payload  hitPayload += customDimensionParameter + \u0026#39;=\u0026#39;; hitPayload += (hitPayload.length + hitPayload.length.toString().length); sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload, true); originalSendHitTask(sendModel); } } catch(e) { console.error(\u0026#39;Error sending hit payload length to Google Analytics\u0026#39;); sendModel.set(\u0026#39;hitPayload\u0026#39;, originalHitPayload, true); originalSendHitTask(sendModel); } }); }; }  To configure this customTask, you just need to update the customDimensionIndex variable with the index number of your Custom Dimension (in my example, the index is 10).\nThis function interrupts sendHitTask, which is the task used to actually send the request to Google Analytics. The payload sent to Google Analytics is appended with the Custom Dimension you have created, and the value of that Custom Dimension is set to the entire length of the payload. Thus, when a tag that uses this customTask fires, the request to Google Analytics will contain the length of the payload as the value of the Custom Dimension you assigned for it.\nTo add it to your tag(s), either use a Google Analytics Settings variable or override the settings of any tag. Scroll down to More Settings \u0026gt; Fields to set, and add a new field.\nField name: customTask\nValue: {{customTask - hit payload length}}\n  Now any tag that has this field set will add the hit payload length as a Custom Dimension to the request.\nYou can verify this by opening the Network tab of your browser\u0026rsquo;s developer tools. The tag is represented by a request to /collect, and by clicking this request you can see that the Custom Dimension parameter is included with the length of the payload:\n  Other ideas You could actually rewrite the customTask to add some further logic if you are nearing the 8192 byte maximum size. For example, it doesn\u0026rsquo;t really help you to add the payload length as a Custom Dimension, if the payload is never sent due to exceeding the size requirement.\nBy adding some custom code, you could do things like:\n When payload length is at or over 8192 bytes, drop unnecessary fields from the payload until the length is under the limit.\n When payload length is at or over 8192 bytes, send a new hit to Google Analytics which contains some key information from the \u0026ldquo;broken\u0026rdquo; payload, just so that you\u0026rsquo;ll get an idea of the scope of the problem.\n  A typical reason for exceeding payload length is if you are sending Enhanced Ecommerce impression data, or just very large shopping carts. It only takes something like 50-60 products for you to be approaching the limit of 8192 bytes. Unless you can decrease the size of the product payload using regular means, you could do something like drop all non-critical fields from the product objects (e.g. brand, category, variant), and just include the id, name, price, and quantity.\nOr you could drop all product data except for id in these cases, and then use Data Import to refresh the additional data.\nSummary Well, it looks like customTask to the rescue again. It\u0026rsquo;s such a powerful feature, and I just love the fact that you can get all meta with your Google Analytics data.\nPeppering the payload with details that are otherwise obfuscated is a great way to add a whole new level of debugging opportunities to your data collection.\nHit payload size limit is nasty in that you won\u0026rsquo;t be alerted if a problem surfaces. The Google Analytics UI won\u0026rsquo;t be able to inform you about this problem because the requests are never sent to GA in the first place. With this Custom Dimension, you can add this information to the payload as a Custom Dimension, and then prepare in advance for the eventuality that you might be hitting the payload maximum size sometime soon.\n"
},
{
	"uri": "https://www.simoahava.com/test-page/",
	"title": "Test page",
	"tags": [],
	"description": "",
	"content": " #wrapper { height: 100%; width: 100%; display: table; } #top { height: 50%; background-color: #5B9BD5; width: 100%; display: table-row; } #bottom { height: 50%; background-color: #fff; width: 100%; display: table-row; } #greeting { color: #fff; font-family: Lobster,sans-serif; font-size: 2em; vertical-align: bottom; text-align: center; display: table-cell; padding: 10px; } #subscribe { vertical-align: top; text-align: center; display: table-cell; padding-top: 20px; }\n#email-field { width: 700px; height: 50px; color: #838383; font-size: 3em; padding: 5px; border: 2px dotted #ddd; font-family: sans-serif; } #subscribe-button { background-color: #f08406; border: 1px solid #ad5d15; -webkit-box-shadow: inset 0px 1px 0px rgba(255,255,255,0.4); -moz-box-shadow: inset 0px 1px 0px rgba(255,255,255,0.4); box-shadow: inset 0px 1px 0px rgba(255,255,255,0.4); text-shadow: 0px 1px 1px rgba(0,0,0,0.4); color: #fff; padding: 15px 25px; -webkit-border-radius: 6px; -moz-border-radius: 6px; -ms-border-radius: 6px; -o-border-radius: 6px; border-radius: 6px; font-size: 16px; font-weight: bold; font-family: sans-serif; margin-top: 20px; } #thanks { text-align: center; vertical-align: top; padding-top: 20px; font-family: helvetica; font-size: 3em; color: #5B9BD5; } #nothanks a { vertical-align: middle; padding: 10px; font-family: sans-serif; text-decoration: underline; color: #5B9BD5; }  Subscribe NOW to make millions $$$    No thanks, I don\u0026rsquo;t want to make money   \n"
},
{
	"uri": "https://www.simoahava.com/analytics/use-wildcard-css-selectors-with-all-elements-triggers/",
	"title": "#GTMTips: Use Wildcard CSS Selectors With All Elements Triggers",
	"tags": ["google tag manager", "gtmtips", "css selectors"],
	"description": "Use the wildcard (*) CSS selector with the All Elements trigger in Google Tag Manager. This improves the accuracy of capturing clicks on the target elements.",
	"content": " When using the All Elements trigger in Google Tag Manager, it\u0026rsquo;s easy to overlook the fact that it captures all clicks on the page. It\u0026rsquo;s also brutally accurate - it captures clicks on the exact element that was below the mouse button when a click happened. This means that when working with the All Elements trigger, you need to be more careful when identifying the correct element you actually want to track clicks on.\nIn this short guide, I\u0026rsquo;ll show you a simple trick to make sure you always capture clicks on a given element, regardless of what the surrounding HTML structure looks like. All this requires is a simple tweak to the CSS selector you use in the trigger.\nTip 76: Use the wildcard CSS selector with All Elements triggers   The wildcard selector literally means any descendant of the preceding selector. So given a selector like div#nav * would match any elements that are nested with a \u0026lt;div id=\u0026quot;nav\u0026quot;\u0026gt; element, but not the \u0026lt;div\u0026gt; element itself.\nLet me show you a useful example.\n\u0026lt;div id=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;logo\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;/images/logo.png\u0026#34; /\u0026gt; \u0026lt;span\u0026gt;Back home\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; In this scenario, let\u0026rsquo;s say you want to track clicks on \u0026lt;div id=\u0026quot;logo\u0026quot;\u0026gt;, regardless of whether the click falls on the image element or the span.\nIf you try to do it with an All Elements trigger that has either of the following conditions, it won\u0026rsquo;t work:\n Click ID equals logo\n Click Element matches CSS selector div#logo\n  Why not? Because the click will not land on the \u0026lt;div\u0026gt;. Rather, it will land on one of the nested elements, because they are block-level elements that actually fill the wrapping \u0026lt;div\u0026gt; completely. Thus there\u0026rsquo;s no area left in the \u0026lt;div\u0026gt; itself that could be clicked!\nSo, you need to instruct the trigger to track clicks on the \u0026lt;div\u0026gt; itself (this is a good precaution in case there\u0026rsquo;s additional padding that does introduce surface area to the \u0026lt;div\u0026gt;, too) and any of its nested elements. This is where the wildcard selector comes in handy.\nThe selector you\u0026rsquo;ll need to use looks like this:\nClick Element matches CSS selector div#logo, div#logo *\nThis literally means:\n Track clicks that land on a \u0026lt;div id=\u0026quot;logo\u0026quot;\u0026gt; element, or any element nested within this \u0026lt;div\u0026gt;.\n I\u0026rsquo;ll go so far as to say that whenever you use the All Elements trigger, always use this element, element * syntax. That way you\u0026rsquo;ll always be able to track clicks on the appropriate element, regardless of the nested HTML structure.\nThe only edge cases I can think of is if you really want to track clicks on the borders of the wrapping element alone and not anything nested within, but I\u0026rsquo;m having trouble justifying this use case in a real-world scenario. But in case you do want to track clicks specifically on a wrapping element, just drop the wildcard selector and simply use div#logo as the only selector.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/add-facebook-messenger-chat-google-tag-manager/",
	"title": "#GTMTips: Embed Facebook Messenger Chat With Google Tag Manager",
	"tags": ["google tag manager", "gtmtips", "facebook"],
	"description": "A quick guide on how to add the Facebook Messenger Chat plugin to your website using Google Tag Manager.",
	"content": " A while ago, I published a #GTMTips article, where I showed how you can add HTML elements to the page programmatically using Google Tag Manager. This is relevant because GTM\u0026rsquo;s validators prevent you from adding custom parameters to HTML elements that are injected directly via the Custom HTML tag. To circumvent this validation, you need to create the element programmatically, before appending it to the document.\nA while ago, Matteo Gamba asked me a question related to the Facebook Customer Chat Plugin. This plugin lets you add the Messenger chat of your own Facebook application directly to the website. It\u0026rsquo;s pretty cool, but the problem is that you are instructed to embed the plugin using custom HTML attributes, and these will not pass validation.\ncool thanks!\nIt might make sense for you to cover this topic with a dedicated post... basically anyone that will try to use GTM to install the messenger chat will incur into this problem 😉\n\u0026mdash; Matteo Gamba (@sliver86) March 18, 2018  So here I am, responding to the suggestion to write a dedicated guide for the Facebook chat plugin.\nTip 75: Embed the Facebook Messenger chat plugin using Google Tag Manager   First of all head on over to the official Facebook Custom Chat Plugin instructions, and do everything instructed until you reach Step 2 of the setup steps part of the guide.\nAt this point, you are instructed to add a specific \u0026lt;div\u0026gt; to the page. So what you\u0026rsquo;ll need to do is create a new Custom HTML tag in Google Tag Manager, with the following code within:\n\u0026lt;script\u0026gt; (function() { // Modify the variable values below  var page_id = \u0026#39;12345678\u0026#39;; var ref = \u0026#39;\u0026#39;; var theme_color = \u0026#39;#2B913F\u0026#39;; var logged_in_greeting = \u0026#39;Hello, logged in user! Welcome to my chat.\u0026#39;; var logged_out_greeting = \u0026#39;Hello, logged out user! Welcome to my chat.\u0026#39;; // Don\u0026#39;t touch the code below  var el = document.createElement(\u0026#39;div\u0026#39;); el.className = \u0026#39;fb-customerchat\u0026#39;; el.setAttribute(\u0026#39;page_id\u0026#39;, page_id); if (ref.length) { el.setAttribute(\u0026#39;ref\u0026#39;, ref); } el.setAttribute(\u0026#39;theme_color\u0026#39;, theme_color); el.setAttribute(\u0026#39;logged_in_greeting\u0026#39;, logged_in_greeting); el.setAttribute(\u0026#39;logged_out_greeting\u0026#39;, logged_out_greeting); document.body.appendChild(el); })(); \u0026lt;/script\u0026gt; Change the five variable values in lines 4-8 of the code. If you don\u0026rsquo;t have a custom webhook accepting requests from postbacks and referrals, you can leave the string empty.\nCreate a new DOM Ready trigger for this Custom HTML tag. The trigger should be delimited to only firing on pages where you want to see the chat plugin.\n   And that should do it! The code builds the required \u0026lt;div\u0026gt; element programmatically, using the variables you configured in lines 4-8 to populate the parameters.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/definition-of-success/",
	"title": "Definition Of Success",
	"tags": ["agile", "analytics", "definition of success"],
	"description": "How do you define success as part of a software development project? How do you measure success? How do you integrate parameters of success into analytics done within a project?",
	"content": " Agile analytics isn\u0026rsquo;t a novel concept in any shape or form. Things like feedback loops and process-oriented development seem to integrate flawlessly into the analytics paradigm, at least on paper. Heck, there\u0026rsquo;s even the Build-Measure-Learn framework for continuous development. It would be difficult to argue that analytics doesn\u0026rsquo;t have a role in something with measure in the name!\nHowever, past three years of working at Reaktor, one of the world\u0026rsquo;s top agile technology houses, have introduced me to a whole new set of problems with integrating an \u0026ldquo;analytics mindset\u0026rdquo; into an agile workflow, or an \u0026ldquo;agile mindset\u0026rdquo; into the analytics process.\nThe crux of the matter is how to negotiate the time-boxed methodology of a sprint with the ever-fluctuating and contextual parameters of change. To put it succintly: it\u0026rsquo;s difficult to measure the impact of development work in a way that would establish a robust feedback loop.\n  One of the main things working against agile analytics is the very thing that fuels sprints in general: the Definition of Done (DoD). In Scrum, one of the most popular agile frameworks, DoD is basically a checklist of things that each task/feature/sprint must pass in order for the sprint to be deemed a success. DoD has a lot of things working for it:\n It\u0026rsquo;s negotiated by everyone in the team.\n It\u0026rsquo;s not monolithic.\n It\u0026rsquo;s adjusted to better respond to an ever-changing business context.\n It quantifies the success of the agile workflow.\n  In previous posts and talks on the topic, I have recommended adding Analytics as part of the DoD in any development project. By having analytics as a keyword in the DoD, the idea is that when developing features, the ever-important question of \u0026ldquo;Should we measure this?\u0026rdquo; would always be considered. \u0026ldquo;No\u0026rdquo; is a perfectly valid answer to this question - it doesn\u0026rsquo;t make sense to measure everything. But what\u0026rsquo;s important is that this discussion is had in the first place.\n  Anyone working in analytics can share anecdotes of times when they wanted to check some usage statistics from the available data, only to discover that the necessary tags were never deployed to begin with. By adjusting the DoD, this can potentially be avoided.\nHowever, having a Definition of Done has proven to be inadequate for establishing goals fuelled and validated by measurement. Even though a sprint or a feature branch can be deemed done by the criteria established in the DoD, it still doesn\u0026rsquo;t mean that the feature was a success.\nDoing the right things vs. doing things right It\u0026rsquo;s tempting to think of an equivalence between something being done and something being completed. However, I argue that there\u0026rsquo;s a distinction between the two. The first can be formalized with tools such as the Definition of Done. The second one is harder to pin down, because it requires consideration of what is successful.\n Yeah, I can do inspirational images, too!  Consider the following story in a backlog:\n Implement a single-page checkout flow.\n A feature like this could have a very clear Definition of Done, and it would be very easy to validate if this feature can be shipped:\n Test coverage has been updated to include the new code.\n Documentation has been written to cover how the new checkout works.\n Deployment to production is successful.\n The new checkout is measured in Google Analytics.\n The new checkout is deployed to 50% of visitors (A/B test).\n  The new checkout is done when it passes these requirements. The team members working on the new checkout can look at these steps and plan their work accordingly.\nBut what determines if the new checkout flow is a success? It\u0026rsquo;s a technical success once deployed to production, but what actually validates that the new checkout brings added value to the organization?\nA new set of criteria need to be devised for this purpose. These criteria need to take into account the following things:\n Success is subjective. Different stakeholders might have different ideas for what qualifies as a success.\n Success is temporal. What is successful today, might not be successful tomorrow, especially in a constantly evolving and changing business landscape.\n Success is non-binary. It\u0026rsquo;s not always possible to pass a true / false verdict for the success of a developed feature. Sometimes there are varying degrees of success.\n  Definition of Done is a great tool, because it guides us to do things right. However, it lacks the scope to guide us in the prioritization of the tasks at hand. It lacks the ability to determine if we\u0026rsquo;re doing the right things.\n  A Definition of Success for the example in this chapter could be something like:\n This migration is successful for the team when the checkout flow has been deployed to production.\n This migration is successful for the client when the A/B test shows statistically significant results that the new checkout increases revenue per user.\n This migration is successful for the end user when the new flow decreases checkout abandonment.\n  If we take this thought experiment to its conclusion, we\u0026rsquo;ll find that completion stems from the union of a feature being done and a feature being done successfully. It\u0026rsquo;s possible for these two to overlap, such as in the success criterion for the team above, and it\u0026rsquo;s possible that success is impossible to determine for certain features and some particular stakeholders.\nDefinition of Success Definition of Success is a series of questions you ask when prioritizing (grooming) or adding new stories to the backlog. The questions are:\n If this feature is developed, what determines whether it is a success to the end user?\n If this feature is developed, what determines whether it is a success to the project owner / client?\n If this feature is developed, what determines whether it is a success to the team?\n  By asking these questions, you are forced to think about the impact of your project work, not just the outcome. Optimally, impact is something you can measure - something that you can use data and analytics to validate with. But it\u0026rsquo;s perfectly fine to establish success criteria as something more ephemeral.\nLet\u0026rsquo;s take a look at some examples.\n   Feature DoS (end user) DoS (client) DoS (team)     Single-page checkout Drop in Checkout Abandonment Increase in Revenue per User Deployed successfully to production   Migrate from AWS to Google Cloud ??? Reduced costs for pipeline management More familiar tools available for pipeline management   Auto-complete site search Find more relevant search results faster Increase in Revenue from site search Improved performance of the search feature   Marketing dashboard More relevant campaigns More visibility to ROI More visibility to ROI    In the first example, establishing success criteria for something with such potential for impact as a new checkout flow is fairly easy. We can determine hard-and-fast metrics for success, with clearly defined goals which need to be surpassed for the feature to be a success.\nA very technical task, such as migrating a cloud backend from one service partner to another can be more difficult to align with success criteria. How can the end user validate success for the migration? Sometimes, it\u0026rsquo;s perfectly fine to not have an answer for all three vectors. In fact, only when you can\u0026rsquo;t find success criteria for a single vector should you be concerned about the validity of the feature in the first place.\nThe final example shows that more than one of the three vectors can share the same success criteria. In this case, building a marketing dashboard improves the visibility of marketing efforts, and this is beneficial to the client as well as the team that built the dashboard. The success criterion for the end user is again difficult to pin down. In the \u0026ldquo;long run\u0026rdquo;, more visibility to the current marketing efforts should result in better campaigns for the benefit of the end users as well.\nSuccess === Value In the end, we want to build valuable and value-adding things. We want the value of development work to be, at the very least, a sum of its parts. Optimally, we want to surpass expectations and build features that collaborate to produce unexpected value in unexpected ways.\nOne thing that unites the two streams of completion and success is value in and of itself. A feature can be considered successfully done if it produces a net increase in value to the parties that have a stake in the project.\nBut value can be difficult to measure. It can be defined with the same terminology we use when talking about micro and macro conversions in analytics. There is value that can be directly derived from the development of a feature. Typically this would have a currency symbol in front of it. Then there is value that is indirectly inferred, usually after a passage of time.\nTo refer to the examples earlier in this article, we could say that the new single-page checkout flow has direct value, because we can measure its impact on the revenue generated by the site when compared to the old checkout flow (preferably in an A/B test!).\nSimilarly, we can say that creating a new marketing dashboard has indirect value, because we hope that by making the data more transparent we can help build better campaigns that will eventually increase the value of our marketing process.\nRegardless of how you pin it down, you should always be able to describe good success criteria by using value as a focal point.\nFuzzy success Here\u0026rsquo;s one final thought to wrap up this article.\nI want to emphasize that Definition of Success is a communication tool rather than a set of strict validation criteria. It simply doesn\u0026rsquo;t make sense to block development while waiting for some feature to produce enough usable data to determine what its impact was.\n  Validation of whether a feature was successful or not can take a long time. Think of Search Engine Optimization efforts, for example. It might be months before any statistically (and intuitively) significant results emerge. It wouldn\u0026rsquo;t make sense to block the development of a critical new feature while you wait for this data.\nThus, because of this fuzzy, multi-dimensional definition of success, it\u0026rsquo;s so much more difficult to determine whether something was successful than to check if the development work is done.\nWhat to do, then?\nWell, I\u0026rsquo;ll reiterate: Definition of Success is a communication tool. It\u0026rsquo;s an approach that helps you evaluate development tasks based on their value potential. It\u0026rsquo;s more important as a discussion topic than as a directive that guides your development work (like Definition of Done can be).\nOne thing you can do is the exercise described earlier in this article. Set aside time for a session where the whole team takes a good hard look at the backlog of your project. As a team, try to figure out success criteria for each story still waiting for development work. Remember the three questions:\n If this feature is developed, what determines whether it is a success to the end user?\n If this feature is developed, what determines whether it is a success to the project owner / client?\n If this feature is developed, what determines whether it is a success to the team?\n  You should find that this exercise alone can unearth things about the backlog items you wouldn\u0026rsquo;t have thought of before.\nIf you can come up with quantifiable, measurable metrics of success - all the better. Make sure these are being measured when the features are deployed, and make sure the team knows how to access this data.\nI think this exercise is good for team-building, too. You are communicating together, as a unit, what the long-term value of your work is. It\u0026rsquo;s a great opportunity to build motivation, since success criteria often make your overall goals clearer. You want the project to be a success, too, so making sure that all the tasks outlined in the backlog contribute to the success of the entire project makes a lot of sense.\nSummary I wanted to write this article because I think there\u0026rsquo;s just far too little talk about value and success in daily development work. I bet it applies to marketing teams, too, and not just developers. I bet it applies to business designers, to PR, to recruitment, to business owners, to shareholders, to communities, and to the universal laws that govern our existence!\nIt\u0026rsquo;s difficult to talk about success because it\u0026rsquo;s so subjective. Yet here I am, asking you to deploy a tool designed for general use, where the very focus is on this subjective notion of success.\nBut I guess that\u0026rsquo;s my point. It is subjective, but it\u0026rsquo;s also something you absolutely should devote time to. The discussion should also be extended to the entire team. Everyone involved in project work should understand that there is a whole undercurrent of communication, where team members are actively thinking in terms of value and what it might mean to different stakeholders.\nMaybe I\u0026rsquo;ve lived in a bubble, but it\u0026rsquo;s striking how rarely long-term, quantifiable success is tabled for discussion in agile contexts. I totally understand the focus on time-boxed sprints, where success is the net outcome of multiple sprints that are all \u0026ldquo;done\u0026rdquo; and \u0026ldquo;complete\u0026rdquo;. But I think this ignores the shift in many development team dynamics, where designers, analysts, CROs, SEOs, social media managers, business owners, and sales managers are now also part of the mix. Thinking of development work as something that only involves software developers is so last season.\nThus, when these \u0026ldquo;fuzzier\u0026rdquo; roles are added to the mix, the discussion around things like value and success must be extended to cover other things than \u0026ldquo;test coverage at 100%\u0026rdquo;, \u0026ldquo;peer-reviewed\u0026rdquo;, and \u0026ldquo;well-written code\u0026rdquo;.\nHow this can be done systematically and comprehensively is still on the drawing board. But I do hope this concept of a Definition of Success rings true - at the very least as a discussion topic and thought experiment, if nothing else.\nHuge thanks to my Reaktor colleagues, especially Aleksi Lumme, Jaakko Knuutila, and Matias Saarinen, for their collaboration on fleshing out the Definition of Success.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/guide-zones-google-tag-manager-360/",
	"title": "Guide To Zones In Google Tag Manager 360",
	"tags": ["google tag manager", "gtm360", "zones", "guide"],
	"description": "Guide to Zones in Google Tag Manager 360. You can use Zones to link multiple containers to a website, firing tags, triggers, and variables from all linked containers on the site.",
	"content": " Google Tag Manager supports loading multiple containers on the same page. It\u0026rsquo;s useful if you have multiple companies or organizations working on the same site, but for one reason or another (e.g. governance) you want to restrict access to your main container. In these situations, having the other party create their own container and adding it to the site is the best of bad options.\nWell, in Google Tag Manager 360, we now have Zones that make managing multiple partners\u0026rsquo; containers quite a bit easier.\n  Zones have boundaries, which are basically page rules you can use to restrict Zones to only certain pages or groups of pages. In addition to this, Zones let you define type restrictions for tags, triggers, and variables (similar to gtm.whitelist), which gives you even more control over what these linked containers can and cannot run on your site.\nWhy use Zones? Zones lets you link multiple containers to a single site. However, instead of allowing the linked container to fully fire its tags and triggers, you can restrict access to the site on two fronts:\n Boundaries let you specify page rules. The defined Zone is only active (i.e. the containers are only linked) on pages which pass these rules. For example, you could restrict a marketing agency\u0026rsquo;s container to firing only on the landing pages they have created.\n Type Restrictions allow only certain tags, triggers, and variables to work on the page. This is useful if you want to prevent linked containers from running Custom HTML tags or Custom JavaScript variables, for example.\n    A linked container will thus be able to fire any of its tags, triggers, and variables that have not been restricted on pages that are included in the Zone Boundary.\nCreate a new Zone To create a new Zone, click the Zones entry in the navigation, and then the red NEW button.\n  Naturally, you can have more than one Zone defined in your container, and your Zones can have more than one container linked to each Zone.\nLink a container to a Zone In the Zone settings, you can link a new container to the Zone by clicking the Zone Configuration field to enter the edit mode. Then, either click the No linked containers box (if there are no containers yet linked), or the blue plus button to open the container link overlay.\n  In the overlay that opens, you can either click the add container icon, which opens a list of containers you have access to in the current account, or you can just type any container ID to the Container ID field. Remember to give the container a nickname that will help you identify it when looking at the Zone settings.\nYou can even click the add container icon to open the list of containers you have access to, and instead of selecting an existing container, you can click the blue plus button in the corner to create a brand new container within this workflow!\n  Once you\u0026rsquo;ve selected the container, click ADD to add it to the current zone.\n  There are precautions in place to prevent infinite loops (such as adding the current container as a linked container) and too complex links (such as linking a container that links a container that links a container that links a container).\nA word on governance If you choose a container to which you have access, you\u0026rsquo;ll see some additional Container Details in the container selector overlay.\n  This overview lets you inspect what the Latest and Published versions look like. The latter is especially relevant, since that is the container that will be linked to on the site itself. You can also check which users have access to the linked container. These are all, in my opinion, necessary features for enhancing transparency of the workflow.\nThe fact that you can inspect and modify the users of the linked container means that you can set everything up for the zone within the workflow, without having to pogo between different GTM admin views.\nAll in all, you might find it strange that you can just add any container ID you want into the Zone. In other words, you can pull any container in existence and have it fire tags, triggers, and variables on your site!\nWell, when you think about it, that\u0026rsquo;s how GTM works. Nothing\u0026rsquo;s stopping you from adding a container snippet from any container in existence to your site, and nothing\u0026rsquo;s stopping you from linking a container into your Zone, either.\nIt\u0026rsquo;s possible this might lead to governance issues, but the Type Restrictions and Boundaries exist to somewhat alleviate the friction that emerges from this open setup.\nNothing trumps communication, though. Even with Zones, I still suggest you work on improving communication structures within your organization and with your partners. You\u0026rsquo;ll also need to establish a contingency plan for when something goes awry in a linked container.\nAdd some Boundaries Boundaries are page rules. Page rules are conditions that a page needs to meet for the rule to pass.\nThis means that these conditions must exist when the Google Tag Manager container loads. In other words, you can\u0026rsquo;t establish a condition like \u0026ldquo;Once the user clicks button X, activate this Zone\u0026rdquo;. Though, see the next chapter for an exception.\n  In the image above, All Pages is a good Zone Boundary, and Page Path contains /campaign/ is a good Zone Boundary. These conditions can be checked when the page loads.\nEvent equals gtm.click is not a good Zone Boundary, because when the page rules are evaluated, {{Event}} will not equal gtm.click.\nCustom Evaluation However, there is an exception to how Boundary conditions are evaluated. If you have a single-page app, or otherwise need to re-evaluate the Boundary conditions upon certain events (such as a Custom Event trigger to signal the page transition), you can click the little dot-menu and select Show custom evaluation. When you click it, you\u0026rsquo;ll see a new view, which you can use to add triggers which, when fired, will cause the Zone to re-evaluate the Boundary conditions.\n  As you can see, by default the trigger used to evaluate the Boundary conditions is All Pages. In other words, the conditions listed in the Boundary settings need to be present when the Google Tag Manager container first loads.\nHowever, by adding other triggers to this list, the Boundary conditions will be re-evaluated when the triggers fire. So if you have a single-page app, for example, the following process could happen:\n When the container first loads, the page path is /, and thus the Zone is not active.\n When the user then clicks a link to the campaign page, the single-page app changes the URL to /campaign/ without a page load.\n  Now, since the URL changes without a page load, GTM would not re-evaluate the Zone Boundary by default, since it only does so when the All Pages trigger fires upon initial container load.\nBy adding a trigger to this Custom Evaluation list, you can force GTM to re-evaluate the Boundary conditions, perhaps activating the Zone if the conditions pass.\nFor example, here\u0026rsquo;s me using a History Change trigger to force GTM to re-evaluate the Boundary condition upon a browser history event, which is very common with single-page transitions.\n  If the history event changes the page URL to /campaign/, the Zone will become active.\nType Restrictions By default, linked containers work with full capacity. When a container is linked in an active Zone, the container has full freedom to operate just as if it had been added to the page directly.\nWith Type Restrictions, you can delimit the Zone to only permit certain types of tags, triggers, and variables to function in the Zone. To enable Type Restrictions, switch the toggle on.\n  These are the default Type Restrictions that are in place if you toggle Type Restrictions on:\n All Google tag types are enabled. Google tag types are tags for Google products such as Google Analytics, Adometry, DoubleClick, and AdWords.\n All trigger types are enabled.\n All variable types except Custom JavaScript variable are enabled.\n All other tag types are disabled.\n  Most importantly, this means that Custom HTML tags and Custom JavaScript variables are disabled by default. Thus, when toggling the Type Restrictions on, be aware that most containers will have limited functionality.\nSimilarly, if you disable trigger and variable types, do note that containers can have very complex chains of trigger and variable evaluation. By disabling a single type, you can potentially disrupt all the functionality in a linked container.\nAgain, I stress the importance of communication. It can be a very good idea to restrict only certain types of tags, triggers, and variables to fire in the Zone, but you need to make sure you know what the situation in linked containers is before arbitrarily blocking their core functionality.\nTo add or remove Type Restrictions, first click the main type selection. This opens an overlay where you can toggle individual tag, trigger, and variable types on or off. You can also click the ALLOW ALL / RESTRICT ALL button to perform the respective selection action.\n  Preview Zones Preview mode has some extra functionality, too. When you preview the container you defined the Zone in, Preview mode will show you whether or not the Zone is currently active. An active Zone means that any linked container will be able to fire its tags, triggers and variables (as long as Type Restrictions allow them to do so).\n  You can click the Zone in Preview mode to see details about it, such as what linked containers it holds and what Type Restrictions are in place.\nZones that are not active will display as Inactive in Preview mode.\n  If there is a Custom Evaluation rule that changes the activity status of the Zone, then it will change from Inactive to Active in Preview mode.\nIf you have a linked container in Preview mode, too, and you have access to the Preview in your browser, then you\u0026rsquo;ll see a drop-down menu in the Preview mode pane. This allows you to switch to Preview mode for the linked container, if you so wish.\n  Note that if you do not have access to the linked container, you will not have any visibility to what happens within, Preview mode or not.\nSummary I think Zones are a very elegant solution to the problem of access control rights and running multiple containers on the site. Until now, it\u0026rsquo;s been tempting to just add multiple containers to the page when working with partners who might have a different approach to container governance than you do.\nZones don\u0026rsquo;t fix governance issues, but they do provide you with more tools to facilitate governance.\nThe main problem with Zones is that you lack visibility to a linked container. This is understandable, since it would open a completely different can of worms if you had visibility to containers that you can arbitrarily add to your site.\nFor linked containers to which you do have access, you can always put them in Preview mode, which lets you see what\u0026rsquo;s going on when the Zone is active.\nYes, it\u0026rsquo;s a bummer this is only for Google Tag Manager 360. On the other hand, this is most certainly an enterprise feature, which means it makes sense to package it under a paid plan, together with SLA and other support, too. And it\u0026rsquo;s not like this is a must-have feature for most. Zones or no Zones, a single-container setup is still the preferred way of working with Google Tag Manager, at least in my opinion.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/check-container-id-with-eventcallback/",
	"title": "#GTMTips: Check Container ID With eventCallback",
	"tags": ["google tag manager", "gtmtips", "eventcallback"],
	"description": "When using eventCallback with dataLayer.push(), Google Tag Manager automatically passes the container ID which invoked the callback as an argument. Use this to run code against the correct container.",
	"content": " When you use the dataLayer.push() command on a page with a Google Tag Manager container, you pass information to GTM\u0026rsquo;s internal data model and potentially fire tags (if the push() contained an event key). You can also add the eventCallback key to these pushes. The value of this key should be a function, and this function is then executed once the container finishes processing any tags that might have fired on that dataLayer.push().\nThis is useful if you want to give Google Tag Manager time to complete its operations before proceeding with other actions on the page, for example.\nThere\u0026rsquo;s a wrinkle, though. Because Google Tag Manager supports adding multiple containers to the page, the eventCallback is called once for every single container on the page.\n\u0026ldquo;But I don\u0026rsquo;t use multiple containers on the page\u0026rdquo;, I hear you exclaim. Good for you! However, if you are running an Optimize experiment on the page, or if you are also loading gtag.js, eventCallback will be invoked once per each implementation thereof, too. Why? Because they use Google Tag Manager as the underlying tech.\nIn this tip, we\u0026rsquo;ll learn how to detect which Google Tag Manager container invoked the callback and use that to effectively deduplicate the execution of our code.\nTip 74: eventCallback automatically receives the Container ID as the method argument   The tip is simple (as these things usually tend to be). The Google Tag Manager container ID (e.g. GTM-12345) which invoked the eventCallback method will be automatically passed as a parameter to the function you have set up as the eventCallback.\nIf you have multiple containers on the page, eventCallback will fire once for each container, once they finish firing whatever tags the dataLayer.push() triggered. Each time a container invokes the eventCallback method, its container ID will be the argument.\nAs an example, let\u0026rsquo;s say I have three Google Tag Manager containers running on the site.\n Google Tag Manager container with ID GTM-12345\n Google Optimize container with ID GTM-23456\n gtag.js library collecting to UA-12345-1\n  Next, I\u0026rsquo;ll run the following code in the JavaScript console:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ event: \u0026#39;GTMEvent\u0026#39;, eventCallback: function(containerId) { console.log(\u0026#39;Container ID: \u0026#39; + containerId); } });  The output in the console looks something like this:\nContainer ID: GTM-12345 Container ID: GTM-23456 Container ID: UA-12345-1 As you can see, with each iteration of the callback, the container ID was automatically assigned as an argument to the function. With this information, it\u0026rsquo;s easy to deduplicate your eventCallback method so that it only reacts to the \u0026ldquo;correct\u0026rdquo; container.\nFor example, here I want to execute some code only when GTM-12345 invokes the callback:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ event: \u0026#39;GTMEvent\u0026#39;, eventCallback: function(containerId) { if (containerId === \u0026#39;GTM-12345\u0026#39;) { // Run some code  } // Ignore if not GTM-12345  } });  By simply checking what the container ID passed as an argument was, it\u0026rsquo;s trivial to make sure your eventCallback code isn\u0026rsquo;t executed over and over again with each additional container on the page.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/customize-scroll-depth-trigger/",
	"title": "Customize The Scroll Depth Trigger In Google Tag Manager",
	"tags": ["google tag manager", "scroll depth", "triggers", "javascript"],
	"description": "Some tips and tricks on how to customize the scroll depth trigger in Google Tag Manager.",
	"content": " Last updated 9 March 2018 with some new tips.\nThe Scroll Depth trigger in Google Tag Manager has a lot going for it. Tracking how far users scroll down a given page has long since been recognized as an important cog in the engagement tracking machine, and there have been really great solutions for implementing scroll depth tracking for web analytics over the years.\nWith Google Tag Manager\u0026rsquo;s native Scroll Depth trigger, it\u0026rsquo;s tempting to think we now have a be-all end-all solution that covers all the bases. However, as with everything else in analytics, the native scroll depth trigger does require customization to provide you with relevant information about your content and the visitors interacting with it.\n  In this article, I\u0026rsquo;ll explore some tricks that you might find useful when customizing the scroll depth trigger.\n1. Variable percentages depending on page The easiest customization you can make is to track different percentages depending on the page in question. For example, on article pages in my blog I might be interested in tracking in increments of 25% of vertical depth scrolled. But on list pages and summary pages I might only be interested in knowing who scrolls down to the bottom.\nThe Vertical Scroll Depths and Horizontal Scroll Depths fields require a number or a list of numbers (comma-separated) to work. Thus you can easily use a Custom JavaScript variable to return one list of numbers for a certain condition, and a different list of numbers for some other condition.\nFor example, here\u0026rsquo;s a Custom JavaScript variable that does what I described in the first paragraph of this chapter.\nfunction() { return {{Page Path}}.indexOf(\u0026#39;/analytics/\u0026#39;) \u0026gt; -1 ? \u0026#39;25,50,75,100\u0026#39; : \u0026#39;75,100\u0026#39;; }  This variable returns the string 25,50,75,100 if the page URL contains /analytics/, and 75,100 otherwise. Thus, on blog pages, it will measure scroll depth in increments of 25 percent, but on other pages only scrolling up to 75% and 100% in depth.\nThen you can just add this variable to the trigger like so:\n  You don\u0026rsquo;t have to use a Custom JavaScript variable. I\u0026rsquo;m quirky in that I prefer to use it, always. But you could just as well use a RegEx Table variable to achieve the same thing:\n  This is a simple customization, but it does allow you to measure relevant metrics for pages where it makes sense.\n2. Only fire the scroll depth trigger on relevant pages This should be a no-brainer, too. It might make sense to have the scroll depth trigger fire your tags only on pages where you are genuinely interested in scroll depth tracking. For example, I\u0026rsquo;m actually only interested in knowing how far users scroll on my blog pages and nowhere else. Thus I could make this simple modification to the trigger to delimit its firing capabilities:\n  A very simple modification but helps you collect only meaningful data.\n2.1. Prevent the Scroll Depth trigger from activating As you can see, there\u0026rsquo;s no \u0026ldquo;Enable when\u0026hellip;\u0026rdquo; option on the Scroll Depth trigger, similar to what you might see with a Just Links trigger, for example. Thus you might be tempted to think that there\u0026rsquo;s no way to prevent those pesky gtm.scrollDepth events from populating the dataLayer on pages where you are not interested in tracking scroll depths.\nHowever, there\u0026rsquo;s a very easy hack to make sure the trigger doesn\u0026rsquo;t push anything to dataLayer. Just set the percentage threshold to 101. It\u0026rsquo;s impossible to scroll to 101% length of the page, so by setting the threshold to this you\u0026rsquo;ll deactivate the trigger, effectively.\nThus you could modify #2 above by putting the following Custom JavaScript variable into the Percentages field of the trigger:\nfunction() { return {{Page Path}}.indexOf(\u0026#39;/analytics/\u0026#39;) \u0026gt; -1 ? \u0026#39;25,50,75,100\u0026#39; : \u0026#39;101\u0026#39;; }  This sets the thresholds to \u0026lsquo;25,50,75,100\u0026rsquo; on pages where the URL contains /analytics/, and \u0026lsquo;101\u0026rsquo; elsewhere.\n3. Only fire tags on pages where thresholds are not auto-collected One problem with the Scroll Depth trigger is that it doesn\u0026rsquo;t care if the page is long or short. If you have a very short page, it\u0026rsquo;s possible that all the thresholds are met when the page is loaded, which leads to a bunch of gtm.scrollDepth events pushed into dataLayer, firing your tags even though the user never scrolled!\n  Luckily there\u0026rsquo;s a nifty trick we can use to fight this. We can prevent the Scroll Depth trigger from functioning on pages where the ratio between browser viewport height and page height is too high. The browser viewport is the area of the web browser that is filled by your page. The page itself is the entire document, parts of which are likely to be invisible below the fold of the viewport.\nThe higher the ratio between the height of the visible viewport and the height of the page, the less there is to scroll. For example, if the visible viewport is 400 pixels in height, and the page height is also 400 pixels, there is nothing to scroll. The entire page will be visible in the viewport, and any vertical thresholds you have defined in the Scroll Depth trigger will auto-fire.\nSo, if you want to only fire the trigger when the user actually scrolls to 25%, 50%, 75%, and 100%, you need to make sure the ratio between the visible viewport height and the page height is less than 0.25. This means that less than 25% of the page is visible in the browser viewport.\nTo do this, you need to create a Custom JavaScript variable that looks like this:\nfunction() { // Change this to reflect the percentages or pixels you want to fire the trigger for  var verticalScrollDepths = \u0026#39;25,50,75,100\u0026#39;; // Change this to the MAXIMUM ratio of viewport height / page height you want the trigger to activate for  var maximumRatio = 0.25; // Change this to what thresholds should be tracked if the ratio is more than the maximum  // Leave it at \u0026#39;101\u0026#39; if you want to prevent the trigger from functioning in this case  var fallbackDepths = \u0026#39;101\u0026#39;; var heightOfPage = Math.max(document.body.scrollHeight, document.body.offsetHeight, document.documentElement.clientHeight, document.documentElement.scrollHeight, document.documentElement.offsetHeight); var heightOfViewport = Math.max(document.documentElement.clientHeight, window.innerHeight); var ratio = heightOfViewport / heightOfPage; return ratio \u0026lt; maximumRatio ? verticalScrollDepths : fallbackDepths; }  First thing you\u0026rsquo;ll need to do is edit the verticalScrollDepths variable to reflect the list of thresholds you want to track if the page passes the ratio check.\nThen, edit the maximumRatio to reflect the maximum ratio (between 0 and 1) of the height of the visible viewport vs. height of the actual page. A value of 0.25 would mean that at most 25% of the page can be visible in the viewport when the page is loaded.\nFinally, edit the fallbackDepths variable to give a \u0026ldquo;default\u0026rdquo; value for the cases when the maximum ratio is surpassed. If you want to prevent the Scroll Depth trigger from working at all when the maximum ratio is surpassed, use the value 101, because a depth of 101% can never be tracked.\nThen just add this to the \u0026ldquo;Vertical Scroll Depths\u0026rdquo; field and you should be all set.\nNow the trigger will only fire in cases where the page is long enough to make sense for your tracking.\n4. Track scroll percentages of a specific content element This is a bit trickier, but still doable with some JavaScript magic.\nBy default, the Scroll Depth trigger calculates vertical scrolling depth from the top of the page to the bottom of the page. But you might only be interested in knowing the scroll depths of a specific content element, such as the article body. For example, on my site, I don\u0026rsquo;t really care if users scroll past the article end, through the Disqus comments, all the way to the bottom. But I do care if they scroll to the bottom of the main article body.\nThe way to make this work is to first calculate the height of the HTML element that contains the content whose scroll depths you want to track. Then, you need to check how far from the top of the page this element is. Finally, you need to tell the Scroll Depth trigger to track pixel thresholds that correspond with the desired depths of the content element, and add the distance to the top of the page to those numbers.\nI think it\u0026rsquo;s easier to illustrate.\n  As you can see, the total height of the element is 1200 pixels. If I want to track scroll depth increments of 33%, it means that the respective marks are at 400, 800, and 1200 pixels. Since the top of the content element is exactly 250 pixels from the top of the page, I need to add this number to the thresholds before I feed it into the Scroll Depth trigger, because it measures everything counting from the top of the page. Thus the final pixel depths would be 650, 1050, and 1450 pixels.\nNow, since we don\u0026rsquo;t want to hard-code these into the trigger, as that would lead to a horrible mess to manage (every single page would need its own trigger), we can use a Custom JavaScript variable to dynamically calculate the pixel depths.\nfunction() { // Change the contents of this array to reflect the percentages of scroll depth you want to track  var verticalPercentages = [25,50,75,100]; // Change this to fetch the element you want to track scrolling in  var targetElement = document.querySelector(\u0026#39;div.post-content .main-content-wrap\u0026#39;); var elementHeight = targetElement.offsetHeight; var totalOffsetTop = 0; while (targetElement) { totalOffsetTop += (targetElement.offsetTop - targetElement.scrollTop + targetElement.clientTop); targetElement = targetElement.offsetParent; } return verticalPercentages.map(function(percentage) { return parseInt(elementHeight * (percentage * 0.01) + totalOffsetTop); }).join(); }  You\u0026rsquo;d then need to add this variable reference to the Pixel field in the Vertical Scroll Depths selection of the trigger:\n  This setup calculates dynamically the correct pixel thresholds based on the percentages you wrote in the verticalPercentages array. This way, 0 percent depth is the top of the content element (specified in targetElement), and 100 percent depth is the bottom of the content element.\nWith this workaround, you can get more meaningful measurements on pages which have lots of different content areas filling up the real estate of the document itself.\n4.1. Return the scroll depth percentage of element scrolling One thing missing from #4 is the option to report on the percentages the user scrolled down the element. Because the trigger is setup using pixel depths rather than percentages, the {{Scroll Depth Threshold}} built-in variable will always return the pixel depth the user scrolled past, rather than the respective percentage of scrolling.\nGetting the percentage is actually a bit of a hack. The problem with the Scroll Depth trigger is that it\u0026rsquo;s initialized fairly early in the page load, often before DOM Ready and any dynamically injected content is added to the page. This means that the thresholds of scrolling might be smaller than what the percentages actually would reflect.\nThis is, unfortunately, unavoidable right now. The Scroll Depth trigger has no options to delay its initialization until such a time as the content is completely loaded.\nWhat this also means is that any variables you use to determine the height of the content and, subsequently, what the respective percentages actually reflect, can change from one trigger event to the next. Thus, in order to get the actual percentages used by the Scroll Depth trigger, we\u0026rsquo;ll need to do something that I\u0026rsquo;ve repeatedly instructed to avoid at all costs: implement a side effect in the Custom JavaScript variable.\nBasically, we\u0026rsquo;ll need to store the scroll thresholds in a global variable when the Custom JavaScript variable is first run. After the initial run, we\u0026rsquo;ll always pull whatever was stored in the global variable instead of generating a new set each time the variable is invoked. This way, any triggers and tags that use the thresholds will always access the same values, even if they might be off a bit from what the content thresholds actually are.\nThe modification looks like this:\nfunction() { if (typeof window._gtm_scroll_set === \u0026#39;undefined\u0026#39;) { // Change the contents of this array to reflect the percentages of scroll depth you want to track  var verticalPercentages = [25,50,75,100]; // Change this to fetch the element you want to track scrolling in  var targetElement = document.querySelector(\u0026#39;div.post-content .main-content-wrap\u0026#39;); var elementHeight = targetElement.offsetHeight; var totalOffsetTop = 0; while (targetElement) { totalOffsetTop += (targetElement.offsetTop - targetElement.scrollTop + targetElement.clientTop); targetElement = targetElement.offsetParent; } window._gtm_scroll_set = { thresholds: verticalPercentages.map(function(percentage) { return parseInt(elementHeight * (percentage * 0.01) + totalOffsetTop); }).join(), percentages: verticalPercentages }; } return window._gtm_scroll_set.thresholds; }  As you can see, we populate a global variable window._gtm_scroll_set with an object that contains two properties:\n thresholds: the array of scroll thresholds used by the Scroll Depth trigger.\n percentages: the array of vertical percentages you defined in the same variable.\n  Now that we know what the thresholds are, what the percentages are, and we can trust that the same thresholds are returned whenever this Custom JavaScript variable is invoked, we can create another Custom JavaScript variable whose only job is to return which percentage the user scrolled past when the trigger fired. This is what that variable looks like:\nfunction() { if (typeof window._gtm_scroll_set !== \u0026#39;undefined\u0026#39;) { var percentages = window._gtm_scroll_set.percentages; var thresholds = window._gtm_scroll_set.thresholds.split(\u0026#39;,\u0026#39;).map(function(t) { return parseInt(t); }); var crossedIndex = thresholds.indexOf({{Scroll Depth Threshold}}); return percentages[crossedIndex]; } return {{Scroll Depth Threshold}}; }  This Custom JavaScript variable checks which threshold was returned by {{Scroll Depth Threshold}}, and returns the respective percentage value.\nThe order of things is thus:\n Use the first Custom JavaScript variable in the Scroll Depth trigger\u0026rsquo;s Pixel Depths field.\n Use the second Custom JavaScript variable wherever you want to get the percentage value for the scroll depth reached when the trigger fires.\n  Note that even though I am introducing a side effect in the Custom JavaScript variable, it is mitigated by checking if the global variable has already been set. Thus the typical downside of side effects (constantly and unpredictably updating global state) is mitigated.\nIt\u0026rsquo;s not perfect - nothing that impacts global state ever is. There\u0026rsquo;s always the risk that some other JavaScript accesses and modifies window._gtm_scroll_set, which would break your setup.\nSummary These four tips ranged from the really simple to the moderately complex.\nThere are many ways in which you can customize Google Tag Manager\u0026rsquo;s default trigger. With the scroll depth trigger, these customizations are almost necessary, because the trigger itself is lacking in some critical configurations options for now.\nFor example, I would like to see the following features in the trigger:\n Option to establish when the trigger is initialized (e.g. after DOM Ready, with a Data Layer event, etc.).\n Option to prevent the trigger from auto-firing if the thresholds have been crossed when the page loads.\n Option to reset the trigger manually, which is useful especially on single-page apps.\n Option to define a content element instead of the entire page for determining scroll depth.\n  With the tips in this article, you can do plenty, but especially the feature where you could reset the trigger is sorely missing from the current implementation.\nDo you have tips you want to share for Google Tag Manager\u0026rsquo;s Scroll Depth trigger?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/add-html-elements-page-programmatically/",
	"title": "#GTMTips: Add HTML Elements To The Page Programmatically",
	"tags": ["google tag manager", "gtmtips", "javascript", "custom html tag"],
	"description": "Google Tag Manager&#39;s Custom HTML tags strip out any non-standard parameters from HTML elements you add directly to the tag. By addng the elements programmatically, you can work around this limitation.",
	"content": " One of the annoying quirks of Google Tag Manager is that it strips out any non-standard HTML attributes from elements you add to Custom HTML tags. I\u0026rsquo;m using \u0026ldquo;non-standard\u0026rdquo; as a qualifier here, because I don\u0026rsquo;t have an exhaustive list of attributes that are ignored. But at least data attributes (e.g. data-id) and attributes with custom names (e.g. aria-labelledby) are either stripped out upon injection, or GTM might actually prevent you from even saving the container if the Custom HTML tag has elements with these attributes.\nSo this tip might be very useful to you if you want to annotate your custom HTML elements with custom attributes.\nTip 73: Add elements to page programmatically   Here\u0026rsquo;s the problem. Say you have an element that looks like this:\n\u0026lt;script src=\u0026quot;/myScript.js\u0026quot; data-simo-script=\u0026quot;My Script\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\nIf you add that line to a Custom HTML tag, the actual element that ends up on the page will look something like this:\n  As you can see, the data attribute is stripped out.\nHere\u0026rsquo;s another example. Say you have an element that looks like this:\n\u0026lt;input type=\u0026quot;text\u0026quot; aria-labelledby=\u0026quot;firstname\u0026quot;/\u0026gt;\nThis won\u0026rsquo;t even let you save the container. You\u0026rsquo;ll see an error message like this:\n  This is unfortunate, because there might be good reason to add these custom attributes to your elements.\nSo, here\u0026rsquo;s the solution. Use JavaScript instead! You can rewrite the Custom HTML tag to add the element to the page using JavaScript, and thus you can add any custom attributes to it that you want.\nHere\u0026rsquo;s how it works.\n\u0026lt;script\u0026gt; (function() { // Change \u0026#39;script\u0026#39; to whatever element you want to create, e.g. \u0026#39;img\u0026#39; or \u0026#39;input\u0026#39;.  var el = document.createElement(\u0026#39;script\u0026#39;); // Add any standard attributes you need, e.g. \u0026#39;src\u0026#39;, \u0026#39;width\u0026#39;, \u0026#39;type\u0026#39;, \u0026#39;name\u0026#39;.  // The syntax is el.setAttribute(attribute_name, attribute_value).  el.setAttribute(\u0026#39;src\u0026#39;, \u0026#39;/myScript.js\u0026#39;); // Add any non-standard attributes with the same method.  el.setAttribute(\u0026#39;data-simo-script\u0026#39;, \u0026#39;My Script\u0026#39;); // Finally, inject the element to the end of \u0026lt;body\u0026gt;  document.body.appendChild(el); })(); \u0026lt;/script\u0026gt;  Here you create the element using JavaScript\u0026rsquo;s DOM methods. All attributes are added with the setAttribute() method, and finally the element is added to the end of \u0026lt;body\u0026gt;.\nIt\u0026rsquo;s a bit of an overhead compared to adding the element directly to the Custom HTML tag, but the end result is cleaner, since you have full control over what attributes are added to the element, and where in the page it is added to.\nTry it out!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/check-for-undefined-value/",
	"title": "#GTMTips: Check For Undefined Value",
	"tags": ["google tag manager", "gtmtips", "triggers", "variables"],
	"description": "How to check if a variable value is undefined when building Google Tag Manager triggers.",
	"content": " This is one of those #GTMTips posts that I was certain I\u0026rsquo;d already written. So it came as a mild surprise when I realized I\u0026rsquo;d never tackled this aspect of Google Tag Manager.\nIt\u0026rsquo;s a short and sweet tip again. Today we\u0026rsquo;ll learn how to check if a variable is undefined using Google Tag Manager.\nTip 73: Check for undefined variable values   If a variable is undefined, it means that a variable with the given name does not currently have any valid value in memory. In JavaScript, the typical check for undefined is done like this:\nfunction checkIfUndefined(variable) { return typeof variable === \u0026#39;undefined\u0026#39;; }  With Google Tag Manager, you can\u0026rsquo;t run JavaScript evaluations in triggers. Instead, if you wanted to do the check above, you\u0026rsquo;d need to create a Custom JavaScript variable that returns true if the variable whose status you want to check is, indeed, undefined.\nHowever, there\u0026rsquo;s an easier way. Google Tag Manager does some magic for you and lets you check for undefined type using a simple string check. This might sound a bit unorthodox, and it is, but currently it\u0026rsquo;s the fastest way to check for undefined type without having to resort to extra trips through a Custom JavaScript variable.\nThe method itself is really simple. In the trigger where you want to run the check, simply create a new condition which checks if the given variable does not equal undefined, like so:\n  This trigger fires if the value in {{Page Type}} is not undefined.\nNote that this only checks for undefined variables. It doesn\u0026rsquo;t work for other falsy values, such as false, null, 0, or NaN. For these, you would have to run additional checks, and you can even use a regular expression:\n{{Variable}} does not match RegEx (ignore case) ^(undefined|null|0|false|NaN|)$\nAll of these falsy values are resolved to strings in GTM for checking against in triggers. The regular expression above matches all falsy values in JavaScript, and is thus useful as a generic check for potentially invalid values in variables.\nCertain problems with GTM\u0026rsquo;s approach can surface if, for example, you actually have the literal string \u0026quot;undefined\u0026quot; as the value of a variable. It\u0026rsquo;s not an impossible scenario to conjure, since \u0026ldquo;undefined\u0026rdquo; is a word that has functional depth in the English language. There\u0026rsquo;s no way for GTM to distinguish between this valid string value and the undefined value the variable might have, at least not in triggers. So to make the check as robust and unambiguous as possible, you would have to resort to a Custom JavaScript variable after all.\nfunction() { var variableToValidate = {{Some Variable}}; return !!variableToCheckForFalsy; }  The Custom JavaScript variable above returns true if the variable has a valid, non-falsy (i.e. truthy) value, and false otherwise.\nBy the way, I did not make up these ridiculous truthy and falsy terms. They are accepted jargon in programming.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/customtask-the-guide/",
	"title": "customTask - The Guide",
	"tags": ["google tag manager", "customtask", "tasks", "google analytics"],
	"description": "Guide to the customTask feature in Universal Analytics. Includes instructions how to use customTask, and how to combine multiple customTask solutions.",
	"content": " Last updated 4 September 2018\nIf you have been reading my blog articles over the past year, you might have noticed a disturbing trend. I\u0026rsquo;ve published 9 articles on customTask since the API was released. It might not sound like much, but I can\u0026rsquo;t think of a single feature in Google Analytics or Google Tag Manager that has so completely convinced me of its usefulness in such a short time.\nThe customTask API is a feature of the Universal Analytics library (used by Google Tag Manager\u0026rsquo;s tags, too). It lets you get and set values from and to the (Measurement Protocol) hit as it\u0026rsquo;s being generated. This is really useful for a couple of reasons, which I\u0026rsquo;ve covered in the previous articles, but I\u0026rsquo;ll go over them briefly in the beginning of this guide, too.\n  Suffice to say that especially for Google Tag Manager, customTask adds a lot of value. With GTM, it\u0026rsquo;s always been quite difficult to access the hit-building process when using tag templates. Luckily, customTask offers a solution to this problem, and at least for this particular developer it\u0026rsquo;s opened a whole new world of Google Analytics customization.\nHowever, in spite of writing all those articles on customTask, I recently realized that I never actually took the time to explain more thoroughly how it works. Also, I haven\u0026rsquo;t yet shared solutions for combining multiple customTask tricks in a single tag. This guide seeks to address these points.\n Be sure to check out my customTask Builder tool as well - it will help you compile the necessary JavaScript for customTask to run in your setup without conflicts!\n How Tasks work When you run the ga('send', 'pageview') command either directly in your site JavaScript or indirectly via Google Tag Manager\u0026rsquo;s Google Analytics tags, you actually request that the Universal Analytics JavaScript library (analytics.js) compile an HTTP request to the Google Analytics servers.\nThe endpoint to which the hits are sent is typically /collect on the Google Analytics collector domain. The process of building and sending hits to the GA servers is also known as Measurement Protocol (MP). In fact, MP is the underlying process used by all GA tracking mechanisms, be they the ga('send'...) JavaScript SDK, Google Tag Manager\u0026rsquo;s GA tags, native SDKs for Android and iOS, and custom-built HTTP requests from point-of-sales systems, for example.\n  When you use the JavaScript SDK, either via ga('send', 'pageview') or the Google Analytics tags in GTM, you are thus initiating a sequence of processes, where the final product is the actual MP request to Google Analytics. This sequence comprises a number of tasks, of which customTask is the first one that is executed.\nHere\u0026rsquo;s a quick recap of what each task does, listed in the order they are applied to the hit.\n   Task Description     customTask No functionality of its own, but can be used to manipulate the model object before it is processed by the other tasks.   previewTask If the request is generated from the pageview of a \u0026ldquo;Top Sites\u0026rdquo; thumbnail in Safari, abort the hit.   checkProtocolTask Aborts the request if the page protocol is not valid (http or https).   validationTask Checks if the fields in the request have valid and expected values. Aborts the request if this is not the case (e.g. trying to send a string as the Event Value).   historyImportTask If there is still legacy tracking running on the site, this task imports information from the old GA library cookies into Universal Analytics. Very useful if the site is migrating to Universal Analytics.   samplerTask If you\u0026rsquo;ve decided to manually sample the users to stay within Google Analytics\u0026rsquo; processing limits, this task aborts the request if the user is sampled out of data collection.   buildHitTask Generates the hitPayload string, which is essentially the list of query parameters and their values passed to the Measurement Protocol request.   sendHitTask Sends the hitPayload in a Measurement Protocol request to the GA servers.   timingTask If you are automatically sampling pages for page speed measurements, this task sends the timing hit to Google Analytics.   displayFeaturesTask If you have enabled display features in GA settings, this task compiles the request to the DoubleClick servers.    Each tasks receives the model object as a parameter. The model object contains all the fields that have been set in the tracker, as well as any enhancements applied in the tasks themselves.\nThe beauty of customTask is that because it runs before any of the other tasks, you can use it to overwrite behavior of these other tasks. For example, if you want to run Google Analytics locally or in a Chrome Extension, you\u0026rsquo;ll need to make sure checkProtocolTask is never run, because it aborts the hit builder if the page protocol is not http or https. The customTask would look like this:\nvar customTask = function(model) { // Prevent checkProtocolTask from running  model.set(\u0026#39;checkProtocolTask\u0026#39;, null); };  As you can see, the task is actually a field in the model object that you can manipulate just as you can manipulate any other field in the model. For example, if you want to grab the tracking ID (UA-XXXXXX-Y) and send it in the Custom Dimension with index 15, you can use the following customTask:\nvar customTask = function(model) { // Get the tracking ID from the model object  var trackingId = model.get(\u0026#39;trackingId\u0026#39;); // Set the tracking ID to Custom Dimension 15  model.set(\u0026#39;dimension15\u0026#39;, trackingId); };  To see what fields are available in the model object, check this developer documentation. Note that it\u0026rsquo;s not complete, since it\u0026rsquo;s missing all the tasks.\nBy running these model interactions with customTask, you have a lot of control over how the task sequence is run. Especially with Google Tag Manager, it would be difficult to run any complicated logic for when and how to manipulate sendHitTask, if you applied it directly to the tag as a field.\nHow to add customTask to your hits To add customTask to your Google Tag Manager tags, you need to create a Custom JavaScript variable which returns the customTask method in the variable body. Practically all my customTask articles show examples of what this Custom JavaScript variable looks like.\nWhen you are ready to add the variable to your tags, you can do it either via a Google Analytics Settings variable (recommended), or by overriding the tag settings directly.\nYou need to scroll down to Fields to set, and add a new field which looks like this:\n  If using the on-page Universal Analytics (analytics.js) snippet, you add the customTask like this, for example:\nvar _customTask = function() { // Set Client ID to Custom Dimension 199  return function(customTaskModel) { customTaskModel.set(\u0026#39;dimension199\u0026#39;, customTaskModel.get(\u0026#39;clientId\u0026#39;)); }; }; ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;); ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, _customTask()); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;);  Do note that you can only set one customTask per tracker / hit / tag. If you want to add more than one \u0026ldquo;trick\u0026rdquo; to the customTask function, you need to write the JavaScript that combines all the different solutions into one coherent whole.\nOr, you can use my customTask Builder tool, which does the dirty work for you.\nThings you can do with customTask As written above, customTask is special for two reasons.\n It has no special functionality of its own. A task queue can and will run perfectly without customTask defined.\n It runs before any other task, meaning you have full control over how the queue is processed.\n  With these two things in mind, here\u0026rsquo;s the list of all the customTask tricks I\u0026rsquo;ve written about, with a description of what makes them special.\n1. Set Client ID as a Custom Dimension Link to article: #GTMTips: Use customTask To Access Tracker Values In Google Tag Manager.\nThis is one of the simpler tricks. It doesn\u0026rsquo;t manipulate the task queue itself at all, it simply gets the Client ID from the model object, and then sets it as the value of the specified Custom Dimension.\nIt\u0026rsquo;s an elegant solution to a difficult problem. Without customTask, getting and setting the Client ID in a Google Analytics tag was difficult. If the tag is run for a first-time visitor who hasn\u0026rsquo;t received a Client ID yet, the actual clientId field is not available when the regular tag fields are resolved. A typical hack for this solution was to fetch the Client ID by creating a dummy tracker or by sending the Client ID with an Event tag that fired after the Pageview.\nBut with customTask, there\u0026rsquo;s no need for such unorthodox methods.\n2. Duplicate Google Analytics tags to more than one property Link to article: #GTMTips: Send Google Analytics Tag To Multiple Properties.\nThis is customTask at its purest. The customTask function first stores a reference to sendHitTask in a global variable, after which it overwrites sendHitTask in the current model object with the duplicator code.\nThe duplicator first lets the original hit fire to GA, after which it replaces the Tracking ID in the hitPayload with the Tracking ID of the second property. Then, the global sendHitTask is invoked again, and the hit is sent to the second property with an identical payload.\nNote! The reason the reference to sendHitTask is stored in a global variable is to avoid issues with field multiplication. Let\u0026rsquo;s say you always use this to get the original sendHitTask reference:\nvar originalSendTask = model.get('sendHitTask');\nEach time this customTask code is run, it will get a reference to what is stored in the model object\u0026rsquo;s sendHitTask. Unfortunately, when building standard Ecommerce hits, or when automatically sampling timing hits, the tag is automatically sent more than once. Thus the reference to the original sendHitTask is recursively augmented with each iteration of model.set('sendHitTask');, resulting in code being executed erratically.\nBy having a global variable store the reference to the original sendHitTask, this recursive problem is avoided.\n3. Track offline users in Google Analytics Link to article: Track Users Who Are Offline In Google Analytics.\nThis is all David Vallejo. His solution tackles the problem of lost internet connectivity and hits that are aborted because of this. It uses customTask to check if the user is offline, and if they are, the hits are stored in a batch queue. Once connectivity is restored, the queue is processed, and the hits are finally sent to GA.\n4. Remove PII from GA payloads Link to article: #GTMTips: Remove PII From Google Analytics Hits.\nWith GDPR coming soon, covering all your bases with regard to private data is a good idea. Fixing potential PII leaks before they hit Google Analytics servers is a good method as any to make sure you\u0026rsquo;re complying with Google Analytics\u0026rsquo; Terms of Service as well as the increasingly stricter regulations for sending and collecting personal data.\n  Here, customTask takes the hit payload before it is sent to GA, and purges it of all matches against any given regular expressions. These regular expressions can be built to match things like email addresses and social security numbers.\n5. Fix site speed sampling messing with your Custom Metrics Link to article: Prevent Site Speed Sampling Rate From Skewing Custom Dimensions And Custom Metrics.\nThis is a fairly simple trick, but it fixes a potential issue with Custom Metric data being skewed by the automatically collected page timing hits. The issue is that the timing hit copies all parameters from the Page View tag that is being sampled, and thus any Custom Dimensions and Custom Metrics are sent more than once, too.\nHere, customTask is attached to the Page View tag, where it checks if the hit type is timing (due to the automatically generated timing hit), and if it is, it removes all references to Custom Dimensions and Metrics from the request.\n6. Respect opt-out Link to article: #GTMTips: Respect Opt-Out From Advertising And Analytics.\nA simple trick, again. This time customTask checks if the user has specific opt-out settings in the browser, and if they do, it aborts the requests to Google Analytics and DoubleClick. You\u0026rsquo;ll need to manually create the setting itself, be it a pop-up that stores the opt-out in a browser cookie or something, but once you\u0026rsquo;ve done it, this solution makes it easy to enact the opt-out programmatically.\n7. Send details about Optimize experiments to Google Analytics Link to article: Send Event And Custom Dimension If Google Optimize Experiment Is Running.\nThis trick tackles an issue with how Google Optimize data is being reported in Google Analytics. Basically, the Experiment Name and Experiment ID dimensions are scoped to the user for the duration of the experiment. Thus it\u0026rsquo;s not possible to get a segment of the actual sessions when the user was actively participating in an experiment page.\nThe customTask checks for certain features of the Page View tag it is attached to, and if these features are found, it updates a Custom Dimension in the hit payload with details about the experiment. You can then segment your GA data with these Custom Dimensions to see sessions where the user was actually active on an experiment page.\n8. Auto-link domains with regular expressions Link to article: #GTMTips: Auto Link Domains With Regex.\nWith this trick, customTask brings Google Tag Manager to feature parity with analytics.js. Regular, on-page Google Analytics tracking lets you use regular expressions with the Auto-Link Domains plugin. Google Tag Manager only accepts string values.\nHere, customTask actually applies the Auto-Link plugin to the tracker object itself, passing the array of regular expressions to the plugin. This way, domains can be automatically linked with cross-domain parameters based on a regular expression match, rather than an exhaustive list of strings.\n9. Send Google Analytics payloads to Snowplow Link to article: #GTMTips: Automatically Duplicate Google Analytics Hits To Snowplow.\nI\u0026rsquo;m a huge fan of Snowplow, mainly because it\u0026rsquo;s open-source and tackles many difficult issues having to do with sessionization and tracking schemas. This trick uses customTask to replicate what the \u0026ldquo;official\u0026rdquo; Snowplow Google Analytics plugin does.\n  Google Tag Manager doesn\u0026rsquo;t support adding plugins to tags, so using customTask to replicate plugin features is as good a solution as any.\n10. Send Google Analytics payload length as a Custom Dimension Link to article: Send Google Analytics Payload Length As Custom Dimension.\nThis tip lets you collect the payload length of each Google Analytics request as a Custom Dimension in Google Analytics.\nThe maximum length of a Google Analytics payload is 8192 bytes. It\u0026rsquo;s useful to check if you\u0026rsquo;re approaching this value with some of your hits, because if the payload length exceeds this, the hit is never sent to Google Analytics.\nBe sure to check my tip below on how to automatically reduce the payload length.\n11. Send Hit Type as a Custom Dimension Link to article: #GTMTips: Add Hit Type As A Custom Dimension.\nWith this trick, you can send the hit type (e.g. pageview, event, timing) as a Custom Dimension with every hit to which this customTask is attached.\nVery useful for debugging, since you can now build segments where you directly refer to the hit type, which is not available (surprisingly) as a default dimension in Google Analytics.\n12. Automatically reduce payload length Link to article: Automatically Reduce Google Analytics Payload Length.\nWith this customTask, the payload sent to Google Analytics is automatically parsed and, if necessary, reduced to go under the maximum payload length of 8192 bytes.\nIt\u0026rsquo;s very typical especially with Enhanced Ecommerce to send very long payloads to Google Analytics. Unfortunately, if these payloads exceed the maximum length, the hits are never sent and key data will thus be missing from your data set.\nYou can use this trick to recursively parse the payload and drop unnecessary parameters from it, which only serve to waste valuable space under the length cap.\n13. Create and update a session cookie Link to article: Create And Update Google Analytics Session Timeout Cookie.\nThis trick creates (or updates) a browser cookie which expires after a timeout you have configured (30 minutes by default).\nEach hit that uses this customTask will refresh the cookie very time the hit is fired.\nThus, if this cookie exists in the browser, it\u0026rsquo;s an indication that there might well be a Google Analytics session active for the current user.\nYou can use the cookie to block event hits from being dispatched to Google Analytics if there is no active session, for example.\n14. Tracking cross-domain iframes Link to article: Tracking Cross-Domain Iframes - Upgraded Solution.\nHere we\u0026rsquo;ll update an older solution of mine by using customTask and a window.setInterval() polling script together to great effect.\nThe idea is that when the hit is built, the customTask looks for the given iframe on the page, and if it\u0026rsquo;s found within a configured timeout, the iframe is reloaded with cross-domain tracking parameters.\nThis is a more elegant way to approach the problem of cross-domain iframes, because it skips past the race condition of running the script before the iframe has been loaded on the page, and it also uses the correct tracker object instead of just the first tracker on the page.\nPutting it all together (literally)  NOTE! I\u0026rsquo;ve built a tool which you can use to compile the necessary JavaScript automatically. You\u0026rsquo;ll still want to read through this chapter, though, as it explains why building the script can be a chore.\n If you like customTask as much as I do, chances are you\u0026rsquo;ll want to use more than one trick listed above (and elsewhere) in your tags. There\u0026rsquo;s a catch though. You need to respect the basic features of JavaScript, mainly:\n You can only set a single field once per tag, so you can only set one customTask field per tag.\n You can only set a single model parameter once per tag, so you can only set one sendHitTask attribute per tag, for example.\n  So, let\u0026rsquo;s say you want to do both tricks (2) (Send GA hit to more than one property) and (4) (Remove PII from GA hits). You might be tempted to try this:\nfunction() { return function(model) { // Specify the PII regular expressions  var piiRegEx = [{ name: \u0026#39;EMAIL\u0026#39;, regex: /.{4}@.{4}/g }]; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_originalSendTask\u0026#39;; var originalSendTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); // Clear the payload from PII:  model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { ... }); // Duplicate the hit to another tracking ID:  model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { ... }); }; }  Unfortunately, this would not work. You are setting the sendHitTask field twice, meaning the second one is the only one that counts (since it overwrites the first set).\nInstead, you need to apply some JavaScript chops and combine both of these solutions in the same sendHitTask. It\u0026rsquo;s not exactly trivial, and there\u0026rsquo;s no textbook method for doing it. You\u0026rsquo;ll need to figure out the order in which the code should be processed.\nIn this example, we want the PII purge to happen before any hits are sent or duplicated. So the final code would look something like this:\nfunction() { return function(model) { // Specify the PII regular expressions  var piiRegEx = [{ name: \u0026#39;EMAIL\u0026#39;, regex: /.{4}@.{4}/g }]; // Specify the GA tracking ID of the property to which you want to duplicate the hits  var newTrackingId = \u0026#39;UA-12345-2\u0026#39;; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_originalSendTask\u0026#39;; var originalSendTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); var i, hitPayload, parts, val, oldTrackingId; model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { // Clear the payload of PII:  hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;).split(\u0026#39;\u0026amp;\u0026#39;); for (i = 0; i \u0026lt; hitPayload.length; i++) { parts = hitPayload[i].split(\u0026#39;=\u0026#39;); // Double-decode, to account for web server encode + analytics.js encode  val = decodeURIComponent(decodeURIComponent(parts[1])); piiRegEx.forEach(function(pii) { val = val.replace(pii.regex, \u0026#39;[REDACTED \u0026#39; + pii.name + \u0026#39;]\u0026#39;); }); parts[1] = encodeURIComponent(val); hitPayload[i] = parts.join(\u0026#39;=\u0026#39;); } sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload.join(\u0026#39;\u0026amp;\u0026#39;), true); originalSendTask(sendModel); // Rewrite the tracking ID  hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); oldTrackingId = new RegExp(sendModel.get(\u0026#39;trackingId\u0026#39;), \u0026#39;gi\u0026#39;); sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload.replace(oldTrackingId, newTrackingId), true); originalSendTask(sendModel); }); }; }  The code is fairly complex, and complexity increases with each distinct trick you want to run. This is an unfortunate consequence of the limitations of JavaScript and the fact that there is only one customTask to manipulate.\nIn the end, it\u0026rsquo;s really up to your JavaScript skills. You\u0026rsquo;ll need to be aware of how the browser runs the code line-by-line, and thus you\u0026rsquo;ll need to make sure that whatever you want to run first is also executed first by the browser. That\u0026rsquo;s why in the example above I have the PII purge running before the hit duplication. If the PII purge happened AFTER the hit is duplicated, it would be redundant, since it would still allow PII to potentially flow to Google Analytics.\nSummary As I wrote in the beginning, customTask is one of the nicest features to emerge in Google Analytics in a long time. With Google Tag Manager, it\u0026rsquo;s a real powerhouse of customization.\nIt\u0026rsquo;s a good idea to read about the Task queue in general. Understanding how tasks work will give you great insight into how analytics.js compiles and dispatches hits to Google Analytics. Once you have a good grasp on all the different moving parts of the Tasks queue, you should be able to come up with cool customTask solutions of your own, which you can then share in the comments of this article, for example!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/edit-google-analytics-tag-settings/",
	"title": "#GTMTips: Edit Google Analytics Tag Settings",
	"tags": ["google tag manager", "gtmtips", "google analytics", "google analytics settings"],
	"description": "You can find the old interface for editing individual Google Analytics tag settings by checking the &#34;Enable overriding settings in this tag&#34; toggle.",
	"content": " When the Google Analytics Settings variable was introduced in May 2017, it resulted in a significant change in the Google Analytics tag user interface in Google Tag Manager. The default UI for editing a tag was stripped down of all GA-specific settings, and the new Google Analytics Settings drop-down was the replacement.\nUnfortunately, the bulk of Google Tag Manager articles online (including those on this blog) still refer to the old interface in screenshots and instructions. This #GTMTips article is a very quick tip to show you how to reveal tag-specific settings without using a Google Analytics Settings variable.\nTip 72: Edit Google Analytics tag settings   If you want to reveal the More Settings list, which comprises items like Fields to Set, Custom Dimensions and Ecommerce settings (among others), all you need to do is check the box titled:\n Enable overriding settings in this tag.\n This setting means that even if the tag uses a Google Analytics Settings variable as the basis for all its settings, any changes you make in the tag-specific settings can be used to override those set by the variable.\nSimilarly, if you don\u0026rsquo;t want to use a Google Analytics Settings variable, you must check this box to edit the tag-specific fields.\nFor fields that have free text input, such as Fields to Set and Custom Dimensions, any rows you add will override the equivalent settings or dimensions you set in the Google Analytics Settings variable.\nSome fields such as Tracking ID and all the fields that have a drop-down list for value selection (e.g. Enable Enhanced Ecommerce Features) let you either inherit the value from the Google Analytics Settings variable (default option), or you can override the settings variable with some other value.\n  To recap, just check Enable overriding settings in this tag if you want to reveal the hidden More Settings menu in your tags. I would recommend, however, that you take a look at the Google Analytics Settings variable, and take the time to migrate your Google Analytics tags to use it. It will make your life a whole lot easier, especially if managing a boatload of GA tags!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/fix-missing-page-view-broken-triggers/",
	"title": "#GTMTips: Fix Missing Page View Event And Broken Triggers",
	"tags": ["google tag manager", "gtmtips", "triggers", "datalayer"],
	"description": "If you can&#39;t see the Page View event in your Preview mode list, and GTM&#39;s triggers work erratically, you most likely have a broken dataLayer implementation.",
	"content": " Google Tag Manager should be relatively easy to implement. Just paste the container snippet to the \u0026lt;head\u0026gt; of the page and you\u0026rsquo;re good to go! However, at some point you\u0026rsquo;ll want to configure the dataLayer structure, too (read more about dataLayer here). There are two ways to do it: the right way and the wrong way.\nIn this article, we\u0026rsquo;ll see what happens if you do it the wrong way, how to identify the issue, and how to fix it.\nTip 71: Page View event missing, and GTM\u0026rsquo;s triggers don\u0026rsquo;t work?   If you open Preview mode on your site, and look at the list of events in the left-hand side navigation, you should always see the following three GTM default events:\n Page View - This is the event pushed into dataLayer in Google Tag Manager\u0026rsquo;s container snippet (event name is gtm.js).\n DOM Ready - This is the event pushed into dataLayer once the page HTML has been rendered by the browser (event name is gtm.dom).\n Window Loaded - This is the event pushed into dataLayer once the page and all linked resources have completed load, execution, and render (event name is gtm.load).\n  You should always see (2) and (3) - there\u0026rsquo;s very little you can do to mess these up. But it\u0026rsquo;s possible you won\u0026rsquo;t see the Page View event. If you don\u0026rsquo;t it means you\u0026rsquo;ve messed up the dataLayer implementation.\nGoogle Tag Manager establishes the dataLayer construct with its own .push() method in the JavaScript library that represents your container. The gtm.js event is pushed into dataLayer in the container snippet, and it is used to trigger any tags that use the Page View or All Pages triggers.\nThe main reason for not seeing the Page View events is simple. You have overwritten the dataLayer modified in the container snippet with a brand new array. You do it like this:\n\u0026lt;!-- Google Tag Manager container snippet here --\u0026gt; (function...) \u0026lt;!-- Google Tag Manager container snippet ends --\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script\u0026gt; var dataLayer = [{ someVariable: \u0026#39;someValue\u0026#39; }]; \u0026lt;/script\u0026gt; See the problem? By using the syntax var dataLayer = ..., you are resetting the dataLayer variable to a new Array, thus overwriting anything that was in it before (such as Google Tag Manager\u0026rsquo;s own listener). Since you overwrite dataLayer, it no longer works properly with GTM, and a typical symptom is that GTM\u0026rsquo;s triggers don\u0026rsquo;t work anymore, either. So if you have a Click / All Elements trigger on the site and nothing is pushed to dataLayer when you click around, chances are you\u0026rsquo;ve overwritten GTM\u0026rsquo;s dataLayer with your reinitialization.\nHow to fix it? Simple. Always check for the existence of dataLayer before adding items to it, and always add items to dataLayer only with the push() command.\n// WRONG! NEVER USE THIS: var dataLayer = [{ pageType: \u0026#39;home\u0026#39; }]; // CORRECT! ALWAYS USE THIS: window.dataLayer = window.dataLayer || []; window.dataLayer.push({ pageType: \u0026#39;home\u0026#39; });  This is a popular topic on this blog and many others simply because it\u0026rsquo;s so easy to screw it up. It doesn\u0026rsquo;t help that somewhere in GTM\u0026rsquo;s documentation there are still instructions to use the declarative method for setting up dataLayer.\nAny other typical Google Tag Manager mistakes you can think of, which have been around for a long time, and probably will surface for a long time to come?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/snowplow-full-setup-with-google-analytics-tracking/",
	"title": "Snowplow: Full Setup With Google Analytics Tracking",
	"tags": ["google tag manager", "snowplow", "amazon", "aws"],
	"description": "Step-by-step process for setting up a Snowplow analytics pipeline with data pulled in from your Google Analytics trackers.",
	"content": " A recent guide of mine introduced the Google Analytics adapter in Snowplow. The idea was that you can duplicate the Google Analytics requests sent via Google Tag Manager and dispatch them to your Snowplow analytics pipeline, too. The pipeline then takes care of these duplicated requests, using the new adapter to automatically align the hits with their corresponding data tables, ready for data modeling and analysis.\nWhile testing the new adapter, I implemented a Snowplow pipeline from scratch for parsing data from my own website. This was the first time I\u0026rsquo;d done the whole process from end-to-end myself, so I thought it might be prudent to document the process for the benefit of others who might want to take a jab at Snowplow but are intimidated by the moving parts.\n  And make no mistake. There are plenty of moving parts. Snowplow leverages a number of Amazon Web Services components, in addition to a whole host of utilities of its own. It\u0026rsquo;s not like setting up Google Analytics, which is, at its most basic, a fairly rudimentary plug-and-play affair.\n Image source: https://goo.gl/D2f3xi  Take this article with a grain of salt. It definitely does not describe the most efficient or cost-effective way to do things, but it should help you get started with Snowplow, ending up with a data store full of usable data for modeling and analysis. As such, it\u0026rsquo;s not necessarily a guide rather than a description of the steps I took, in good and bad.\n  WARNING: If you DO follow this guide step-by-step (which makes me very happy), please do note that there will be costs involved. For example, my current, very light-weight setup, is costing me a couple of dollars a day to maintain, with most costs incurred by running the collector on a virtual machine in Amazon\u0026rsquo;s cloud. Just keep this in mind when working with AWS. It\u0026rsquo;s unlikely to be totally free, even if you have the free tier for your account.\nTo start with I ended up needing the following things to make the pipeline work:\n The Linux/Unix command line (handily accessible via the Terminal application of Mac OS X).\n Git client - not strictly necessary but it makes life easier to clone the Snowplow repo and work with it locally.\n A new Amazon Web Services account with the introductory free tier (first 12 months).\n A credit card - even with the free tier the pipeline is not free.\n A domain name of my own (I used gtmtools.com) whose DNS records I can modify.\n A Google Analytics tag running through Google Tag Manager.\n A lot of time.\n    The bullets concerning money and custom domain name might be a turn-off to some.\nYou might be able to set up the pipeline without a domain name by using some combination of Amazon CloudFront and Route 53 with Amazon\u0026rsquo;s own SSL certificates, but I didn\u0026rsquo;t explore this option.\nAnd yes, this whole thing is going to cost money. As I wrote in the beginning, I didn\u0026rsquo;t follow the most cost-effective path. But even if I did, it would still cost a dollar or something per day to keep this up and running. If this is enough of a red flag for you, then take a look at what managed solutions Snowplow is offering. This article is for the engineers out there who want to try building the whole thing from scratch.\nWhy Snowplow? Why do this exercise at all? Why even look towards Snowplow? The transition from the pre-built, top-down world of Google Analytics to the anarchy represented by Snowplow\u0026rsquo;s agnostic approach to data processing can be daunting.\nLet me be frank: Snowplow is not for everyone. Even though the company itself offers managed solutions, making it as turnkey as it can get, it\u0026rsquo;s still you building an analytics pipeline to suit your organization\u0026rsquo;s needs. This involves asking very difficult questions, such as:\n What is an \u0026ldquo;event\u0026rdquo;?\n What constitutes a \u0026ldquo;session\u0026rdquo;?\n Who owns the data?\n What\u0026rsquo;s the ROI of data analytics?\n How should conversions be attributed?\n How should I measure users across domains and devices?\n  If you\u0026rsquo;ve never asked one of these (or similar) questions before, you might not want to look at Snowplow or any other custom-built setup yet. These are questions that inevitably surface at some point when using tools that give you very few configuration options.\nAt this point I think I should add a disclaimer. This article is not Google Analytics versus Snowplow. There\u0026rsquo;s no reason to bring one down to highlight the benefits of the other. Both GA and Snowplow have their place in the world of analytics, and having one is not predicated on the absence of the other.\nThe whole idea behind the Google Analytics plugin, for example, is that you can duplicate tracking to both GA and to Snowplow. You might want to reserve GA tracking for marketing and advertising attribution, as Google\u0026rsquo;s backend integrations are still unmatched by other platforms. You can then run Snowplow to collect this same data so that you\u0026rsquo;ll have access to an unsampled, raw, relational database you can use to enrich and join with your other data sets.\nSnowplow is NOT a Google Analytics killer. They\u0026rsquo;re more like cousins fighting together for the honor of the same family line, but occasionally quarreling over the inheritance of a common, recently deceased relative.\nWhat we are going to build Here\u0026rsquo;s a diagram of what we\u0026rsquo;re hopefully going to build in this article:\n  I wonder why no one\u0026rsquo;s hired me as a designer yet\u0026hellip;\nThe process will cover the following steps.\n The website will duplicate the payloads sent to Google Analytics, and send them to a collector written with Clojure.\n The collector runs as a web service on AWS Elastic Beanstalk, to which traffic is routed and secured with SSL from my custom domain name using AWS Route 53.\n The log data from the collector is stored in AWS S3.\n A utility is periodically executed on my local machine, which runs an ETL (extract, transform, load) process using AWS EMR to enrich and \u0026ldquo;shred\u0026rdquo; the data in S3.\n The same utility finally stores the processed data files into relational tables in AWS Redshift.\n  So the process ends with a relational database that has all your collected data populated periodically.\nStep 0: Register on AWS and setup IAM roles What you need for this step  You\u0026rsquo;ll just need a credit card to register on AWS. You\u0026rsquo;ll get the benefits of a free tier, but you\u0026rsquo;ll still need to enable billing.  Register on AMR The very first thing to do is register on Amazon Web Services and setup an IAM (Identity and Access Management) User that will run the whole setup.\nSo browse to https://aws.amazon.com/, and select the option to create a free account.\n  The free account gives you access to the free tier of services, some of which will help keep costs down for this pipeline, too.\nCreate an Identity and Account Management (IAM) user Once you\u0026rsquo;ve created the account, you can do the first important thing in setting up the pipeline: create an IAM User. We\u0026rsquo;ll be following Snowplow\u0026rsquo;s own excellent IAM setup guide for these steps.\nIn the Services menu, select IAM from the long list of items.\n   In the left-hand menu, select Groups.\n Click the Create New Group in the view that opens.\n Name the group snowplow-setup.\n Skip the Attach Policy step for now by clicking the Next Step button.\n Click Create Group.\n  Now in the left-hand menu, select Policies.\n Click Create Policy.\n Select the JSON tab, and replace the contents with the following:\n  { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;acm:*\u0026#34;, \u0026#34;autoscaling:*\u0026#34;, \u0026#34;aws-marketplace:ViewSubscriptions\u0026#34;, \u0026#34;aws-marketplace:Subscribe\u0026#34;, \u0026#34;aws-marketplace:Unsubscribe\u0026#34;, \u0026#34;cloudformation:*\u0026#34;, \u0026#34;cloudfront:*\u0026#34;, \u0026#34;cloudwatch:*\u0026#34;, \u0026#34;ec2:*\u0026#34;, \u0026#34;elasticbeanstalk:*\u0026#34;, \u0026#34;elasticloadbalancing:*\u0026#34;, \u0026#34;elasticmapreduce:*\u0026#34;, \u0026#34;es:*\u0026#34;, \u0026#34;iam:*\u0026#34;, \u0026#34;rds:*\u0026#34;, \u0026#34;redshift:*\u0026#34;, \u0026#34;s3:*\u0026#34;, \u0026#34;sns:*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] }  Next, click Review Policy.\n Name the policy snowplow-setup-policy-infrastructure.\n Finally, click Create Policy.\n  Now go back to Groups from the left-hand menu, and click the snowplow-setup group name to open its settings.\n   Switch to the Permissions tab and click Attach Policy.\n From the list that opens, select snowplow-setup-policy-infrastructure and click Attach Policy.\n    Now select Users from the left-hand menu, and click the Add user button.\n Name the user snowplow-setup.\n Check the box next to Programmatic access.\n Click Next: Permissions.\n With Add user to group selected, check the box next to snowplow-setup, and click the Next: Review button at the bottom of the page.\n Finally, click Create user.\n  The following screen will show you a success message, and your user with an Access Key ID and Secret Access Key (click Show to see it) available. At this point, copy both of these somewhere safe. You will need them soon, and once you leave this screen you will not be able to see the secret key anymore. You can also download them as a CSV file by clicking the Download .csv button.\nYou have now created a user with which you will set up your entire pipeline. Once everything is set up, you will create a new user with fewer permissions, who will take care of running and managing the pipeline.\nCongratulations, step 0 complete!\nWhat you should have after this step  You should have successfully registered a new account on AWS.\n You should have a new IAM user named snowplow-setup with all the access privileges distributed by the custom policy you created.\n  Step 1: The Clojure collector What you need for this step  A custom domain name and access to its DNS configuration  Getting started This is going to be one of the more difficult steps to do, since there\u0026rsquo;s no generic guide for some of the things that need to be done with the collector endpoint. If you want, you can look into the CloudFront Collector instead, because that runs directly on top of S3 without needing a web service to collect the hits. However, it doesn\u0026rsquo;t support the Google Analytics hit duplicator, which is why in this article we\u0026rsquo;ll use the Clojure collector.\nThe Clojure collector is basically a web endpoint to which you will log the requests from your site. The endpoint is a scalable web service running on Apache Tomcat, which is hosted on AWS\u0026rsquo; Elastic Beanstalk. The collector has been configured to automatically log the Tomcat access logs directly into AWS S3 storage, meaning whenever your site sends a request to the collector, it logs this request as an access log entry, ready for the ETL process that comes soon after.\nBut let\u0026rsquo;s not get ahead of ourselves.\nSetting up the Clojure collector The first thing you\u0026rsquo;ll need to do is download the Clojure collector WAR file and store it locally in a temporary location (such as your Downloads folder).\nYou can download the binary by following this link. It should lead you to a file that looks something like clojure-collector-1.X.X-standalone.war.\nOnce you\u0026rsquo;ve downloaded it, you can set up the Elastic Beanstalk application.\nIn AWS, open the Services menu again, and select Elastic Beanstalk.\nAt this point, you\u0026rsquo;ll also want to make sure that any AWS services you use in this pipeline are located in the same region. There are differences to what services are supported in each region. I built the pipeline in EU (Ireland), and the Snowplow guide itself uses US West (Oregon). Click the region menu and choose the region you want to use.\n   Next, click the Create New Application link in the top-right corner of the page (just below the region selector).\n Give the application a descriptive name (e.g. Snowplow Clojure Collector) and description (e.g. I love Kamaka HF-3), and then click Next.\n In the New Environment view, select Create web server.\n     In the Environment Type view, set the following:   Predefined configuration: Tomcat\nEnvironment type: Single instance\n  Then, click Next.\n In the Application Version view, select Upload your own, click Choose file, and find the WAR file you downloaded earlier in this chapter. Click Next to upload the file.\n     In the Environment Info view, you\u0026rsquo;ll need to set the Environment name, which is then used to generate the Environment URL (which, in turn, will be the endpoint URL receiving the collector requests).\n Remember to click Check availability for the URL to make sure someone hasn\u0026rsquo;t grabbed it yet. Click Next once you\u0026rsquo;re done.\n     In Additional Resources, you can leave both options unchecked for now, and click Next.\n In Configuration Details, select m1.small as the instance type. You can leave all the other options to their default settings. Click Next.\n     No need to add any Environment Tags, so click Next again.\n In the Permissions view, by clicking Next, AWS assigns default roles to Instance profile and Service role, so that\u0026rsquo;s fine.\n Finally, you can take a quick look at what you\u0026rsquo;ve done in the Review view, before clicking the Launch button.\n  At this point, you\u0026rsquo;ll see that AWS is firing up your environment, where the Clojure collector WAR file will start running the instant the environment has been created.\n  Once the environment is up and running, you can copy the URL from the top of the view, paste it into the address bar of your browser, and add the path /i to its end, so it ends up something like:\nhttp://simoahava-snowplow-collector.eu-west-1.elasticbeanstalk.com/i\nIf the collector is running correctly, you should see a pixel in the center of the screen. By clicking the right mouse button and choosing Inspect (in the Google Chrome browser), you should now find a cookie named sp in the Applications tab. If you do, it means the collector is working correctly.\n  Congratulations! You\u0026rsquo;ve set up the collector.\nHowever, we\u0026rsquo;re not done here yet.\nEnable logging to S3 Automatically logging the Tomcat access logs to S3 storage is absolutely crucial for this whole pipeline. The batch process looks for these logs when sorting out the data into queriable chunks. Access logs are your typical web server logs, detailing all the HTTP requests made to the endpoint, with request headers and payloads included.\nTo enable logging, you\u0026rsquo;ll need to edit the Elastic Beanstalk application you just created. So, once the endpoint is up and running, you can open it by clicking the application name while in the Elastic Beanstalk service front page.\n   Next, select Configuration from the left-hand menu.\n Click the cogwheel in the box titled Software Configuration.\n     Under Log Options, check the box next to Enable log file rotation to Amazon S3. If checked, service logs are published to S3.    This is a crucial step, because it will store all the access logs from your endpoint requests to S3, ready for ETL.\nClick Apply to apply the change.\nSet up the load balancer Next, we need to configure the Elastic Beanstalk environment for SSL.\nBefore you do anything else, you’ll need to switch from a single instance to a load-balancing, auto-scaling environment in Elastic Beanstalk. This is necessary for securing the traffic between your domain name and the Clojure collector.\nIn the AWS Services menu, select Elastic Beanstalk, and then click your application name in the view that opens.\n   In the next view, select Configuration in the left-hand menu.\n Click the cogwheel in the box titled Scaling.\n From the Environment type menu, select Load balancing, auto scaling, and then click the Apply button, and Save in the next view.\n    You now have set up the load balancer.\nRoute traffic from your custom domain name to the load balancer Next, we\u0026rsquo;ll get started on routing traffic from your custom domain name to this load balancer.\n Open the Services menu in the AWS console, and select Route 53 from the list.\n In the view that opens, click Create Hosted Zone.\n Set the Domain Name to the domain whose DNS records you want to delegate to Amazon. I chose collector.gtmtools.com. Leave Type as Public Hosted Zone, and click Create.\n     In the view that opens, you\u0026rsquo;ll see the settings for your Hosted Zone. Make note of the four NS records AWS has assigned to your domain name. You\u0026rsquo;ll need these in the next step.     Next, you\u0026rsquo;ll need to go wherever it is you manage your DNS records. I use GoDaddy.\n You need to add the four NS addresses in the AWS Hosted Zone as NS records in the DNS settings of your domain name. This is what the modifications would look like in my GoDaddy control panel:\n    As you can see, there are four NS records with host collector (for collector.gtmtools.com), each pointing to one of the four corresponding NS addresses in the AWS Hosted Zone. I set the TTL to the shortest possible GoDaddy allows, which is 600 seconds. That means that within 10 minutes, the Hosted Zone name servers should respond to collector.gtmtools.com.\nYou can test this with a service such as https://dig.whois.com.au/dig/, or any similar service that lets you check DNS records. Once the DNS settings are updated, you can increase the TTL to something more sensible, such as 1 hour, or even 1 day.\nNow that you\u0026rsquo;ve set up your custom domain name to point to your Route 53 Hosted Zone, there\u0026rsquo;s just one step missing. You\u0026rsquo;ll need to create an Alias record in the Hosted Zone, which points to your load balancer. That way when typing the URL collector.gtmtools.com into the browser address bar, the DNS record first directs it to your Hosted Zone, where a new A record shuffles the traffic to your load balanced Clojure collector endpoint. Phew!\n So, in the Hosted Zone you\u0026rsquo;ve created, click Create Record Set.\n In the overlay that opens, leave the Name empty, since you want to apply the name to the root domain of the NS (collector.gtmtools.com in my case). Keep A - IPv4 address as the Type, and select Yes for Alias.\n When you click the Target field, a drop-down list should appear, and your load balancer should be selectable under the ELB Classic load balancers heading. Select that, and then click Create.\n    Now if you visit http://collector.gtmtools.com/i, you should see the same pixel response as you got when visiting the Clojure collector endpoint directly. So your domain name routing works!\nBut we\u0026rsquo;re STILL not done here.\nSetting up HTTPS for the collector To make sure the collector is secured with HTTPS, you will need to generate a (free) AWS SSL certificate for it, and apply it to the Load Balancer. Luckily this is easy to do now that we\u0026rsquo;re working with Route 53.\n The first thing to do is generate the SSL certificate. In Services, find and select the AWS Certificate Manager. Click Get started to, well, get started.\n Type the domain name you want to apply the certificate to in the relevant field. I wrote collector.gtmtools.com.\n Click Next when ready.\n     In the next step you need to choose a validation method. Since we\u0026rsquo;ve delegated DNS of collector.gtmtools.com to Route 53, I chose DNS Validation without hesitation.\n Then click Review, and then Confirm and request.\n Validation is done in the next view. With Route 53, this is really easy. Just click Create record in Route 53, and Create in the overlay that opens. Amazon takes care of validation for you!\n    After clicking Create, you should see a Success message, and you can click the Continue button in the bottom of the screen. It might take up to 30 minutes for the certificate to validate, so go grab a cup of coffee or something! We still have one more step left\u0026hellip;\nSwitch the load balancer to support HTTPS You\u0026rsquo;ll still need to switch your load balancer to listen for secure requests, too.\n In Services, open Elastic Beanstalk, click your application name in the view that opens, and finally click Configuration in the left-hand menu. You should be able to do this stuff in your sleep by now!\n Next, scroll down to the box titled Load Balancing and click the cogwheel in it.\n In the view that opens, set Secure listener port to 443, and select the SSL certificate you just generated from the menu next to SSL Certificate ID. Click Apply when ready.\n    All done! At this point, you might also want to take a look at this Snowplow guide for configuring the collector further (e.g. applying proper scaling settings to the load balancer).\nThe process above might seem convoluted, but there\u0026rsquo;s a certain practical logic to it all. And once you have the whole pipeline up and running, it will be easier to understand how things proceed from the S3 storage onwards.\nSetting up the custom domain name is a bit of chore, though. But if you use Route 53, most of the things are either automated for you or taken care of with the click of a button.\nWhat you should have after this step  The Clojure collector application running in an Elastic Beanstalk environment.\n Your own custom domain name pointing at the router configured in Amazon Route 53.\n An SSL secured load balancer, to which Route 53 diverts traffic to your custom domain name.\n Automatic logging of the collector Tomcat logs to S3. The bucket name is something like elasticbeanstalk-region-id, and you can find it by clicking Services in the AWS navigation and choosing S3. The logs are pushed hourly.\n  Step 2: The tracker You\u0026rsquo;ll need to configure a tracker to collect data to the S3 storage.\nThis is really easy, since you\u0026rsquo;re of course using Google Analytics, and tracking data to it using Google Tag Manager tags.\nNavigate to my recent guide on setting up the duplicator, do what it says, and you\u0026rsquo;ll be set. Remember to change the endpoint variable in the Custom JavaScript variable to the domain name you set up in the previous chapter (https://collector.gtmtools.com/ in my case).\nStep 2.5: Test the tracker and collector Once you\u0026rsquo;ve installed the GA duplicator, you can test to see if the logs are being stored in S3 properly.\nIf the duplicator is doing its job correctly, you can open the Network tab in your browser\u0026rsquo;s developer tools, and look for requests to your collector endpoint. You should see POST requests for each GA call, with the payload of the request in the POST body:\n  If you don\u0026rsquo;t see these requests, it means you\u0026rsquo;ve misconfigured the duplicator somehow, and you should re-read the instructions.\nIf you see the requests but there\u0026rsquo;s an error in the HTTP response, you\u0026rsquo;ll need to check the process outlined in the previous two chapters again.\nAt something like 10 minutes past each hour, the Clojure collector running in Elastic Beanstalk will dump all the Tomcat access logs to S3. You should check that they are being stored, because the whole batch process hinges on the presence of these logs.\nIn S3, there will be a bucket prefixed with elasticbeanstalk-region-id. Within that bucket, browse to folder resources / environments / logs / publish / (some ID) / (some ID). In other words, within the publish folder will be a folder named something like e-ab12cd23ef, and within that will be a folder named something like i-1234567890. Within that final folder will be all your logs in gzip format.\nLook for the ones named _var_log_tomcat8_rotated_localhost_access_log.txt123456789.gz, as these are the logs that the ETL process will use to build the data tables.\nIf you open one of those logs, you should find a bunch of GET and POST entries. Look for POST entries where the endpoint is /com.google.analytics/v1, and the HTTP status code is 200. If you see these, it means that the Clojure collector is almost certainly doing its job. The entry will contain a bunch of interesting information, such as the IP address of the visitor, the User-Agent string of the browser, and a base64 encoded string with the payload. If you decode this string, you should see the full payload of your Google Analytics hit as a query string.\n  Step 3: Configure the ETL process What you need for this step  A collector running and dumping the logs in an S3 bucket.\n Access Key ID and Secret Access Key for the IAM user you created in Step 0.\n  Getting started This step should be pretty straightforward, at least more so than the previous one.\nThe process does a number of things, and you\u0026rsquo;ll want to check out this page for more info.\nBut, in short, here are the main steps operated by the AWS Elastic MapReduce (EMR) service.\n The Tomcat logs are cleaned up so that they can be parsed more easily. Irrelevant log entries are discarded.\n Custom enrichments are applied to the data, if you so wish. Enrichments include things like geolocation from IP addresses, or adding weather information to the data set.\n The enriched data is then shredded, or split into more atomic data sets, each corresponding with a hit that validates against a given schema. For example, if you are collecting data with the Google Analytics setup outlined in my guide, these hits would be automatically shredded into data sets for Page Views, Events, and other Google Analytics tables, ready for transportation to a relational database.\n Finally, the data is copied from the shredded sets to a database created in Amazon Redshift.\n  We\u0026rsquo;ll go over these steps in detail next. It\u0026rsquo;s important to understand that each step of the ETL process leaves a trace in S3 buckets you\u0026rsquo;ll build along the way. This means that even if you choose to apply the current process to your raw logs, you can rerun your entire log history, if you\u0026rsquo;ve decided to keep the files, with new enrichments and shredding schemas later on. All the Tomcat logs are archived, too, so you\u0026rsquo;ll always be able to start the entire process from scratch, using all your historical data, if you wish!\nThe way we\u0026rsquo;ll work in this process is run a Java application name EmrEtlRunner from your local machine. This application initiates and runs the ETL process using Amazon\u0026rsquo;s Elastic MapReduce. At some point, you might want to upgrade your setup, and have EmrEtlRunner execute in an AWS EC2 instance (basically a virtual machine in Amazon\u0026rsquo;s cloud). That way you could schedule it to run, say, every 60 minutes, and then forget about it.\nDownload the necessary files The ETL runner is a Unix application you can download from this link. To grab the latest version, look for the file that begins with snowplow_emr_rXX, where XX is the highest number you can find. At the time of writing, the latest binary is snowplow_emr_r97_knossos.zip.\n Download this ZIP file, and copy the snowplow-emr-etl-runner Unix executable into a new folder on your hard drive. This folder will be your base of operations.\n At this point, you\u0026rsquo;ll want to also clone the Snowplow Github repo in that folder, because it has all the config file templates and SQL files you\u0026rsquo;ll need later on.\n So browse to the directory to where you copied the snowplow-emr-etl-runner file, and run the following command:\n  git clone https://github.com/snowplow/snowplow.git If you don\u0026rsquo;t have Git installed, now would be a good time to do it.\n   Now you should have both the snowplow-emr-etl-runner file and the snowplow folder in the same directory.\n Next, create a new folder named config, and in that, a new folder named targets.\n Then, perform the following copy operations:\n Copy snowplow/3-enrich/emr-etl-runner/config/config.yml.sample to config/config.yml.\n Copy snowplow/3-enrich/config/iglu_resolver.json to config/iglu_resolver.json.\n Copy snowplow/4-storage/config/targets/redshift.json to config/targets/redshift.json.\n     In the end, you should end up with a folder and file structure like this:\n. |-- snowplow-emr-etl-runner |-- snowplow | |-- -SNOWPLOW GIT REPO HERE- |-- config | |-- iglu_resolver.json | |-- config.yml | |-- targets | |-- redshift.json  Create an EC2 key pair At this point, you\u0026rsquo;ll also need to create a private key pair in Amazon EC2. The ETL process will run on virtual machines in the Amazon cloud, and these machines are powered by Amazon EC2. For the runner to have full privileges to create and manage these machines, you will need to provide it with access control rights, and that\u0026rsquo;s what the key pair is for.\n In AWS, select Services from the top navigation, and click on EC2. In the left-hand menu, browse down to Key Pairs, and click the link.\n At this point, make sure you are in the Region where you\u0026rsquo;ll be running all the proceeding jobs. For consistency\u0026rsquo;s sake, it makes sense to stay in the same Region you\u0026rsquo;ve been in all along. Remember, you can choose the Region from the top navigation.\n     Once you\u0026rsquo;ve made sure you\u0026rsquo;re in the correct Region, click Create Key Pair.\n Give the key pair a name you\u0026rsquo;ll remember. My key pair is named simoahava.\n Once you\u0026rsquo;re done, you\u0026rsquo;ll see your new key pair in the list, and the browser automatically downloads the file \u0026lt;key pair name\u0026gt;.pem to your computer.\n    Create the S3 buckets At this time, you\u0026rsquo;ll need to create a bunch of buckets (storage locations) in Amazon S3. These will be used by the batch process to manage all your data files through various stages of the ETL process.\nYou will need buckets for the following:\n :raw:in - you already have this, actually. It\u0026rsquo;s the elasticbeanstalk-region-id created by the Clojure collector running in Elastic Beanstalk.\n :processing - intermediate bucket for the log files before they are enriched.\n :archive - you\u0026rsquo;ll need three different archive buckets: :raw (for the raw log files), :enriched (for the enriched files), :shredded (for the shredded files).\n :enriched - you\u0026rsquo;ll need two buckets for enriched data: :good (for data sets successfully enriched), :bad (for those that failed enrich).\n :shredded - you\u0026rsquo;ll likewise need two buckets for shredded data: :good (for data sets successfully shredded), :bad (for those that failed shredding).\n :log - a bucket for logs produced by the ETL process.\n  To create these buckets, head on over to S3 by clicking Services in the AWS top navigation, and choosing S3.\nYou should already have your :raw:in bucket here, it\u0026rsquo;s the one whose name starts with elasticbeanstalk-.\nLet\u0026rsquo;s start with creating a new bucket that will contain all the \u0026ldquo;sub-buckets\u0026rdquo; for ETL.\nClick +Create bucket, and name the bucket something like simoahava-snowplow-data. The bucket name must be unique across all of S3, so you can\u0026rsquo;t just name it snowplow. Click Next a couple of times and then finally Create bucket to create this root bucket.\n  Now click the new bucket name to open the bucket. You should see a screen like this:\n  Click + Create folder, and create the following three folders into this empty bucket:\n archive\n enriched\n shredded\n    Then, in archive, create the following three folders:\n raw\n enriched\n shredded\n  Next, in both enriched and shredded, create the following two folders:\n good\n bad\n  Thus, you should end up with a bucket that has the following structure:\n. |-- elasticbeanstalk-region-id |-- simoahava-snowplow-data | |-- archive | | |-- raw | | |-- enriched | | |-- shredded | |-- encriched | | |-- good | | |-- bad | |-- shredded | | |-- good | | |-- bad Finally, create one more bucket in the root of S3 named something like simoahava-snowplow-log. You\u0026rsquo;ll use this for the logs produced by the batch process.\nPrepare for configuring the EmrEtlRunner Now you\u0026rsquo;ll need to configure the EmrEtlRunner. You\u0026rsquo;ll use the config.yml file you copied from the Snowplow repo to the config/ folder. For the config, you\u0026rsquo;ll need the following things:\n The Access Key ID and Secret Access Key for the snowplow-setup user you created all the way back in Step 0. If you didn\u0026rsquo;t save these, you can generate a new Access Key through AWS IAM.\n You will need to download and install the AWS Command Line Interface. You can use the official guide to install it with Python/pip, but if you\u0026rsquo;re running Mac OS X, I recommend using Homebrew instead. Once you\u0026rsquo;ve installed Homebrew, you just need to run brew install awscli to install the AWS client.\n  Once you\u0026rsquo;ve installed awscli, you need to run aws configure in your terminal, and do what it instructs you to do. You\u0026rsquo;ll need your Access Key ID and Secret Access Key handy, as well as the region name (e.g. eu-west-1) where you\u0026rsquo;ll be running your EC2 (again, I recommend to use the same region for all parts of this pipeline process).\n$ aws configure AWS Access Key ID: \u0026lt;enter your IAM user Access Key ID here\u0026gt; AWS Secret Access Key: \u0026lt;enter you IAM user Secret Access Key here\u0026gt; Default region name: \u0026lt;enter the region name, e.g. eu-west-1 here\u0026gt; Default output format: \u0026lt;just press enter\u0026gt; This is what it looked like when I ran aws configure.\n  After running aws configure, the next command you\u0026rsquo;ll need to run is aws emr create-default-roles. This will create default roles for the EmrEtlRunner, so that it can perform the necessary tasks in EC2 for you.\nOnce you\u0026rsquo;ve done these steps (remember to still keep your Access Key ID and Secret Access Key close by), you\u0026rsquo;re ready to configure EmrEtlRunner!\nConfigure EmrEtlRunner EmrEtlRunner is the name of the utility you downloaded earlier, with the filename snowplow-emr-etl-runner.\nEmrEtlRunner does a LOT of things. See this diagram to see an overview of the process. At this point, we\u0026rsquo;ll do all the steps except for step 13, rdb_load. That\u0026rsquo;s the step where the enriched and shredded data are copied into a relational database. We\u0026rsquo;ll take care of that in the next step.\nAnyway, EmrEtlRunner is operated by config.yml, which you\u0026rsquo;ve copied into the config/ directory. I\u0026rsquo;ll show you the config I use, and highlight the parts you\u0026rsquo;ll need to change.\naws: access_key_id: AKIAIBAWU2NAYME55123 secret_access_key: iEmruXM7dSbOemQy63FhRjzhSboisP5TcJlj9123 s3: region: eu-west-1 buckets: assets: s3://snowplow-hosted-assets jsonpath_assets: log: s3://simoahava-snowplow-log raw: in: - s3://elasticbeanstalk-eu-west-1-375284143851/resources/environments/logs/publish/e-f4pdn8dtsg processing: s3://simoahava-snowplow-data/processing archive: s3://simoahava-snowplow-data/archive/raw enriched: good: s3://simoahava-snowplow-data/enriched/good bad: s3://simoahava-snowplow-data/enriched/bad errors: archive: s3://simoahava-snowplow-data/archive/enriched shredded: good: s3://simoahava-snowplow-data/shredded/good bad: s3://simoahava-snowplow-data/shredded/bad errors: archive: s3://simoahava-snowplow-data/archive/shredded emr: ami_version: 5.9.0 region: eu-west-1 jobflow_role: EMR_EC2_DefaultRole service_role: EMR_DefaultRole placement: ec2_subnet_id: subnet-d6e91a9e ec2_key_name: simoahava bootstrap: [] software: hbase: lingual: jobflow: job_name: Snowplow ETL master_instance_type: m1.medium core_instance_count: 2 core_instance_type: m1.medium core_instance_ebs: volume_size: 100 volume_type: \u0026#34;gp2\u0026#34; volume_iops: 400 ebs_optimized: false task_instance_count: 0 task_instance_type: m1.medium task_instance_bid: 0.015 bootstrap_failure_tries: 3 configuration: yarn-site: yarn.resourcemanager.am.max-attempts: \u0026#34;1\u0026#34; spark: maximizeResourceAllocation: \u0026#34;true\u0026#34; additional_info: collectors: format: clj-tomcat enrich: versions: spark_enrich: 1.12.0 continue_on_unexpected_error: false output_compression: NONE storage: versions: rdb_loader: 0.14.0 rdb_shredder: 0.13.0 hadoop_elasticsearch: 0.1.0 monitoring: tags: {} logging: level: DEBUG The keys you need to edit are listed next, with a comment on how to edit them. All the keys not listed below you can leave with their default values. I really recommend you read through the configuration documentation for ideas on how to modify the rest of the keys to make your setup more powerful.\n   Key Comment     :aws:access_key_id Copy-paste the Access Key ID of your IAM user here.   :aws:secret_access_key Copy-paste the Secret Access Key of your IAM user here.   :aws:s3:region Set this to the region where your S3 buckets are located in.   :aws:s3:buckets:log Change this to the name of the S3 bucket you created for the ETL logs.   :aws:s3:buckets:raw:in This is the bucket where the Tomcat logs are automatically pushed to. Do not include the last folder in the path, because this might change with an auto-scaling environment. Note! Keep the hyphen in the beginning of the line as in the config file example!   :aws:s3:buckets:raw:processing Set this to the respective processing bucket.   :aws:s3:buckets:raw:archive Set this to the archive bucket for raw data.   :aws:s3:buckets:enriched:good Set this to the enriched/good bucket.   :aws:s3:buckets:enriched:bad Set this to the enriched/bad bucket.   :aws:s3:buckets:enriched:errors Leave this empty.   :aws:s3:buckets:enriched:archive Set this to the archive bucket for enriched data.   :aws:s3:buckets:shredded:good Set this to the shredded/good bucket.   :aws:s3:buckets:shredded:bad Set this to the shredded/bad bucket.   :aws:s3:buckets:shredded:errors Leave this empty.   :aws:s3:buckets:shredded:archive Set this to the archive bucket for shredded data.   :aws:emr:region This should be the region where the EC2 job will run.   :aws:emr:placement Leave this empty.   :aws:emr:ec2_subnet_id The subnet ID of the Virtual Private Cloud the job will run in. You can use the same subnet ID used by the EC2 instance running your collector.   :aws:emr:ec2_key_name The name of the EC2 Key Pair you created earlier.   :collectors:format Set this to clj-tomcat.   :monitoring:snowplow Remove this key and all its children (:method, :app_id, and :collector).    Just two things to point out.\nFirst, when copying the :aws:s3:buckets:raw:in path, do not copy the last folder name. This is the instance ID. With an auto-scaling environment set for the collector, there might be multiple instance folders in this bucket. If you only name one folder, you\u0026rsquo;ll risk missing out on a lot of data.\n  You can get the :aws:emr:ec2_subnet_id by opening the Services menu in AWS and clicking EC2. Click the link titled Running Instances (there should be 1 running instance - your collector). Scroll down the Description tab contents until you find the Subnet ID entry. Copy-paste that into the aws:emr:ec2_subnet_id field.\n  If you\u0026rsquo;ve followed all the steps in this chapter, you should now be set.\nYou can verify everything works by running the following command in the directory where the snowplow-emr-etl-runner executable is, and where the config folder is located.\n./snowplow-emr-etl-runner run -c config/config.yml -r config/iglu_resolver.json\n  You can also follow the process in real-time by opening the Services menu in AWS and clicking EMR. There, you should see the job named Snowplow ETL. By clicking it, you can see all the steps it is running through. If the process ends in an error, you can also debug quite handily via this view, since you can see the exact step where the process failed.\n  Once the ETL has successfully completed, you can check your S3 buckets again. Your Snowplow data buckets should now contain a lot of new stuff. The folder with the interesting data is archive / shredded. This is where the good shredded datasets are copied to, and corresponds to what would have been copied to the relational database had you set this up in this step.\nAnyway, with the ETL process up and running, just one more step remains in this monster of a guide: setting up AWS Redshift as the relational database where you\u0026rsquo;ll be warehousing your analytics data!\nWhat you should have after this step  The snowplow-emr-etl-runner executable configured with your config.yml file.\n New buckets in S3 to store all the files created by the batch process.\n The ETL job running without errors all the way to completion, enriching and shredding the raw Tomcat logs into relevant S3 buckets.\n  Step 4: Load the data into Redshift What you need for this step  The ETL process configured and available to run at your whim.\n Shredded files being stored in the archive / shredded S3 bucket.\n An SQL query client. I recommend SQL Workbench/J, which is free. That\u0026rsquo;s the one I\u0026rsquo;ll be using in this guide.\n  Getting started In this final step of this tutorial, we\u0026rsquo;ll load the shredded data into Redshift tables. Redshift is a data warehouse service offered by AWS. We\u0026rsquo;ll use it to build a relational database, where each table stores the information shredded from the Tomcat logs in a format easy to query with SQL. By the way, if you\u0026rsquo;re unfamiliar with SQL, look no further than this great Codecademy course to get you started with the query language!\nThe steps you\u0026rsquo;ll take in this chapter are roughly these:\n Create a new cluster and database in Redshift.\n Add users and all the necessary tables to the database.\n Configure the EmrEtlRunner to automatically load the shredded data into Redshift tables.\n  Once you\u0026rsquo;re done, each time you run EmrEtlRunner, the tables will be populated with the parsed tracker data. You can then run SQL queries against this data, and use it to proceed with the two remaining steps (not covered in this guide) of the Snowplow pipeline: data modeling and analysis.\nCreate the cluster In AWS, select Services from the top navigation and choose the Amazon Redshift service.\nAgain, double-check that you are in the correct region (the same one where you\u0026rsquo;ve been working on all along, or, at the very least, the one where your S3 logs are). Then click the Launch cluster button.\n  Give the cluster an identifier. I named my cluster simoahava. Give a name to the database, too. The name I chose was snowplow.\nKeep the database port at its default value (5439).\nAdd a username and password to your master user. This is the user you\u0026rsquo;ll initially log in with, and it\u0026rsquo;s the one you\u0026rsquo;ll create the rest of the users and all the necessary tables with. Remember to write these down somewhere - you\u0026rsquo;ll need them in just a bit.\nClick Continue when ready.\n  In the next view, leave the two options at their default values. Node type should be dc2.large, and Cluster type should be Single Node (with 1 as the number of compute nodes used). Click Continue when ready.\n  In the Additional Configuration view, you can leave most of the options at their default values. For the VPC security group, select the default group. The settings should thus be something like these:\nCluster parameter group: default-redshift-1.0\nEncrypt database: None\nChoose a VPC: Default VPC (\u0026hellip;)\nCluster subnet group: default\nPublicly accessible: Yes\nChoose a public IP address: No\nEnhanced VPC Routing: No\nAvailability zone: No Preference\nVPC security groups: default (sg-\u0026hellip;)\nCreate CloudWatch Alarm: No\nAvailable roles: No selection\nOnce done, click Continue.\nYou can double-check your settings, and then just click Launch cluster.\nThe cluster will take some minutes to launch. You can check the status of the cluster in the Redshift dashboard.\n  Once the cluster has been launched, you are ready to log in and configure it!\nConfigure the cluster and connect to it The first thing you\u0026rsquo;ll need to do is make sure the cluster accepts incoming connections from your local machine.\nSo after clicking Services in the AWS top navigation and choosing Amazon Redshift, go to Clusters and then click the cluster name in the dashboard.\nUnder Cluster Properties, click the link to the VPC security group (should be named something like default (sg-1234abcd)).\n  You should be transported to the EC2 dashboard, and Security Groups should be active in the navigation menu.\nIn the bottom of the screen, the settings for the security group you clicked should be visible.\nSelect the Inbound tab, and make sure it shows a TCP connection with Port Range 5439 and 0.0.0.0/0 as the Source. This means that all incoming TCP connections are permitted (you can change this to a more stricter policy later on).\nIf the values are different, you can Edit the Inbound rule to match these.\n  Now it\u0026rsquo;s time to connect to the cluster. Go back to Amazon Redshift, and open your cluster settings as before. Copy the link to the cluster from the top of the settings list.\n  Next, open the SQL query tool of your choice. I\u0026rsquo;m using SQL Workbench/J. Select File / Connect Window, and create a new connection with the following settings changed from defaults:\nDriver: Amazon Redshift (com.amazon.redshift.jdbc.Driver)\nURL: jdbc:redshift://cluster_url:cluster_port/database_name\nUsername: master_username\nPassword: master_password\nAutocommit: Check\nIn URL, copy-paste the Redshift URL with port after the colon and database name after the slash.\nAs Username and Password, add the master username and master password you chose when creating the cluster.\nMake sure Autocommit is checked. These are settings I have:\n  Once done, you can click OK, and the tool will connect to your cluster and database.\nOnce connected, you can feed the command SELECT current_database(); and click the Execute button to check if everything works. This is what you should see:\n  If the query returns the name of the database, you\u0026rsquo;re good to go!\nCreate the database tables First, we\u0026rsquo;ll need to create the tables that will store the Google Analytics tracker data within them. The tables are loaded as .sql files, and these files contain DDL (data-definition language) constructions that build all the necessary schemas and tables.\nFor this, you\u0026rsquo;ll need access to the schema .sql files, which you\u0026rsquo;ll find in the following locations within the snowplow Git repo:\n snowplow/4-storage/redshift-storage/sql/atomic-def.sql\n snowplow/4-storage/redshift-storage/sql/manifest-def.sql\n  Load atomic-def.sql first, and run the file in your SQL query tool while connected to your Redshift database. You should see a message that the schema atomic and table atomic.events were created successfully.\n  Next, run manifest-def.sql while connected to the database. You should see a message that the table atomic.manifest was created successfully.\nNow you need to load all the DDLs for the Google Analytics schemas. If you don\u0026rsquo;t create these tables, then the ETL process will run into an error, where the utility tries to copy shredded events into non-existent tables.\nYou can find all the required .sql files in the following three directories:\n https://github.com/snowplow/iglu-central/tree/master/sql/com.google.analytics\n https://github.com/snowplow/iglu-central/tree/master/sql/com.google.analytics.enhanced-ecommerce\n https://github.com/snowplow/iglu-central/tree/master/sql/com.google.analytics.measurement-protocol\n  You need to load all the .sql files in these three directories and run them while connected to your database. This will create a whole bunch of tables you\u0026rsquo;ll need if you want to collect Google Analytics tracker data.\nIt might be easiest to clone the iglu-central repo, and then load the .sql files into your query tool from the local directories.\nOnce you\u0026rsquo;re done, you should be able to run the following SQL query and see a list of all the tables you just created as a result (should be 40 in total):\nSELECT * FROM pg_tables WHERE schemaname='atomic';\n  Create the database users Next thing we\u0026rsquo;ll do is create three users:\n storageloader, who will be in charge of the ETL process.\n power_user, who will have admin privileges, so you no longer have to log in with the master credentials.\n read_only, who can query data and create his/her own tables.\n  Make sure you\u0026rsquo;re still connected to the database, and copy-paste the following SQL queries into the query window. For each $password, change it to a proper password, and make sure you write these user + password combinations down somewhere.\nCREATE USER storageloader PASSWORD \u0026#39;$password\u0026#39;; GRANT USAGE ON SCHEMA atomic TO storageloader; GRANT INSERT ON ALL TABLES IN SCHEMA atomic TO storageloader; CREATE USER read_only PASSWORD \u0026#39;$password\u0026#39;; GRANT USAGE ON SCHEMA atomic TO read_only; GRANT SELECT ON ALL TABLES IN SCHEMA atomic TO read_only; CREATE SCHEMA scratchpad; GRANT ALL ON SCHEMA scratchpad TO read_only; CREATE USER power_user PASSWORD \u0026#39;$password\u0026#39;; GRANT ALL ON DATABASE snowplow TO power_user; GRANT ALL ON SCHEMA atomic TO power_user; GRANT ALL ON ALL TABLES IN SCHEMA atomic TO power_user; Again, remember to change the three $password values to proper SQL user passwords.\nIf all goes well, you should see 12 \u0026ldquo;COMMAND executed successfully\u0026rdquo; statements.\nFinally, you need to grant ownership of all tables in schema atomic to storageloader, because this user will need to run some commands (specifically, vacuum and analyze) that only table owners can run.\nSo, first run the following query in the database.\nSELECT \u0026#39;ALTER TABLE atomic.\u0026#39; || tablename ||\u0026#39; OWNER TO storageloader;\u0026#39; FROM pg_tables WHERE schemaname=\u0026#39;atomic\u0026#39; AND NOT tableowner=\u0026#39;storageloader\u0026#39;; In the query results, you should see a bunch of ALTER TABLE atomic.* OWNER TO storageloader; queries. Copy all of these, and paste them into the statement field as new queries. Then run the statements.\n  Now, if you run SELECT * FROM pg_tables WHERE schemaname='atomic' AND tableowner='storageloader';, you should see all the tables in the atomic schema as a result.\nYou have successfully created the users and the tables in the database. All that\u0026rsquo;s left is to configure the EmrEtlRunner to execute the final step of the ETL process, where the storageloader user copies all the data from the shredded files into the corresponding Redshift tables.\nCreate new IAM role for database loader The EmrEtlRunner will copy the files to Redshift using a utility called RDB Loader (Relational Database Loader). For this tool to work with sufficient privileges, you\u0026rsquo;ll need to create a new IAM Role, which grants the Redshift cluster read-only access to your S3 buckets.\n So, in AWS, click Services and select IAM.\n Select Roles from the left-hand navigation. Click the Create role button.\n In the Select type of trusted entity view, keep the default AWS Service selected, and choose Redshift from the list of services. In the Select your use case list, choose Redshift - Customizable, and then click Next: Permissions.\n     In the next view, find the policy named AmazonS3ReadOnlyAccess, and check the box next to it. Click Next: Review.     Name the role something useful, such as RedshiftS3Access and click Create Role when ready.\n You should be back in the list of roles. Click the newly created RedshiftS3Access role to see its configuration. Copy the value in the Role ARN field to the clipboard. You\u0026rsquo;ll need it very soon.\n     Finally, select Services from AWS top navigation and choose the Amazon Redshift service. Click Clusters in the left-hand navigation to see the list of running clusters.\n Check the box next to your Snowplow cluster, and click Manage IAM Roles.\n     In the Available roles list, choose the role you just created, and then click Apply changes to apply the role to your cluster.    The Cluster Status should change to modifying. Once it\u0026rsquo;s done, the status will change to available, and you can check if the role you assigned is labeled as in-sync by clicking Manage IAM Roles again.\nEdit the Redshift target configuration If you copied all necessary files back in Step 3, your project config/ directory should include a targets/ folder with the file redshift.json in it. If you don\u0026rsquo;t have it, go back to Step 3 and make sure you copy the redshift.json template to the correct folder.\nOnce you\u0026rsquo;ve found the template, open it for editing, and make sure it looks something like this:\n{ \u0026#34;schema\u0026#34;: \u0026#34;iglu:com.snowplowanalytics.snowplow.storage/redshift_config/jsonschema/2-1-0\u0026#34;, \u0026#34;data\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;AWS Redshift enriched events storage\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;simoahava.coyhone1deuh.eu-west-1.redshift.amazonaws.com\u0026#34;, \u0026#34;database\u0026#34;: \u0026#34;snowplow\u0026#34;, \u0026#34;port\u0026#34;: 5439, \u0026#34;sslMode\u0026#34;: \u0026#34;DISABLE\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;storageloader\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;roleArn\u0026#34;: \u0026#34;arn:aws:iam::375284143851:role/RedshiftS3Access\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;atomic\u0026#34;, \u0026#34;maxError\u0026#34;: 1, \u0026#34;compRows\u0026#34;: 20000, \u0026#34;sshTunnel\u0026#34;: null, \u0026#34;purpose\u0026#34;: \u0026#34;ENRICHED_EVENTS\u0026#34; } } Here are the fields you need to edit:\n host: The URL of your Redshift cluster\n database: The database name\n username: storageloader\n password: storageloader password\n roleArn: The Role ARN of the IAM role you created in the previous step  All the other options you can leave with their default values.\nRe-run EmrEtlRunner through the whole process Now that you\u0026rsquo;ve configured everything, you\u0026rsquo;re ready to run the EmrEtlRunner with all the steps in the ETL process included. This means enrichment of the log data, shredding of the log data to atomic datasets, and loading these datasets into your Redshift tables.\nThe command you\u0026rsquo;ll need to run in the root of your project folder (where the snowplow-emr-etl-runner executable is) is this:\n./snowplow-emr-etl-runner run -c config/config.yml -r config/iglu_resolver.json -t config/targets This command will process all the data in the :raw:in bucket (the one with all your Tomcat logs), and proceed to extract and transform them, and finally load them into your Redshift tables. The process will take a while, so go grab a coffee. Remember that you can check the status of the job by browsing to EMR via the AWS Services navigation.\nOnce complete, you should see something like this in the command line:\n  Test it Now you should be able to login to the database using the new read_only user. If you run the following query, it should return a list of timestamps and events for each Client ID visiting your site.\nSELECT u.root_tstamp, u.client_id, h.type FROM atomic.com_google_analytics_measurement_protocol_user_1 AS u JOIN atomic.com_google_analytics_measurement_protocol_hit_1 AS h ON u.root_id = h.root_id ORDER BY root_tstamp ASC   Considering how much time you have probably put into making everything work (if following this guide diligently), I really hope it all works correctly.\nWrapping it all up By following this guide, you should be able to set up an end-to-end Snowplow batch pipeline.\n Google Tag Manager duplicates the payloads sent to Google Analytics, and sends these to your Amazon endpoint, using a custom domain name whose DNS records you have delegated to AWS.\n The endpoint is a collector which logs all the HTTP requests to Tomcat logs, and stores them in an S3 bucket.\n An ETL process is then run, enriching the stored data, and shredding it to atomic datasets, again stored in S3.\n Finally, the ETL runner copies these datasets into tables you\u0026rsquo;ve set up in a new relational database running on an AWS Redshift cluster.\n  There are SO many moving parts here, that it\u0026rsquo;s possible you\u0026rsquo;ll get something wrong at some point. Just try to patiently walk through the steps in this guide to see if you\u0026rsquo;ve missed anything.\nFeel free to ask questions in the comments, and maybe I or my readers will be able to help you along.\nYou can also join the discussions in Snowplow\u0026rsquo;s Discourse site - I\u0026rsquo;m certain the folks there are more than happy to help you if you run into trouble setting up the pipeline.\nDo note also that the setup outlined in this guide is very rudimentary. There are many ways you can, and should, optimize the process, such as:\n Add SSL support to your Redshift cluster.\n Scale the instances (collector and the ETL process) correctly to account for peaks in traffic and dataset size.\n Move the EmrEtlRunner to AWS, too. There\u0026rsquo;s no need to run it on your local machine.\n Schedule the EmrEtlRunner to run (at least) once a day, so that your database is refreshed with new data periodically.\n  Good luck!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/automatically-fork-google-analytics-hits-snowplow/",
	"title": "#GTMTips: Automatically Duplicate Google Analytics Hits To Snowplow",
	"tags": ["google tag manager", "gtmtips", "snowplow", "customTask"],
	"description": "A guide for implementing the Google Analytics JavaScript plugin when using Google Tag Manager.",
	"content": " I\u0026rsquo;m back with another customTask tip, but this time I\u0026rsquo;m exploring some new territory. Snowplow just introduced their latest version update, which included (among other things) an adapter for processing Google Analytics payloads. Never heard of Snowplow? It\u0026rsquo;s a collection of open-source libraries designed to let you build your own analytics pipeline, all the way from data collection, through ETL (extract, transform, load), using custom enrichments and JSON schemas, and finally into your own data warehouse, where you can then analyze the data using whatever tools you find preferable. Everything is designed to run over Amazon Web Services, so you don\u0026rsquo;t need to invest in local server hardware or hosting services.\n Snowplow pipeline - from https://goo.gl/X9Jfeo  In essence, it\u0026rsquo;s a full-service, do-it-yourself analytics solution. Snowplow has deservedly gained a lot of momentum over the recent years, as more and more companies have matured to the point where they want full control of their data. And I don\u0026rsquo;t just mean data ownership, but also things like controlling the aggregation schemas that have proven to be rather rigid in Google Analytics, and being in full charge when and how the data is sampled and normalized.\nAnyway, at some point I\u0026rsquo;ll author a proper article about Snowplow - one that it deserves. This time I\u0026rsquo;m just going to show you how to setup the Google Analytics duplicator / tracker, so that you can start collecting hits in your Snowplow pipeline by simply leveraging the payload generated and collected by Google Analytics.\nTip 70: Duplicate Google Analytics payload to Snowplow   If you read the release announcement, you might have noticed that the release is essentially a Google Analytics plugin, which is easy to add if you\u0026rsquo;re using the analytics.js tracking snippet.\nUnfortunately, with Google Tag Manager there is no reliable way to load a plugin in your Google Analytics tags. That means you\u0026rsquo;re left with clumsy workarounds, such as\n A Custom HTML tag which you use to load analytics.js and create a tracker with the plugin.\n Some customTask hack where you load the plugin mid-hit.\n  The first one is unwieldy because you would then need to have all your tags use the same tracker name if you wanted them all to duplicate the payloads to Google Analytics.\nThe second simply doesn\u0026rsquo;t work. Even if you do manage to load the plugin in the tracker, Google Analytics would not stop to wait for the plugin to be registered, but would simply send the hit before the plugin has had time to attach and modify the tracker object itself.\nSo in this tip, we\u0026rsquo;re just going to skip the plugin altogether, and replicate its functionality using customTask.\nTo make it all work, create a new Custom JavaScript variable, name it something like {{customTask - Snowplow duplicator}}, and add the following code within:\nfunction() { // Add your snowplow collector endpoint here  var endpoint = \u0026#39;https://collector.simoahava.com/\u0026#39;; return function(model) { var vendor = \u0026#39;com.google.analytics\u0026#39;; var version = \u0026#39;v1\u0026#39;; var path = ((endpoint.substr(-1) !== \u0026#39;/\u0026#39;) ? endpoint + \u0026#39;/\u0026#39; : endpoint) + vendor + \u0026#39;/\u0026#39; + version; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; var originalSendHitTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { var payload = sendModel.get(\u0026#39;hitPayload\u0026#39;); originalSendHitTask(sendModel); var request = new XMLHttpRequest(); request.open(\u0026#39;POST\u0026#39;, path, true); request.setRequestHeader(\u0026#39;Content-type\u0026#39;, \u0026#39;text/plain; charset=UTF-8\u0026#39;); request.send(payload); }); }; }  Then you need to edit every single Google Analytics tag whose data you also want to send to Snowplow.\nAt this point, if you haven\u0026rsquo;t done so yet, it\u0026rsquo;s a good idea to make use of the Google Analytics Settings variable. Instead of having to modify every single tag, you only need to make the necessary change (see below) in the GAS variable, after which you can add that GAS variable to all your Google Analytics tags. Useful!\n  Anyway, the change you need to make is under More Settings / Fields to set of your Google Analytics tags or the Google Analytics Settings variable. If you\u0026rsquo;re editing tags directly, you\u0026rsquo;ll need to check the \u0026ldquo;Enable overriding settings in this tag\u0026rdquo; option to see the More Settings fields. Here\u0026rsquo;s the field you need to add.\nField name: customTask\nValue: {{customTask - Snowplow duplicator}}\nRemember - the change needs to be done in all the Google Analytics tags whose data you want to fork to Snowplow.\nNote! At the time of writing, only the Clojure Collector in Snowplow supports the Google Analytics adapter. Hopefully they\u0026rsquo;ll release support for the Scala Stream Collector soon, as it will give you access to that sweet, juicy Google Analytics real-time data! Make sure you follow the Snowplow discussion forum - it\u0026rsquo;s a good place as any to get information on the roadmap.\nThis is a pretty sweet addition to Snowplow, because it lets you operate with parameters and values that are familiar to you, if you\u0026rsquo;ve used Google Analytics before. It also lets you leverage existing Google Analytics tracking, so you don\u0026rsquo;t need to rewrite the tracking setup on your site just to migrate to Snowplow.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/simple-custom-event-listeners-gtm/",
	"title": "#GTMTips: Simple Custom Event Listeners With Google Tag Manager",
	"tags": ["google tag manager", "javascript", "events", "gtmtips"],
	"description": "How to create simple custom event listeners with Google Tag Manager. You can track any user interaction on the site with this solution.",
	"content": " First of all, check out this article for an overview of how custom event listeners work in Google Tag Manager. The reason I\u0026rsquo;m writing this #GTMTips article is that I want to upgrade the solution slightly, and I want to bring it back into the spotlight. Why? Because it\u0026rsquo;s still one of the most effective ways to customize your Google Tag Manager implementation.\nA custom event listener is a handler you write with JavaScript. It lets you handle any JavaScript DOM events, such as click, form submit, mouse hover, drag, touch, error, page load and unload, and so many more. It also lets you leverage the useCapture parameter which will prove very helpful if you have other JavaScript on the site interfering with GTM\u0026rsquo;s default event triggers.\nTip 69: Create custom event listeners with ease   The solution comprises the following items: a Custom HTML tag firing with the page load, and a Custom JavaScript variable providing the callback. You\u0026rsquo;ll also need a bunch of Data Layer variables to fetch the values pushed into dataLayer by the callback.\nThe idea is that when the page loads, you attach your custom listener to whatever element you want to track for the given event. Then, when this interaction is recorded by the browser, the code pushes an object into dataLayer which you can then use to populate your tags.\nThe Custom HTML tag This is what the Custom HTML tag would look like.\n\u0026lt;script\u0026gt; (function() { // Use events from https://developer.mozilla.org/en-US/docs/Web/Events  var eventName = \u0026#39;dragstart\u0026#39;; // Attach listener directly to element or document if element not found  var el = document.querySelector(\u0026#39;img#download\u0026#39;) || document; // Leave useCapture to true if you want to avoid propagation issues.  var useCapture = true; el.addEventListener(eventName, {{JS - Generic Event callback}}, useCapture); })(); \u0026lt;/script\u0026gt; Fire this on a Page View trigger if attaching directly to the document node, or a DOM Ready trigger if attaching directly to an element and the element is in the HTML source, or a Window Loaded trigger if attaching directly to an element that is added dynamically to the page during the page load.\nMake sure you change the eventName value to reflect which event you want to track. If you want to track clicks, change it to click. If you want to track users hovering over the element, change it to mouseover, and so on.\nYou can choose to add the listener directly to an element by using the appropriate CSS selector as the parameter of document.querySelector(). Alternatively, you can add the listener directly on the document node.\nFinally, you can set useCapture to false if you want to use the bubble phase instead of the capture phase with your event handler. Because you are simply tracking interactions and not actually creating any side effects, I really recommend leaving this as true.\nThis is significant especially if you have other JavaScript on the site messing with event propagation. A typical symptom of this is that your Form and Just Links triggers refuse to work. So by using the capture phase, you are evading propagation-stopping JavaScript, and might just be able to track these events when GTM\u0026rsquo;s default triggers are unable to do so.\nThe last line actually adds the listener, providing a Custom JavaScript variable as the callback.\nThe Custom JavaScript variable Here\u0026rsquo;s what {{JS - Generic Event callback}} should look like:\nfunction() { return function(event) { window.dataLayer.push({ event: \u0026#39;custom.event.\u0026#39; + event.type, \u0026#39;custom.gtm.element\u0026#39;: event.target, \u0026#39;custom.gtm.elementClasses\u0026#39;: event.target.className || \u0026#39;\u0026#39;, \u0026#39;custom.gtm.elementId\u0026#39;: event.target.id || \u0026#39;\u0026#39;, \u0026#39;custom.gtm.elementTarget\u0026#39;: event.target.target || \u0026#39;\u0026#39;, \u0026#39;custom.gtm.elementUrl\u0026#39;: event.target.href || event.target.action || \u0026#39;\u0026#39;, \u0026#39;custom.gtm.originalEvent\u0026#39;: event }); }; }  This callback pushes a bunch of information about the event into dataLayer, namespacing everything with the custom.gtm. prefix. The event name itself will be custom.event.\u0026lt;event name\u0026gt;, e.g. custom.event.click for a click event or custom.event.dragstart when tracking the dragging action.\nThe variables pushed into dataLayer mirror those used by GTM\u0026rsquo;s default triggers, with the exception of custom.gtm.originalEvent which will contain a reference to the original event that invoked the callback. This is significant if you need information from this event object, such as which mouse button was clicked when a click is registered. This is (currently) missing from GTM\u0026rsquo;s default trigger functionality.\nData Layer variables You need to create a Data Layer variable for each of the keys pushed into dataLayer. To mimic Google Tag Manager\u0026rsquo;s naming schema for Built-in variables, you could use something like these:\n   Variable name Data Layer Variable Name     {{Custom Event Element}} custom.gtm.element   {{Custom Event Classes}} custom.gtm.elementClasses   {{Custom Event ID}} custom.gtm.elementId   {{Custom Event Target}} custom.gtm.elementTarget   {{Custom Event URL}} custom.gtm.elementUrl   {{Custom Event Original Event}} custom.gtm.originalEvent    The Custom Event trigger To fire your tags when a custom event is registered, you\u0026rsquo;ll need a Custom Event trigger set to the event name pushed into dataLayer in the Custom JavaScript variable callback. So, to follow the example of the dragstart event (registered when the user starts dragging the given element in the browser), the trigger would look like this:\n  Working example Let\u0026rsquo;s tackle a problem that you might well have on your site. You want to track a form element with id contactUs, but no matter what you do, GTM\u0026rsquo;s own Form trigger refuses to fire. You\u0026rsquo;ve looked around, read my articles, and come to the conclusion that the problem is other JavaScript on the site stopping the propagation of the form submit event. Your friendly local developer tells you that due to the nature of the plugin you use, it\u0026rsquo;s impossible to change this behavior.\nCustom event listeners to the rescue! You can trust the useCapture flag to track the form submission even though propagation has been stopped. Here\u0026rsquo;s what the Custom HTML tag would look like:\n\u0026lt;script\u0026gt; (function() { // Use events from https://developer.mozilla.org/en-US/docs/Web/Events  var eventName = \u0026#39;submit\u0026#39;; // Attach listener directly to element or document if element not found  var el = document.querySelector(\u0026#39;form#contactUs\u0026#39;) || document; // Leave useCapture to true if you want to avoid propagation issues.  var useCapture = true; el.addEventListener(eventName, {{JS - Generic Event callback}}, useCapture); })(); \u0026lt;/script\u0026gt; Add a DOM Ready trigger to this tag, set to fire on pages which have this particular form in the HTML source.\nNow, whenever a form submission is detected, your Custom HTML tag will go off, pushing the following object into dataLayer:\n{ \u0026#39;event\u0026#39;: \u0026#39;custom.event.submit\u0026#39;, \u0026#39;custom.gtm.element\u0026#39;: form#contactUs, \u0026#39;custom.gtm.elementClasses\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;custom.gtm.elementId\u0026#39;: \u0026#39;contactUs\u0026#39;, \u0026#39;custom.gtm.elementTarget\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;custom.gtm.elementUrl\u0026#39;: \u0026#39;https://www.domain.com/my-form-handler/\u0026#39;, \u0026#39;custom.gtm.originalEvent\u0026#39;: submitEvent }  And you can pick these up with the Data Layer variables you created earlier.\nYou\u0026rsquo;ll just need a Custom Event trigger, where the Event name field has the value custom.event.submit.\nOnce you attach that trigger to your tag, you can use the Data Layer variables to populate all the relevant fields.\nSummary Whenever I talk about GTM to someone, and that\u0026rsquo;s very often, I always end up talking about the many ways we can customize Google Tag Manager to work even more efficiently on our websites. Custom Event listeners are still, after all these years, my favorite way of customizing a GTM setup.\nThey give you so much power in tracking user interactions on the site.\nAs always, I hope GTM continues to release new default triggers for us. I\u0026rsquo;ve long dreamed of a \u0026ldquo;blank\u0026rdquo; event trigger, where you simply have to add the DOM event name, and it would also have a checkbox for whether you want to use capture mode or not. It would make this custom solution redundant, but that\u0026rsquo;s only a good thing in my book.\nHave you created any creative custom event listeners in your GTM setups?\n"
},
{
	"uri": "https://www.simoahava.com/web-development/static-site-search-google-app-engine-search-api/",
	"title": "Static Site Search With Hugo + App Engine + Search API + Python",
	"tags": ["app engine", "search api", "hugo", "static site", "google cloud"],
	"description": "How to make static site search work using Google App Engine&#39;s Search API and a static site generated with Hugo.",
	"content": " As the year changed to 2018, I decided to abandon WordPress, which I had been using for over 12 years as my content management system of choice. I had many reasons to do so, but the biggest motivators were the opportunity to try something new and to abandon the bloat and clutter of WordPress for a more simple, more elegant order of things. Spurred on by another adopter, Mark Edmondson, I decided to give Hugo a go (pun intended).\n  The migration wasn\u0026rsquo;t easy, as I had to convert WordPress\u0026rsquo; relational database into a static list of markdown files. Along the way, I had to configure two themes (regular and AMP), optimize all my images, JavaScript, and stylesheets, and go through every single one of my 200+ articles, looking for stylistic issues and broken links (oh boy, were there many of those!).\nHugo is written in the Go language, and it\u0026rsquo;s fairly easy to use if you\u0026rsquo;re familiar with markdown and the command line of your operating system. The trick about a static site is that all the content is stored in static files in your file server. There is no relational database to fall back on, which means that a static site can be both blazing fast and a chore to maintain.\nOne of the biggest headaches for me was how to set up site search. Without a database or a web server generating dynamic HTML documents, finding a suitable way to index the content in the browser and respond quickly and efficiently to search queries seemed like an insurmountable task.\nI tried a number of things at first, including:\n Algolia, which I had to give up beacuse I had too much content for their free tier.\n lunr.js running on a NodeJS virtual machine in Google\u0026rsquo;s cloud, which I had to give up because I got a bill of 400$ for instance upkeep for the month of December alone.\n Custom-built solution that digested JSON generated by Hugo and parsed it for searching with jQuery directly in the browser, which I had to give up since downloading an indexed JSON file of around 5 megabytes on every page is not conducive to a good user experience.\n  After the failed experiment with lunr.js, I still wanted to give Google\u0026rsquo;s App Engine another chance. I\u0026rsquo;ve been in love with App Engine ever since publishing the first version of my GTM Tools on it. Well, as it turns out, App Engine has a really useful and flexible Search API for Python, which seems to be tailormade to work with the JSON generated by Hugo in a static site!\n  The setup My setup looks like this:\n The Hugo config file is configured to output an index.json into the public directory, with all the content of my site ready for indexing.\n A script which deploys this JSON file into the App Engine project.\n An App Engine project which uses the Python Search API client to build an index of this JSON.\n The App Engine project also provides an HTTP endpoint to which my site makes all the search queries. Each request is processed as a search query, and the result is returned in the HTTP response.\n Finally, I have a bunch of JavaScript running the search form and the search results page on my site, sending the request to the App Engine endpoint as well as formatting the search results page with the response.\n  The beauty of using the Search API is that I\u0026rsquo;m well below the quota limits for the free version, and thus I don\u0026rsquo;t have to pay a dime to make it all work!\n  1. The config file modification The change to Hugo\u0026rsquo;s config file is easy to make, because Hugo has built in support for generating the JSON in a format that most search libraries digest. In the configuration file, you need to find the output configuration, and add \u0026quot;JSON\u0026quot; as one of the outputs for the home content type. So it looks something like this:\n[output] home = [ \u0026#34;HTML\u0026#34;, \u0026#34;RSS\u0026#34;, \u0026#34;JSON\u0026#34; ] This configuration change generates an index.json file into the root of your public folder whenever the Hugo project is built.\nHere\u0026rsquo;s an example of a what a blog post might look like in this file:\n[ { \u0026#34;uri\u0026#34;: \u0026#34;https://www.simoahava.com/upcoming-talks/\u0026#34;, \u0026#34;title\u0026#34;: \u0026#34;Upcoming Talks\u0026#34;, \u0026#34;tags\u0026#34;: [], \u0026#34;description\u0026#34;: \u0026#34;My upcoming conference talks and events\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;17 March 2018: MeasureCamp London 20 March 2018: SMX München 19 April 2018: Advanced GTM Workshop (Hamburg) 24 May 2018: NXT Nordic (Oslo) 20 September 2018: Advanced GTM Workshop (Hamburg) 14-16 November 2018: SMXL Milan I enjoy presenting at conferences and meetups, and I have a track record of hundreds of talks since 2013, comprising keynotes, conference presentations, workshops, seminars, and public trainings. Audience sizes have varied between 3 and 2,000.\\nMy favorite topics revolve around web analytics development and analytics customization, but I\\u0026rsquo;m more than happy to talk about integrating analytics into organizations, knowledge transfer, improving technical skills, digital marketing, and content creation.\\nSome of my conference slides can be found at SlideShare.\\nFor a sample, here\\u0026rsquo;s a talk I gave at Reaktor Breakpoint in 2015.\\n You can contact me at simo (at) simoahava.com for enquiring about my availability for your event.\\n\u0026#34; } ] 2. The deploy script The deploy script is a piece of Bash code which builds the Hugo site, copies the index.json into my search project folder, and then deploys the entire search project into App Engine. Here\u0026rsquo;s what it looks like:\ncd ~/Documents/Projects/www-simoahava-com/ rm -rf public hugo cp public/index.json ../www-simoahava-com-search/ rm -rf public cd ~/Documents/Projects/www-simoahava-com-search/ gcloud app deploy curl https://search-www-simoahava-com.appspot.com/update The hugo command builds the site and generates the public folder. From the public folder, the index.json is then copied to my search project folder, which is subsequently deployed into App Engine using the command gcloud app deploy. Finally, a curl command to my custom endpoint makes certain that my Python script updates the search index with the latest version of index.json.\n3. The Python code running in App Engine In App Engine, I\u0026rsquo;ve simply created a new project with a name that\u0026rsquo;s easy enough to remember as the endpoint. I haven\u0026rsquo;t added any billing to the account, because I\u0026rsquo;ve set a challenge for myself to build a free search API for my site.\nSee this documentation for a quick start guide on how to get started with Python and App Engine. Focus especially on how to setup the App Engine project (you don\u0026rsquo;t need to enable billing), and how to install and configure the gcloud command line tools for your project.\nThe Python code looks like this.\n#!/usr/bin/python from urlparse import urlparse from urlparse import parse_qs import json import re import webapp2 from webapp2_extras import jinja2 from google.appengine.api import search # Index name for your search documents _INDEX_NAME = \u0026#39;search-www-simoahava-com\u0026#39; def create_document(title, uri, description, tags, content): \u0026#34;\u0026#34;\u0026#34;Create a search document with ID generated from the post title\u0026#34;\u0026#34;\u0026#34; doc_id = re.sub(\u0026#39;[\\s+]\u0026#39;, \u0026#39;\u0026#39;, title) document = search.Document( doc_id=doc_id, fields=[ search.TextField(name=\u0026#39;title\u0026#39;, value=title), search.TextField(name=\u0026#39;uri\u0026#39;, value=uri), search.TextField(name=\u0026#39;description\u0026#39;, value=description), search.TextField(name=\u0026#39;tags\u0026#39;, value=json.dumps(tags)), search.TextField(name=\u0026#39;content\u0026#39;, value=content) ] ) return document def add_document_to_index(document): index = search.Index(_INDEX_NAME) index.put(document) class BaseHandler(webapp2.RequestHandler): \u0026#34;\u0026#34;\u0026#34;The other handlers inherit from this class. Provides some helper methods for rendering a template.\u0026#34;\u0026#34;\u0026#34; @webapp2.cached_property def jinja2(self): return jinja2.get_jinja2(app=self.app) class ProcessQuery(BaseHandler): \u0026#34;\u0026#34;\u0026#34;Handles search requests for comments.\u0026#34;\u0026#34;\u0026#34; def get(self): \u0026#34;\u0026#34;\u0026#34;Handles a get request with a query.\u0026#34;\u0026#34;\u0026#34; uri = urlparse(self.request.uri) query = \u0026#39;\u0026#39; if uri.query: query = parse_qs(uri.query) query = query[\u0026#39;q\u0026#39;][0] index = search.Index(_INDEX_NAME) compiled_query = search.Query( query_string=json.dumps(query), options=search.QueryOptions( sort_options=search.SortOptions(match_scorer=search.MatchScorer()), limit=1000, returned_fields=[\u0026#39;title\u0026#39;, \u0026#39;uri\u0026#39;, \u0026#39;description\u0026#39;] ) ) results = index.search(compiled_query) json_results = { \u0026#39;results\u0026#39;: [], \u0026#39;query\u0026#39;: json.dumps(query) } for document in results.results: search_result = {} for field in document.fields: search_result[field.name] = field.value json_results[\u0026#39;results\u0026#39;].append(search_result) self.response.headers.add(\u0026#39;Access-Control-Allow-Origin\u0026#39;, \u0026#39;https://www.simoahava.com\u0026#39;) self.response.write(json.dumps(json_results)) class UpdateIndex(BaseHandler): \u0026#34;\u0026#34;\u0026#34;Updates the index using index.json\u0026#34;\u0026#34;\u0026#34; def get(self): with open(\u0026#39;index.json\u0026#39;) as json_file: data = json.load(json_file) for post in data: title = post.get(\u0026#39;title\u0026#39;, \u0026#39;\u0026#39;) uri = post.get(\u0026#39;uri\u0026#39;, \u0026#39;\u0026#39;) description = post.get(\u0026#39;description\u0026#39;, \u0026#39;\u0026#39;) tags = post.get(\u0026#39;tags\u0026#39;, []) content = post.get(\u0026#39;content\u0026#39;, \u0026#39;\u0026#39;) doc = create_document(title, uri, description, tags, content) add_document_to_index(doc) application = webapp2.WSGIApplication( [(\u0026#39;/\u0026#39;, ProcessQuery), (\u0026#39;/update\u0026#39;, UpdateIndex)], debug=True) At the very end, I\u0026rsquo;m binding requests to the / endpoint to ProcessQuery, and requests to /update to UpdateIndex. In other words, these are the two endpoints I am serving.\nUpdateIndex loads the index.json file, and for every single content piece within (blog posts, pages, etc.), it grabs the title, uri, description, tags, and content parameters from the content JSON, and creates documents for each instance. Then, each document is added to the index.\nThis is how the Search API can be used to translate any JSON file into a valid search index, that you can then build queries against.\nQueries are made by polling the /?q=\u0026lt;keyword\u0026gt; endpoint, where keyword matches a valid query against the Search API query engine. Each query is processed by ProcessQuery, which takes the query term, polls the search index with that term, and then compiles a result of all the documents that the search index returns for that query (in ranked order). This result is then pushed into a JSON response back to the client.\nThe search API gives you plenty of room to optimize the index and for compiling complex queries. I\u0026rsquo;ve opted for a fairly mundane approach, which might lead to some odd ranking outliers, such as documents that should clearly be at the top of a list of relevant results ending up in the end, but I\u0026rsquo;m still quite happy with how the robustness of the API.\n4. The JavaScript Finally, I need some client-side code to produce the search results page. Since Hugo doesn\u0026rsquo;t have a web server, I can\u0026rsquo;t do the search server-side - it must be done in the client. This is one of the cases where a static site loses some of its shine when compared to its counterparts that come equipped with a web server and server-side processing capabilities. A Hugo site is built and deployed all at once, so there\u0026rsquo;s no dynamic generation of HTML pages after building - everything has to happen in the client.\nAnyway, the search form on my site is very simple. It just looks like this:\n\u0026lt;form id=\u0026#34;search\u0026#34; action=\u0026#34;/search/\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;q\u0026#34; type=\u0026#34;text\u0026#34; class=\u0026#34;form-control input--xlarge\u0026#34; placeholder=\u0026#34;Search blog...\u0026#34; autocomplete=\u0026#34;off\u0026#34;\u0026gt; \u0026lt;/form\u0026gt;\nWhen the form is submitted, it does a GET request to the /search/ page on my site, adding whatever was typed into the field as the q query parameter, so the URL becomes something like\nhttps://www.simoahava.com/search/?q=google+tag+manager\nOn the /search/ page, I have a loading spinner which waits until the request to the search endpoint is completed. The search call is done with JavaScript, and it looks like this:\n(function($) { var printSearchResults = function(results) { // Update the page DOM with the search results... \t}; var endpoint = \u0026#39;https://search-www-simoahava-com.appspot.com\u0026#39;; var getQuery = function() { if (window.location.search.length === 0 || !/(\\?|\u0026amp;)q=/.test(window.location.search)) { return undefined; } var parts = window.location.search.substring(1).split(\u0026#39;\u0026amp;\u0026#39;); var query = parts.map(function(part) { var temp = part.split(\u0026#39;=\u0026#39;); return temp[0] === \u0026#39;q\u0026#39; ? temp[1] : false; }); return query[0] || undefined; }; $(document).ready(function() { var query = getQuery(); if (typeof query === \u0026#39;undefined\u0026#39;) { printSearchResults(); return; } else { $.get(endpoint + \u0026#39;?q=\u0026#39; + query, function(data) { printSearchResults(JSON.parse(data)); }); } }); })(window.jQuery)  To keep things simple, I\u0026rsquo;ve only included the relevant pieces of code that can be used elsewhere, too. In short, when the /search/ page is loaded, whatever is included as the value of the q query parameter is immediately sent to the search API endpoint. The response is then processed and built into a search results page.\nSo, if the page URL is https://www.simoahava.com/search/?q=google+tag.manager, this piece of JavaScript turns that into a GET request to https://search-www-simoahava-com.appspot.com/?q=google+tag+manager. You can visit that URL to see what the response looks like.\nThis response is the processed, and the search results page is built.\nSummary This is how I\u0026rsquo;ve chosen to build site search using the flexibility of Hugo together with the powerful Search API offered by Google\u0026rsquo;s App Engine.\nBased on my limited amount of research, it\u0026rsquo;s as good a solution as any, and it seems quite fast without compromising the power of the search query engine. However, as more content builds up, it\u0026rsquo;s conceivable that the query engine either gets slower or I start hitting my free tier quotas, at which point I\u0026rsquo;ll need to rethink my approach.\nThe weak link at the moment is that everything is done client-side. That means that contrary to the philosphy of static sites, a lot of processing takes place in the browser. But I\u0026rsquo;m not sure how this could be avoided, since a static site doesn\u0026rsquo;t offer you the capabilities of a server-side processor.\nAt this time, it\u0026rsquo;s a trade-off I\u0026rsquo;m willing to make, but I am anxious to hear feedback if the search is clumsy or not working properly for you.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/new-tools-released/",
	"title": "New Tools Released",
	"tags": ["google tag manager", "gtm tools", "google sheets", "api"],
	"description": "Introducing GTM Tools by Simo Ahava, a Google Sheets plugin for Google Tag Manager management. Also releasing Slack integration to the original GTM Tools (www.gtmtools.com)",
	"content": " Over the past few weeks, I\u0026rsquo;ve been coding like crazy. The three biggest outcomes of this frenzy have been this new blog design (switched finally away from WordPress and took the plunge back into the world static sites using Hugo), a new Google Sheets add-on for managing Google Tag Manager containers and assets, and a Slack integration in GTM Tools. In this article, I\u0026rsquo;ll quickly introduce the last two, as I\u0026rsquo;m writing a separate article about the site redesign.\nSlack integration for www.gtmtools.com   GTM Tools is a free set of web tools for managing your Google Tag Manager containers, tags, triggers, and variables. There\u0026rsquo;s a bunch of things you can do with the toolset, and I urge you to follow the link in the beginning of this paragraph to learn more, or simply go to https://www.gtmtools.com/ to start using the tool.\nAnyway, a recent addition, inspired by Jeffrey Gomez\u0026rsquo; idea in #measure Slack, was a Slack integration with your GTM container. What this means in practice is that once the integration is enabled, a bot named GTM Tools will enter the channel of your choice. Every 15 minutes, it will check if there\u0026rsquo;s a new, published version of the container you made the integration in, and if one is found, it will inform of this to the channel.\n  To enable the integration, you need to browse to a container page in GTM Tools, and then click the Click here to enable integration link. A modal dialog opens, which instructs you to add the GTM Tools service account email address as a Read user to the GTM container in question. You must do this for the integration to work - GTM Tools must be allowed to query the published version if you want it to inform you when a published version is created.\nOnce you\u0026rsquo;ve added the user, you will need to click the now activated Add to Slack button, which will take you to Slack\u0026rsquo;s own portal. There you\u0026rsquo;ll need to select the workspace and channel to which the GTM Tools bot will be added.\nAnd then you\u0026rsquo;re good to go! You can test the integration by publishing the container, and then waiting for the next 15 minute interval to pass. The bot checks the container every 15 minutes on the hour, so :00, :15, :30, :45 and so on.\nAt some point I hope to develop the bot further, perhaps even adding conversational capabilities to it.\nNew Google Sheets add-on One of the things I\u0026rsquo;ve been using the Google Tag Manager API for since it was introduced is documentation. Until recently, I\u0026rsquo;d been using a simple command-line Python script to output a CSV file of all the relevant fields.\nHowever, GTM has a nifty integration with Apps Script, which means you can access the Google Tag Manager API using Google Sheets\u0026rsquo; script editor, for example. And what better way to create and manage documentation than spreadsheets? Well, truthfully, I\u0026rsquo;m sure there are many better ways to do it, but Google Sheets has proven to be just fine for most of my documentation needs.\nAnyway, I have written and published a Google Sheets add-on which lets you automatically generate documentation from any container you have access to. In addition to creating the documentation, you can also mass-update the \u0026ldquo;Notes\u0026rdquo; field in all your tags, triggers, and variables. So now there\u0026rsquo;s no excuses left NOT to document carefully what each tag, trigger, and variable does.\n  You can read all about the add-on from its dedicated tools page in this blog.\nFeedback? I would really like to get feedback on all my tools, so please drop me a comment in this article or in the relevant tools page.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/opt-out-of-google-analytics-tracking/",
	"title": "#GTMTips: Opt-out Of Google Analytics Tracking",
	"tags": ["googletagmanager", "gtmtips", "opt-out", "google analytics", "tag sequencing", "customtask"],
	"description": "You can have your site visitors easily opt-out of Google Analytics tracking by setting a specific global variable before the first Google Analytics tag fires on the page.",
	"content": " A while ago I posted a #GTMTips post where I detailed the steps you can take to opt-out of all Google Analytics tracking and the DoubleClick redirects that often follow. It was a fun exercise, but because it relies on preventing requests on a tag-by-tag basis (using the ubiquituous customTask), it can be a chore to handle in large containers.\nIn this article, we\u0026rsquo;ll continue with the theme of opting out from Google Analytics tracking by leveraging a solution provided by the tool itself. To make it work, we\u0026rsquo;ll use a Custom HTML tag together with some tag sequencing.\nTip 68: Opt-out of Google Analytics tracking with a global variable   The trick is to set a global variable before the first GA tag fires on the page. This is crucial, because the global variable needs to be created before the tracker object is created. So, unfortunately, customTask will not work this time (I know, HUGE disappointment!).\nThe variable itself is very simple to create. It needs to look like this:\nwindow['ga-disable-UA-XXXXXX-Y'] = true\nHere, UA-XXXXXX-Y is the tracking ID you want to block for all subsequent GA requests sent on the page. You can create multiple global variables like this, one for each tracking ID you want to block.\nSo, if I wanted to block GA tracking to UA-12345-1 when the user has a specific cookie in their browser, I could use something like this in a Custom HTML tag:\n\u0026lt;script\u0026gt; if ({{Cookie - _ga_opt_out}} === \u0026#39;true\u0026#39;) { window[\u0026#39;ga-disable-{{GA ID}}\u0026#39;] = true; } \u0026lt;/script\u0026gt; Here, {{Cookie - _ga_opt_out}} is an (imaginary) first party cookie, which stores the value true if the user has opted out of tracking on my (imaginary) site. {{GA ID}} is a constant variable that returns the Google Analytics tracking ID the user is opting-out from.\nOr, if I want to use the doNotTrack feature that most browsers let you set in their settings:\n\u0026lt;script\u0026gt; if (navigator.doNotTrack \u0026amp;\u0026amp; navigator.doNotTrack === 1) { window[\u0026#39;ga-disable-{{GA ID}}\u0026#39;] = true; } \u0026lt;/script\u0026gt; Note that you should not add any triggers to this Custom HTML tag, as it will only fire when in a tag sequence.\nFinally, you need to find the first Universal Analytics tag that fires on the page with that tracking ID. Typically this would be a Page View tag which fires on the All Pages trigger.\nThen, scroll down to its Advanced Settings, and make sure the Tag Sequencing setting is setup as follows:\n  This setting ensures that before the Page View tag fires, your opt-out script has time to complete, and set the browser to opt-out of Google Analytics tracking to the tracking ID established in the global variable.\nThat\u0026rsquo;s all there is to it, really. The obvious downside is that if you are tracking to more than one GA property, you\u0026rsquo;ll need to exclude all of them. You\u0026rsquo;ll also need to modify the conditional statement in the script to match whatever opt-out scheme your website offers.\n"
},
{
	"uri": "https://www.simoahava.com/upcoming-talks/",
	"title": "Upcoming Talks",
	"tags": [],
	"description": "Simo Ahava&#39;s upcoming conference schedule and event participation.",
	"content": "  20 September 2018: Advanced GTM Workshop (Hamburg) 24 September 2018: Snowplow Meetup (Helsinki) 31 October - 2 November 2018: Google Marketing Platform Partner Summit 6-8 November 2018: SMXL Milan 14 November 2018: Analyticsdagarna, Stockholm 19 March 2019: Conversionboost, Copenhagen 4 April 2019: Go Analytics, Moscow 9-11 April 2019: Web à Québec    I enjoy presenting at conferences and meetups, and I have a track record of hundreds of talks since 2013, comprising keynotes, conference presentations, workshops, seminars, and public trainings. Audience sizes have varied between 3 and 2,000.\nMy favorite topics revolve around web analytics development and analytics customization, but I\u0026rsquo;m more than happy to talk about integrating analytics into organizations, knowledge transfer, improving technical skills, digital marketing, and content creation.\nSome of my conference slides can be found at SlideShare.\nFor a sample, here\u0026rsquo;s a talk I gave at Reaktor Breakpoint in 2015.\n  You can contact me at simo (at) simoahava.com for enquiring about my availability for your event.\n"
},
{
	"uri": "https://www.simoahava.com/tools/gtm-tools-by-simo-ahava/",
	"title": "GTM Tools Add-on For Google Sheets",
	"tags": [],
	"description": "",
	"content": " The GTM Tools by Simo Ahava is a Google Sheets add-on. It lets you manage and update your Google Tag Manager containers, tags, triggers, and variables.\n  In this first iteration, the tools feature a Documentation builder, which lets you automatically generate documentation for the latest version of your Google Tag Manager container, tags, triggers, and variables. In addition to this, the toolset features a Push changes to Notes functionality, which lets you automatically mass update the Notes field across your tags, triggers, and variables.\n  How to get it In Google Sheets, open the Add-ons menu, and click Get add-ons.\n  You should see the Chrome web store window open. Enter \u0026ldquo;GTM Tools by Simo Ahava\u0026rdquo; into the search field and press Enter. You should see the add-on appear in the search results.\n  Click the + FREE button. You will be asked to sign in with your Google ID, and then approve the add-on access to your data. The add-on requires read and write access to your Google Tag Manager data, and read and write access to your Google Sheets account.\nYou are then ready to use the tool!\nBuild documentation You should see the GTM Tools by Simo Ahava menu item in the Add-ons menu. You might need to reload the page if it isn\u0026rsquo;t there, or if it seems to be missing all its menu items.\nWhen you click Build documentation, the add-on will prompt you for a Google Tag Manager account and container. The list will include all containers your current logged in Google user ID has access to. Once you\u0026rsquo;ve selected a container, click Build to start the process.\n  The builder creates four new sheets: one for your container version, and one each for your tags, triggers, and variables.\n  As you can see, each sheet is prefixed with the container ID.\nEach sheet will contain useful information about your container, based on the Latest version of your container. If no version has been created yet, the documentation builder will not work.\n Never rename these default sheets created by the tool! They are necessary for the add-on to work.\n Mark changes to Notes The next thing you can do is manually edit the Notes field of the tags, triggers, and variables sheets. You can edit or create notes entries for each item, if you wish.\nOnce you\u0026rsquo;ve made all the changes to the Notes fields (changes to other fields are ignored, and you should NEVER, EVER, modify the JSON column), choose Mark changes to Notes in the add-on menu. A new dialog opens.\n  When you click Mark changes, the tool will go through all the tag, trigger, and variable documentation sheets, and highlight each field that diverges from the latest version. This is to give you a visual clue of which fields have changed values within.\n  The dialog will also tell you how many fields were highlighted as a result.\nPush changes to Notes Once you\u0026rsquo;ve made changes to the notes fields, you can push these changes to a GTM container. The container is automatically selected based on the sheet you have active in Google Sheets. So if you have active one of the documentation sheets prefixed for GTM-XXXXX-X, then that will be used as the target container for the push. If you have selected one of the sheets prefixed with GTM-YYYYY-Y, then that will be used, etc.\nSee the screenshot at the beginning of this article for an example of what the modal looks like when you have a valid sheet selected.\nOnce you click PUSH CHANGES, the tool will update all the tags, triggers, and variables in the sheets for this container, modifying the notes field of each to match the changes you made. The changes will be done in the workspace you chose using the selector in the modal.\n  When the push is complete, the modal will inform you how many changes were made. You can also click a link in the modal to have the tools create a new container version of the workspace you just updated.\n   This is at your own risk. If the workspace doesn\u0026rsquo;t validate, it will result in an error. Note that all changes in the workspace will be included in the new version.\n After you\u0026rsquo;ve pushed the changes, you should really create a new version as soon as possible. Otherwise the documentation will always interpret the changes to the notes to be new changes, because they are always compared against the latest container version.\nWhen a new version has been created, you should always re-run Build documentation.\nWhen rebuilding the documentation, the add-on will always show the following prompt if a sheet has already been created by the tool. You will have the option of overwriting the sheet or skipping it in the documentation build process. Unless you\u0026rsquo;ve made some manual changes to the sheets generated by the documentation (I\u0026rsquo;d recommend against this), it\u0026rsquo;s a good idea to always allow the add-on to overwrite the sheets\u0026rsquo; contents with the data from the latest version of the container.\n  Words of caution For the add-on to work properly, follow the following guidelines:\n Never edit the sheet names - it\u0026rsquo;s imperative that the sheets use the default names created by the add-on\n Never delete or modify the named ranges created by the add-on\n Never edit values in the JSON column\n  Changing other column values than Notes will not do anything. At some point I might add the option to mass update the other fields, too.\nPrivacy Policy What information do you collect? The GTM Tools by Simo Ahava add-on collects no information from its users. It is an API tool used for managing and updating Google Tag Manager containers, tags, triggers, and variables.\nThe only thing the add-on logs is the generic Google Cloud Console API usage statistics, which tells the owner how much the enabled APIs are being used, but this data cannot be used to identify users or individual use patterns.\nHow do you use the information? No user or usage information is used. The only thing the owner monitors is API usage, so that it can be determined if quotas need to be increased to ensure the tool works smoothly.\nWhat information do you share? No information is shared with third parties, with other users, with analytics tools, with marketing partners, or any other party.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/auto-link-domains-with-regex/",
	"title": "#GTMTips: Auto Link Domains With Regex",
	"tags": ["googletagmanager", "gtmtips", "customtask", "auto-link domains", "cross-domain tracking"],
	"description": "Use Google Tag Manager to add load listeners to your asynchronously loading script elements. The load listener will inform GTM once the script has completely loaded, helping you avoid race conditions.",
	"content": " Google Tag Manager makes it fairly easy to do cross-domain tracking. Basically, you list the hostnames you want to automatically decorate with linker parameters in the Auto-Link Domains field of your Page View tag, and that takes care of decorating the URLs with the necessary parameter. It\u0026rsquo;s dead easy, even if there are a bunch of traps you need to watch out for (see my post on troubleshooting cross-domain tracking issues).\nHowever, for some reason, GTM doesn\u0026rsquo;t support regular expressions in the Auto-Link Domains field. The autoLink method supports both strings and regular expression literals, but GTM only uses the first. Hopefully, at some point this will be fixed and this article will become obsolete. The reason we want regular expressions is to be able to do things like negative lookbehinds, where we specify that a subset of domains of any given hostname be excluded from decoration. In the image below, you can see an example of this. The regular expression specifies that all other domains except www.simoahava.com should be decorated with cross-domain parameters.\nTo make this work in GTM of today, we\u0026rsquo;ll use the amazing customTask feature (see here for all my customTask solutions).\nTip 67: Use customTask to auto-link domains based on regular expressions   The trick is to use a Custom JavaScript variable as the value of the customTask field. This is what the variable looks like:\nfunction() { return function(model) { var domainList = [ /^.*(?\u0026lt;!dev\\.)hostname\\.com$/, \u0026#39;somedomain.com\u0026#39;, \u0026#39;www.domain.com\u0026#39;, /^example\\.com$/ ]; var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; var name = model.get(\u0026#39;name\u0026#39;); ga(name + \u0026#39;.require\u0026#39;, \u0026#39;linker\u0026#39;); ga(name + \u0026#39;.linker:autoLink\u0026#39;, domainList); }; }  In the domainList array, you need to add all the domains you want to automatically link separating each value with a comma. You can specify both strings (wrap them in quotes) and regular expression literals. When you use strings, the auto-linker uses an open-ended pattern match. Thus if you have 'example.com' as one member of the array, GTM will decorate example.com and all its subdomains.\nRegular expressions give you the power of zero-length assertions such as negative and positive lookbehinds. This makes it easy to match, for example, all subdomains of example.com except for test.example.com.\n/^.*(?\u0026lt;!test\\.)example\\.com$/\nThis regular expression reads out as: match any string that contains example.com except for those strings where example.com is directly preceded by test..\nThe rest of the variable basically invokes the Universal Analytics tracker object used in the current hit, loads the linker plugin, and then decorates the domain list with cross-domain parameters.\nAll you then have to do is add this variable to the value of the customTask field in your Page View tag\u0026rsquo;s Fields to set.\n  This simple fix will make auto-linking domains for cross-domain tracking purposes much more flexible with Google Tag Manager. But, as I mention in the beginning of this article, I really wish that the Auto-Link Domains field in the tag settings will soon support regular expressions, just like the linker plugin regularly does!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/add-clientid-to-custom-dimension-gtag-js/",
	"title": "Add Client ID To Custom Dimension With gtag.js",
	"tags": ["gtag", "Universal Analytics", "client id", "custom dimension"],
	"description": "Quick guide on how to add the Universal Analytics Client ID as a custom dimension when using the new global tag (gtag.js).",
	"content": " When Google released gtag.js, the new, global tracking library designed to (eventually) replace analytics.js, many Universal Analytics practitioners and users were confused (see e.g. Jeff\u0026rsquo;s great overview here). It seemed like gtag.js wasn\u0026rsquo;t really solving any immediate problem, since analytics.js had done a bang-up job with Universal Analytics tracking for all these years. However, gtag\u0026rsquo;s modus operandi is the ability to leverage the same semantic information (distributed across dataLayer!) across a number of Google products, starting with GA and AdWords.\nBut migrating to gtag.js isn\u0026rsquo;t just a find-and-replace operation - there are many things to consider due to the fact that they are completely different tracking libraries, and feature parity is yet to be reached.\n  One of the things I was really concerned about was how to add my favorite custom dimension to the hits: the Client ID stored in the _ga cookie. With gtag.js, this is actually ridiculously easy, and you don\u0026rsquo;t need to leverage customTask or the ga.getAll() tracker method (which still does exist when using gtag.js!).\nHuge thanks to Yamata Ryoda for pointing this method out. You can read the original tip (in Japanese) here.\nHow to add Client ID to a custom dimension with gtag.js So after the long preamble here\u0026rsquo;s the tip in all its glory:\ngtag(\u0026#39;config\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, { \u0026#39;custom_map\u0026#39;: { \u0026#39;dimensionX\u0026#39;: \u0026#39;clientId\u0026#39; } });  Just replace UA-12345-1 with your Universal Analytics tracking ID, and the X in dimensionX with the custom dimension index, and gtag.js takes care of the rest.\nSuch a simple way to do it. My main gripe right now is that this isn\u0026rsquo;t officially documented, and we don\u0026rsquo;t know what other \u0026ldquo;special\u0026rdquo; values gtag.js hides under its hood. And what if I wanted to send the string \u0026ldquo;clientId\u0026rdquo; to GA as the value of that custom dimension? Hmm. Might not be that common.\nSummary So there is a really easy way to add the Client ID to a custom dimension when using gtag.js. It\u0026rsquo;s so easy, in fact, that you should do it right now. Sending the Client ID to Google Analytics is almost necessary in order to see reports distributed row-by-row, where each row is a distinct Google Analytics user. You only get this otherwise in the User Explorer reports.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/add-load-listener-script-elements/",
	"title": "#GTMTips: Add A Load Listener To Script Elements",
	"tags": ["googletagmanager", "gtmtips", "javascript", "event listener", "race condition"],
	"description": "Use Google Tag Manager to add load listeners to your asynchronously loading script elements. The load listener will inform GTM once the script has completely loaded, helping you avoid race conditions.",
	"content": " One of the challenges in working with Google Tag Manager (or any JavaScript-based platform for that matter) is what to do with race conditions. A race condition emerges when you have two resources competing for execution in the browser, and there is a degree of unpredictability to which \u0026ldquo;wins\u0026rdquo; the race.\nA prime example is working with jQuery. It\u0026rsquo;s one of the most popular JavaScript libraries out there, and websites utilize it for a multitude of things, many useful for Google Tag Manager, too. For example, jQuery trivializes asynchronous HTTP requests and DOM traversal, both of which can cause headaches to GTM users.\nHowever, since jQuery is often, and should often be, downloaded asynchronously, there\u0026rsquo;s the risk that jQuery hasn\u0026rsquo;t loaded yet when GTM starts executing your tags. Thus we need some mechanism to let Google Tag Manager know when an asynchronously downloaded or requested resource has become available.\nTip 66: Add a load listener to script elements   There are two ways you can go about this. The first one is to use a Custom HTML tag, and then fire a dataLayer.push() once the resource has completely loaded. The second way is to use tag sequencing, and tell GTM that the setup tag (where you load the script) has completed by using the internal onHtmlSuccess() method. But I\u0026rsquo;m getting ahead of myself.\ndataLayer.push() in the load listener callback The first method is to create a Custom HTML tag that fires as early as possible. So you\u0026rsquo;d want to add the All Pages trigger to it, so that it fires as soon as the GTM container has loaded.\nAt this point it\u0026rsquo;s important that you do not load the script by simply adding the \u0026lt;script src=\u0026quot;url_to_jquery\u0026quot; async=\u0026quot;true\u0026quot;\u0026gt; into the Custom HTML tag. Instead, we\u0026rsquo;ll introduce some extra control by using JavaScript to create the element, add the listener to it, and inject it manually to the page. You could use the onload attribute directly in the element, but the risk here is that you overwrite any existing onload attribute. By using JavaScript DOM manipulation methods, you won\u0026rsquo;t mess with any pre-existing listeners.\n\u0026lt;script\u0026gt; (function() { var el = document.createElement(\u0026#39;script\u0026#39;); el.src = \u0026#39;https://code.jquery.com/jquery-3.2.1.js\u0026#39;; el.async = \u0026#39;true\u0026#39;; el.addEventListener(\u0026#39;load\u0026#39;, function() { window.dataLayer.push({ event: \u0026#39;jQueryLoaded\u0026#39; }); }); document.head.appendChild(el); })(); \u0026lt;/script\u0026gt; When this Custom HTML tag is run by GTM, the browser creates an asynchronous request to download the jquery-3.2.1.js from the CDN (Content Distribution Network). Once this asynchronous process is over, a dataLayer.push({event: 'jQueryLoaded'}) fires, and you can then build a Custom Event trigger for this event name to fire any tags that are dependent on jQuery having loaded.\nUsing Tag Sequencing If you only have a single tag that needs the asynchronously downloaded resource, a fairly elegant way to do this would be with tag sequencing. With tag sequencing, you would create a Custom HTML tag for this code, and add it as the Setup tag in the sequence. The logic is that the asynchronous request is executed in the Setup tag, and once it\u0026rsquo;s complete, the main tag can fire with confidence that the resource it is dependent on has completely loaded.\nThis is what the Custom HTML tag for the Setup tag would look like:\n\u0026lt;script\u0026gt; (function() { var el = document.createElement(\u0026#39;script\u0026#39;); el.src = \u0026#39;https://code.jquery.com/jquery-3.2.1.js\u0026#39;; el.async = \u0026#39;true\u0026#39;; el.addEventListener(\u0026#39;load\u0026#39;, function() { window.google_tag_manager[{{Container ID}}].onHtmlSuccess({{HTML ID}}); }); document.head.appendChild(el); })(); \u0026lt;/script\u0026gt; Note that for this to work, you must enable the Built-in variables Container ID and HTML ID.\nThe mysterious window.google_tag_manager[].onHtmlSuccess() method is an internal function you need to use in tag sequencing if you want GTM to wait for some code (e.g. asynchronous callbacks) to execute before moving from the setup tag to the main tag. If you didn\u0026rsquo;t have this piece of code here, GTM would simply jump straigth to the main tag after executing the last line of the setup tag, and in that case it\u0026rsquo;s very possible that jQuery hasn\u0026rsquo;t completely downloaded yet.\nSummary These two methods can be used to get the best of both worlds: asynchronous requests WITH predictability. Race conditions can be brutal and difficult to identify. It\u0026rsquo;s only once you start logging JavaScript errors that you might notice an increase in error messages like jQuery is not defined. This is a signal that you might be trying to use a resource before it has completely loaded. Using a load listener is a handy way to combat this.\n"
},
{
	"uri": "https://www.simoahava.com/search/",
	"title": "Search results",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/seo/",
	"title": "SEO",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/gtm-tips/",
	"title": "GTM Tips",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/",
	"title": "Google Tag Manager and Google Analytics",
	"tags": [],
	"description": "Simo Ahava is a Google Developer Expert for Google Analytics and Google Tag Manager. This is a blog all about web analytics development.",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/conference-bio/",
	"title": "Conference Biography",
	"tags": [],
	"description": "",
	"content": "   Simo Ahava is a recognized expert on customizing web analytics and tag management solutions to improve the entire \u0026ldquo;life cycle\u0026rdquo; of data collection, processing, and reporting. His main areas of expertise lie with Google Analytics and Google Tag Manager, and Google has appointed him as a Google Developer Expert in these fields. He is especially interested in the interface between marketing and development, and his main focus is on increasing awareness, skills, and critical thinking around data.\nSimo is a partner and co-founder at 8-bit-sheep. He also writes a popular blog on all things Google Analytics and Google Tag Manager development at www.simoahava.com. An experienced speaker and prolific blogger, Simo can be seen and heard in conferences, product forums, support communities, and developer meet-ups alike.\nTwitter: @SimoAhava\nGoogle+: +SimoAhava\nLinkedIn: http://fi.linkedin.com/in/simoahava\n"
},
{
	"uri": "https://www.simoahava.com/about-simo-ahava/",
	"title": "About Simo Ahava",
	"tags": [],
	"description": "",
	"content": "   Hi, I\u0026rsquo;m Simo Ahava. I\u0026rsquo;m partner and co-founder at 8-bit-sheep.\nI have also been a Google Developer Expert for Google Analytics since 2014.\nI hail from Helsinki, the capital of Finland. I have a background in academics (English language and linguistics), in IT, in digital marketing, and in web development. I\u0026rsquo;ve been a student of code since 1997, and I built my first website the same year. Marketing, IT disciplines, and web analytics all fell into my sphere of interest shortly after.\nMy blog has a singular purpose: To tell complicated stories in a simple, understandable, and actionable way.\nMost often, I talk about web analytics, but I also have soft spots for digital marketing in general, for SEO, and for web development.\nI believe in data, in best practices, in education, and in making an online impact.\nBut enough about me. What about you? You\u0026rsquo;ve come to the right place if you\u0026rsquo;re:\n looking for advice with Google Analytics or Google Tag Manager (just drop me a line in post comments and I\u0026rsquo;ll get right back to you)\n interested in learning about the latest trends in digital marketing\n curious about data and what it can do for you\n searching for a speaker in your conference or seminar\n  Contact me You can contact me through all the means listed in the header / sidebar. I\u0026rsquo;m definitely most active in Google+, especially in the Google Analytics and Google Tag Manager communities. I also try to use Twitter as much as possible.\nIn my spare time, I play the ukulele like there\u0026rsquo;s no tomorrow. I also have a beautiful and wonderful wife, who makes everything worth it, and a son for whom I would drop everything else in a heartbeat.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/send-event-custom-dimension-google-optimize-experiment-running/",
	"title": "Send Event And Custom Dimension If Google Optimize Experiment Is Running",
	"tags": ["customtask", "google analytics", "google optimize", "Google Tag Manager", "universal analytics"],
	"description": "Use customTask to detect if Google Optimize is running an experiment, and send this data to Google Analytics for segmenting.",
	"content": " I really like Google Optimize. It has a fairly intuitive UI, setting up experiments is easy, and there\u0026rsquo;s integrations for both Google Tag Manager and Google Analytics built into the system. It\u0026rsquo;s still a JavaScript-based, client-side A/B-testing tool, so problems with flicker and asynchronous loading are ever-present (though this is somewhat mitigated by the page-hiding snippet).\nOne issue with the Google Analytics integration is the difficulty of creating segments for sessions where the users were actively participating in the experiment. In fact, there\u0026rsquo;s no specific signal in Google Analytics that tells you the NOW the user is \u0026ldquo;experiencing\u0026rdquo; an experiment. You\u0026rsquo;ll find the Experiment Name and Experiment ID dimensions, yes, but they have one drawback:\nThe Experiment Name and Experiment ID dimensions are user-scoped for the duration of the experiment!\nSo if the user takes part in an experiment, all their hits and sessions from that moment on until the experiment is over will be annotated with the Experiment Name and Experiment ID values.\n  But I want to know exactly and only the sessions where my users were seeing the experiment content. I want to use this information to create segments where I can view other conversion goals or funnels than those configured into Optimize. This is increasingly important if you want to use Optimize for some quick personalization proofs-of-concept, since then it\u0026rsquo;s vital to know how the user reacted during the session when they saw the change in the content.\nAnyway, to make this whole thing work with the rarified analytics.js snippet and Google Tag Manager, we will use a feature I have seldom written about: customTask. OK, I\u0026rsquo;ve written about it plenty.\nWith customTask, we can automatically add a session-scoped Custom Dimension to all hits that took part in an experiment, and in some edge cases we\u0026rsquo;ll also send an event to GA to make sure the data is carried over.\nHow it works When you land on a page where an Optimize experiment is running (i.e. the page is (one of) the target(s) of the experiment), your Google Analytics hits will contain the \u0026amp;exp parameter with a value consisting of all the experiment IDs and variant IDs the user is participating in:\n  This key is what GA then uses to attribute the user to these particular experiments. So once that hit reaches GA, my Client ID will be associated with those two experiment IDs until the experiment is over.\nNow, what I actually want to happen is for a Custom Dimension to be added to that Page View hit if it has the \u0026amp;exp key. For this, I need to use customTask so that it can sniff the requests to Google Analytics, and in case they contain this key, dynamically add the Custom Dimension parameter with the experiment string. That way I\u0026rsquo;ll have the experiment data sent to Google Analytics nicely in the Custom Dimension of my choice!\nIf you\u0026rsquo;re using Google Tag Manager to deploy Google Optimize, the same code will apply, but instead of leveraging a Page View hit, the Optimize tag will use a special hitType === 'data' hit, which takes your experiment data to GA.\n  Unfortunately for us, this data hit type is not exposed in Google Analytics, so we can\u0026rsquo;t use that to segment our visitors, nor does piggy-backing it with a Custom Dimension do anything. So, we need to configure Google Tag Manager to actually send an extra event when a data hit is encountered that also has the \u0026amp;exp parameter with it.\nImplement via analytics.js If you\u0026rsquo;re using the analytics.js snippet, here\u0026rsquo;s what you need to do:\n\u0026lt;script\u0026gt; // Analytics.js snippet  (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;https://www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-XXXXXX-Y\u0026#39;,\u0026#39;auto\u0026#39;) // NEW: Add customTask field to tracker  ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, function(model) { // Change this to the Custom Dimension index to which you want to send the experiment data!  var customDimensionIndex = \u0026#39;6\u0026#39;; // Make sure the new hit is only generated once (thanks Vibhor Jain!)  var hasNewHitBeenGenerated = false; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; var originalSendTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); if (sendModel.get(\u0026#39;exp\u0026#39;)) { if (sendModel.get(\u0026#39;hitType\u0026#39;) === \u0026#39;data\u0026#39; \u0026amp;\u0026amp; !hasNewHitBeenGenerated) { var tracker = sendModel.get(\u0026#39;name\u0026#39;); originalSendTask(sendModel); ga(tracker + \u0026#39;.send\u0026#39;, \u0026#39;event\u0026#39;, \u0026#39;Optimize\u0026#39;, sendModel.get(\u0026#39;exp\u0026#39;), {nonInteraction: true}); hasNewHitBeenGenerated = true; return; } if (hitPayload.indexOf(\u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex + \u0026#39;=\u0026#39;) === -1) { sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload + \u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex + \u0026#39;=\u0026#39; + sendModel.get(\u0026#39;exp\u0026#39;), true); } } originalSendTask(sendModel); }); }); // NEW BLOCK ENDS  ga(\u0026#39;require\u0026#39;, \u0026#39;GTM-XXXXXX\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; The change to the original Optimize-modified analytics.js snippet is the entire block starting with // NEW:... and ending with // NEW BLOCK ENDS.\nThis code listens to all GA hits sent with the default tracker, and if they have the \u0026amp;exp parameter, then the Custom Dimension is dynamically added to the hits, along with the experiment ID string the user is associated with. Note that you must change the value of var customDimensionIndex to reflect the Custom Dimension index you\u0026rsquo;ve created in Google Analytics. I prefer to use a Session-scoped Custom Dimension, but you could use hit-scoped, too, for increased granularity.\n   That\u0026rsquo;s all you need to do with analytics.js. On pages not included in the experiment, no Custom Dimension or any extra hit is sent. Business will be as usual.\nImplement via Google Tag Manager In Google Tag Manager, you need to create a new Custom JavaScript variable, and give it a name like {{JS - customTask - Optimize experiment}}. The variable should look like this:\nfunction() { return function(model) { // Change this to the Custom Dimension index to which you want to send the experiment data!  var customDimensionIndex = \u0026#39;6\u0026#39;; // Make sure the new hit is only generated once (thanks Vibhor Jain!)  var hasNewHitBeenGenerated = false; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; var originalSendTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); if (sendModel.get(\u0026#39;exp\u0026#39;)) { if (sendModel.get(\u0026#39;hitType\u0026#39;) === \u0026#39;data\u0026#39; \u0026amp;\u0026amp; !hasNewHitBeenGenerated) { var tracker = sendModel.get(\u0026#39;name\u0026#39;); originalSendTask(sendModel); ga(tracker + \u0026#39;.send\u0026#39;, \u0026#39;event\u0026#39;, \u0026#39;Optimize\u0026#39;, sendModel.get(\u0026#39;exp\u0026#39;), {nonInteraction: true}); hasNewHitBeenGenerated = true; return; } if (hitPayload.indexOf(\u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex + \u0026#39;=\u0026#39;) === -1) { sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload + \u0026#39;\u0026amp;cd\u0026#39; + customDimensionIndex + \u0026#39;=\u0026#39; + sendModel.get(\u0026#39;exp\u0026#39;), true); } } originalSendTask(sendModel); }); }; }  It\u0026rsquo;s pretty much exactly the same code you would use in the analytics.js.\nThen, go to your Google Optimize tag, and scroll down to Fields to set. Add a new field with:\nField name: customTask\nValue: {{JS - customTask - Optimize experiment}}\nSo that it looks like this:\n  And that should be it. Now when you browser the experiment pages, you should see a hit with type 'data' being sent, and immediately after that an event hit which looks like this:\n  Summary I really wish that the Optimize / Google Analytics integration would give us a hit or dimension we could use to segment sessions that actively participated in an experiment. Right now you either need to replicate the test conditions in a segment (and if you sample only a part of your visitors even this won\u0026rsquo;t cut it), or use a solution like the one described in this article.\nEven if this were superfluous and unnecessary, I\u0026rsquo;m giddy with excitement to show yet another cool use case for customTask. I\u0026rsquo;m fairly certain that if we hadn\u0026rsquo;t already given our baby boy a gorgeous name, the world would have come to know him as customTask Ahava. For now, it will have to do as his nickname. That\u0026rsquo;s how much I love customTask!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/respect-opt-out-from-advertising-and-analytics/",
	"title": "#GTMTips: Respect Opt-Out From Advertising And Analytics",
	"tags": ["customtask", "googletagmanager", "gtmtips", "universal analytics"],
	"description": "Use customTask to block Google Analytics and the DoubleClick redirect in case the user has opted out from tracking and/or advertising.",
	"content": " With GDPR looming around the corner, it\u0026rsquo;s time to explore the options you have at your disposal for respecting the new, stricter regulations for tracking users and for collecting data about their visits to your website.\n UPDATE 20 June 2018: Google has released the allowAdFeatures field which renders the solution below redundant (at least for the displayFeaturesTask part of it). Please refer to this article for more details on how to conditionally block the advertising hit to DoubleClick.\n In this article, we\u0026rsquo;ll explore the wonderful customTask (again), to see how you can programmatically prevent the request to Google Analytics or the redirect to DoubleClick from ever taking place, in case certain conditions are met. These conditions could be, for example, a cookie which signifies that the user does not want to be tracked, or some other flag in the browser that you can listen to. It\u0026rsquo;s up to you to determine how you want to persist information about the user\u0026rsquo;s tracking preferences, so in this article I\u0026rsquo;ll just show you how to actually implement the blocker, using a browser cookie as an example of where the tracking preferences are stored.\nTip 65: Block the GA request and the DoubleClick redirect   In this hypothetical scenario, we have two 1st party cookies indicating if the user wants to be excluded from Google Analytics tracking and/or the advertising data redirect to DoubleClick:\n  Next, we\u0026rsquo;ll create the respective 1st Party Cookie variables in Google Tag Manager:\n  The variables are named (1) {{Cookie - _ga_opt_out}} and (2) {{Cookie - _dcl_opt_out}}.\nNext, you\u0026rsquo;ll need a Custom JavaScript variable that looks like this:\nfunction() { return function(model) { if ({{Cookie - _ga_opt_out}} === \u0026#39;true\u0026#39;) { model.set(\u0026#39;sendHitTask\u0026#39;, null); } if ({{Cookie - _dcl_opt_out}} === \u0026#39;true\u0026#39;) { model.set(\u0026#39;displayFeaturesTask\u0026#39;, null); } }; }  Finally, you need to add this Custom JavaScript variable to all your Universal Analytics tags by going to Fields to set, and adding a new field:\n  Note that the easiest way to do this is to use a Google Analytics Settings variable, and set the field there. Then add the GAS variable to all your Universal Analytics tags. If you want to set this per-tag, remember to check Enable overriding settings for this tag to find the Fields to set option.\nThe way this works now is that if the user has the _ga_opt_out cookie and its value is 'true', the request to Google Analytics will be blocked. And if the user has the _dcl_opt_out cookie and its value is 'true', the redirect to DoubleClick will be blocked, too.\nThis tip was, again, meant to first and foremost show you the amazing power of the customTask feature. It\u0026rsquo;s a versatile tool with which you can really manipulate what your website is doing in terms of Universal Analytics tracking.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/scroll-depth-trigger-google-tag-manager/",
	"title": "The Scroll Depth Trigger In Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "scroll depth", "trigger"],
	"description": "Introduction and guide to the scroll depth trigger in Google Tag Manager.",
	"content": " Scroll depth tracking in web analytics is one of those things you simply must do, especially if you have a content-heavy site. Tracking scroll depth not only gives you an indication of how much users are digesting your content, but it also lets you turn meaningless metrics such as Bounce Rate into something far more useful.\nIf you\u0026rsquo;ve already been tracking scroll depth in Google Tag Manager, you\u0026rsquo;ve probably been using either Rob Flaherty\u0026rsquo;s brilliant Scroll Depth jQuery plugin, or LunaMetrics\u0026rsquo; equally ingenious Scroll Tracking recipe. I\u0026rsquo;m sure you\u0026rsquo;ll be very pleased to know that Google Tag Manager just released a native Scroll Depth trigger, with which setting up scroll depth tracking will be a doozy!\n  The new trigger comes with all the base features you\u0026rsquo;d expect in a scroll depth tracking plugin. There\u0026rsquo;s no option to track scrolling to specific HTML elements, but luckily the recently released Element Visibility trigger takes care of this.\nThe trigger configuration You can find the trigger in the Google Tag Manager user interface, by navigating to Triggers, clicking the NEW button, and selecting the Scroll Depth trigger template from the list.\n  When you create the trigger, you\u0026rsquo;ll see the following configurable options:\n Vertical Scroll Depths - set the trigger up for tracking vertical scroll\n Percentages - track percentages of vertical scroll\n Pixels - track vertical pixel depths\n  Horizontal Scroll Depths - set the trigger up for tracking horizontal scroll\n Percentages - track percentages of horizontal scroll\n Pixels - track horizontal pixel depths\n  All pages / Some pages - enable the trigger either on all pages or only on some pages\n  The settings should be quite self-explanatory. For example, to track vertical scroll (i.e. scrolling from top to bottom) so that an event is triggered with 25% of page scrolled, 50% of page scrolled, 75% of page scrolled, and reaching the end, you\u0026rsquo;d set the trigger up as in the very first image of this article.\nYou might want to delimit the trigger to collect data only on content pages, which is where the Some pages option will come useful:\n  That\u0026rsquo;s it for the configuration.\nHow to use the trigger It\u0026rsquo;s a good idea to use the Preview mode for this. Set the trigger up with e.g. 25% thresholds (as in the image at the beginning of this article), visit a page on your site, and scroll some. You\u0026rsquo;ll see the following Data Layer object pushed when you reach a scroll threshold:\n  Here are the relevant Data Layer variables that are created:\n event: 'gtm.scrollDepth' - this is the name of the event that is automatically pushed into dataLayer. This event, in turn, activates the Scroll Depth trigger.\n gtm.scrollThreshold: 25 - this is the value of the threshold that was crossed. For example, when I scrolled to 25% of the page, I see the value 25 here. If I\u0026rsquo;d set 25 pixels as the threshold, I\u0026rsquo;d still see 25 here.\n gtm.scrollUnits: 'percent' - this will show either 'percent' or 'pixels', depending on which unit you chose for the trigger.\n gtm.scrollDirection: 'vertical' - this will show either 'vertical' or 'horizontal', depending on which type of scrolling action caused the threshold to be passed (and what you configured the trigger to listen to).\n  Note that you don\u0026rsquo;t need to create Data Layer Variables for gtm.scrollThreshold, gtm.scrollUnits, or gtm.scrollDirection. They have been added as new Built-in Variables, named Scroll Depth Threshold, Scroll Depth Units, and Scroll Depth Direction, respectively.\n  You\u0026rsquo;ll find the new Built-in Variables by navigating to Variables in the Google Tag Manager user interface, and clicking CONFIGURE under the \u0026ldquo;Built-In Variables\u0026rdquo; heading.\nPutting it together With this information, it will be easy to setup a Google Analytics Event tag to collect your scroll tracking data. For example, the following tag fires for each 25% of page scrolled.\n  You can even configure the \u0026ldquo;Non-Interaction\u0026rdquo; field to be true for the 25% mark, and false for the rest. This will make sure that your site\u0026rsquo;s Bounce Rate isn\u0026rsquo;t affected by minimal scroll. The Custom JavaScript variable you\u0026rsquo;d use in the Non-Interaction field would look like this:\nfunction() { return {{Scroll Depth Threshold}} === 25; }  This returns true if the user crossed the 25% mark, and false otherwise.\nCaveat You need to be mindful of one thing when working with a scroll depth tracking plugin. If you load the page so that you are on or have crossed any one of the defined thresholds, the gtm.scrollDepth trigger will automatically fire for all the thresholds you have crossed.\nSo, if you are at the very bottom of a page and you reload the page, GTM will fire a trigger for each of the thresholds 25%, 50%, 75%, and 100%, without the user explicitly scrolling.\nThis might have an impact on your data collection, so you just need to be mindful of this. This is also one reason why it\u0026rsquo;s a good idea to have the first threshold as non-interactive, because if the page is very short, it\u0026rsquo;s possible the trigger will fire even if the user didn\u0026rsquo;t scroll one bit.\nSummary The scroll depth trigger now offered by Google Tag Manager natively works very nicely, and checks most of the boxes you\u0026rsquo;d expect in such a plugin.\nIf you want to track scrolling to specific elements, be sure to check out the Element Visibility trigger!\nOne thing that is questionable is how well this jives with a single-page app. When you transition from one page to the other, any scroll tracking trigger that was active on the previous page would still be active, and thus the depth tracker would not reset to accommodate scrolling on the new, dynamically loaded content. It remains to be seen if the plugin will support somehow \u0026ldquo;resetting\u0026rdquo; it for single-page transitions.\nWhat do you think of this release? Does this make the alternatives out there obsolete, or do you think this new trigger is desperately in need of some additional features?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/element-visibility-trigger-google-tag-manager/",
	"title": "The Element Visibility Trigger In Google Tag Manager",
	"tags": ["dom", "Google Tag Manager", "visibility"],
	"description": "Introduction and guide to the element visibility trigger in Google Tag Manager.",
	"content": " Holy visibility, Batman! Visibility is a seriously undervalued aspect of web analytics tracking. Too often, we fall into the trap of thinking that \u0026ldquo;Page Views\u0026rdquo; actually have something to do with \u0026ldquo;viewing\u0026rdquo; a page. Or that tracking scrolling to 25%, 50%, or 75% of vastly different pages makes sense on the aggregate level. So you will be very pleased to know that the Google Tag Manager team (who have been on FIRE recently), have just published the Element Visibility trigger. And oh BOY what a trigger it is!\n  It\u0026rsquo;s a very impressive trigger. Not only does it let you do some proper scroll tracking (track to elements, not percentages), but it also includes a feature that lets you track changes in the DOM. This has typically been quite difficult to track purely client-side, so having the feature natively in Google Tag Manager is very cool. On top of that, you can actually measure true view impressions (impressions for items that are visible to the user) AND combine that with the actual time the element was viewed for.\nIn short, the Element Visibility trigger fires whenever an element, or elements, you specify appear in the browser\u0026rsquo;s viewport. The viewport is the visible area of the browser window, meaning if an element is visible there, it is viewable by the user.\n  With this in mind, let\u0026rsquo;s jump straight to the features.\nSelection method You have two options here - element ID and CSS Selector. The former uses document.getElementById to match the first element in the page with the given ID. The latter uses CSS Selectors to match the element or a group of elements on the page.\n  At this point I really recommend you read up on CSS selectors (see also my article on the topic). They really make Google Tag Manager more than just the sum of its parts.\n ID - the trigger waits for an element with a specific id attribute to appear in the viewport.\n CSS Selector - the trigger waits for elements that match the CSS selector string to enter the viewport.\n  The obvious difference between the two is that you can add multiple element selectors into the CSS selector string. For example, if I want to track when the header, the article title, the article body, and the article footer enter the viewport, I could use something like this as the selector:\n#header, h2.title, div.content, div.footer\nThe trigger could then fire when each one of these enters the viewport (see below).\nThe ID selector, on the other hand, performs better if you have only one element to track.\nWhen to fire this trigger This is where you\u0026rsquo;ll govern what this trigger actually is. Is it a check to see if a certain element is in the viewport when the page is loaded, or is it an advanced scroll trigger?\n   Once per page - this trigger will only fire once on the current page. The moment is when the first element that matches the ID or the selector string enters the viewport. Thus if you\u0026rsquo;ve specified multiple selectors or there are multiple elements with the same ID, this trigger setting will make the trigger fire only once - when the first matched element enters the viewport.\n Once per element - this trigger will fire just once if an element with a specific ID appears in the viewport (even if multiple elements share the same ID, in which case it will fire just for the first one). However, when using CSS selectors, this setting will fire once for each element matched by the selector(s). In other words, this would be the setting to use if you wanted to create a trigger that fires when different parts of the page enter the viewport!\n Every time an element appears on-screen - this trigger fires whenever any matched element appears in the viewport, and will do so each time the element reappears.\n  Of these, I wager the first two will be most used. Tracking if an element is visible is very useful for e.g. true view impression tracking, and tracking when multiple different elements appear can be used to create an advanced scroll trigger. There might be use cases for the last option too, though.\nAdvanced - Minimum Percent Visible Here you can specify a value in percentages, which is how much of the element needs to be in the viewport for the trigger to fire. So if you set the value to \u0026ldquo;50\u0026rdquo;, at least 50% of the matched element needs to be visible for the trigger to fire.\n  This is a great way to make sure that enough of the ad or content piece is visible for you to interpret the data as meaningful.\nAdvanced - On-Screen Duration In this field, you can specify the total time in milliseconds the element must be visible in the viewport for the trigger to fire. Note that this is cumulative, so let\u0026rsquo;s say you have the following setting:\n  This would fire the trigger only after the matched element(s) have been visible in the viewport for a total of 5 seconds. In other words, the user could first scroll to the element, view it for one second, then scroll until the element disappears, then scroll back to the element, view it for four additional seconds, at which point the trigger fires.\n  Note that because GTM has to manage a timer for each element that you want to monitor, tracking a single element with the Element ID selection method performs better than a bunch of elements defined with CSS selectors.\nAdvanced - Observe DOM changes This setting lets you track the visibility of elements that might not exist in the DOM when the page first loads! In other words, if you have dynamically inserted elements, you can check this box to track when they become visible, too.\nThe most obvious use case is if you have a form which is resilient to GTM\u0026rsquo;s Form Trigger due to complications in the on-site JavaScript, you can use this trigger setting to wait for an HTML element with the thank you message to pop up. So something like this:\n  Now the trigger will fire when an element with the ID #form-thank-you becomes visible, even if it\u0026rsquo;s dynamically inserted into the Document Object Model!\nSimilar to tracking On-Screen Duration, the DOM Changes setting performs better when you track a single element with the Element ID selection method.\nThe event object contents When the visibility trigger fires, an event with the name gtm.elementVisibility is pushed into Data Layer. The object has a number of variables you can refer to using Built-in Variables (or Data Layer Variables if you want to configure them manually).\n gtm.element - the element that became visible. You can capture this with the Click / Form Element Built-in Variable.\n gtm.elementClasses - the class name string of the element that became visible. You can capture this with the Click / Form Classes Built-in Variable.\n gtm.elementId - the ID value of the element that became visible. You can capture this with the Click / Form ID Built-in Variable.\n gtm.elementTarget - the target attribute value of the element that became visible. You can capture this with the Click / Form Target Built-in Variable.\n gtm.elementUrl - the href or action attribute value of the element that became visible. You can capture this with the Click / Form URL Built-in Variable.\n gtm.visibleRatio - a decimal number between 0 and 100, telling you how much of the element was visible in the viewport when the trigger fired in percentages. You can capture this with the Percent Visibile Built-in Variable.\n gtm.visibleTime - the total cumulative time the element has been in the viewport when the trigger fires. The number is in milliseconds. You will only see a value larger than 0 if you\u0026rsquo;ve set the \u0026ldquo;On-Screen Duration\u0026rdquo; in your trigger (because without a minimum on-screen duration, the trigger will always fire immediately when the element appears). You can capture this with the On-Screen Duration Built-in Variable.\n gtm.visibleFirstTime - the time in milliseconds when the element first became visible in the viewport. This time is calculated as the delta from the moment the browser started rendering the Google Tag Manager container snippet to the moment the trigger fired.\n gtm.visibleLastTime - the time in milliseconds when the element most recently became visible in the viewport. The calculation is similar to gtm.visibleFirstTime, except this time each time the trigger fires for the given element, the value is updated.\n  You can use these variables (preferable as Built-in Variables) to create even more advanced configurations in your other tags, triggers, and variables.\nBuilt-in Variables There are some new built-in variables introduced, too:\n  In addition to these, you have the regular Click / Form Built-in Variables at your disposal, since the element that fired the Element Visibility trigger is used to populate these Built-in Variables.\nSummary The past month or two have been crazy in Google Tag Manager land. Features that we\u0026rsquo;ve been dying to see have been released with impressive speed and attention to detail.\nOut of the bunch, I think this new Element Visibility is my favorite one. It has the potential to turn your entire web analytics tracking around, since you can actually focus on tracking interactions that matter rather than interactions that simply take place. Visibility is such a huge aspect of things we do on a web page. If an element is not visible, it can\u0026rsquo;t really be engaged with by a user.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/happy-5th-birthday-google-tag-manager/",
	"title": "Happy 5th Birthday Google Tag Manager!",
	"tags": ["celebration", "Google Tag Manager"],
	"description": "Post celebrating the 5th birthday of Google Tag Manager.",
	"content": " 5 years ago, on 1st October 2012, this lovely video popped up in Google\u0026rsquo;s Analytics Blog:\nIt was accompanied by a blog post, which contained a brief look into many of Google Tag Manager\u0026rsquo;s key features, some of which are still relevant today.\nGoogle Tag Manager is a free tool that consolidates your website tags with a single snippet of code and lets you manage everything from a web interface. You can add and update your own tags, with just a few clicks, whenever you want, without bugging the IT folks or rewriting site code. It gives marketers greater flexibility, and lets webmasters focus on other important tasks. At this time, those of us who started using the tool immediately, or who had been beta-testing it, saw quickly what the key selling point of GTM was. It was a way to impact change on the website as quickly as possible, without having to wait for a release to be verified and pushed live.\nThe ability to consolidate tags in a single container was great, though the initial inventory of tags was a far cry from what we have access to today. A typical source of friction with digital marketing has been to deploy these tags and code snippets on the site, and then manage and keep them up-to-date when the site itself changes. With Google Tag Manager, this task became almost trivial, because now the library itself made sure that the code used in the tags was always up-to-date.\nI wrote my first article about Google Tag Manager almost a year later, when Google Tag Manager looked like this:\n  By the way, my blog looked like this back then:\n  As time passed, more and more features were integrated into the tool. The pace of the development team was impressive, and there was an openness in the community that I had never witnessed before. It seemed like GTM\u0026rsquo;s developers were invested in us, the users, and always listened to our feedback with genuine interest.\nSome key features (in my opinion) that were introduced were:\n February 2013, Google Tag Assistant was released, with capabilities to analyze GTM implementations, too.\n August 2013, GTM SDKs for Android and iOS saw daylight.\n October 2013, Auto-Event Tracking was introduced (and everything changed for the better).\n April 2014, Universal Analytics was released out of beta.\n May 2014, 2-step verification was introduced as an additional security layer.\n July 2014, the Preview \u0026amp; Debug feature was released.\n October 2014, New version of the UI and the GTM API were released.\n February 2015, Matches CSS Selector operator was introduced.\n August 2015, Tag Sequencing was launched.\n May 2016, the Firebase Google Tag Manager container for mobile was launched.\n August 2016, Workspaces introduced.\n September 2016, the instructions for implementing the GTM container snippet were (finally) rewritten. Now the right place for the JavaScript container snippet is in the \u0026lt;head\u0026gt; of the page.\n October 2016, the AMP container was published.\n March 2017, version 2 of the Google Tag Manager API was released.\n September 2017, the YouTube Video trigger was released.\n  That\u0026rsquo;s definitely not an exhaustive list - just a timeline of events that I remember being of special importance.\nIn mid-October 2014, we even had the first \u0026ldquo;Google Tag Manager Summit\u0026rdquo;, when a bunch of dedicated GTM nerds congregated in Copenhagen, Denmark. Many active GTM users were present (people like Julien Coquet, Phil Pierce, Tahir Fayyaz, Doug Hall, Christian Pluzek, and Kristoffer Ewald to name a few), and the session was run by Brian Kuhn, the lead developer of Google Tag Manager, and Lukas Bergstrom, the then Product Manager for Google Tag Manager.\nWe had a great first GTM \u0026quot;summit\u0026quot; at Copenhagen with @briankuhn and @lukasb. A very productive day! #googletagmanager pic.twitter.com/N3aibq40Ow\n\u0026mdash; Simo Ahava (@SimoAhava) October 21, 2014  Another \u0026ldquo;GTM Summit\u0026rdquo; never took place, though time was always reserved in the Google Analytics Partner Summits for sessions dedicated to Google Tag Manager. I hope we can still get our own little Google Tag Manager conference or summit - there\u0026rsquo;s still lots to discuss!\nNow and going forward Today, Google Tag Manager is in an interesting place. It has an impressive adoption rate, with almost 30% of the sites in the Quantcast top 10K websites (per traffic) embedding the GTM snippet on their pages.\nIn the organization, GTM is also interestingly placed. It\u0026rsquo;s not just a tool for the marketing department, nor is it just a tool for business analysts, nor is it just a tool for developers. It\u0026rsquo;s a tool that has the possibility to unite all these stakeholders in a modern organization, thanks to how it offers something for everyone.\nTake a look at the slideshow above, especially from slide 24 onwards. I share some of my thoughts for how Google Tag Manager is so perfectly situated in a modern, digital organization.\nAbsolution doesn\u0026rsquo;t come for free, though. Making the most of Google Tag Manager is an investment, and it requires you to step out of your comfort zone. If you treat it as a way to circumvent your IT process, you\u0026rsquo;ll be sorely missing out on what the tool can do at its best.\nBut what\u0026rsquo;s next? What can Google Tag Manager do to keep the ball rolling?\nIntelligence It\u0026rsquo;s difficult to imagine Google Tag Manager NOT jumping on the bandwagon of intelligent apps. There are so many things in GTM that could benefit from rule-based automation.\nJust imagine dynamically launched tags, based on a user\u0026rsquo;s or a user cohort\u0026rsquo;s behavior rather than a fixed set of triggers you need to define a priori.\nOr tags that are created, deployed, and published at just the right time for just the people.\nOr benchmarking your container content, with something like \u0026ldquo;45% of companies in your market segment use HotJar for extra insight about visitors and their sessions. Get started?\u0026ldquo;.\nBecause Google Tag Manager is a tool designed to alleviate friction and reduce trivial, manual labor in tag management, it would make sense that it took this step towards actually being an insight engine in addition to a tag container.\nCollaboration One of the criticisms against Google Tag Manager has been that it\u0026rsquo;s not enterprise-worthy. There\u0026rsquo;s a lack of multi-user support (access control levels), of delimiting access per tag / folder / workspace to specific groups, of selective publishing, and so forth. These are all things I\u0026rsquo;m certain we\u0026rsquo;ll see in the future, in some shape or form. I would be surprised if the GTM team did not think about the enterprise\u0026rsquo;s needs first in today\u0026rsquo;s competitive market, especially since the release of Google Tag Manager 360.\n  With Workspaces, we took a big leap towards collaborative tag management, and with the approval workflow, it was easier to get thins done together without compromising quality of work. Still, I expect we\u0026rsquo;ll see more features like these in the future. Being able to handle projects with multiple organizations working on the same container is something that GTM simply must have solid support for.\nFull stack With Google Tag Manager for Mobile Apps, we\u0026rsquo;ve already seen GTM in use on the application level. And if you\u0026rsquo;ve used GTM for mobile, you might have been disappointed at its reach, especially if you\u0026rsquo;re familiar with GTM for the web.\nThe problem with a \u0026ldquo;full stack GTM\u0026rdquo; is that the kind of stuff that is borderline OK in the web browser (injecting and executing ad hoc JavaScript) might not work as fluently server-side. So you can\u0026rsquo;t just create a \u0026ldquo;Custom HTML Tag\u0026rdquo; in your iOS container using a native SDK, because iOS applications would not allow that type of unverified code to be released in them after going live.\nBut I\u0026rsquo;m also thinking about server-side stuff, like being able to use a dataLayer queue server-side, too, which then has the capability of executing HTTP requests and communicating with the full technology stack. This way we could run things like monitoring services, which collect data on what tags have fired and raise alerts when anomalies are detected. We could introduce state into Google Tag Manager, by having the web server persist information stored in dataLayer from page to page.\nHey, a guy can dream!\nGoogle integrations It\u0026rsquo;s a scary thought, but in five years\u0026rsquo; time it\u0026rsquo;s possible that GTM will be so tightly bound to the Google ecosystem that its usability for anything else diminishes. I\u0026rsquo;m certain that Google has an incentive (and pressure) to improve the DoubleClick integration in Google Tag Manager, and to make Firebase work more fluently through the Google Tag Manager container. Perhaps AMP will still be a thing in five years, and the AMP / web containers have merged so that it\u0026rsquo;s impossible to distinguish one from the other.\n  And perhaps Google Tag Manager will finally introduce something akin to state, where audience data is pulled from Google Analytics, so that we can use audience rules to fire our tags. It\u0026rsquo;s already implemented in Optimize, so I\u0026rsquo;m thinking: why not!\nSummary It\u0026rsquo;s been an amazing five years. For some like me, these five years have been life-changing. For the entire web analytics industry, I fail to see anything but positive things come out of Google Tag Manager\u0026rsquo;s popularity. It\u0026rsquo;s brought developers back into the mix! We finally have a tool which encourages developer involvement, and really shines when imported into an agile organization, ready to tackle digital challenges with a talented, hybrid team.\nIf there\u0026rsquo;s one thing I wish, it\u0026rsquo;s that Google Tag Manager would remain accessible. With that, I don\u0026rsquo;t mean that I want the UI to be any more coddling than it already it is. No, I mean that the developers, engineers, product managers, evangelists, and other Google folk invested in the tool would stay active in the community, bringing the tool development closer to its most dedicated users. I don\u0026rsquo;t want GTM to become another license tool, where only those who have the money for GTM 360 are privy to the cool stuff.\nSo once again, happy birthday Google Tag Manager! Congratulations to the whole GTM team at Google for taking such good care of a tool loved by so many.\nHere\u0026rsquo;s to another 5, extremely successful years for GTM!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/prevent-site-speed-sampling-rate-skewing-custom-dimensions-custom-metrics/",
	"title": "Prevent Site Speed Sampling Rate From Skewing Custom Dimensions And Custom Metrics",
	"tags": ["customtask", "data quality", "page timings", "universal analytics"],
	"description": "Use customTask to prevent your automatically collected site speed metrics from skewing your Google Analytics custom dimensions and metrics.",
	"content": " Universal Analytics can collect Page Timing data from users that load your pages. This data is populated in to the Behavior -\u0026gt; Site Speed -\u0026gt; Page Timings report, and it\u0026rsquo;s a very useful feature for optimizing your website.\n  However, there\u0026rsquo;s a murky underside to this generous feature. The way Page Timings collection works is that when Pageview hits are sent from the site, a sample of these (1% by default) are automatically followed by a timing hit which includes page performance data grabbed from the Navigation Timing API.\n  So far so good. This is how it\u0026rsquo;s supposed to work. If you\u0026rsquo;ve set siteSpeedSampleRate to 100, the first pageview request of every page will be automatically followed by this timing hit.\nHowever, the timing hit copies its information from the pageview hit. Basically, all the Custom Dimensions and Custom Metrics are copied from the pageview. Luckily, things like Enhanced Ecommerce metadata are not copied into the timing hit.\n  As you can see, the timing hit below the pageview has the same Custom Dimension and the same Custom Metric as the Pageview hit. This is annoying, especially if you use hit-scoped Custom Dimensions or pretty much any type of Custom Metrics. This is data inflation that you can\u0026rsquo;t control.\nSo we need a way to reset Custom Dimensions and Custom Metrics for the timing hit.\nI am grateful to Clément Simon for helping me come up with the following solution.\nSolution: customTask If you\u0026rsquo;ve been reading my recent articles, you might have seen this coming. I consider customTask to be one of the most versatile features recently added to analytics.js.\nWe\u0026rsquo;ll use customTask to check if the hit type is a timing hit, and if it is, we\u0026rsquo;ll make sure no Custom Dimensions and Custom Metrics are sent with the hit.\nanalytics.js This is what the situation is with analytics.js before you make the change:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {siteSpeedSampleRate: 100}); ga(\u0026#39;set\u0026#39;, \u0026#39;dimension1\u0026#39;, \u0026#39;My Value\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;, {metric1: 20);  This creates a tracker, sets a Custom Dimension, and then sends a pageview request with a Custom Metric. Since you\u0026rsquo;re sampling Page Timings at 100%, the pageview hit will be instantly followed by a timing hit that contains these two custom definitions, too.\nTo fix it, this is what you\u0026rsquo;ll do:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {siteSpeedSampleRate: 100}); ga(\u0026#39;set\u0026#39;, \u0026#39;dimension1\u0026#39;, \u0026#39;My Value\u0026#39;); ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, function(model) { var tempFieldObject = {}; var i = 1; if(model.get(\u0026#39;hitType\u0026#39;) === \u0026#39;timing\u0026#39;) { while (i !== 201) { tempFieldObject[\u0026#39;dimension\u0026#39; + i] = undefined; tempFieldObject[\u0026#39;metric\u0026#39; + i] = undefined; i++; } model.set(tempFieldObject); } }); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;, {metric1: 20});  This clears all the possible Custom Dimensions and Custom Metrics from the timing hit, and thus data inflation is avoided.\nGoogle Tag Manager To fix this in Google Tag Manager, you\u0026rsquo;ll need a Custom JavaScript Variable, and you\u0026rsquo;ll need to add a new field in your Page View tag.\nThe Custom JavaScript Variable has the following code:\nfunction() { return function(model) { var tempFieldObject = {}; var i = 1; if(model.get(\u0026#39;hitType\u0026#39;) === \u0026#39;timing\u0026#39;) { while (i !== 201) { tempFieldObject[\u0026#39;dimension\u0026#39; + i] = undefined; tempFieldObject[\u0026#39;metric\u0026#39; + i] = undefined; i++; } model.set(tempFieldObject); } }; }  And then you add it to your tag like this:\n  Whichever method you use, the customTask implementation will purge all Custom Dimensions and Custom Metrics from the automatically generated timing hit.\nSummary This was just a quick tip to fix a potential data integrity issue on your site. Granted, it\u0026rsquo;s rare for you to run into problems with the Custom Dimension duplication (unless you use it against the ga:hits metric), but on an aggregate level the Custom Metrics inflation can be troublesome.\nThis isn\u0026rsquo;t the only thing where the Site Speed Sample Rate can wreak havoc on your data. With Google Tag Manager and \u0026ldquo;virtual\u0026rdquo; pageviews, you might be inflating your page timing data by a great deal, and I\u0026rsquo;ve written about how to solve this issue here.\nNote also that these are client-side fixes to something that, in my opinion, should be prevented by analytics.js to start with. I don\u0026rsquo;t understand why the Page Timing hit just copies everything from the pageview. I\u0026rsquo;d want it to be configurable, at the very least.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/the-regex-table-variable-in-google-tag-manager/",
	"title": "The RegEx Table Variable In Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "regular expression", "variable"],
	"description": "Introduction and guide to Google Tag Manager&#39;s RegEx Table variable type.",
	"content": " Ever since the Lookup Table variable was introduced in Google Tag Manager, users have been craving for more. The Lookup Table does exactly what it promises: lookups. These are exact match operations, which are extremely inexpensive to perform, because they can only have a binary result: either the match exists in the data store being queried or it doesn\u0026rsquo;t. This performance stays constant even if the data store being queried increases in size. However, exact match has one significant problem: it\u0026rsquo;s exact match. Thus even though the Lookup Table variable is extremely useful, it\u0026rsquo;s missing the flexibility of, I don\u0026rsquo;t know, say, regular expressions. You will be pleased to hear, then, that Google Tag Manager has released a new variable type: the RegEx Table!\n  First of all, if you are unfamiliar with regular expressions, here are some great resources:\n Interactive tutorials by RegexOne\n Extremely comprehensive guide from regular-expressions.info\n LunaMetrics\u0026rsquo; Regular Expressions e-book for Google Analytics\n Google Analytics Regular Expressions Cheat Sheet by Jay Taylor\n  Needless to say, RegEx is a powerful pattern-matching syntax to learn, and can help you enormously in keeping your Google Tag Manager container lean and mean.\nThe RegEx Table variable You\u0026rsquo;ll find the RegEx Table variable in the list of variable types you can create as a User-defined variable. Once you choose this variable type, you\u0026rsquo;ll see the following configuration:\n  There are many similarities with the Lookup Table variable, for good reason, but there\u0026rsquo;s also a bunch of settings that turn this new variable into a formidable force in its own right.\n1. Input variable The Input variable shares its functionality with the Lookup Table. The input variable is what you\u0026rsquo;ll be making your pattern checks against. For example, if you want to use the RegEx table to look for patterns in the current page path, you\u0026rsquo;d choose the {{Page Path}} variable as the input.\n  The input variable is evaluated row-by-row, from top-to-bottom, against each pattern. When a pattern matches, the respective output is returned and processing of the table stops.\n2. RegEx Table Next, you have the table itself. In the table, you add rows, where each row represents a pattern you want to match in the input, and an output returned by the variable in case the pattern matches.\nThe pattern is always interpreted as a regular expression. All the following patterns are valid examples:\n simoahava.com - will match \u0026ldquo;simoahava \u0026lt;+ any character +\u0026gt; com\u0026rdquo;\n simoahava\\.com - will match \u0026ldquo;simoahava.com\u0026rdquo;.\n ^simoahava\\.com$ - will match exactly \u0026ldquo;simoahava.com\u0026rdquo; (won\u0026rsquo;t allow leading or trailing characters).\n (simoahava)\\.com - will match \u0026ldquo;simoahava.com\u0026rdquo; and create a group (see below) of \u0026ldquo;simoahava\u0026rdquo;.\n  A pattern like [simoahava\\.com is not a valid regular expression, because \u0026ldquo;[\u0026rdquo; is a reserved character, and it is being incorrectly used in this pattern. Google Tag Manager will not warn you of errors in the regular expression, but you\u0026rsquo;ll know something is wrong if the Preview mode output for the variable is boolean false. Conversely, if no match is made or there is no output for a matched pattern, the variable will return undefined.\nThe output is what the variable returns when a row is matched against the input. The return type is a string, unless you add another variable into the output. This is a great way to chain RegEx Table variables, just as you could chain Lookup Table variables.\nFor example, here\u0026rsquo;s a simple chain of a RegEx Table and a Lookup Table:\n  And here\u0026rsquo;s how to unravel the process:\n If the page hostname matches the pattern beta\\.simoahava\\.com, then return \u0026ldquo;UA-12345-1\u0026rdquo;.\n If the page hostname doesn\u0026rsquo;t match either beta\\.simoahava\\.com or \\.simoahava\\.com, also return \u0026ldquo;UA-12345-1\u0026rdquo; (Default Value of the RegEx table).\n If the page hostname matches \\.simoahava\\.com and the user is in Debug Mode, return \u0026ldquo;UA-12345-2\u0026rdquo;.\n If the page hostname matches \\.simoahava\\.com and the user is not in Debug Mode, return \u0026ldquo;UA-12345-3\u0026rdquo;.\n  As you can see, the RegEx Table returns the first match that is made. Thus even though beta\\.simoahava\\.com and \\.simoahava\\.com overlap for any hostname that contains the string \u0026ldquo;beta.simoahava.com\u0026rdquo;, the RegEx table returns \u0026ldquo;UA-12345-1\u0026rdquo;, because that is the first match that the variable makes.\n3. Set Default Value As with Lookup Tables, you can set a Default Value that is always returned in case no match is made. Just like pattern outputs, this can be another Google Tag Manager variable.\n4. Ignore Case If you check Ignore Case, patterns are matched regardless of case. So a pattern with WwW\\.SiMOAHava\\.com will match against the domain of my site, as long as Ignore Case is checked.\nIgnore Case is checked by default.\n5. Full Matches Only If you check Full Matches Only, then all patterns must match the entire input. This is the equivalent of wrapping each individual pattern with ^...$.\nFor example, if you have Full Matches Only checked, and you have a pattern of www\\.simoahava\\.com, then the input variable must return exactly \u0026ldquo;www.simoahava.com\u0026rdquo;, without any other characters. If you\u0026rsquo;d have the setting unchecked, then www\\.simoahava\\.com would also match any of the following:\n greatest.website.ever.is.www.simoahava.com\n aawwwwww.simoahava.com\n visit.www.simoahava.com.please\n  And so forth.\nFull Matches Only is checked by default.\n6. Enable Capture Groups and Replace Functionality This is interesting! In addition to matching the input against a pattern and returning a corresponding output, you can actually use parts of the matched pattern within the returned output. This is achieved with capturing groups and the dollar symbol syntax.\nA group (capturing and non-capturing) in RegEx is a pattern that you define with parentheses. Most groups can then be captured using the dollar symbol syntax when using the String.replace() method or, consequently, the Enable Capture Groups and Replace Functionality feature of GTM\u0026rsquo;s RegEx table. Here are the options for the dollar symbol syntax:\n $$ inserts a \u0026lsquo;$\u0026rsquo;.\n $\u0026amp; inserts the matched pattern.\n $` inserts whatever precedes the matched pattern in the string.\n $' inserts whatever follows the matched pattern in the string.\n $n inserts the _n_th capturing group.\n  These all have their uses, but the last one, $n should prove to be the most useful. You can use it to normalize patterns across a range of values. For example, let\u0026rsquo;s say you have a variable which stores the user\u0026rsquo;s phone number in the following formats:\n 358101001000\n 0101001000\n 010-1001000\n 010 100 1000\n +358101001000\n  You want to normalize all of these to the last format (+358101001000) whenever the phone number variable is used. This is how you\u0026rsquo;d configure the RegEx table:\n  The first pattern looks for strings that start with \u0026lsquo;358\u0026rsquo; followed by any numbers. This pattern is simply replaced with the plus symbol followed by the pattern itself.\nThe second pattern looks for a string of numbers preceded by a \u0026lsquo;0\u0026rsquo;. The output is \u0026lsquo;+358\u0026rsquo; and the string of numbers, omitting the leading \u0026lsquo;0\u0026rsquo;.\nThe third pattern looks for a string of numbers preceded by a \u0026lsquo;0\u0026rsquo;, then a hyphen, and then a string of numbers again. The output is \u0026lsquo;+358\u0026rsquo; and then the two strings of numbers, omitting the leading \u0026lsquo;0\u0026rsquo; and the hyphen.\nThe fourth pattern looks for a string of numbers preceded by a \u0026lsquo;0\u0026rsquo;, then a space, then another string of numbers, a space, and finally one more group of numbers. The output is \u0026lsquo;+358\u0026rsquo; and the three groups of numbers, omitting the leading \u0026lsquo;0\u0026rsquo; and the spaces.\nThe final pattern checks if the phone number is already well-formed, returning the pattern itself if this is the case.\nUsing the RegEx Table like this, we can create simple string transformations which help normalize and clean up data across a variety of formats. As you can see, Full Matches Only is checked in this example. That means we don\u0026rsquo;t have to worry about anything that happens outside the matched pattern, since only full matches to the pattern are transformed.\nIf you leave Full Matches Only unchecked, then Enable Capture Groups and Replace Functionality will replace all matches of the pattern found within the Input Variable with what you have in the Output. For example, if you have a RegEx Table variable that looks like this:\n  Then whenever the string \u0026ldquo;analytics\u0026rdquo; is found within a page path, it will be replaced with \u0026ldquo;google-analytics\u0026rdquo;.\nHere is an example:\n/analytics/track-users-who-are-offline-in-google-analytics/ becomes /google-analytics/track-users-who-are-offline-in-google-google-analytics/.\nNote that the example above only works if Full Matches Only is unchecked. Otherwise the variable would only replace page paths which are exactly analytics, and page paths like that do not exist.\nThe little help bubble actually recommends to avoid combining this pattern replacement with unchecked Full Matches Only. This is because there\u0026rsquo;s no validation of the input variable, and you might end up replacing things that you didn\u0026rsquo;t mean to!\nEnable Capture Groups and Replace Functionality is checked by default.\nSummary That\u0026rsquo;s the RegEx Table in all its simple glory! I know it will make some operations so much simpler. You no longer need to use clumsy Custom JavaScript variables to perform your pattern matches, since the RegEx Table has that built into its modus operandi.\nThe option to replace any matches with custom strings (in which you can incorporate parts of the match using groups) is pretty powerful, too.\nAll in all, this is a very welcome addition to Google Tag Manager\u0026rsquo;s variable offering. It remains to be seen if the Lookup Table still has a place in the table after this, because with the RegEx table you can do exact match lookups, too. The difference is perhaps in the syntax (with Lookup Tables you don\u0026rsquo;t need to use regular expressions) and performance (lookups will always perform much faster than regular expression matches), though the latter might be very insignificant in the context of a web page.\n"
},
{
	"uri": "https://www.simoahava.com/digital-marketing/the-myth-of-the-non-technical-marketer/",
	"title": "The Myth Of The Non-Technical Marketer",
	"tags": ["developer", "marketer", "non-technical"],
	"description": "There is no such thing as a non-technical (digital) marketer. Anyone working in digital is already technical. The question is what to do about this.",
	"content": " There\u0026rsquo;s a fabled, mythical beast that prowls the jungles of digital marketing. They have no issues with running and analyzing crawler data, offering suggestions for server-side redirects, building remarketing audiences, implementing tag management solutions, speaking of Data Layers, copy-pasting code from Stack Overflow, configuring bid managers, and speaking at conferences presenting on all the aforementioned activities. However, for some reason, they still claim that they are \u0026ldquo;non-technical\u0026rdquo;, or \u0026ldquo;just marketers\u0026rdquo;.\nThis archetype is only enforced by conference presenters who actually apologize before showing a slide that might have some JavaScript (heaven forbid!), or by bloggers who do the same if they need to show some code or even a screenshot of an HTML template in their articles! What\u0026rsquo;s up with that? If it\u0026rsquo;s necessary to include code to get the point across, then why not just present it without treating it as some bogeyman that needs to be exorcized through ridicule?\n  Why focus on dumbing things down for this imaginary, unskilled audience, rather than tactfully steering them towards a path where they can enhance their technological aptitude?\nI just don\u0026rsquo;t get it. The whole polarization of non-technical vs. technical is silly and artificial, and nothing irks me as much as this constant undervaluing of the human capacity to learn new things. Code allergy should be a thing of the past by now. Why not instead embrace the fact that our industry is rife with opportunities to not only understand more about the technology stack we work with, but also to combine this technical know-how with our marketing skills for some true hybrid insight?\nAnyway, my point is that if you\u0026rsquo;re working in digital marketing, you are already \u0026ldquo;technical\u0026rdquo;. I\u0026rsquo;m really sorry about this, but that\u0026rsquo;s just the way it is. Non-technical (digital) marketer is an oxymoron.\nYou already possess a set of skills that requires training, education, and a technology-oriented mind to handle. You are firmly situated in a continuum of learning, which doesn\u0026rsquo;t subscribe to a binary world of \u0026ldquo;technical\u0026rdquo; vs. \u0026ldquo;non-technical\u0026rdquo;, but rather comprises a vast number of skills that each conspire to make you better at what you do for a living.\nIn fact, it\u0026rsquo;s impossible to categorize the complexity of human experience, yet for some reason we find ourselves doing so in our daily routines, and (sub)consciously subscribe to prototypes that don\u0026rsquo;t really exist. This is why job titles suck - especially those that imply proficiency in some skills (and, via inference, lack thereof in others).\nWhat can be done? If you work in digital and you\u0026rsquo;ve always considered yourself \u0026ldquo;non-technical\u0026rdquo;, the first thing to do is accept the fact that you\u0026rsquo;re not. Indeed, you are a \u0026ldquo;techie\u0026rdquo;, a \u0026ldquo;nerd\u0026rdquo;, and a \u0026ldquo;geek\u0026rdquo; (choose which one works best). The main question is what skills you currently possess, and what learning track you\u0026rsquo;re on.\nTo help you with this discovery, I recommend looking at people in your industry to see how they\u0026rsquo;ve evolved over the years. There are so many folks out there who possess the tech skills required to successfully navigate the digital ocean, and you can rest assured they weren\u0026rsquo;t born with this talent. They\u0026rsquo;ve had to study, learn, work, toil, starve, and sweat to get to where they are now.\nTo get you started, take a look at what Aleyda Solis, Annie Cushing, Mike King, Mike Arnesen, Carmen Mardiros, Mark Edmondson, David Vallejo, Dan Wilkerson, Linda Lawton, and Annemarie Klaassen are doing and sharing. They are just a handful of skilled people out of a multitude, who, in addition to being really good at what they do, are extremely generous with knowledge transfer and inspiring others to improve.\nAlso, take a look at the MeasureCamp (un)conference. It\u0026rsquo;s mainly around digital analytics, but the concept is brilliant in that it minimizes ego and sales pitches (two things that kill any good conference presentation), and instead focuses solely on sharing and learning together.\nOther than that, dig deep inside you and find out just what part of your current skillset is lacking. Why do you call yourself \u0026ldquo;non-technical\u0026rdquo;? Is it because you don\u0026rsquo;t know how to code? Head on over to Codecademy to rectify that. Is it because you don\u0026rsquo;t understand enough about the browser stack to be confident in your technical SEO skills? Take a look at The Technical SEO Renaissance by the inimitable Mike King to see where technical SEO is today. Or perhaps you\u0026rsquo;re interested in mobile optimization, web analytics, and conversion optimization?\nThere\u0026rsquo;s something for each gap in your skill set.\nSo, all you need to do is roll up your sleeves and get to work. Once you accept the fact that you\u0026rsquo;re not \u0026ldquo;non-technical\u0026rdquo;, it\u0026rsquo;s just a question of opening the flood gates and letting the deluge of knowledge carry you away.\nSo should we stop reinforcing these stupid, arbitrary silos? I\u0026rsquo;ll wrap this up with a rant, reworded from something I wrote a couple of years ago in Google+.\n Marketer, analyst, developer - these labels are attached to people often thanks to their job titles, but also in order to reinforce stereotypes that help tools like tag management solutions (TMS) sell better. Marketer is seen as the antithesis of the developer, and the analyst shuttles between these two roles depending on if they\u0026rsquo;re supporting growth in either marketing channels or within the organization. Throw in the mix growth hackers and data scientists while you\u0026rsquo;re at it. Nothing wrong with labels, but once they\u0026rsquo;re used as excuses to belittle the multitude of things that can be done in digital, that\u0026rsquo;s when it really bothers me. The non-technical (read: lazy) marketer has been the primus motor for TMS development. Almost as much as the uncooperative developer, sitting grumpily in his or her dungeon, sipping Jolt cola and laughing at the \u0026ldquo;stupid marketer\u0026rsquo;s\u0026rdquo; requests. The analyst is someone who\u0026rsquo;s hired for insight, but they\u0026rsquo;re reduced to either solving problems between the two aforementioned parties, or to tweaking lazily installed Google Analytics implementations. Seriously, all you need to do is look into an organization that\u0026rsquo;s doing it right to see that these labels are ridiculous. The true, modern, digital employee is a hybrid. They are forced to transcend silos because they\u0026rsquo;ve understood that a holistic, contextual view is what drives growth, instead of a singular focus on verticals like marketing, SEO, PPC, social media, plug-and-play analytics, or some legacy-burdened, development-driven framework.\n So, please. Can we stop being apologetic for the non-technical marketer, the emotionally detached developer, and the data-driven analyst? Perhaps that way people can become more ambitious and strive towards a more multi-disciplined approach - things that today\u0026rsquo;s digital landscape desperately calls for.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/the-youtube-video-trigger-in-google-tag-manager/",
	"title": "The YouTube Video Trigger In Google Tag Manager",
	"tags": ["Google Tag Manager", "trigger", "youtube"],
	"description": "Introduction and guide to the YouTube Video trigger in Google Tag Manager.",
	"content": " Let\u0026rsquo;s cut straight to the chase. Google Tag Manager has just released the YouTube Video trigger, which gives you native support for YouTube video tracking. And it\u0026rsquo;s great! Even though we\u0026rsquo;ve been more than satisfied with the excellent tracking scripts provided by e.g. Cardinal Path and LunaMetrics (with a small modification from yours truly), this is a no-brainer for native support in Google Tag Manager.\n  The YouTube Video trigger checks pretty much all the boxes I\u0026rsquo;d expect in a video tracking trigger. It has built-in events for things like Start, Progress (e.g. 25%, 50%, 75%), and Complete. You can also use it to decorate the embedded YouTube URLs with the required enablejsapi=1 query parameter, if they don\u0026rsquo;t already have it.\nThe YouTube Video trigger supports tracking lazy-loaded or dynamically inserted videos, too, which will be a relief to sites that defer loading videos until they are actually interacted with by the user.\nCreate and configure the trigger To create the trigger, scroll to Triggers in the Google Tag Manager user interface, and create a new trigger. You\u0026rsquo;ll find the YouTube Video option in the sidebar that flies out when you click to choose a trigger type.\n  Once you\u0026rsquo;ve selected the YouTube Video trigger type, it\u0026rsquo;s time to configure it. Here are the options.\n Capture - Start - collects a start when the user starts watching the video.\n Capture - Complete - collects a complete when the user reaches the end of the video.\n Capture - Pause, Seeking, and Buffering - collects a pause when the user pauses the video or jumps forward or back, and buffering when the video starts buffering due to lack of bandwith.\n Capture - Progress - collects a progress the moment the user passes either a percentage or time threshold (e.g. 25%, 50%, 75% or 10 second mark, 30 second mark, one minute mark).\n Advanced - Add JavaScript API support to all videos - if your YouTube embeds lack the necessary enablejsapi=1 parameter, you can check this to automatically add it to all your videos. NOTE! This reloads the iframe, so users might see the video flicker when they first load the page. This option, when checked, also adds the required https://www.youtube.com/iframe_api library to the page.\n  Here\u0026rsquo;s what the dataLayer payload looks like whenever a YouTube event is triggered.\n event: 'gtm.video' - the event name pushed into dataLayer for all YouTube video events. This is what fires your YouTube trigger.\n gtm.videoProvider: 'youtube' - specifies the platform whose videos you are tracking. You can take this as a hint that support for other platforms is planned!\n gtm.videoStatus: 'start' - specifies the status of the video that caused the event to trigger. These different status values are only triggered if you\u0026rsquo;ve enabled them in the trigger settings. Possible values are 'start', 'complete', 'pause', 'buffering', and 'progress'.\n gtm.videoUrl: 'https://www.youtube.com/watch?v=...' - the original URL of the embedded video.\n gtm.videoTitle: 'Best of Simo Ahava' - the title of the embedded video.\n gtm.videoDuration: 197 - the total length of the video in seconds.\n gtm.videoCurrentTime: 30 - the time mark where the user is at when the video event happened.\n gtm.videoElapsedTime: 10 - the time elapsed since the last time the video was paused or buffering.\n gtm.videoPercent: 15 - the percentage mark where the user is at when the video event happened.\n gtm.videoVisible: true - either true or false, depending on whether or not the video was visible in the browser viewport when the video event happened.\n  One thing that might make you breathe easier is that there are new Built-in Variables for all these items in the dataLayer. You can find them by clicking the red CONFIGURE button when browsing to Variables / Built-In Variables in the Google Tag Manager user interface.\n  Quick word about progress tracking Do note that tracking progress is relative to the entire video length and not the actual time or percentage you\u0026rsquo;ve been watching the video.\nSo if you configure the trigger to fire at 25%, 50%, and 75%, it will fire those events when the user reaches the respective marks in the video timeline even if they haven\u0026rsquo;t watched continuously from the beginning. Thus, if you start playing a video and jump straight to the 25% mark, the event will fire even though you only just started watching.\nThe same applies to the time thresholds.\nYou can leverage the Video Elapsed Time variable to see how long the user has been continuously watching the video since the last pause. Using the time and percentage thresholds only tells you if the user reached a specific milestone in the video, not necessarily if they actually watched all the way to that point. It\u0026rsquo;s a small but potentially significant difference.\nPutting it all together Since there are so many combinations of events you can collect with the YouTube Video trigger, I\u0026rsquo;ll show a fairly generic way of measuring start, pause, percentage progress and complete events with just one Universal Analytics Event tag. The tag looks like this:\n  The trigger that fires this tag looks like this:\n  And the Custom JavaScript Variable named {{JS - Get video action}} looks like this:\nfunction() { var status = {{Video Status}}; switch (status) { case \u0026#39;start\u0026#39;: return \u0026#39;Start playing\u0026#39;; case \u0026#39;pause\u0026#39;: return \u0026#39;Pause\u0026#39;; case \u0026#39;buffering\u0026#39;: return \u0026#39;Buffering\u0026#39;; case \u0026#39;progress\u0026#39;: return \u0026#39;Reached \u0026#39; + {{Video Percent}} + \u0026#39;%\u0026#39;; case \u0026#39;complete\u0026#39;: return \u0026#39;Reached the end\u0026#39;; } }  This translates the default parameter values of the video object in dataLayer to a more readable format. Thus we can use the same Event tag for all video events.\nTrack lazy-loaded / dynamically inserted videos If your videos load during the initial page load, then everything is smooth sailing for you. By checking the Add JavaScript API support to all videos option, GTM will take care of initializing the videos so that they can be tracked by the trigger. This option also downloads the required API library for you (see below).\nHowever, more and more sites are performance-wary these days, and they defer loading any embedded content until the user has intimated that they want to watch the video. You can read about the technical implications here.\nLuckily, the YouTube Video trigger does support tracking videos that are loaded and embedded after the initial page load. The only thing you need to do is make sure that when a video is first loaded, the page loads the YouTube API library:\n\u0026lt;script src=\u0026quot;https://www.youtube.com/iframe_api\u0026quot;\u0026gt;\nSo if your site does lazy-load or otherwise dynamically load videos (e.g. if it\u0026rsquo;s a single-page app), make sure that the library above is loaded before the first video is added to the site.\nAgain, if the video is present during the initial page load, you don\u0026rsquo;t have to worry about this. The Add JavaScript API support to all videos takes care of loading this library for you.\nSummary I\u0026rsquo;m quite happy with the YouTube Video trigger. It does pretty much all I\u0026rsquo;d expect from the first iteration of the feature. I hope we\u0026rsquo;ll see support for other video services and players in the future.\nThere\u0026rsquo;s not a lot I miss. Mainly, I\u0026rsquo;d like for there to be a gtm.videoTotalElapsedTime, which would measure how much in total I\u0026rsquo;ve been watching any given video. The gtm.videoElapsedTime only tells me the elapsed time since the last pause/buffer/seek, but not what the total time watched has been.\nWhat do you think of the YouTube Video trigger? Is it just perfect for your tracking needs, or do you have features in mind you\u0026rsquo;d want to see in a future release?\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/remove-pii-google-analytics-hits/",
	"title": "#GTMTips: Remove PII From Google Analytics Hits",
	"tags": ["customtask", "gtmtips", "JavaScript", "pii"],
	"description": "Use customTask to automatically strip all personally identifiable information (PII) from requests sent to Google Analytics from your website.",
	"content": " Sending personally identifiable information (PII) to Google Analytics is one of the things you should really avoid doing. For one, it\u0026rsquo;s against the terms of service of the platform, but also you will most likely be in violation of national, federal, or EU legislation drafted to protect the privacy of individuals online.\nIn this #GTMTips post, I\u0026rsquo;ll show you a way to make sure that any tags you configure this solution with will not contain strings that might be construed as PII. The tip is for Google Tag Manager, but with very little modifications it will work with Universal Analytics, too.\n(UPDATE 8 September 2017: Check out Brian Clifton\u0026rsquo;s great extension of this solution: Remove PII from Google Analytics)\nTip 64: Remove PII from hits to Google Analytics   The solution hinges around customTask, which has fast become my favorite new feature in the analytics.js library. See the following articles to understand why I think so:\n #GTMTips: Use customTask To Access Tracker Values In Google Tag Manager\n #GTMTips: Send Google Analytics Tag To Multiple Properties\n Track Users Who Are Offline In Google Analytics\n  Anyway, to make the whole thing run, create the following Custom JavaScript variable:\nfunction() { return function(model) { // Add the PII patterns into this array as objects  var piiRegex = [{ name: \u0026#39;EMAIL\u0026#39;, regex: /.{4}@.{4}/g },{ name: \u0026#39;HETU\u0026#39;, regex: /\\d{6}[A+-]\\d{3}[0-9A-FHJ-NPR-Y]/gi }]; var globalSendTaskName = \u0026#39;_\u0026#39; + model.get(\u0026#39;trackingId\u0026#39;) + \u0026#39;_sendHitTask\u0026#39;; // Fetch reference to the original sendHitTask  var originalSendTask = window[globalSendTaskName] = window[globalSendTaskName] || model.get(\u0026#39;sendHitTask\u0026#39;); var i, hitPayload, parts, val; // Overwrite sendHitTask with PII purger  model.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;).split(\u0026#39;\u0026amp;\u0026#39;); for (i = 0; i \u0026lt; hitPayload.length; i++) { parts = hitPayload[i].split(\u0026#39;=\u0026#39;); // Double-decode, to account for web server encode + analytics.js encode  try { val = decodeURIComponent(decodeURIComponent(parts[1])); } catch(e) { val = decodeURIComponent(parts[1]); } piiRegex.forEach(function(pii) { val = val.replace(pii.regex, \u0026#39;[REDACTED \u0026#39; + pii.name + \u0026#39;]\u0026#39;); }); parts[1] = encodeURIComponent(val); hitPayload[i] = parts.join(\u0026#39;=\u0026#39;); } sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload.join(\u0026#39;\u0026amp;\u0026#39;), true); originalSendTask(sendModel); }); }; }  Once you add this variable to your Universal Analytics tags as the customTask field, any hits sent by these tags will be parsed by this variable, which replaces the instances of PII with the string [REDACTED pii_type].\n   At the beginning of the code snippet, you\u0026rsquo;ll see the configuration object piiRegex. It\u0026rsquo;s an array of object literals, where each object has two properties: name and regex. The first is what will be used in the replace string after \u0026ldquo;REDACTED\u0026rdquo;. So if name is \u0026ldquo;EMAIL\u0026rdquo;, you\u0026rsquo;ll see \u0026ldquo;[REDACTED EMAIL]\u0026rdquo; in your Google Analytics reports wherever PII data was removed.\nThe second parameter, regex, is where you\u0026rsquo;ll add the regular expression literal for whatever PII pattern you want to redact. In the example above, I have two patterns:\n /.{4}@.{4}/g - this matches all @ symbols plus the four preceding and four following characters. So if ANY part of the payload (URL, Custom Dimension, Event Label, etc.) has the @ symbol, then the string will be obfuscated. Thus, simo.s.ahava@gmail.com becomes simo.s.a[REDACTED EMAIL]l.com.\n /\\d{6}[A+-]\\d{3}[0-9A-FHJ-NPR-Y]/gi - this is a reasonably good abstraction of the Finnish personal identity code. It\u0026rsquo;s not perfect, because the personal identity code is actually a calculation, so you can\u0026rsquo;t use simple pattern matches to only find valid codes. This regular expression will probably result in many false positives, especially if your GA hits include UUIDs or any type of alphanumeric hashes. But it\u0026rsquo;s still better than collecting this sensitive data.\n  You can add your own regular expression patterns as new objects of the array.\nWhen you add this variable into the customTask field of a Universal Analytics tag, the code will run through the entire payload, looking for matches to the regular expressions you provide in the configuration array. If any matches are made, they are redacted.\nDo you have other, useful regular expressions for finding and weeding out personally identifiable information?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-users-who-are-offline-in-google-analytics/",
	"title": "Track Users Who Are Offline In Google Analytics",
	"tags": ["customtask", "google analytics", "Google Tag Manager", "JavaScript", "tasks"],
	"description": "Use this solution to automatically collect data from users who are offline, and send the data to Google Analytics once they are back online.",
	"content": " The steady increase in mobile use over the last years has introduced some new challenges for web analytics. It\u0026rsquo;s not just about mismatches in the tracking model (the concept of sessions is even more absurd for apps than it is for desktop browsing), but about something more fundamental, more basic. Think about it: if a visitor visits the website using a mobile device, there\u0026rsquo;s a significant chance of them losing internet connectivity and going unintentionally offline.\nActually, it\u0026rsquo;s enough for them to simply traverse an area with poor coverage - if the HTTP requests sent by the browser don\u0026rsquo;t complete in time, they timeout, and the hits are lost.\nFor Google Analytics pageviews it\u0026rsquo;s not such a big deal, because if the user sees the web page, it\u0026rsquo;s very likely the first pageview has completed. However, what about all the other interactions that we want to track, and the user doesn\u0026rsquo;t have an internet connection to boot? That\u0026rsquo;s right - we\u0026rsquo;ll lose these interactions, since the requests are dropped by the browser and never picked up, even when the user gets their connection back.\nIn this article, the brilliant David Vallejo and I will offer a solution for retrieving these hits initially dropped by the browser due to the internet connection being offline. OK, who am I kidding, this is all David. I\u0026rsquo;m just a glorified editor at this point.\n  Anyway, let\u0026rsquo;s frame it like this: the visitor is viewing our contact page, and we have an event queued up for when they click on our email contact information. However, the visitor is also on the subway, and the moment they click the email, they enter a tunnel. Oh noes! They lose their internet connection (damn subways without WiFi), and we miss our vital conversion tracking.\nThat\u0026rsquo;s the premise. Here\u0026rsquo;s the execution.\nIn this article, we\u0026rsquo;ll touch upon a number of fairly technical concepts, but we\u0026rsquo;ll try to frame them so that they make sense in the big picture.\n Universal Analytics Tasks API\n The browser\u0026rsquo;s Storage API\n Sending Google Analytics hits with a delay (the \u0026amp;qt parameter)\n Sending custom POST and HEAD requests (HTTP protocol)\n Batching Universal Analytics Hits\n  All of these concepts are very useful to know if you want to know more about the mechanisms that the web browser employs to compile and dispatch requests to Universal Analytics.\nLet\u0026rsquo;s go!\n1. Universal Analytics Tasks API Each time a send command is dispatched to the ga() global method, a series of tasks are run in sequence by the analytics.js library. These tasks do a number of things, such as construct the payload, validate it, sample the requests, and finally dispatch the requests to the Universal Analytics endpoint.\nThe neat thing about these tasks is that we can intercept them and modify them using the API provided by analytics.js.\nYou can find a list of all available tasks in the API here. However, in this article we will focus on just a very special, very significant task: customTask. It\u0026rsquo;s a new task introduced very recently (here\u0026rsquo;s a guide by Simo).\nThis task is true to its name - it\u0026rsquo;s entirely customizable. It runs first in the task queue, so you can use it to configure the tracker object or even to set other tasks up for customization.\nIn this guide, we\u0026rsquo;ll use customTask to modify the sendHitTask. This way we can check if the user has internet connectivity when sendHitTask is run, and we can do a number of things if the user has dropped their connection. We use customTask instead of directly accessing sendHitTask simply because this way is much more Google Tag Manager-friendly.\nIn short, here\u0026rsquo;s the process:\ncustomTask modifies sendHitTask with OUR CODE before hit is sent.\nIn order to detect if the user has internet connectivity, we could simply poll our own web server endpoint. However, that wouldn\u0026rsquo;t be a good litmus test since it could be just Google\u0026rsquo;s servers that are not responding. That\u0026rsquo;s why we\u0026rsquo;ll actually poll Google\u0026rsquo;s endpoint to check if the user has the connectivity required for Google Analytics tracking.\n2. The offline tracker The solution is that with every single request to Universal Analytics, we\u0026rsquo;ll send an HTTP HEAD request to the Universal Analytics endpoint. If the endpoint isn\u0026rsquo;t responding, we can infer that the user does not have connectivity for communicating with Google Analytics, and so we\u0026rsquo;ll store the hit into browser storage until such a time that internet coverage is restored.\n  We\u0026rsquo;ll use localStorage for the queue, but we\u0026rsquo;ll need to cheat a little. localStorage itself doesn\u0026rsquo;t introduce any structure or a deeper data model - it just processes key-value pairs. So, to give us some additional flexibility, we\u0026rsquo;ll use the Lockr open-source database layer. It\u0026rsquo;s a simple and efficient framework, and it has pretty solid browser support.\nThis solution picks up the Universal Analytics hit payload from sendHitTask, and if there is no internet connection, this hit is stored in localStorage with the timestamp of the request. Thus, when we later do manage to send the stored hit, we can send it at its original timestamp to Universal Analytics.\n2.1. The \u0026amp;qt parameter The \u0026amp;qt Measurement Protocol stands for queue time. Basically, you can set a number in milliseconds in that parameter, and the hit will be sent with a timestamp that many milliseconds in the past. For example, if I know that the hit I want to send actually happened 45 minutes ago, I can set the parameter to:\n\u0026amp;qt=2700000\nThere\u0026rsquo;s just an odd little quirk you need to know about \u0026amp;qt. The latest you can send the displaced hit is at 03:59:59 the following day (in the timezone of the Google Analytics view the hit is being sent to). Thus, the maximum value for \u0026amp;qt is 27 hours, 59 minutes, and 59 seconds (in milliseconds), if the hit occurred at exactly midnight, and you then send it the following morning, just before 4 AM.\nYes, it might be difficult to grasp, so we\u0026rsquo;ll go with the official recommendation: avoid sending hits more than 4 hours in the past, since there\u0026rsquo;s no guarantee they will get sent.\n3. The HTTP HEAD request So what is this HEAD request and why are we using it? Well, it\u0026rsquo;s identical to GET, except it only returns the HTTP headers (and associated metadata), never any content.\nIt\u0026rsquo;s thus a great method to use if we only want to test an endpoint, and not get into the expensive process of actually retrieving data from it.\nSince we are only interested in knowing if the Universal Analytics endpoint responds, the HTTP HEAD request is perfect for this purpose. Also, see how efficient it is compared to POST and GET:\n  4. The JavaScript code The code comes in three parts. First is the library for extending the database: Lockr. Next we have the customTask execution, and finally we\u0026rsquo;ll chain the HTTP HEAD and batch requests together to make the whole thing click.\n4.1. Lockr download To get started, go ahead and load Lockr on your site in any way you want. If you\u0026rsquo;re using Google Tag Manager, we recommend loading the following code in a Custom HTML Tag that fires on All Pages with the highest possible Tag Priority. Alternatively, if you accept some overhead and redundancy, you can just add the library to the top of the Custom JavaScript Variable itself, as in the example in the next chapter.\nHere\u0026rsquo;s the minified JavaScript code - it should be executed by the browser before the offline tracking solution is run:\n!function(e,t){\u0026#34;undefined\u0026#34;!=typeof exports?\u0026#34;undefined\u0026#34;!=typeof module\u0026amp;\u0026amp;module.exports\u0026amp;\u0026amp;(exports=module.exports=t(e,exports)):\u0026#34;function\u0026#34;==typeof define\u0026amp;\u0026amp;define.amd?define([\u0026#34;exports\u0026#34;],function(r){e.Lockr=t(e,r)}):e.Lockr=t(e,{})}(this,function(e,t){\u0026#34;use strict\u0026#34;;return Array.prototype.indexOf||(Array.prototype.indexOf=function(e){var t=this.length\u0026gt;\u0026gt;\u0026gt;0,r=Number(arguments[1])||0;for((r=r\u0026lt;0?Math.ceil(r):Math.floor(r))\u0026lt;0\u0026amp;\u0026amp;(r+=t);r\u0026lt;t;r++)if(r in this\u0026amp;\u0026amp;this[r]===e)return r;return-1}),t.prefix=\u0026#34;\u0026#34;,t._getPrefixedKey=function(e,t){return(t=t||{}).noPrefix?e:this.prefix+e},t.set=function(e,t,r){var o=this._getPrefixedKey(e,r);try{localStorage.setItem(o,JSON.stringify({data:t}))}catch(r){console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr didn\u0026#39;t successfully save the \u0026#39;{\u0026#34;+e+\u0026#34;: \u0026#34;+t+\u0026#34;}\u0026#39; pair, because the localStorage is full.\u0026#34;)}},t.get=function(e,t,r){var o,n=this._getPrefixedKey(e,r);try{o=JSON.parse(localStorage.getItem(n))}catch(e){o=localStorage[n]?{data:localStorage.getItem(n)}:null}return o?\u0026#34;object\u0026#34;==typeof o\u0026amp;\u0026amp;void 0!==o.data?o.data:void 0:t},t.sadd=function(e,r,o){var n,a=this._getPrefixedKey(e,o),i=t.smembers(e);if(i.indexOf(r)\u0026gt;-1)return null;try{i.push(r),n=JSON.stringify({data:i}),localStorage.setItem(a,n)}catch(t){console.log(t),console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr didn\u0026#39;t successfully add the \u0026#34;+r+\u0026#34; to \u0026#34;+e+\u0026#34; set, because the localStorage is full.\u0026#34;)}},t.smembers=function(e,t){var r,o=this._getPrefixedKey(e,t);try{r=JSON.parse(localStorage.getItem(o))}catch(e){r=null}return r\u0026amp;\u0026amp;r.data?r.data:[]},t.sismember=function(e,r,o){return t.smembers(e).indexOf(r)\u0026gt;-1},t.keys=function(){var e=[],r=Object.keys(localStorage);return 0===t.prefix.length?r:(r.forEach(function(r){-1!==r.indexOf(t.prefix)\u0026amp;\u0026amp;e.push(r.replace(t.prefix,\u0026#34;\u0026#34;))}),e)},t.getAll=function(e){var r=t.keys();return e?r.reduce(function(e,r){var o={};return o[r]=t.get(r),e.push(o),e},[]):r.map(function(e){return t.get(e)})},t.srem=function(e,r,o){var n,a,i=this._getPrefixedKey(e,o),c=t.smembers(e,r);(a=c.indexOf(r))\u0026gt;-1\u0026amp;\u0026amp;c.splice(a,1),n=JSON.stringify({data:c});try{localStorage.setItem(i,n)}catch(t){console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr couldn\u0026#39;t remove the \u0026#34;+r+\u0026#34; from the set \u0026#34;+e)}},t.rm=function(e){var t=this._getPrefixedKey(e);localStorage.removeItem(t)},t.flush=function(){t.prefix.length?t.keys().forEach(function(e){localStorage.removeItem(t._getPrefixedKey(e))}):localStorage.clear()},t});  After this code puke, we\u0026rsquo;re ready to jump in the deep end with some offline hit tracking!\n4.2. Offline hit tracker for on-page Universal Analytics The following JavaScript runs with the default Universal Analytics tracker, and thus any hits sent with the ga('send', '...'); will be included in the process.\nTo make the whole thing work, you should setup your code in the following order:\n\u0026lt;head\u0026gt; ... \u0026lt;script\u0026gt; // Put the Lockr code here first  \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; var _offlineTracker = function(customTaskModel) { // _offlineTracker (see below) here  }; \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; // Universal Analytics snippet here  ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;); // Add the following line AFTER the \u0026#39;create\u0026#39; command and BEFORE the first \u0026#39;send\u0026#39; command  ga(\u0026#39;set\u0026#39;, \u0026#39;customTask\u0026#39;, _offlineTracker); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; ... \u0026lt;/head\u0026gt;\nAnd here\u0026rsquo;s the code for the _offlineTracker callback function.\nvar _offlineTracker = function(customTaskModel) { Lockr.prefix = \u0026#39;ga_\u0026#39;; // Grab the original sentHitTask Function from the first tracker. to kept the original hit sending function.  var originalSendHitTask = customTaskModel.get(\u0026#39;sendHitTask\u0026#39;); customTaskModel.set(\u0026#39;sendHitTask\u0026#39;, function(model) { // Let\u0026#39;s send the original hit using the native functionality  originalSendHitTask(model); // Grab the hit Payload  var payload_lz = model.get(\u0026#39;hitPayload\u0026#39;); // Check if GA Endpoint is Ready  var http = new XMLHttpRequest(); http.open(\u0026#39;HEAD\u0026#39;, \u0026#39;https://www.google-analytics.com/collect\u0026#39;); http.onreadystatechange = function() { // Google Analytics endpoint is not reachable, let\u0026#39;s save the hit  if (this.readyState === this.DONE \u0026amp;\u0026amp; this.status !== 200) { Lockr.sadd(\u0026#39;hits\u0026#39;, payload_lz + \u0026#34;\u0026amp;qt=\u0026#34; + (new Date() * 1)); } else { // Google Analytics endpoint is available, let\u0026#39;s check if there are any unsent hits  if (Lockr.smembers(\u0026#34;hits\u0026#34;).length \u0026gt; 0) { // Process hits in queue  var current_ts = new Date() * 1 / 1000; var hits = Lockr.smembers(\u0026#34;hits\u0026#34;); // ./batch endpoint only allows 20 hits per batch, let\u0026#39;s chunk the hits array.  var chunk_size = 20; var chunked_hits = Lockr.smembers(\u0026#34;hits\u0026#34;).map(function(e, i) { return i % chunk_size === 0 ? hits.slice(i, i + chunk_size) : null; }).filter(function(e) { return e; }); // Let\u0026#39;s loop thru the chunks array and send the hits to GA  for (var i = 0; i \u0026lt; chunked_hits.length; i++) { var xhr = new XMLHttpRequest(); xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;https://www.google-analytics.com/batch\u0026#39;, true); // Build the Batch Payload and Take care of calculating the Queue Time  xhr.send(chunked_hits[i].map(function(x) { if (x.indexOf(\u0026#34;\u0026amp;qt=\u0026#34;) \u0026gt; -1) { return x.replace(/qt=([^\u0026amp;]*)/, \u0026#34;qt=\u0026#34; + Math.round(current_ts - x.match(/qt=([^\u0026amp;]*)/)[1] / 1000) * 1000); } else return x; }).join(\u0026#34;\\n\u0026#34;)); } //Hits sent, flush the Storage  Lockr.flush(); } } }; http.send(); }); };  Once you create this _offlineTracker and invoke it in the ga('set', 'customTask', _offlineTracker) command, every single hit that uses this tracker will be stored in the queue if there is no internet connectivity. Once a hit is sent with a solid connection, all hits in the queue are sent as well.\n4.3. Offline hit tracker for Google Tag Manager With Google Tag Manager, you can get by with a single Custom JavaScript variable. This variable can be configured to include the Lockr code as well, so it\u0026rsquo;s completely self-contained. Give the variable a descriptive name, e.g. {{JS - customTask Offline Hit Tracker}} and put the following code within:\nfunction() { return function(customTaskModel) { // Load Lockr if it hasn\u0026#39;t already been loaded  if (!window.Lockr) { !function(e,t){\u0026#34;undefined\u0026#34;!=typeof exports?\u0026#34;undefined\u0026#34;!=typeof module\u0026amp;\u0026amp;module.exports\u0026amp;\u0026amp;(exports=module.exports=t(e,exports)):\u0026#34;function\u0026#34;==typeof define\u0026amp;\u0026amp;define.amd?define([\u0026#34;exports\u0026#34;],function(r){e.Lockr=t(e,r)}):e.Lockr=t(e,{})}(this,function(e,t){\u0026#34;use strict\u0026#34;;return Array.prototype.indexOf||(Array.prototype.indexOf=function(e){var t=this.length\u0026gt;\u0026gt;\u0026gt;0,r=Number(arguments[1])||0;for((r=r\u0026lt;0?Math.ceil(r):Math.floor(r))\u0026lt;0\u0026amp;\u0026amp;(r+=t);r\u0026lt;t;r++)if(r in this\u0026amp;\u0026amp;this[r]===e)return r;return-1}),t.prefix=\u0026#34;\u0026#34;,t._getPrefixedKey=function(e,t){return(t=t||{}).noPrefix?e:this.prefix+e},t.set=function(e,t,r){var o=this._getPrefixedKey(e,r);try{localStorage.setItem(o,JSON.stringify({data:t}))}catch(r){console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr didn\u0026#39;t successfully save the \u0026#39;{\u0026#34;+e+\u0026#34;: \u0026#34;+t+\u0026#34;}\u0026#39; pair, because the localStorage is full.\u0026#34;)}},t.get=function(e,t,r){var o,n=this._getPrefixedKey(e,r);try{o=JSON.parse(localStorage.getItem(n))}catch(e){o=localStorage[n]?{data:localStorage.getItem(n)}:null}return o?\u0026#34;object\u0026#34;==typeof o\u0026amp;\u0026amp;void 0!==o.data?o.data:void 0:t},t.sadd=function(e,r,o){var n,a=this._getPrefixedKey(e,o),i=t.smembers(e);if(i.indexOf(r)\u0026gt;-1)return null;try{i.push(r),n=JSON.stringify({data:i}),localStorage.setItem(a,n)}catch(t){console.log(t),console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr didn\u0026#39;t successfully add the \u0026#34;+r+\u0026#34; to \u0026#34;+e+\u0026#34; set, because the localStorage is full.\u0026#34;)}},t.smembers=function(e,t){var r,o=this._getPrefixedKey(e,t);try{r=JSON.parse(localStorage.getItem(o))}catch(e){r=null}return r\u0026amp;\u0026amp;r.data?r.data:[]},t.sismember=function(e,r,o){return t.smembers(e).indexOf(r)\u0026gt;-1},t.keys=function(){var e=[],r=Object.keys(localStorage);return 0===t.prefix.length?r:(r.forEach(function(r){-1!==r.indexOf(t.prefix)\u0026amp;\u0026amp;e.push(r.replace(t.prefix,\u0026#34;\u0026#34;))}),e)},t.getAll=function(e){var r=t.keys();return e?r.reduce(function(e,r){var o={};return o[r]=t.get(r),e.push(o),e},[]):r.map(function(e){return t.get(e)})},t.srem=function(e,r,o){var n,a,i=this._getPrefixedKey(e,o),c=t.smembers(e,r);(a=c.indexOf(r))\u0026gt;-1\u0026amp;\u0026amp;c.splice(a,1),n=JSON.stringify({data:c});try{localStorage.setItem(i,n)}catch(t){console\u0026amp;\u0026amp;console.warn(\u0026#34;Lockr couldn\u0026#39;t remove the \u0026#34;+r+\u0026#34; from the set \u0026#34;+e)}},t.rm=function(e){var t=this._getPrefixedKey(e);localStorage.removeItem(t)},t.flush=function(){t.prefix.length?t.keys().forEach(function(e){localStorage.removeItem(t._getPrefixedKey(e))}):localStorage.clear()},t}); } Lockr.prefix = \u0026#39;ga_\u0026#39;; // Grab the original sentHitTask Function from the first tracker. to kept the original hit sending function.  var originalSendHitTask = customTaskModel.get(\u0026#39;sendHitTask\u0026#39;); customTaskModel.set(\u0026#39;sendHitTask\u0026#39;, function(model) { // Let\u0026#39;s send the original hit using the native functionality  originalSendHitTask(model); // Grab the hit Payload  var payload_lz = model.get(\u0026#39;hitPayload\u0026#39;); // Check if GA Endpoint is Ready  var http = new XMLHttpRequest(); http.open(\u0026#39;HEAD\u0026#39;, \u0026#39;https://www.google-analytics.com/collect\u0026#39;); http.onreadystatechange = function() { // Google Analytics endpoint is not reachable, let\u0026#39;s save the hit  if (this.readyState === this.DONE \u0026amp;\u0026amp; this.status !== 200) { Lockr.sadd(\u0026#39;hits\u0026#39;, payload_lz + \u0026#34;\u0026amp;qt=\u0026#34; + (new Date() * 1)); } else { // Google Analytics endpoint is available, let\u0026#39;s check if there are any unsent hits  if (Lockr.smembers(\u0026#34;hits\u0026#34;).length \u0026gt; 0) { // Process hits in queue  var current_ts = new Date() * 1 / 1000; var hits = Lockr.smembers(\u0026#34;hits\u0026#34;); // ./batch endpoint only allows 20 hits per batch, let\u0026#39;s chunk the hits array.  var chunk_size = 20; var chunked_hits = Lockr.smembers(\u0026#34;hits\u0026#34;).map(function(e, i) { return i % chunk_size === 0 ? hits.slice(i, i + chunk_size) : null; }).filter(function(e) { return e; }); // Let\u0026#39;s loop thru the chunks array and send the hits to GA  for (var i = 0; i \u0026lt; chunked_hits.length; i++) { var xhr = new XMLHttpRequest(); xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;https://www.google-analytics.com/batch\u0026#39;, true); // Build the Batch Payload and Take care of calculating the Queue Time  xhr.send(chunked_hits[i].map(function(x) { if (x.indexOf(\u0026#34;\u0026amp;qt=\u0026#34;) \u0026gt; -1) { return x.replace(/qt=([^\u0026amp;]*)/, \u0026#34;qt=\u0026#34; + Math.round(current_ts - x.match(/qt=([^\u0026amp;]*)/)[1] / 1000) * 1000); } else return x; }).join(\u0026#34;\\n\u0026#34;)); } //Hits sent, flush the Storage  Lockr.flush(); } } }; http.send(); }); }; }  Add this code to all your Universal Analytics tags by scrolling to More settings -\u0026gt; Fields to set. Here you add a new field with:\nField name: customTask\nValue: {{JS - customTask Offline Hit Tracker}}\n   Once you\u0026rsquo;ve done this, then all your tags with this customTask setting are protected against poor connectivity, and whenever the connection is restored, the batch queue is processed.\n4.4. About batching Universal Analytics lets you send hits to its endpoint in batches. This is used mostly by the iOS and Android SDKs. The main point in using the batch endpoint (/batch) is to have as few HTTP requests dispatched as possible. Here, batching means that we can send multiple Universal Analytics payloads in a single HTTP request.\nBatching does have some limitations we\u0026rsquo;ll need to consider:\n A maximum of 20 hits can be specified per request.\n The combined size of all hit payloads cannot be greater than 16K bytes.\n No single hit payload can be greater than 8K bytes.\n The request needs to be done using POST\n  For our solution, each time the number of stored hits is more than 1, we send the payloads using the batch endpoint. In case there are too many hits stored in the queue, we\u0026rsquo;re chunking them so that multiple batch requests are sent in succession until the entire queue is processed.\n5. Improvements Keep in mind that this current post is meant to show how to track the hits that may happen while the user is offline (due to a connectivity gap). At the same time, we\u0026rsquo;ve taken the opportunity to showcase some cool and relatively little-known Google Analytics JavaScript API functionalities.\nA solid improvement would be to skip the originalSendTask part, and just overwrite the sendHitTask task entirely. This way you can skip the HTTP HEAD request, because you can just check if the initial hit to Google Analytics is dispatched successfully.\nThe one thing you need to keep in mind if you want to overwrite the sendHitTask is that you\u0026rsquo;ll need to replicate the transport logic for the request. The analytics.js library supports three different ways to dispatch the requests:\n 'image' - max 2K payload size sent with a GET request to a pixel endpoint\n 'xhr' - max 8K payload size sent as an HTTP POST request\n 'beacon' - POST request that uses the navigator.sendBeacon() to make sure your requests are sent even if the user has already navigated away from the page\n  So you\u0026rsquo;ll need to replicate this logic in your custom sendHitTask method. It\u0026rsquo;s not exactly trivial to do, but an able developer should be able to do it, especially once the constraints (see previous paragraph) are known.\nAnother thing you might want to do is add a Custom Dimension to all the payloads that are stored in the queue. This Custom Dimension could be named something like Offline hit, and you should set the value to true if the hit was sent from the offline queue. Thus you can monitor how many hits in your data were initially aborted due to poor internet connectivity.\n6. Summary I\u0026rsquo;m really glad to have David guest star on this blog - it\u0026rsquo;s been a long time coming! This solution is great for two reasons. First, it\u0026rsquo;s actually very usable, especially if your site caters to mobile visitors. Second, it showcases a number of features of the web browser and the analytics.js library that can be extended to other purposes, too.\nThe Tasks API is really interesting, as it allows you to manipulate the payloads dispatched by the website. And with the introduction of customTask, we finally have a very handy way of accessing tasks with Google Tag Manager.\nNote that if you have a web application with offline capabilities, and you are using service workers to manage this functionality, Google has released a useful library for employing service workers to do precisely the same thing we\u0026rsquo;re doing in this article.\nWe hope you enjoyed this solution! Let us know in the comments\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/pagination-and-quick-search/",
	"title": "#GTMTips: Pagination And Quick Search",
	"tags": ["Google Tag Manager", "gtmtips", "search", "user interface"],
	"description": "Introducing new Google Tag Manager user interface features - pagination and quick search.",
	"content": " If you open the Google Tag Manager user interface and browser your tags, triggers, and variables, you might notice that the UI now has two new features:\n Pagination, where only 50 results are shown per page\n A quick search / filter bar at the top of each list, which lets you narrow the list down to results that match your query\n  Pagination might be a nuisance in large containers, but it was implemented to improve performance. Fetching the list of assets and rendering them on the screen can be a pretty hefty amount of API work, especially if the container is bloated. By introducing pagination, only 50 items are processed at a time, which speeds up the UI. However, being forced to plow through pages of assets can get tedious.\nThat\u0026rsquo;s why the quick search / filter bar is so useful. It lets you filter the page to show results that match your query, regardless of what page the result is actually on. So it\u0026rsquo;s a great way to quickly access your results.\nTip 63: Filtering through pages of data   This tip is as simple as it gets. If you have more than 50 tags, or 50 triggers, or 50 variables, then the respective lists in your Google Tag Manager user interface will be paginated so that only 50 results are shown per page.\nTo find what you want quickly, you can use the quick search / filter bar at the top of each list table. This will filter the results to show only those that match your query.\nAnd here\u0026rsquo;s another tip. You can use the forward slash (/) key to place focus on the search field. You can try this with other products, too, as it\u0026rsquo;s a fairly universal way of focusing on a search / filter box. Note that this requires that you have a \u0026ldquo;natural\u0026rdquo; forward slash key in your keyboard layout. So folks in Finland, for example, are somewhat out of luck, because forward slash is typed with SHIFT+7, which doesn\u0026rsquo;t work in the GTM UI. Nevertheless, if your keyboard has a number pad, you should find the forward slash key on that. Let me know in the comments if you can access the quick search some other way, and if it\u0026rsquo;s been localized in your own keyboard layout.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/two-new-unofficial-ga-add-ons-for-google-sheets/",
	"title": "Two New Unofficial GA Add-ons For Google Sheets",
	"tags": ["add-on", "apps script", "google analytics", "google sheets", "JavaScript", "open source"],
	"description": "Introducing two unofficial Google Analytics add-ons for Google Sheets. You can manage Custom Dimensions and validate your Google Analytics account hierarchy, right from Google Sheets.",
	"content": " More often than not, much of what we do in web analytics can be automated. This applies especially to implementations, audits, configurations, and reporting. So when I\u0026rsquo;m faced with a menial, manual task that might take hours for me to complete if done by hand, I always look at what could be done with some scripting and API work. I want to introduce a couple of Google Sheets add-ons I\u0026rsquo;ve written and released to the public. They both automate tasks which I found completely ridiculous to do by hand.\n  The two add-ons, Google Analytics Validator and Google Analytics Custom Dimension Manager, are unofficial, free-to-use, and open-source. They were created initially for my own benefit alone, but at some point I wondered if others might find them useful, too. That\u0026rsquo;s why I ended up publishing them.\nGoogle Analytics Validator You can add Google Analytics Validator to Google Sheets via this link, and you can access the open-source code in this GitHub repo.\n  Google Analytics Validator has three purposes:\n You can use it to create a sheet with a master list of all the accounts, properties, and views your Google ID has access to.\n From this list, you can then choose any number of properties/views for Custom Dimension analysis. This means that a new sheet is built, with the name, scope, and active status of all the Custom Dimensions created for each property.\n Finally, you can fetch the number of hits collected in the last 7 days for any selected view. This tells you if there are Custom Dimensions that haven\u0026rsquo;t collected any data recently.\n  It\u0026rsquo;s a simple tool, but it should give you some insight to how Custom Dimensions are aligned across all your accounts, properties, and views.\nGoogle Analytics Custom Dimension Manager You can add Google Analytics Custom Dimension Manager to Google Sheets via this link, and you can access the open-source code in this GitHub repo.\n  The Google Analytics Custom Dimension Manager lets you mass update Custom Dimensions in any account/property you have required access rights to. The values that you use to update/create the dimensions with are populated in a special Source Data sheet.\nNOTE! There\u0026rsquo;s a limit of 500 write requests per day for this project. Naturally, this is nowhere near enough to cater to multiple users who might be using the add-on. I am applying for an increase in the quota, but if this tool is something you\u0026rsquo;ll need consistently, you might want to grab the open-source code and recreate the add-on as a project of your own.\nThis should save you some time if you need to update 200 dimensions across multiple properties, for example.\nFeedback If you want to leave me feedback, you can do it either via email (simo at simoahava.com), or you can open an issue in either GitHub repo. I appreciate any feedback I can get!\n"
},
{
	"uri": "https://www.simoahava.com/tools/google-analytics-custom-dimension-manager/",
	"title": "Custom Dimension Manager For Google Analytics",
	"tags": [],
	"description": "",
	"content": " The Custom Dimension Manager For Google Analytics is a Google Sheets add-on. It lets you update Custom Dimensions in any given Google Analytics property en masse.   When updating, new dimensions are created automatically with values from a source data sheet (or using a default value if no value is specified), and for existing dimensions you have the choice to update or skip.   The add-on is completely free to use. It\u0026rsquo;s a hobby project, but I would still welcome any feedback. You can send the feedback to simo (at) simoahava.com.\nShoutout Mr. Pedro Ávila from Google published in 2015 a very similar Google Sheets extension. His extension and mine serve a very similar purpose, and since I did read Pedro\u0026rsquo;s article when it was released, the work he did for his extension has certainly inspired the work I put into mine, even if both extensions were developed completely independently and have a completely different codebase.\nI recommend checking out Pedro\u0026rsquo;s work in the dedicated GitHub repo, and you can download his extension from this link.\nHow to get it In Google Sheets, open the Add-ons menu, and click Get add-ons.   You should see the Chrome web store window open. Enter \u0026ldquo;google analytics custom dimension manager\u0026rdquo; into the search field and press Enter. You should see the add-on appear in the search results.   Click the + FREE button. You will be asked to sign in with your Google ID, and then approve the add-on access to your data. The add-on requires read and write access to your Google Analytics management data, and read and write access to your Google Sheets account.\nYou are then ready to use the tool!\nGitHub repo You can download the open-source code from the GitHub repo: ga-custom-dimension-manager.\nHow it works You should see the Custom Dimension Manager For Google Analytics menu item in the Add-ons menu. You might need to reload the page if it isn\u0026rsquo;t there, or if it seems to be missing all its menu items.\nFirst, click on 1. Build/reformat Source Data sheet. This creates a new sheet named \u0026ldquo;Source Data\u0026rdquo;. It is populated with Custom Dimensions from 1-200, as well as a row where you can set the default value for empty rows. For each dimension, you can now write the name, scope (HIT or PRODUCT or SESSION or USER), and active status (true or false). If you leave a row empty, the tool will use what you specified in the \u0026ldquo;DEFAULT/EMPTY\u0026rdquo; row.\nIf the sheet already existed, the tool only updates the header and the dimension ID column.   Once you\u0026rsquo;re done, click on 2. Manage Custom Dimensions in the menu. You\u0026rsquo;ll see a dialog open, where you need to choose the property whose dimensions to update. Note the warning. To UPDATE a Custom Dimension, only EDIT access to the Property is needed. To CREATE a new Custom Dimension, EDIT access is required for both Account and Property.\nOnce you\u0026rsquo;ve selected the Property to update, you\u0026rsquo;ll need to also choose whether to update only dimensions 1-20, or whether to update all the dimensions (1-200). The latter option only works with Google Analytics 360 accounts, so be mindful of that when working with the tool.   When you\u0026rsquo;re ready, press START, and the tool will instantly begin to update/create the Custom Dimensions based on the Source Data sheet.\nThree things can happen now.\n If the dimension to be updated already exists, and its values differ from those in the Source Data sheet, you have the choice to either UPDATE your Google Analytics data with that from the Source Data, or you can SKIP this dimension, not making any changes to GA.\n If the dimension to be updated already exists, but it has identical values to those in the Source Data sheet, the dimension is automatically skipped.\n If the dimension to be updated doesn\u0026rsquo;t exist yet, it is automatically created with the values from the Source Data sheet.\n  Once the process is over, the tool will inform you of this, and you can visit Google Analytics to check if the dimensions were created properly.\nPrivacy Policy What information do you collect? The Google Analytics Custom Dimension Manager collects no information from its users. It is an API tool used for managing and updating Custom Dimensions in the user\u0026rsquo;s Google Analytics account and property hierarchy.\nThe only thing the add-on logs is the generic Google Cloud Console API usage statistics, which tells the owner how much the enabled APIs are being used, but this data cannot be used to identify users or individual use patterns.\nHow do you use the information? No user or usage information is used. The only thing the owner monitors is API usage, so that it can be determined if quotas need to be increased to ensure the tool works smoothly.\nWhat information do you share? No information is shared with third parties, with other users, with analytics tools, with marketing partners, or any other party.\n"
},
{
	"uri": "https://www.simoahava.com/tools/google-analytics-validator/",
	"title": "Google Analytics Validator",
	"tags": [],
	"description": "",
	"content": " The Google Analytics Validator is a Google Sheets add-on. It lets you build a spreadsheet of all the accounts, properties, and views you have access to in Google Analytics. Then, you can select any number of these properties to populate a second sheet, where each Custom Dimension configured in the property is displayed with its name, scope, and active status.   Finally, you can poll for the last 7 days data for any selected property/view to see if the Custom Dimension has collected any hits.   The add-on is completely free to use. It\u0026rsquo;s a hobby project, but I would still welcome any feedback. You can send the feedback to simo (at) simoahava.com.\nHow to get it In Google Sheets, open the Add-ons menu, and click Get add-ons.   You should see the Chrome web store window open. Enter \u0026ldquo;google analytics validator\u0026rdquo; into the search field and press Enter. You should see the add-on appear in the search results.   Click the + FREE button. You will be asked to sign in with your Google ID, and then approve the add-on access to your data. The add-on requires read-only access to your Google Analytics data, and read and write access to your Google Sheets account.\nYou are then ready to use the tool!\nGitHub repo You can download the open-source code from the GitHub repo: ga-validator-apps-script.\nHow it works You should see the Google Analytics Validator menu item in the Add-ons menu. You might need to reload the page if it isn\u0026rsquo;t there, or if it seems to be missing all its menu items.\nFirst, click on 1. Build Google Analytics hierarchy. This collects all the Google Analytics accounts, properties, and views you have access to, and builds them into a new sheet with the name \u0026ldquo;GA Hierarchy\u0026rdquo;.   NOTE! If this sheet already exists, it is overwritten.\nNext, type the letter x or X in the Select for analysis (x/X) column for each property/view that you want to include in the Custom Dimension analysis.\nOnce you\u0026rsquo;re done, click on 2. Run validator in the menu. This creates a new sheet named \u0026ldquo;GA Dimensions\u0026rdquo; (overwriting any existing sheet with the name), where all the dimensions from 1-200 are populated with values drawn from the properties you selected for analysis.\nFinally, you can select any cell in a data column, and then click 3. Fetch last 7 days data\u0026hellip; in the menu. This populates the LAST 7 DAYS column for the given view, fetching data from the last 7 days for each dimension that is active. The data that is fetched is the ga:hits metric.   This tool has three purposes:\n It gives you a master list of accounts, properties, and views you have access to.\n It lets you see how Custom Dimensions are configured across properties.\n It lets you analyze which Custom Dimensions have not collected any data recently.\n  Privacy Policy What information do you collect? The Google Analytics Validator collects no information from its users. It is an API tool for building sheets of data based on your Google Analytics account and data hierarchy, and no usage information is collected or used in any way.\nThe only thing the add-on logs is the generic Google Cloud Console API usage statistics, which tells the owner how much the enabled APIs are being used, but this data cannot be use to identify users or individual use patterns.\nHow do you use the information? No user or usage information is used. The only thing the owner monitors is API usage, so that it can be determined if quotas need to be increased to ensure the tool works smoothly.\nWhat information do you share? No information is shared with third parties, with other users, with analytics tools, with marketing partners, or any other party.\n"
},
{
	"uri": "https://www.simoahava.com/tools/chrome-extensions/",
	"title": "Chrome Extensions",
	"tags": [],
	"description": "",
	"content": " Here are the two Chrome Extensions I\u0026rsquo;ve written.\n GTM Sonar - Debug your on-site JavaScript to see if it\u0026rsquo;s compatible with the event listeners Google Tag Manager leverages\n Internalize for Google Analytics - Send a Custom Dimension hit at the click of a button. This tool is intended to annotate traffic in a certain way, letting you filter it out or process it in any way you choose\n     GTM Sonar is especially useful for debugging potential problems with interfering JavaScript.\nRelated posts: \u0026ndash; Internalize for Google Analytics v1.0 \u0026ndash; Google Tag Manager Sonar v1.2\nFeedback Feel free to send me any feedback relating to the tools. I don\u0026rsquo;t do extensive testing, nor are the tools especially optimized performance-wise. These are issues I would love to tackle had I more time, but I\u0026rsquo;m really grateful for any ideas, feedback, or criticism you might want to throw my way.\n"
},
{
	"uri": "https://www.simoahava.com/tools/gtm-tools/",
	"title": "GTM Tools",
	"tags": [],
	"description": "",
	"content": "   GTM Tools are utilities created for managing Google Tag Manager containers. The main features are:\n Clone containers from one account to another (or within the same account)\n Visualize containers\n Inspect containers, and add individual assets (Tags, Triggers, Variables) to a \u0026ldquo;Shopping cart\u0026rdquo;\n Clone Shopping cart contents as a new container in a GTM account\n Save Shopping cart contents into an asset library for future use\n  The toolset can be found at:\n\u0026gt;\u0026gt; www.gtmtools.com \u0026lt;\u0026lt; The release notes and user guide can be found here: GTM Tools: Release notes and user guide.\nFeedback Feel free to send me any feedback relating to the tools. I don\u0026rsquo;t do extensive testing, nor are the tools especially optimized performance-wise. These are issues I would love to tackle had I more time, but I\u0026rsquo;m really grateful for any ideas, feedback, or criticism you might want to throw my way.\nDEPRECATED: GTM Tools @SimoAhava Deprecated, use the new version at www.gtmtools.com\nThe GTM Tools @SimoAhava is my pet project which I started working on the minute I was allowed access to Google Tag Manager\u0026rsquo;s API. It includes a number of cloner utilities, which allow you to transfer assets from one container to another in your Google Tag Manager ecosystem. Also, there\u0026rsquo;s the Container Visualizer, of which I\u0026rsquo;m definitely most proud.\n   Included are:\n Container Cloner - Lets you copy tag(s) from one account to another\n Tag Cloner - Lets you copy tag(s) from one container to another\n Rule Cloner - Lets you copy rule(s) from one container to another\n Macro Cloner - Lets you copy macro(s) from one container to another\n Container Visualizer - Draws a pretty visualization of a container, showing the links between different assets (tags, rules, macros)\n  I have a pretty long list of planned features, but most importantly I\u0026rsquo;m working on providing support for the new UI features (triggers, variables), and I\u0026rsquo;m also looking into bundling assets together in the hopes of letting users download, update, and upload these bundles en masse to containers.\nRelated posts: \u0026ndash; Introducing GTM Tools \u0026ndash; Container Visualizer for Google Tag Manager\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/track-selection-drop-list/",
	"title": "#GTMTips: Track Selection In Drop-Down List",
	"tags": ["event listener", "form", "Google Tag Manager", "selection"],
	"description": "How to track when users select something in a drop-down list using Google Tag Manager.",
	"content": " Tracking what a user selects in a drop-down (or select) list/menu can be very useful. This is particularly the case when the selection immediately does something, such as initiate a download or navigate the user to another page. But even if there is no immediate action, it\u0026rsquo;s still interesting to know what selections users might be doing, if only to uncover yet another piece of the engagement puzzle. Here\u0026rsquo;s the Google Tag Manager way to do it!\nTip 62: Listen for changes in a drop-down menu   The setup is somewhat complicated, and requires a Custom HTML Tag together with some variables. But the end result is that when a user makes a selection, the web page pushes an object into dataLayer, which you can then use to track the results.\nHere\u0026rsquo;s what the Custom HTML Tag should look like:\n\u0026lt;script\u0026gt; (function() { // Change the CSS selector in the parenthesis to match your select menu  var selectMenu = document.querySelector(\u0026#39;select#selectMenu\u0026#39;); var callback = function(e) { var selectedOption = e.target.options[e.target.selectedIndex]; window.dataLayer.push({ event: \u0026#39;selectionMade\u0026#39;, selectedElement: selectedOption }); }; selectMenu.addEventListener(\u0026#39;change\u0026#39;, callback, true); })(); \u0026lt;/script\u0026gt; Set this tag to fire on a DOM Ready trigger.\nYou\u0026rsquo;ll need to modify the line which begins with var selectMenu = ..., so that the query selector matches the select HTML element you actually want to track. If CSS selectors are unfamiliar to you, you can read up on them here, or you can use some other DOM method like document.getElementById(). Regardless, you will need to store a reference to the select element in the selectMenu variable for this solution to work.\nThe code creates a custom 'change' listener, which is triggered when the value in the element being monitored changes. This is very useful with forms, since you can attach this type of listener to any form field to see if the user changed the value within.\nFinally, when a 'change' event is detected, the callback pushes an object into dataLayer, which contains the custom event selectionMade as well as an object reference to the option the user selected.\nWhen you want to fire your tag upon a selection, you will need a Custom Event Trigger that looks like this:\n  Then, depending on how the actual option element has been configured, you could use one of these Data Layer Variables to collect the information:\n    The first grabs the value attribute from the selected option, or if there is no value it grabs the text content. The second grabs the text content even if the option had a value attribute.\nPut these all together, and you\u0026rsquo;ll be tracking those drop-down / select list selections in no time!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/create-string-multiple-object-properties/",
	"title": "#GTMTips: Create String From Multiple Object Properties",
	"tags": ["array", "facebook", "Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Use array methods to combine multiple properties in different objects into a single string or some other set. This tip is for Google Tag Manager.",
	"content": " Facebook\u0026rsquo;s pixel has an attribute named content_ids (required for Dynamic Ads), which requires an Array of content IDs as its value. It\u0026rsquo;s very possible you\u0026rsquo;re running this pixel on a site which already has Enhanced Ecommerce for Universal Analytics implemented, and now you want to use the same Enhanced Ecommerce data that your developers have already made available in this Facebook pixel.\nOr perhaps you want to concatenate a list of strings, such as article tags (['culture', 'politics']), and send it as a comma-separated string to Google Analytics ('culture,politics').\nThis is easy to do - just follow this tip!\nTip 61: Build an Array or concatenated string from multiple object properties   With JavaScript\u0026rsquo;s Array methods, this is easy to do. Here\u0026rsquo;s a walkthrough using an actual example.\nLet\u0026rsquo;s say you have an order receipt page on your ecommerce store, where you have implemented the following Enhanced Ecommerce purchase setup:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ event: \u0026#39;ecommerce\u0026#39;, ecommerce: { purchase: { actionField: { id: \u0026#39;order1\u0026#39;, revenue: \u0026#39;10.00\u0026#39; }, products: [{ id: \u0026#39;product1\u0026#39;, price: \u0026#39;6.00\u0026#39;, quantity: 1 },{ id: \u0026#39;product2\u0026#39;, price: \u0026#39;4.00\u0026#39;, quantity: 1 }] } } });  If you know your Enhanced Ecommerce, this code represents a well-formed purchase object, and if you have an Enhanced Ecommerce enabled tag firing on an ecommerce Custom Event Trigger, you should be able to collect this purchase data in your Universal Analytics property.\nBut now we have a pixel (such as Facebook), which requires an Array of only the product IDs (i.e. ['product1', 'product2']. Or, you might have a tracker, which requires a comma-separated string of the same (i.e. 'product1,product2'].\nFirst, you\u0026rsquo;ll need to create a Data Layer Variable which points to the Array that holds the objects whose properties you want to access. In this case, it would be ecommerce.purchase.products:\n  I\u0026rsquo;ve chosen to name this {{DLV - ecommerce.purchase.products}}.\nNext, you\u0026rsquo;ll need a Custom JavaScript Variable where the magic happens. This variable returns an Array of all the product IDs (i.e. ['product1', 'product2']).\nfunction() { var products = {{DLV - ecommerce.purchase.products}}; return products.reduce(function(arr, prod) { return arr.concat(prod.id); }, []); }  The reduce() method basically takes an Array (the products Array), and for every member in the Array you can choose to increment an accumulator (an empty Array in this case) with the data of your choice. In this case, we\u0026rsquo;re taking the id value from every item in the Array, and building a new Array with this information.\nIf you want to turn this into a comma-separated string (i.e. 'product1,product2'), you only need to chain another Array method to the return statement:\nfunction() { var products = {{DLV - ecommerce.purchase.products}}; return products.reduce(function(arr, prod) { return arr.concat(prod.id); }, []).join(); }  The join() method flattens any Array into a string, using whatever you pass into the parentheses as the separator. If you don\u0026rsquo;t explicitly define a delimiter, a comma is automatically used.\nThese two functions should let you easily turn any complex Array of objects into a single, straightforward data structure - whatever you need in any given situation.\nUPDATE: Thanks to postman31\u0026rsquo;s comment below, you can also use the Array.prototype.map() method to perform these tasks even more elegantly.\nfunction() { var products = {{DLV - ecommerce.purchase.products}}; return products.map(function(prod) { return prod.id; }); // OR:  // return products.map(function(prod) { return prod.id; }).join(); }  "
},
{
	"uri": "https://www.simoahava.com/gtm-tips/send-google-analytics-tag-multiple-properties/",
	"title": "#GTMTips: Send Google Analytics Tag To Multiple Properties",
	"tags": ["duplicate", "gtmtips", "tasks", "universal analytics", "customtask"],
	"description": "Use customTask to automatically send each Google Analytics tag to multiple properties. Everything is done with Google Tag Manager.",
	"content": " Here we are again, revisiting an old theme. When using Google Tag Manager, we often want to send the contents of the same tag to multiple Universal Analytics properties. With on-page GA, this used to be quite simple, as all you had to do was create a new tracker and then just remember to run the ga('trackerName.send'...) commands to all the trackers (or you could use my duplicator plugin). With GTM, your options are more limited, since Google Tag Manager abstracts the tracker object, giving you far fewer tools to work with.\nEven though there are workarounds, only the very recent release of the customTask gave us a way to do this economically with minimum risk to our existing tracking.\nTip 60: Use customTask to duplicate your GA hits   With this solution, you\u0026rsquo;re overriding customTask in the GA tags that you want to distribute to multiple properties. The new customTask modifies the Universal Analytics task queue, so that the original hit is first sent, then the payload is duplicated with a new tracking ID, and then the modified payload is sent to GA, too.\nThe way it works is simple. In all your Universal Analytics tags that you want to duplicate, scroll down to Fields to set, and add a new field:\nField name: customTask\nValue: {{JS - customTask hit duplicator}}\nThe {{JS - customTask hit duplicator}} is a new, user-defined Custom JavaScript Variable that you need to create. The variable content should look like this:\nfunction() { // Replace newTrackingId value with the UA property to which you want to duplicate this tag  var newTrackingId = \u0026#39;UA-XXXXX-Y\u0026#39;; var globalSendTaskName = \u0026#39;_\u0026#39; + newTrackingId + \u0026#39;_originalSendTask\u0026#39;; return function(customModel) { window[globalSendTaskName] = window[globalSendTaskName] || customModel.get(\u0026#39;sendHitTask\u0026#39;); customModel.set(\u0026#39;sendHitTask\u0026#39;, function(sendModel) { var hitPayload = sendModel.get(\u0026#39;hitPayload\u0026#39;); var trackingId = new RegExp(sendModel.get(\u0026#39;trackingId\u0026#39;), \u0026#39;gi\u0026#39;); window[globalSendTaskName](sendModel); sendModel.set(\u0026#39;hitPayload\u0026#39;, hitPayload.replace(trackingId, newTrackingId), true); window[globalSendTaskName](sendModel); }); }; }  Remember to change the value of the newTrackingId variable to contain the Property ID you want to send your duplicated hit data to!\nNow, when your Universal Analytics tag with this customTask field is run, the solution runs through the following steps:\n First, the tag with its original settings is executed (line 9).\n Next, the original Tracking ID in the hit payload is replaced with the newTrackingId (line 10).\n Finally, the modified hit payload is sent to Universal Analytics (line 11).\n  If you want, you can run this sendModel.set('hitPayload'...) --\u0026gt; originalSendTask(sendModel) multiple times to send the data to even more Universal Analytics properties.\nWhen you add the customTask field with this variable to your Universal Analytics tags, these tags will automatically duplicate the entire hit payload to the new tracking ID you specified.\nBecause you are overwriting the sendHitTask task, the hit payload has already been generated, which is why you need to modify it with regular expressions rather than being able to simply change values in the model object itself. It\u0026rsquo;s not the most elegant option when you want to make other changes to the hit payload (e.g. change the index of a custom dimension), but it does its job.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/use-customtask-access-tracker-values-google-tag-manager/",
	"title": "#GTMTips: Use customTask To Access Tracker Values In Google Tag Manager",
	"tags": ["client id", "Google Tag Manager", "gtmtips", "tasks", "universal analytics", "customtask"],
	"description": "Set the Client ID, for example, in all your Google Analytics hits as a Custom Dimension. You can do this with Google Tag Manager and customTask.",
	"content": " One of the things I\u0026rsquo;ve recommended from the get-go is to always send the Client ID to Google Analytics with your users\u0026rsquo; hits. This is very useful for adding a level of granularity to your tracking. At first, I recommended using an Event tag to do this. Then I modified my approach a little so that you could send it with your initial Page View (thus not inflating your hit counts).\nHowever, Universal Analytics recently released a new task API, customTask, which lets you access the model object mid-tag, thus letting you modify the payload that is dispatched to Google Analytics. In this article, I\u0026rsquo;ll show you how this works by using the classic example of sending the Client ID to Google Analytics.\nTip 59: Access the model object mid-tag in Google Tag Manager The setup is really simple. You need a Custom Dimension setup in Universal Analytics, and then you simply need to add a new Field to set in your Page View tag (or whatever you want to use to send the data to GA). Remember to read my article on sending this type of metadata to Google Analytics, if you\u0026rsquo;re unsure why you would want to do this in the first place.\nThe tag setup would look like this:\n  Field name should be set to customTask, and as its value you need to use a Custom JavaScript Variable. The variable looks like this:\nfunction() { // Modify customDimensionIndex to match the index number you want to send the data to  var customDimensionIndex = 5; return function(model) { model.set(\u0026#39;dimension\u0026#39; + customDimensionIndex, model.get(\u0026#39;clientId\u0026#39;)); } }  What happens is that once Google Tag Manager starts executing the tag code, it first encounters the customTask field. It resolves the variable to a closure, which is basically a function that automatically receives a model object as a parameter. The model object can be manipulated using the get and set methods.\nNext, we set the Custom Dimension at index 5 (as determined by the value of customDimensionIndex) to the Client ID, which we retrieve with the get method of the model object.\nThis little trick means that we can tell the GA tag to fetch the Client ID from the tracker object and send it in a Custom Dimension without any extra hacks or workarounds that we had to employ previously. The fact that customTask has no other function in Universal Analytics means that we don\u0026rsquo;t have to mind the fact that we\u0026rsquo;re overwriting a task method with this tag.\nYou can use this for any fields in the model/tracker object if you wish.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-analytics-settings-variable-in-gtm/",
	"title": "Google Analytics Settings Variable In GTM",
	"tags": ["google analytics settings", "Google Tag Manager", "universal analytics", "variable"],
	"description": "Introduction and guide to the Google Analytics Settings variable in Google Tag Manager.",
	"content": " Let\u0026rsquo;s face it - most of us use Google Tag Manager for one main purpose: to deploy and configure Google Analytics tracking on a website. I\u0026rsquo;d wager that once you start using GTM, you won\u0026rsquo;t be implementing Universal Analytics the old-fashioned way, with on-page code, any more. But running Universal Analytics tags through GTM isn\u0026rsquo;t yet a perfect workflow. We\u0026rsquo;re still missing things like proper plugin support and the option to properly differentiate between the tracker and the hit - both of which are easy to do with an on-page implementation.\nFor me, and I\u0026rsquo;m sure for many others, one of the biggest problems with Universal Analytics has been how to manage scale. Once you have dozens of tags that have some settings configured in a specific way, e.g. cross-domain tracking settings or custom page paths, it becomes a nightmare to update each and every one when you want to make a change to one of these generic settings. Well, it\u0026rsquo;s been a long time coming, but Google Tag Manager just introduced a feature to help us with this: the Google Analytics Settings variable.\n  The variable contains the fields you\u0026rsquo;ll find under \u0026ldquo;More Settings\u0026rdquo; of Universal Analytics tags, combined with some set fields that are (typically) absolutely necessary to include in all tags anyway (Tracking ID and cookieDomain, specifically). The advent of this new variable type gives you three ways to create and manage Universal Analytics tags:\n Copy all settings from the Google Analytics Settings variable.\n Don\u0026rsquo;t use a Google Analytics Settings variable at all, and instead set all fields manually.\n Use a combination of both: set the fields with a Google Analytics Settings variable, and then overwrite some of the fields with custom values on a tag-by-tag basis.\n  This gives you a lot of flexibility to work with.\nThe Google Analytics Settings variable is available in your web containers as well as your mobile Firebase containers.\nThe Google Analytics Settings variable You can find the new variable in the variable creation menu that pops open when you start building a new User-Defined Variable.\n  The first thing you\u0026rsquo;ll notice is that the Cookie Domain field is auto-populated with the value auto. This is an excellent change, and removes one of the key differences between the recommended analytics.js tracking code (which has auto as the default value for cookieDomain) and the default Universal Analytics tag template in Google Tag Manager (which does not have a cookieDomain value set at all).\nNote that the Tracking ID field is required, so add your Universal Analytics property tracking ID or a variable you\u0026rsquo;ve used before to it before saving the new variable.\nIf you click More Settings you\u0026rsquo;ll find all the fields available for configuration in Universal Analytics tag templates. You can set these as you wish, remembering that they will be applied to all tags that use this variable.\n  Note that obvious conflicts are resolved automatically. If you Enable Enhanced Ecommerce Features in your Google Analytics Settings variable, and then add this variable to a Timing type Universal Analytics tag, the Timing tag won\u0026rsquo;t magically turn into an Enhanced Ecommerce enabled tag. Since Enhanced Ecommerce hits can only be sent with Page View and Event tags, this particular setting is simply ignored in incompatible tag types.\nAdding the settings to your tags To add your settings to tags, you\u0026rsquo;ll find a new drop-down under the heading Google Analytics Settings that instructs you to select a variable from the list. You can also start a new variable creation workflow from this menu.\n  As you can see, you can still configure the Advanced Settings individually for this tag. That\u0026rsquo;s because Advanced Settings have nothing to do with Google Analytics - all tags in Google Tag Manager have these same Advanced Settings fields.\nYou\u0026rsquo;ll still need to add individual triggers to this tag. Again, triggers are not specific to Universal Analytics tags. The Google Analytics Settings variable only conflates all Google Analytics settings into a single variable configuration.\nAs I mentioned in the introduction of this article, there are three ways to implement a Google Analytics Settings variable in your Universal Analytics tags. The first one is in the screenshot above. When you apply the variable and save the tag, all Google Analytics settings are derived from the variable. This is definitely the most light-weight and straightforward way to implement the variable.\nThe second way is to ignore the variable completely, and just create an individual, one-off tag. In this case, you need to do two things:\n Leave Select Settings Variable\u0026hellip; as the value of the drop-down.\n Check the box next to Enable overriding settings in this tag.\n  Once you do these two things, you\u0026rsquo;ll completely ignore any Google Analytics Settings variables and just configure the tag independently. A very useful thing to still have, especially if you want to do some quick prototyping.\nThe third way to implement the settings variable is a combination of the two methods above. This is useful if you want the benefit of the settings, but you want to make some adjustments for this tag in particular. For example, I might want to use my \u0026ldquo;GA Settings - Enhanced Ecommerce\u0026rdquo; settings in my Add To Cart event tag, so that it makes use of all the settings I\u0026rsquo;ve configured for my Enhanced Ecommerce tags. But I want to make a small adjustment: I want to use a Custom JavaScript Variable for the Enhanced Ecommerce payload instead of dataLayer. This is what this modification would look like:\n  If you use a Google Analytics Settings variable, all fields that you set in that variable are inherited in the tag that uses the variable. You can always override the fields, but it might be difficult to remember just which fields have been set.\nFor this conundrum, there\u0026rsquo;s a brilliant UI workflow update. See the little (I) icons in the screenshot above, marked with a yellow star? When you click that icon, an overlay opens with the variable in question for you to review or even edit! You can now modify or edit variables mid-workflow, without having to leave the tag settings to make adjustments.\nThis is, naturally, vital for the Google Analytics Settings variable as well, because you want to be careful you\u0026rsquo;re not overriding fields that should not be overridden. It would be helpful to see the actual modified values and settings inherited from the variable in the tag itself, but I guess there are technical limitations why this is not (yet) possible.\nIdeas for use Here are three types of Google Analytics Settings variables I use in my projects.\n1. General settings This is the one I use as a generic settings variable in tags that have no special function (e.g. regular Page View and Event tags).\n  These are fields I use in all my tags.\n2. Cross-domain tracking If I have a rollup property to which I collect cross-domain tracking data, I have a Google Analytics Settings variable for that, too.\n  And in all my rollup tags, I would have the settings from above. If I had rollup tags that have BOTH Enhanced Ecommerce and cross-domain requirements, I would set them up with cross-domain tracking settings and then manually add the Enhanced Ecommerce settings.\n3. Enhanced Ecommerce settings And finally, I have a generic settings template for all Enhanced Ecommerce tags.\n  With this tag, I can setup simple Enhanced Ecommerce settings for all my EEC tags. In some special cases, I can override these default settings with custom stuff.\nSummary This is a pretty smooth feature for managing your Universal Analytics tags. I firmly believe this is a great timesaver, as it will help you avoid typical data quality mishaps with misconfigured tags. With the Google Analytics Settings variable, it\u0026rsquo;s also easy to help new users become accustomed with your data collection configuration. New users, typically, are the weakest link for data quality, as they might not know all the settings the Universal Analytics tags in your organization should be configured with.\nIf there\u0026rsquo;s one thing I\u0026rsquo;m missing it\u0026rsquo;s variable chaining. I would like to be able to use a Google Analytics Settings variable within a Google Analytics Settings variable. In the three examples of the previous chapter, you can see that all these settings variables share the same Custom Dimensions. I would like to specify that all these three settings variable use another settings variable as the base, and then simply add/modify all the necessary settings. This way I could create a hierarchy of settings variables, making it even more unlikely that misconfigured fields lead to data quality issues.\nNaturally, chaining variables can lead to issues, too, so proper governance and common sense would still rule.\nDo you have some \u0026ldquo;go-to\u0026rdquo; settings configurations in your tags, for which you could leverage the new settings variable?\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/enable-fire-triggers-google-tag-manager/",
	"title": "#GTMTips: Enable And Fire Triggers In Google Tag Manager",
	"tags": ["forms", "gtmtips", "links", "triggers"],
	"description": "Difference between enabling and firing triggers in Google Tag Manager&#39;s Just Links and Form triggers.",
	"content": " This is, by no means, a novel topic in this blog. I\u0026rsquo;ve covered Google Tag Manager\u0026rsquo;s event tracking and triggers numerous times before (see below).\n Auto-Event Tracking In GTM 2.0\n #GTMtips: Track Outbound Links In GTM V2\n #GTMtips: Fix Problems With GTM Listeners\n Trigger Guide For Google Tag Manager\n  However, based on the number of queries we still see in the Google Tag Manager Product Forums about event tracking, I believe one particular aspect of GTM\u0026rsquo;s triggers invites revisiting. I\u0026rsquo;m talking about the way that Just Links, Form, and Timer triggers can be both Enabled and Fired. This can easily lead to some confusion.\nTip 58: Difference between enabling a trigger and firing a trigger   With Just Links and Form triggers, if you check either Wait for Tags or Check Validation in the trigger settings, you will see the following condition appear:\n  With the Timer trigger, you will always need to specify an enabling condition.\nThe Enable this trigger when\u0026hellip; condition is for determining on which pages the trigger should work in the first place. It\u0026rsquo;s sole purpose is to delimit the trigger itself to listening to events only on pages that you allow it to.\nIn contrast, when you choose Some Link Clicks, for example, and the Fire this trigger when.. condition appears, THAT\u0026rsquo;S where you specify conditions for the tag to fire.\nA common mistake is to use something like {{Click Classes}} or {{Click ID}} in the Enable this trigger when\u0026hellip; condition. This is a mistake because Click variables are only produced after a Click trigger fires. But the Click trigger won\u0026rsquo;t fire if it\u0026rsquo;s not enabled on the page. So by expecting a Click variable to have some value in the enabling condition of trigger would be counter-intuitive. It might work, if you have some other trigger that\u0026rsquo;s already created the Click variable, but it won\u0026rsquo;t work as you expect it to.\nWhen implementing a Just Links, Form, or Timer trigger with the Enable this trigger when\u0026hellip; specified, you\u0026rsquo;ll want to test first with as broad a condition as you can. This would be something like Page URL contains /, which would enable the trigger on every single page that has the Google Tag Manager container snippet. Then, if you run into issues when testing the links and forms on the site, you can either add some page conditions to the triggers to ensure the trigger is only enabled on pages where it works, or you can uncheck Wait for Tags and/or Check Validation to improve compatibility.\nWhy have \u0026ldquo;Enable\u0026hellip;\u0026rdquo; optional in the first place? So why this complexity? Why can\u0026rsquo;t listeners just be active on all pages? Well, typically they COULD be active, since there\u0026rsquo;s very little overhead from a listener that doesn\u0026rsquo;t really do anything.\nHowever, the Wait for Tags setting in particular can be hazardous in some contexts (e.g. a React-driven single-page site), as it does some pretty invasive things to ensure your tags are being sent. In these cases, you can set the trigger settings so that pages where you know it causes problems are excluded from the Enable this trigger when\u0026hellip; setting.\nShould this be easier? Yes, it should. Judging by the number of times the trigger user interface has changed, and considering the number of problems people still have with these triggers, I can\u0026rsquo;t help but think there must be a more user-friendly way of approaching this dichotomy. In a sense, the first version of auto-event tracking (in GTM v1) was better, since back then event tracking was enabled by using special \u0026ldquo;Listener tags\u0026rdquo; that required triggers (or rules, as they were called then) themselves. In those cases, it was very easy to understand the difference between enabling and firing a trigger.\nPart of the problem, I think, is that triggers of the same type have both an enabling and a firing condition. So you could have a Just Links trigger that is only enabled on page X and another Just Links trigger that is enabled on all pages. GTM handles this conflict by using a special gtm.triggers key in the Data Layer, which basically implements the enabling condition of each respective trigger.\nIn other words, the enabling condition morphs pretty naturally into another firing condition when you have multiple triggers of the same type set up in your container. This can easily lead to confusion, since the Enable this trigger when.. setting should only be used to avoid conflicts with other JavaScript on the website and not to control when triggers fire tags (since that\u0026rsquo;s what the firing condition is for).\nWhat do you think? How could the trigger UI and user experience be improved?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/new-approval-workflow-gtm-360/",
	"title": "New Approval Workflow In GTM 360",
	"tags": ["approval", "Google Tag Manager", "user permissions", "workflow"],
	"description": "Introduction and guide to the new approval workflow in Google Tag Manager 360.",
	"content": " Apart from the unlimited number of workspaces, the 360 Suite version of Google Tag Manager didn\u0026rsquo;t have any differentiation from the free version feature-wise, until today.\n  GTM just introduced an approval workflow, which allows you to exercise some additional control over what changes are pushed to the live site, or created into versions.\nNote that this update also introduced a small change in the regular GTM UI - mainly, the menu that used to have \u0026ldquo;Create Version\u0026rdquo;, \u0026ldquo;Publish\u0026rdquo; and \u0026ldquo;Preview\u0026rdquo; is now changed into a dual button layout with just Preview and Submit as the options.\nWhen you click Submit, a new overlay opens with tabs for creating a version, publishing the workspace, and, if you are using GTM 360, for requesting approval of your changes.\n  In this article, I want to take a quick look at the new approval workflow and how it works.\nChanges to user permissions First of all, user permissions are more useful now. The permission levels per container haven\u0026rsquo;t changed in name, but their functionality has changed somewhat if you are using GTM 360.\n View still lets you only view the container and preview older versions. Nothing\u0026rsquo;s changed here.\n Edit lets you make changes to a workspace, but instead of creating a version and publishing a version, you can only submit a request for approval.\n Approve lets you create versions and approve requests, but you still can\u0026rsquo;t publish a version.\n Publish gives you full access in the container.\n    If you are using GTM 360, the new way to sort these permissions would be to allow Edit access for users who should be able to contribute to the container, but who must always submit their changes into the approval queue before they can be created into a version (or published).\nYou can give Approve access to users who can process this queue, comment on and approve the requests, but who still don\u0026rsquo;t have the power to actually update the live container on the site by publishing a version.\nThis new duality is interesting, as it can definitely be used for good and bad. Restricting access can create friction in an organization, which is why, I guess, the approval workflow is an optional feature that you can choose to ignore if you want. Personally I would have liked to see a flag in the settings that sets the approval process as mandatory or optional. By mandatory I mean that even users with full access would still need one other member to approve their changes.\nHow the process works First, take a look at my patented, crappy-as-hell, Powerpoint illustration below:\n  The workflow starts after you\u0026rsquo;ve made changes to the workspace, and you are ready to submit the workspace draft for approval. You can start the approval process by clicking the Submit button and opening the Request Approval tab.\n  In this tab, you can choose a user from whom you are requesting approval by clicking the Choose Approver button. Note that this is optional. If you do not choose an approver, the request can be processed by any user with at least Approve user permissions.\nNext, you can add a Comment to the request. This is highly recommended, as typing a comment actually starts a dialogue between you and any approvers. It\u0026rsquo;s a good way to keep tabs on why a request was rejected, for example, and the comment thread can also include notes on how to improve the quality of the changes.\nAs before when creating or publishing a version, you can see all changes to the workspace in the bottom of the approval request.\nSo, what happens when you click the Request button?\nWorkspace submitted for approval First of all, the workspaces selector will show a gavel symbol next to the workspace name, indicating that there is a pending approval request for this workspace.\n  Next, all users will see a blue or red notification symbol next to the Approvals menu item, which tells them that a new approval request has been submitted. The symbol is red if you are the named approver who received the request, and blue otherwise.\n  There will also be a new notification just below the main menu, indicating that there is a pending approval, and the name of the user who requested the approval.\nAll these UI signals are used to make sure the workflow doesn\u0026rsquo;t end up being an obstruction in your regular GTM use.\nNote that an approval workflow doesn\u0026rsquo;t prevent changes to the workspace. The approval workflow isn\u0026rsquo;t supposed to be a gatekeeper - rather, it\u0026rsquo;s a way for you to communicate changes you have committed to the workspace to other users of GTM.\nThus, you can continue making changes to the workspace, and the approval request will simply be updated with the changes you make.\nIf you are the user who submitted the request, you can always choose to Withdraw the request, i.e. remove it from the approval workflow. This won\u0026rsquo;t delete your workspace changes, just the approval request.\n  If you are someone with at least Approve rights, this is what you\u0026rsquo;ll see when you open the approval for processing:\n  Send Back request When the approver clicks Send Back, hopefully after having added some comments to the request, the approval request is returned to the user who made the request, and its state will be set to Needs work.\n  At this point, you should open the approval request and see what comments were left by the person who sent it back (hopefully they left a comment!).\nOnce you\u0026rsquo;re done with your changes, you can Resubmit the request (after adding a comment yourself), or you can simply delete the request via the dot menu.\n  By clicking Resubmit, you simply submit the request again to the user you\u0026rsquo;re requesting approval from.\nApprove request If you have at least Approve user permissions, you can choose to approve the request (even if you\u0026rsquo;re not the user approval was requested from).\nWhen you click Approve, you\u0026rsquo;ll see the following dialog:\n  At this point you can choose to Submit the changes, meaning the overlay with Create a version and Publish a version flies out, and you can commit the changes to the latest and/or the live container version.\nIf you choose to Leave Unsubmitted, the request will be approved, but the workspace will not be created into a version.\n  At this point, the workspace can still be worked on, but the changes have been approved, meaning the next time a user clicks Submit they can only create a version or publish the workspace. This is an odd state of limbo, and I would personally recommend to have version creation or publish as the final step of all approval workflows.\nThis is the extent of the approval workflow, for now. As said, the UI doesn\u0026rsquo;t enforce the workflow - you can continue using GTM as you have before. However, if you want added transparency, and if you want to leverage the user permission levels more efficiently, I recommend at least taking a look at the workflow.\nSummary In many ways, this change is in line with the direction Google Tag Manager has been moving towards ever since Environments was released a long while ago. It\u0026rsquo;s clear that GTM containers have many uses and users, and often there\u0026rsquo;s a lot of friction in how these moving parts mesh together. With things like Environments, Workspaces, and now the Approval workflow, you have more control over what takes place, by whom, and in what order.\nIt\u0026rsquo;s still just a feature. You still need to have an understanding of how it works as well as a need to use the Approval feature. I think it\u0026rsquo;s very useful in multi-user projects, especially when the container is operated on by users who might not have a clear idea of how the container works in the current organization.\nNaturally, I would have enjoyed this more had it been a feature in the free version of Google Tag Manager, and hopefully at some point it will trickle to free GTM as well.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-autocomplete-search-google-tag-manager/",
	"title": "Track Autocomplete Search In Google Tag Manager",
	"tags": ["google analytics", "Google Tag Manager", "search", "site search"],
	"description": "How to track auto-complete search to Google Analytics using Google Tag Manager.",
	"content": " Autocomplete search is a tricky thing to track. The underlying logic is that when the user starts feeding characters into a search form, the search suggests results based on a limited input. If the user is not satisfied with the results, they can continue adding characters to the search, thus increasing the accuracy. Often there\u0026rsquo;s also the option to revert to a regular search with what they\u0026rsquo;ve already written. Tracking this logic in tools like Google Analytics is difficult, because there\u0026rsquo;s really no way to know if the search was successful.\n  Take the example in the screenshot above. The user has written ban into the search field, and they\u0026rsquo;ve received a list of search items to proceed with. If they now chose any item in that list, would the search be considered successful?\nYes. And (maybe) no. Yes, it would be a successful search because the user clicked an item in the list, thus validating the suggestion. And (maybe) no, because we have no idea if that is the item the user was searching for in the first place. If the purpose of our search is to match a response to a query, then any click on the search results is a success. If the purpose of our search is to match a response to the original intent of the query, then only a certain type of search result click is a success.\n  This is going too far into the ontology of search and intent, so I\u0026rsquo;m going to stop with the philosophy here. However, what I do want to show you is a pretty simple way of tracking what users do search in the autocomplete search field, using Google Tag Manager. It\u0026rsquo;s up to you to decipher if the searches are successful, though.\nHow it works The setup is basically just a Custom HTML tag. In this tag, we\u0026rsquo;ll write a custom listener for the keydown browser event, which is registered when the user presses (down) a key. You must provide a minimum length of search for this handler, as well as the timeout you want the browser to wait before sending a search term to Google Analytics (or whatever platform you want to use this with).\nFor example, if you set minLength = 3 and timeout = 2000, the handler will only send searches that are at least three characters in length, and where 2 seconds have elapsed since the last character was written. This is necessary to eliminate accidental keystrokes and search terms with far too little information to be useful.\nThe search event thus occurs when two seconds have passed since the last character has been typed OR when the user presses the Enter key OR when the focus leaves the search field.\nThe code is all contained in a single Custom HTML tag which fires on the DOM Ready trigger. You\u0026rsquo;ll then need a Custom Event trigger to fire when a valid search is recorded, as well as a Data Layer Variable to grab that search term.\n1. The Custom HTML tag Here\u0026rsquo;s the code that runs the whole thing:\n\u0026lt;script\u0026gt; (function() { // Set searchField to the search input field.  // Set timeout to the time you want to wait after the last character in milliseconds.  // Set minLength to the minimum number of characters that constitutes a valid search.  var searchField = document.querySelector(\u0026#39;input#search-field\u0026#39;), timeout = 2000, minLength = 3; var textEntered = false; var timer, searchText; var handleInput = function() { searchText = searchField ? searchField.value : \u0026#39;\u0026#39;; if (searchText.length \u0026lt; minLength) { return; } window.dataLayer.push({ event: \u0026#39;customSearch\u0026#39;, customSearchInput: searchText }); textEntered = false; }; var startTimer = function(e) { textEntered = true; window.clearTimeout(timer); if (e.keyCode === 13) { handleInput(); return; } timer = setTimeout(handleInput, timeout); }; if (searchField !== null) { searchField.addEventListener(\u0026#39;keydown\u0026#39;, startTimer, true); searchField.addEventListener(\u0026#39;blur\u0026#39;, function() { if (textEntered) { window.clearTimeout(timer); handleInput(); } }, true); } })(); \u0026lt;/script\u0026gt; First, you need to define some utility variables.\n Set searchField to capture the search field HTML element. This is the element to which the handlers will be attached to.\n Set timeout to the time in milliseconds you want the script to wait after the last character has been typed into the field. This is to prevent the search event from happening too often, especially when people type slowly.\n Set minLength to the minimum number of characters that constitutes a search. If the search is less than this number in length, the search will not be recorded.\n  The handleInput method checks if the search is long enough. If it is, an object is pushed to dataLayer with the following key-value pairs:\n event: 'customSearch', which we\u0026rsquo;ll use to build the Custom Event Trigger that fires any tags you want when a search is recorded.\n customSearchInput: searchText, which grabs the text the user wrote into the search field.\n  The startTimer method is run each time the user types something into the search field. First, it stops the current timer (which is counting the time to the timeout limit), because we want to reset the timer with each key press.\nNext, it checks if the key that was pressed was the Enter key (keyCode === 13). If it was, then we interpret this as a valid search and run the handleInput method. Finally, the timer is started again, and after the timer hits the timeout limit, handleInput is called.\nThe final rows of the script add the keydown and blur listeners to the search field to track keystrokes and if the focus leaves the search field, respectively.\n2. The triggers To fire the Custom HTML tag above, use a DOM Ready trigger. It makes sense to only fire the trigger on pages where you have the search form, so adding a DOM Variable condition to the trigger is not an altogether bad idea.\n  This way your search listener will only fire on pages with the search field (sensible!).\nNext, you\u0026rsquo;ll need a Custom Event trigger to fire your tags when a successful search is registered:\n  As you can see, I\u0026rsquo;m also checking if the search field had some text. This is, again, a sensible precaution to avoid false positives if something goes wrong with the script.\n3. The Data Layer Variable The Data Layer Variable you\u0026rsquo;ll need to capture the search term is simple:\n  This Data Layer Variable pulls the value of the key customSearchInput, pushed by the script upon a successfully recorded search.\nPutting it all together So now you have the components, and it\u0026rsquo;s time to put this all together. Below is an example, where I use a Universal Analytics tag to send the search term to Google Analytics using a custom query parameter.\n  The key is the page field, which is overwritten with:\n/search/?q={{DLV - customSearchInput}}\nThus, when the Universal Analytics fires with the Event - customSearch trigger, the page field is sent with the custom path /search/?q=searchterm. So if I wrote uunilohi into the search field, the page path sent to GA would be /search/?q=uunilohi.\nAfter this, all you need to do is go to View Settings in Google Analytics, and set the parameter q to be the site search parameter Google Analytics uses to build the site search reports.\nSummary Tracking autocomplete search is difficult not just because of the technical restrictions but because it\u0026rsquo;s difficult to determine original intent with just a few characters to work with.\nIt can be argued that ANY search that precedes a click of search results or even a conversion is successful, and I tend to agree with this. However, especially for content creators it\u0026rsquo;s important to align searches with relevant results, not just any old result that the user finds attractive. For this reason, it\u0026rsquo;s important to track partial searches as well as searches with refined inputs.\nHow have you solved the problem of autocomplete search? Do you trust the site search reports when you see only partial searches, and do you find this information useful when optimizing the site to be more responsive to complex searches?\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/user-permissions/",
	"title": "#GTMTips: User Permissions",
	"tags": ["Google Tag Manager", "gtmtips", "permissions"],
	"description": "How user permissions work in the different parts of Google Tag Manager.",
	"content": " In this #GTMTips article, we\u0026rsquo;ll take a look at user permissions and access control levels that Google Tag Manager lets you set today. Doing access control right from a user interface AND user experience perspective is really difficult, and GTM is no exception. Nevertheless, there are several levels of user control that you can modify from account and container settings, and it\u0026rsquo;s useful to familiarize with these so that managing a big, sprawling account hierarchy would be just a bit easier.\nTip 57: User Permissions And Access Control Levels   Since the concept of an account in Google Tag Manager is not as important as, say, in Google Analytics, the access levels for accounts come in two sorts:\n Admin access lets the user modify other users\u0026rsquo; permission levels, and Admin level has always at least Read access to each container.\n User access prevents the user from modifying other users\u0026rsquo; permission levels, and they can also have the No Access level for containers.\n  Note that there is no owner in Google Tag Manager. Admin access can be freely distributed, and it can be revoked, even from the user who created the account.\nOn Container level, the available permission levels are:\n No Access means the user will not even see this container in the list of containers in the UI or via API queries.\n Read gives the user view-only access to the container. This includes browsing workspace drafts, opening tags, triggers, and variables, but not being able to edit them in any way. One feature of Read access that is often ignored is that users can Preview container versions by going to the Versions page and choosing Preview from the version action menu (see screenshot below). Note that users can\u0026rsquo;t preview workspace drafts.\n Edit access lets users create workspaces and edit assets within those workspaces, but they cannot Create Versions or Publish those workspaces. Note that Edit access CAN Preview workspace drafts.\n Approve is almost the same as Edit except the user has now permission to Create Versions out of workspace drafts. They still can\u0026rsquo;t Publish anything, though.\n Publish is the highest access level for containers. It gives you full access to the container, including ability to create and modify Environments, and even to delete containers.\n    With these access control levels, you can distribute access within a single container pretty granularly. However, there\u0026rsquo;s a bunch of things many users would still love to see with permission distribution, most notably involving folders. Also, a nice, juicy approval queue would be great to have, so that users with limited permissions could still submit a workspace draft for approval programmatically, rather than having to sort out the publish workflow in person (I know, social interaction, YUCH!).\nBONUS: I\u0026rsquo;ve lost account access / I don\u0026rsquo;t know who has access to GTM-XXXXX - what do I do? This must be one of the most frequently asked questions in the Product Forums. Typically it\u0026rsquo;s a case of a GTM container being deployed on the site, but no one has access to it, nor does anyone know WHO is the current admin. (Folks, this is what lack of governance does. Learn from it!).\nAnyway, I\u0026rsquo;m going to quote Googler Andrew Lanzone, who had the perfect answer for what to do in case you need to retrieve access information for any given container or account.\n The easiest option is to track down the person with admin rights on the account. If you can, contact a user who has admin rights on the GTM account and ask them to add you to the account (as admin as well). If you have access to the email accounts of the departed employees, you can try logging in with those accounts and adding yourself as an admin.\nIf that is not possible, file a feedback request (choose \u0026ldquo;Send feedback\u0026rdquo; from the \u0026hellip; menu in the GTM header) and we can try and contact the account admins on your behalf.\nIn general, we recommend:\n You should have multiple admins on your account.\n At least one email address on the account should be monitored on a daily basis if possible.\n You should have a handoff plan for when people leave the company and/or end business relationships.\n   Here\u0026rsquo;s the source for Andrew\u0026rsquo;s tips.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/gtm-tools-release-notes-and-user-guide/",
	"title": "GTM Tools: Release Notes And User Guide",
	"tags": ["api", "Google Tag Manager", "gtm tools"],
	"description": "Release notes and user guide to GTM Tools for Google Tag Manager. Use it to manage, clone, and create containers.",
	"content": " With the release of the latest Google Tag Manager API version, it\u0026rsquo;s time to release the new version of GTM Tools. Most of the changes have been done under the hood, with the entire codebase refactored for improved stability.\nI released the first toolset in October 2014, and quickly released an updated UI a few months later. Aside from a few bug fixes and stability improvements, the tools have remained largely unchanged since then. Now with the new API version, it was time to update the tools again.\nThus this current version is actually the third iteration of the tools. The changes might not seem that dramatic, but trust me when I say this is the best version of the tools so far. The added features should make it easier to use the tools, the stability upgrades should prevent the tools from bugging out as often as before, and there are plenty of improvements that make it easier for me to manage and release new versions of the tools.\n  This article will be the closest thing to a \u0026ldquo;user guide\u0026rdquo; the tools can have, so I\u0026rsquo;ll jump straight to the subject matter right after this disclaimer:\nGTM Tools is not a commercial product.\nThis toolset is my own, personal, intellectual property, with no purpose of making money out of it or making it the best possible product out there. It\u0026rsquo;s got bugs, the code is still pretty convoluted in places, and I haven\u0026rsquo;t done nearly enough testing. It\u0026rsquo;s a toolset that you might find useful or then you might not.\nWhen you use GTM Tools you need to accept this. Note that GTM Tools doesn\u0026rsquo;t have a single method that destroys or deletes your GTM data. It can only create, read, and update.\nNote also that when you use the Library feature, the assets you save into the library will be viewable by me, as I need to access this information for debugging and management purposes. I will, under no circumstances, use or copy your data. I will only read the data in situations where I deem it necessary to keep GTM Tools functional.\nI would also appreciate if you sent me email (simo(at)simoahava.com) when encountering any bugs, errors, or freezes. Just remember to check the Known Issues part of this guide first.\nThe tool is located in this URL:\nhttps://www.gtmtools.com/\nLatest releases 6 Sept 2018  List folders in Inspect view.\n Clicking a folder row highlights all items in the folder.\n You can add all items in a folder into the cart.\n Added Expand/collapse all toggle to item list in Inspect view.\n  5 Sept 2018  Preserve Tag Sequencing details for tags when cloning an entire container from one account to another.  11 Jan 2018  Added Slack integration to container pages.\n Fixed \u0026ldquo;Last Modified\u0026rdquo; when viewing version details to match the last modified of the version and not the container.\n  29 Dec 2017  Switched to HTTPS  3 Apr 2017  Published the new version of the tools. Main changes are listed in 1. What\u0026rsquo;s changed?.  1. What\u0026rsquo;s changed? Here are the main changes to this latest version of GTM Tools:\n You can now revoke GTM Tools\u0026rsquo; access to your data via the profile drop-down (Revoke access).\n Click Show container type in any container list to see what type each container is.\n You can only Save to cart an asset if it matches the container type already saved in cart. In other words, you can\u0026rsquo;t combine assets of different container types (e.g. Web and Firebase) in the cart.\n You can only Clone cart contents to container if the cart type matches the container type. Thus you can\u0026rsquo;t clone Web assets to a Firebase container, for example.\n This means that you can only Save to library a cart of a single type. And this, in turn, means that if you want to clone a saved container to an existing container, they must have the same type.\n You can now Display notes in any Inspect container view.\n You can export a Container overview as CSV in any Inspect container view.\n You can select the Container version you want to inspect.\n You can\u0026rsquo;t have multiple assets with the same name in the cart. If you do, these conflicting assets are flagged in the cart page.\n Added Workspaces to all clone operations. Basically, you need to select a Workspace you are cloning into. You can also create a new Workspace as the target, if you wish.\n Improved stability and error handling.\n  I rewrote almost the entire codebase, so stability and performance should have improved. This doesn\u0026rsquo;t mean it\u0026rsquo;s error-free (far from it).\n2. Login And Authentication GTM Tools uses your Google Account for authentication. This means that when you first open the tool website, you will need to Sign in with your Google credentials. Note that GTM Tools has no sign in of its own. The tools use your Google sign-in to access your data. The only data that is permanently stored is your Asset Library data.\n  Once you\u0026rsquo;ve signed in, you will need to authorize GTM Tools for access to Google Tag Manager and your Google profile. Specifically, here are the authorization scopes you allow access to:\n  If you refuse to allow access, you will not be able to use the toolset.\nOnce you\u0026rsquo;re in the actual tool interface, you can see the profile you\u0026rsquo;ve logged in with in the upper right corner of the page. You can click this link and select Revoke access to revoke the tool\u0026rsquo;s access to your data at any time. This will not sign you out of your Google account. You can click My Account to access your Google Account settings.\n  3. Home Page The first page you\u0026rsquo;ll see in the tools is the home page. This page is a placeholder, and you should use the navigation bar in the top of the page to move on in the site.\n  The navigation has the following selections in the home page:\n Home – Takes you back to the home page\n GTM Account – This lists all the GTM accounts you have access to with the signed in Google Account.\n Library – Takes you to the Asset Library where you can find your stored containers\n Cart – Shows you how many items you have in your cart, and by clicking the button you will be taken to the Cart page\n Your Profile – Clicking this shows a drop-down menu, where you can choose to access your Google Account settings and/or revoke GTM Tools\u0026rsquo; access to your data.\n  4. Account Page When you choose a GTM account in the Accounts navigation, you will be taken to a page that lists all the containers in the selected GTM account. If you click a container name, you will be taken to the respective Container page.\n  If you click the small down arrow next to a container name, you\u0026rsquo;ll see quick links for the following container actions:\n Inspect - Takes you to the Inspect Container page, where you can view information about the container, and where you can add / remove assets from the container into the cart\n Visualize - Takes you to the Visualize Container page, where you can view a visualization of the Latest Version of the container\n Clone - Opens a modal dialog that lets you clone the Latest Version of the container\n  Note that only Inspect supports accessing other versions than the Latest Version. This is something I intend to fix in a future release. Until then, Clone and Visualize only access the latest container version.\nIf you click Show container type, you\u0026rsquo;ll see a label indicating what type each container is. This is relevant for cart interactions.\n  Read more about these actions in the following sections of this guide.\n5. Container Page The container page is here more for navigational reasons than to add any extra value. You can move through it to the individual actions (Inspect, Visualize, Clone), which you can also do from the account page, as you just learned.\n  The following chapters will include details about the various actions you can take.\nInspect Container On the Inspect Container page, you can see a list of all tags, triggers, and variables in a container. You will also see information about the selected version by clicking the Version Information panel.\n  The number on the right-hand-side of a panel title tells you how many assets are in each respective category.\nBy expanding an asset category, you\u0026rsquo;ll see a list of all the assets under that category.\n  If you click Display notes, an additional column is added, where you can see the notes added for each asset (if any).\n  You will also see two selections:\n Green plus + for adding the asset to your cart (if not added yet)\n Red minus - for removing the asset from your cart (if already added)\n Icon in the Links column if there are dependencies (i.e. linked assets) that you should probably add to your cart as well\n  The green plus or red minus will appear depending on if the asset is in the cart or not. If there are no dependencies, you will only see a dash in the \u0026ldquo;Links\u0026rdquo; column.\n  When you click on the Links icon for dependencies, a modal dialog will open up which lists all the dependencies of the current asset. This means that these dependencies are linked to directly from the asset itself, or from one of its linked assets (it\u0026rsquo;s a recursive check). It\u0026rsquo;s strongly recommended that you include all linked dependencies when adding an asset to the Cart.\n  You can add a dependency to the cart by clicking the Add link, after which you\u0026rsquo;ll see the text Added next to the dependency.\nYou can change the version you are inspecting from the drop-down in the header of the page.\n  By clicking Export overview as CSV, you can export a CSV file that has the current container information in CSV format.\n  Folders The Folders panel lists all the folders you have created in the container.\nHere you can highlight all the items in any given folder (by clicking a folder row in the list).\nYou can also add all items in a folder to the cart by clicking the respective button.\nVisualize Container The Visualize Container page first shows you a brief description of what the tool does. Once you click the Start visualization button, a full-screen modal dialog will open, and you will be able to see a visualization of all the assets in the container as well as any links between them.\nThe asset colors are:\n Grey - Built-In Variables\n Green - Tags\n Blue - Variables\n Red - Triggers\n    If you hover your mouse over an asset, any links to or from that asset will be highlighted. The path color is red if the link is from the selected asset, and the path color is green if the link is to the selected asset.\nHovering over the asset will also show information about it in the small box that appears in the center of the visualization.\nClicking an asset name freezes the paths, so that it\u0026rsquo;s easier for you to navigate to the other end of the path.\nClicking Select Hermit Nodes will highlight all the assets that have no links to or from other assets.\n  You can use the search box to find assets. Start typing, and the assets that match whatever you\u0026rsquo;ve typed will be highlighted as you type.\n  Clone Container There are two ways to clone a container in GTM Tools. Due to architectural reasons, they are a bit different.\nThe first way is through the Account page and the Container page. So either you choose Clone from the drop-down menu next to the container name in the account page, or you click the Clone button on the container page itself.\n  When you choose this clone option, you will be able to choose the GTM account where this container will be cloned to. You can also choose the same GTM account where the container originates from.\n  Once you\u0026rsquo;ve chosen the account and clicked Clone, the process begins, and the source container with all its assets is cloned to the target account.\nIf there already is a container with this name in the target account, the container name will be prefixed with \u0026ldquo;copy of \u0026ldquo; during the process.\nThe second way of cloning a container is with your custom-created containers. This means that you choose to Clone either directly from the Cart page or from your Asset Library page.\n  If you choose this option, it will be possible to merge the stored container with an existing container, or you can choose to create an entirely new container, if you wish.\nNote that you will need to specify to which Workspace you want to clone the contents to. Alternatively, you can also create a new workspace.\nAdditionally, you can only clone the cart or library container to a container that matches the type of the container you are cloning. So you cannot, for example, clone a Firebase cart into a Web container.\n  When you choose to create a New Container, a new container with the name (and workspace name) you give will be created, and all the assets will be copied to that container.\nIf a container already exists with the name you gave, the new container name will be prefixed with \u0026ldquo;copy of\u0026rdquo; during the cloning process.\nIf you choose to clone the assets to an existing container, the contents in your cart or in the stored container will be merged with the assets in the target container. This means that if there is a naming conflict, i.e. an asset with the same name already exists in the target container, the asset\u0026rsquo;s name will be prefixed with \u0026ldquo;copy of\u0026rdquo;, and any links to the asset in other cloned assets will be updated accordingly.\nRenaming containers and assets like this makes merging containers possible while still preserving the established links between assets in the source container.\nIf you choose to merge the assets to an existing container, no existing assets in the target container are modified in any way, so you don\u0026rsquo;t have to worry about data or integrity loss.\nOnce the cloning process begins, there\u0026rsquo;s no way to interrupt it except by refreshing the page or moving away from the page.\n6. Cart Page On the cart page you can see all the assets that you have stored in your cart. You store assets in the cart through the Inspect Container page. The assets are listed first by GTM account name, then by container name, and finally by asset type.\n  Clicking the Remove link next to an asset removes the asset from your Cart.\nClicking the Clone to container button opens a modal dialog that lets you clone the cart contents into an existing container or a new container. If you choose an existing container, the target container must match the container type of the cart.\nClicking the Save cart button opens a modal dialog that lets you save the cart contents into your Asset Library. This way you can save your favorite container configurations to be used later.\n  Clicking the Empty cart button flushes the cart contents.\nIf you have multiple items in the cart with the same name, they will be flagged with details about the container version from which the items were added. You must resolve these conflicts before doing anything with the cart. Currently GTM Tools does not support storing or cloning multiple assets with the same name, so you will need to remove the items from the cart until only one asset per name remains.\n  7. Asset Library The Asset Library page shows you all your stored containers. When you click a container name, you will see how many tags, triggers, and variables are in the stored container. You\u0026rsquo;ll also be able to see when the container was created, as well as the description you gave the container when you saved it.\n  If the library already (globally) has a container of the name you tried to save, the container name will automatically be prefixed with \u0026ldquo;copy of\u0026rdquo;, so don\u0026rsquo;t be surprised if you see this in your stored container name.\nClicking the Clone button lets you clone this container into an existing container or a new container.\nClicking the Visualize button takes you to the Visualize Container page, where you can see a visualization of all the assets stored in the container.\n  Clicking the Delete button opens a modal dialog which confirms this action. If you choose to delete the Container, you\u0026rsquo;ll see a success message shortly, after which the page will automatically reload.\n8. Known Issues Here are some of the issues I know exist in the toolset.\n1) You can add all items in a folder to the cart, but the folder designation itself doesn\u0026rsquo;t carry over. So when you clone the cart, these items will not be put into any folders in the target container. I\u0026rsquo;m trying to figure out a way to do this elegantly. When cloning an entire container, the folder structure is preserved.\n2) Similarly, Tag Sequencing is only supported when cloning an entire container, but not when working with individual assets via the cart.\n3) Version selection should be added to the Clone and Visualize functions of containers as well. Currently version selection only works when inspecting a container.\n4) I want to support working with Workspaces in the Inspect view. It would make it easier to introduce DELETE and UPDATE operations for multiple items at a time.\n4) There are lots of little features that I\u0026rsquo;d like to work on at some point, such as: clone to multiple containers, interact with cart without having to move to the cart page, modify asset settings, etc.\n10. Summary As I hopefully made clear in the introduction, this toolset is my own playing ground. It\u0026rsquo;s not a fully-formed platform, it\u0026rsquo;s not a sponsored product, and it doesn\u0026rsquo;t have a team of engineers working on it 24\u0026frasl;7. Thus I hope you will find it useful, and I\u0026rsquo;ll do my best to fix bugs and new features, but don\u0026rsquo;t expect Premium-level support from me in making things right.\nUse the toolset at your risk.\nThere\u0026rsquo;s no risk to your existing assets, since I don\u0026rsquo;t have any overwrite features in the toolset. The only thing you can botch up is cloning something into something else, and in that case only the thing you were cloning will suffer. Easy enough to clean up afterward in your GTM account.\nI still hope you find the toolset useful, and I would very much appreciate any feedback that you might want to direct to my developer team (i.e. me).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-api-v2-released/",
	"title": "Google Tag Manager API V2 Released",
	"tags": ["api", "Google Tag Manager"],
	"description": "Introduction to the latest version of the Google Tag Manager programmatic API, and especially the changes compared to version 1.",
	"content": " Google Tag Manager has a very nifty programmatic API that lets you do almost anything that\u0026rsquo;s also possible within the GTM UI. I\u0026rsquo;ve used the API a lot, most notably for my GTM Tools, which might be getting a new release soon, too!\nThe API was recently updated to its second release version (V2), and in this article I want to go over the additions, removals, and changes that the new version introduced.\n  First of all, V1 of the API is still fully functional, so you don\u0026rsquo;t have to migrate until you\u0026rsquo;re ready. That being said, the new version brings about a number of changes I\u0026rsquo;m sure you\u0026rsquo;ll find helpful when working with the API.\nBiggest changes The most significant change, in my opinion, is the introduction of workspace as the central focus in almost all interactions with anything on the container level. It\u0026rsquo;s not just that there\u0026rsquo;s a new namespace for workspaces in the API, but that you must always reference a workspace when interacting with container assets. This is going to be the biggest hurdle in a migration, I believe. Anything that happens in a workspace (pretty much all UI interactions with a single container draft) must now be accompanied by the workspace ID of the workspace you want to modify. This, in turn, means a round trip via the workspaces API to get the IDs you need.\n  Another very visible change is the separation of Built-in Variables into its own namespace. Luckily there\u0026rsquo;s also a simple batching shorthand for enabling / deleting multiple Built-in Variables in a single request.\nOn a technical level, when using client libraries you now provide the path to the asset as a single parameter (basically path or parent) instead of using multiple named parameters. The new resource representations include the path key, which you can then use to easily chain API commands together.\nFinally, and I love this, there\u0026rsquo;s support for adding notes to pretty much any resource available via the API. Even though the UI doesn\u0026rsquo;t yet support the notes field as widely, you can now add descriptive text to all assets via the API. Very useful for documenting the container.\n(UPDATE: a short while after writing this article, GTM released support for notes in the UI too, yay!)\nDetailed changes What follows is a walkthrough of all the namespaces in the new version of the API, with information on what changed from V1.\n1. Accounts Resource changes: The Accounts resource has the following new fields:\n path: path of the Account, e.g. accounts/12345 tagManagerUrl: direct URL to your account in the GTM API  Method changes: There are no significant changes in Accounts methods.\n2. Built-in Variables This is a completely new namespace in the API. Instead of passing a list of Built-in Variables in the container resource itself, you now need to explicitly enable Built-in Variables in the workspace of your choice. You can read the full description of this new feature here.\nNote that if you want to enable multiple Built-in Variables in a single request (strongly recommended), you can use a shorthand batch format to do so.\naccounts() .containers() .workspaces() .built_in_variables() .create( parent=\u0026#39;accounts/%s/containers/%s/workspaces/%s\u0026#39; % (accountId, containerId, workspaceId), type=[\u0026#39;clickClasses\u0026#39;, \u0026#39;clickElement\u0026#39;, \u0026#39;clickId\u0026#39;, \u0026#39;clickUrl\u0026#39;, \u0026#39;clickText\u0026#39;, \u0026#39;clickTarget\u0026#39;] ) 3. Containers Resource changes: The Containers namespace hasn\u0026rsquo;t changed that much. The new fields are the same as with Accounts: path and tagManagerUrl. Fields that were removed from V2 are the redundant timeZoneCountryId and timeZoneId. The enabledBuiltInVariable field has been replaced by the Built-in Variables namespace introduced above.\nMethod changes: There are no significant changes to the Containers methods.\n4. Environments Resource changes: The main changes to the Environments resource are the following:\n path: relative path in the API to the given environment\n authorizationTimestamp: supports both nanos and seconds as values\n workspaceId: link to preview a given workspace in the environment\n tagManagerUrl: link to the Environments page in the container\n  Method changes: The most significant change is that the old environments.reauthorize_environments namespace has been removed in favor of simply adding a reauthorize() method to the main Environments API.\n5. Folders Resource changes: The big changes to the Folders resource are:\n path: relative API path to the folder\n workspaceId: ID of the workspace from which the folder was fetched\n tagManagerUrl: link to the folder in the GTM UI\n notes: notes about the folder\n  Method changes: The main changes to the methods are that both folders.entities and folders.move_folders have been replaced with their own dedicated API methods in entities() and move_entities_to_folders(), respectively.\nThere\u0026rsquo;s also a new method, revert(), which lets you revert changes to a folder in the given workspace.\n6. Tags Resource changes: The only changes are the inclusion of path, workspaceId and tagManagerUrl. Otherwise the resource representation has remained relatively unchanged.\nMethod changes: The only big change is the introduction of the revert() method, which lets you cancel any changes to the tag in the given workspace.\n7. Triggers Triggers was affected in exactly the same way as Tags. The changes are identical, with the exception of notes now introduced as a writable field for Triggers, too.\n8. User Permissions (Note, this used to be called just Permissions in the previous API version documentation.) Resource changes: The main changes to User Permissions are:\n path: relative API path to the permission entity, includes the permissionId\n accountAccess.permission: now a string rather than a list/array\n containerAccess[].permission: now a string rather than a list/array\n  Method changes: No significant changes to methods.\n8. Variables Changes to Variables are pretty much on par with what\u0026rsquo;s done to Tags, so check the relevant section above for more details.\n9. Version Headers The Version Headers API is a new addition to the GTM API. Basically, it\u0026rsquo;s a shorthand for accessing versions of any given container. Unlike the Versions API itself, Version Headers only returns, surprise surprise, headers. This keeps the API calls really lean, and lets you quickly get the necessary information, such as the version ID.\nYou can check the documentation for more details on the resource representation.\nThe API has two methods.\n latest() returns the version header of the Latest Container Version. The Latest version is the most recently created version in Google Tag Manager, and is very relevant to Workspaces, since Workspaces need to be synchronized with the Latest container version before they can be published or turned into versions themselves.\n list() returns a list of all container versions in any given container.\n  10. Versions (Note, this used to be called Container Versions in the previous API version documentation.) Resource changes: Here are the changes to Versions in the GTM API:\n path: relative API path to the container version\n description: used to be called notes in the previous API version\n builtInVariable: list of Built-in Variables enabled in the version\n tagManagerUrl: link to the container version in the GTM UI\n  Note that the macro and rule parameters have been deprecated in the new API version.\nMethod changes: Here are the main changes to Versions methods:\n create(): deprecated - container version creation is done via Workspaces\n list(): deprecated - version list is now done via Version Headers\n live(): retrieves the container version that is currently live in the container\n set_latest(): sets the given version as the Latest version in the container - replaces restore() in the previous API version\n  11. Workspaces The Workspaces API was introduced in V2 of the GTM API. You will definitely want to follow this link and familiarize yourself with the new API. Understanding how workspaces function in the container is integral to understanding how the GTM API works.\n create_version() creates a version out of a workspace but only if the version passes all GTM\u0026rsquo;s syntax and validation checks.\n getStatus() returns all the conflicting and/or modified entities in the workspace. This is useful if you want to check if the workspace is ready to be turned into a version.\n resolve_conflict() lets you resolve conflicts in favor of the workspace or the latest version.\n sync() lets you synchronize the workspace with the latest container version - a necessary step to take before creating the version.\n  Workspaces are fundamental to many interactions with the API. Basically, when you work with tags, triggers, variables, folders, and built-in variables, you always need to provide the workspace ID with which you are interacting. There\u0026rsquo;s no single \u0026ldquo;Container draft\u0026rdquo; anymore. There\u0026rsquo;s always a workspace you\u0026rsquo;re working in.\nIn addition to having to update your methods, this also means that you need to rethink some of the API flows you have been using thus far. For example, instead of just creating new items in a container, you now need to specify the workspace you want to work with. This means you might first need to list() the available workspaces to get the ID you are looking for. Or perhaps you want to create() a new workspace so that you don\u0026rsquo;t mess with other people\u0026rsquo;s unfinished work.\nSummary The new API certainly has a lot of stuff to wrap your head around. The introduction of workspaces, for one, is certain to make migration a bit of a headache. However, it would be equally awkward to work with an API that isn\u0026rsquo;t in sync with the feature set of the UI it is managing. For this reason, I think it makes a lot of sense to upgrade to the latest API version as soon as possible.\nMost of the stuff is easy to figure out, such as how to move from accountId= and containerId= to path=accounts/accountId/containers/containerId. In fact, I think changes like this make it easier to work with programming languages that make use of string interpolation (Python, for example). There are some conventions that might take time to understand routinely, such as how to use versionheaders.list instead of versions.list.\nOne thing that\u0026rsquo;s a constant feature request from me is that Google would update their error messages. It\u0026rsquo;s very difficult to understand what\u0026rsquo;s wrong when all you see in the logs is \u0026ldquo;400 Bad Request\u0026rdquo; or \u0026ldquo;500 Backend Error\u0026rdquo;.\nWhat do you think about the new API? Have you written tools for the GTM API you want to share? Please do!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/cross-domain-tracking-with-multiple-ga-trackers/",
	"title": "#GTMTips: Cross-domain Tracking With Multiple GA Trackers",
	"tags": ["cross-domain tracking", "google analytics", "Google Tag Manager", "gtmtips"],
	"description": "How to setup cross-domain tracking to Google Analytics when you have more than one tracker running on the page.",
	"content": " To be fair, this tip isn\u0026rsquo;t just for Google Tag Manager but for regular old on-page Google Analytics as well. It\u0026rsquo;s one of those little things that\u0026rsquo;s corroding your data quality without you ever realizing it. Namely, this tip is about how to handle cross-domain tracking in situations where you are sending data to multiple Google Analytics properties on the same page.\nIt\u0026rsquo;s a very typical scenario - you have a \u0026ldquo;local\u0026rdquo; property, which tracks only the traffic of the current site, and then a \u0026ldquo;rollup\u0026rdquo; property, where you send data from all your organization\u0026rsquo;s websites. The rollup property would need cross-domain tracking enabled, since you want to track users across your organization\u0026rsquo;s many website domains.\nTip 56: Manage Cross-domain Tracking In Multi-Property Setups   The problem, in a nutshell, is that your cross-domain tracking property has the power to overwrite the value of the _ga cookie. It does this with the combination of the allowLinker: true field and a linker parameter in the URL of the page.\nSince all of your trackers and tags, by default, use the _ga, it\u0026rsquo;s possible this is wreaking havoc on your data quality.\nYou see, when a URL is loaded with the linker parameter, such as when traffic from another domain to the current page is decorated with cross-domain linker parameters, any tracker on the page with allowLinker: true checks if the linker parameter is valid. If it is, the Client ID is grabbed from the linker parameter and used on the current page to replace the value of the _ga cookie.\nThus, if there already WAS a _ga cookie with a different Client ID, tough luck. It\u0026rsquo;s now overwritten with what was in the linker parameter.\nThis means that any user who used to have a Client ID of X in your GA tracking will now have a Client ID of Y, meaning they are effectively treated as completely different users.\nAnnoying, right?\nWell, there\u0026rsquo;s a way to fix this. Basically, in all the trackers and tags that DO accept cross-domain tracking, you will need to use a different cookie name than _ga to store the Client ID! This way the cross-domain Client ID will not overwrite any pre-existing user data stored in the browser, but will be isolated in its own cookie where it will harm no one.\nHere are the basic steps.\n In every single tag (GTM) or tracker (regular GA) that is not used for cross-domain tracking, make sure to either leave out the allowLinker field or set its value to false. This is very important.\n In every single tag (GTM) or tracker (regular GA) used for cross-domain tracking, make sure to set the cookieName field to something other than _ga, e.g. _rollupGa, and make sure to set the allowLinker field to true.\n  So in the end you should have two types of field configurations in your GA trackers and tags. One set has no cross-domain settings, no special cookie settings, and no allowLinker field set. The other set has a new cookie name and has the allowLinker field set to true. Here\u0026rsquo;s an example using regular, on-page GA:\n// Regular GA tracker, uses _ga cookie ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {allowLinker: false}); // Rollup GA tracker ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-2\u0026#39;, {name: \u0026#39;rollup\u0026#39;, cookieName: \u0026#39;_rollupGa\u0026#39;, allowLinker: true});  It\u0026rsquo;s important that you audit all your tags and trackers and take extra care to see that not a single one of your non-cross-domain tags has the allowLinker field set to true, and that every single one of your cross-domain tags has the cookieName field set to the custom cookie name.\nThere, I think I\u0026rsquo;ve repeated myself sufficiently to impress you with what you should do the next time you setup cross-domain tracking through GTM or on-page GA.\nGood luck!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/100-google-tag-manager-learnings/",
	"title": "100+ Google Tag Manager Learnings",
	"tags": ["Google Tag Manager", "JavaScript", "Tips"],
	"description": "Over 100 tips and lessons learned after five years of using Google Tag Manager.",
	"content": " I\u0026rsquo;ve always been proud to avoid the typical headline clickbait of \u0026ldquo;Ultimate guide to pigeon care\u0026rdquo;, \u0026ldquo;All you need to know about the Great Vowel Shift\u0026rdquo;, \u0026ldquo;Did you know that you\u0026rsquo;ve been smoking peyote wrong your whole life?\u0026rdquo;. I\u0026rsquo;m ready to make an exception now by adding a BIG WHOPPING NUMBER to the title. You see, the amount of knowledge one can accumulate about anything they do on a daily basis is mind-blowing. It helps if you write a blog about the topic, since creative output is a great way to organize your thoughts. It also helps to be active in community support, since problem-solving is an excellent way to accumulate new skills and to hone the edge of your existing talent.\n  Now, I already have 50+ GTM Tips written, so it\u0026rsquo;s not like this is a novel idea, even on this blog. But this time I just wanted to write short, byte-sized things I\u0026rsquo;ve learned along the way, and I want to share them with you.\nAs you can read from the outrageously baiting title, there should be 100+ tips, but I only enumerated an even 100. That\u0026rsquo;s because I want YOU to add your ideas to the end of this post, and let\u0026rsquo;s see if we can keep it going. Yes, it\u0026rsquo;s my shameful attempt to delegate content creation to the community. I am guilty of that, too, now.\nContainer JavaScript Snippet 1. Initializes the dataLayer The JavaScript snippet part of the GTM container has one very important function (among others). It initializes the window.dataLayer array. Thus, if you haven\u0026rsquo;t initialized a dataLayer object yourself, the container snippet will do this for you. This ensures that dataLayer.push() works within GTM.\n2. Creates the script loader for the GTM library Perhaps even more importantly, the JavaScript container snippet creates a \u0026lt;script\u0026gt; element, which loads the Google Tag Manager container library for your GTM container ID from Google\u0026rsquo;s servers.\n  3. JavaScript snippet should be in \u0026lt;head\u0026gt; but can be (almost) anywhere The latest (and best) recommendation for placing the JavaScript snippet is to put it in the \u0026lt;head\u0026gt; of the document. This helps GTM load as early as possible, resulting in greater tracking accuracy. However, you can execute the JavaScript snippet pretty much any time during the page load and anywhere in your site code where execution of JavaScript is possible. The sooner the library loads, though, the more accurate your data collection will be.\n4. Pushes the initial event: 'gtm.js' The JavaScript snippet also pushes the initial event: 'gtm.js' into dataLayer. This is an important GTM event. It is used by the All Pages and Page View triggers. Any Data Layer variables you want to use with these triggers must be added to dataLayer before the JavaScript container snippet is executed.\n  5. Multiple container snippets on a page are supported You can add multiple JavaScript container snippets on a page. This is officially supported. The caveat is that they all need to use the same dataLayer name.\nContainer \u0026lt;noscript\u0026gt; snippet 6. The \u0026lt;noscript\u0026gt; block should be at the very beginning of \u0026lt;body\u0026gt; At the time of writing, the \u0026lt;noscript\u0026gt; block should be added to the very beginning of \u0026lt;body\u0026gt;. This is the only way that Search Console Verification using the Google Tag Manager method will work. Naturally, if you don\u0026rsquo;t care about verifying the site using the GTM method, nor do you have any use for tracking non-JavaScript visits, you can leave the \u0026lt;noscript\u0026gt; block out altogether. Just don\u0026rsquo;t place it in \u0026lt;head\u0026gt; as that would result in HTML validation issues.\n7. Only executed by browsers with JavaScript disabled The \u0026lt;noscript\u0026gt; snippet is only executed by browsers with JavaScript disabled. If you want to test it, you can disable JavaScript using your browser\u0026rsquo;s developer tools (e.g. Chrome).\n8. Loads an HTML page in an \u0026lt;iframe\u0026gt; The block loads an \u0026lt;iframe\u0026gt; element, which fetches its data as an HTML file from Google Tag Manager\u0026rsquo;s servers. In essence, this HTML file is your container. The HTML will contain the image elements you have configured to fire for JavaScript-disabled visitors.\n9. Only the Page View trigger works Because the JavaScript-less GTM can\u0026rsquo;t run JavaScript (d\u0026rsquo;oh), only the Page View trigger is at your disposal. Thus, there\u0026rsquo;s no dynamic triggers, and no way to wait for the page to load or anything like that. The Page View trigger is fired when the \u0026lt;iframe\u0026gt; contents are fetched.\n10. Use a function() { return true; } Custom JavaScript variable in the trigger A very handy way to fire tags only when executed in the \u0026lt;iframe\u0026gt; is to create a Custom JavaScript Variable with the following content:\nfunction() { return true; }  This variable will only return true if the browser executes it, i.e. executes JavaScript. By adding {{Variable}} does not equal true as a trigger condition fires the trigger only in browsers where JavaScript is disabled.\n11. Only the Custom Image tag is useful Since the JavaScript-less container can\u0026rsquo;t execute JavaScript, you are left with just the Custom Image tag. In other words, you can create image elements that are added directly into the container HTML. These image elements will then be rendered by the browser. In fact, you can even do some basic Google Analytics tracking using an image tag, since GA requests are basically image pixels. See this LunaMetric guide for inspiration.\n12. Can utilize \u0026ldquo;Data Layer\u0026rdquo; parameters via query parameters You can feed \u0026ldquo;Data Layer\u0026rdquo; values to the container HTML using query parameters in the \u0026lt;iframe\u0026gt; src attribute value. The query parameters need to be added as key-value pairs, and the keys that you add can then be used in Data Layer variables. For further details, see the LunaMetrics guide linked to in the previous paragraph, or check the guide I\u0026rsquo;ve written.\nThe dataLayer structure 13. Global JavaScript array The dataLayer structure is a global JavaScript array, and can thus be accessed in any site code that can also access the window object. It\u0026rsquo;s a good idea to always prefix the dataLayer name with window. to avoid conflicts with any locally scoped structures that use the same name.\n14. You can use a different name than dataLayer You can change the name of this global structure in the JavaScript container snippet. Just remember to always use this new name when adding messages to dataLayer!\n  15. Only the .push() method works with GTM Google Tag Manager only reacts to the .push() method. You can .splice(), .slice(), .shift() and .pop() all you like. GTM only listens for .push() commands.\n16. Typically only plain objects work with GTM The most common way to feed data to Google Tag Manager is using plain objects. Each object contains one or more key-value pairs. These key-value pairs are then translated into Data Layer variables, which you can create in Google Tag Manager to fetch values from the Data Layer.\nvar plainObject = { someKey: \u0026#39;someValue\u0026#39;, someOtherKey: \u0026#39;someOtherValue\u0026#39; }; window.dataLayer.push(plainObject);  17. You can use any JavaScript type as a value of a key All JavaScript types are supported as values when you push your dataLayer messages. When you create a Data Layer variable in GTM, it will contain a reference to whatever the value of the key is, regardless of type.\nwindow.dataLayer.push({ type_number: 5, type_string: \u0026#39;hello\u0026#39;, type_object: { someKey: \u0026#39;someValue\u0026#39; }, type_array: [1,2,3,4], type_function: function() { return \u0026#39;hello\u0026#39;!; }, type_boolean: true });  18. Only event key can trigger tags Only a message with an event: 'someValue' key-value pair can trigger tags. Any object without an 'event' key is treated as just a \u0026ldquo;message\u0026rdquo;, and has no triggering power of its own.\n19. You can also .push() a command array There\u0026rsquo;s a special command array you can .push() into dataLayer if you want to execute methods for values already in the data model. So technically it\u0026rsquo;s not just plain objects that dataLayer digests. There\u0026rsquo;s more about this in tip #26.\n20. Never overwrite, always .push() I usually hate to dole out best practices, so consider this a fact of life instead. Never, ever, ever, ever use this syntax:\nvar dataLayer = [{...}];  It\u0026rsquo;s destructive. If this command is executed after the GTM container snippet or after you\u0026rsquo;ve already established a dataLayer object, you will end up overwriting the existing object with this newly initialized structure. Worst-case scenario (surprisingly common) is that you\u0026rsquo;ll end up breaking GTM, since you also overwrite the custom .push() listener added by the container library.\nPrefer this syntax instead:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({...});  21. The array is capped at 300 This is perhaps more obscure, but in addition to adding a .push() listener, the GTM container library also caps the length of the dataLayer structure at 300. This means that when you .push() the 301st item into dataLayer, the first/oldest item in dataLayer is removed. As you will learn in the next section, this has no impact on GTM\u0026rsquo;s data model. It just caps the dataLayer structure itself.\nGTM\u0026rsquo;s data model 22. Copies messages queued via dataLayer.push() When you use the Data Layer Variable, Google Tag Manager doesn\u0026rsquo;t fetch the value from the dataLayer array. Instead, it polls its own internal data model to see if any value has been pushed to the given key (or variable name). If a value is found, GTM returns it. This means that GTM\u0026rsquo;s internal data model has access to the most recently pushed value for any given key.\n23. GTM freezes variable values when a trigger fires Triggers only fire when the key 'event' is pushed into dataLayer. When this happens, GTM \u0026ldquo;freezes\u0026rdquo; the state of the container, and any tags that fire on this trigger will only have access to the current state of the internal data model. Thus, if you want to push values into dataLayer so that they become available to a tag that triggers on the site, these values need to be pushed before or in the same object as the 'event' that triggers the tag.\n  24. Objects are recursively merged Recursive merge is one of the more complex concepts to understand. When you work with primitive values (strings, numbers, booleans, for example), the internal data model of GTM only has access to whatever was most recently pushed into a key whose value is one of these primitive types. However, when you work with structured objects and arrays, it\u0026rsquo;s more complicated.\nWhen you push an object into dataLayer, GTM goes through each key in this object, and only overwrites those that have shared keys and primitive values (or where the type changes). New keys are simply added to the existing object value.\n  When pushing an object to a key that already contains an object with the same keys, only the keys that have primitive values or a different type are overwritten. All others are simply updated.\n25. Arrays are recursively merged In JavaScript, arrays are structured objects, too, where the keys are index numbers that start from 0. So when you push an array into a key that already had an array, these two arrays are recursively merged starting from index 0, and any indices that are not modified remain the same.\n  26. You can run JavaScript methods on existing Data Layer values with a command array What if you already have an array in a key, but instead of merging or overwriting you want to add values to it, i.e. push items to the end of the array? You can use a special command array that you push into dataLayer. The first element in the array is a string that contains the key name and the command you want to execute, and all the other items are passed as arguments to the command.\n  27. Version 1 vs. Version 2 of the Data Layer Variable You\u0026rsquo;ve probably noticed that you can choose a version when using the Data Layer Variable. There are some very important differences between the two.\nVersion 2 supports deep structures with dot notation. If you want to access array indices, you need to use dot notation too (products.0.name rather than products[0].name). Only Version 2 supports recursive merge.\nVersion 1 does not support dot notation, and it only fetches the most recently pushed value whether it\u0026rsquo;s an object or not. Thus there\u0026rsquo;s no recursive merge - what you push is what you get.\n28. google_tag_manager['GTM-XXXX'].dataLayer methods If you want to access values stored in Google Tag Manager\u0026rsquo;s data model from outside GTM or without using a Data Layer Variable, you can use the google_tag_manager interface.\ngoogle_tag_manager['GTM-XXXX'].dataLayer.get('keyName') fetches the value stored in GTM\u0026rsquo;s data model for variable name keyName.\ngoogle_tag_manager['GTM-XXXX'].dataLayer.set('keyName', 'someValue') sets the value of keyName to someValue in GTM\u0026rsquo;s data model. This is the equivalent to using dataLayer.push({keyName: 'someValue'});\ngoogle_tag_manager['GTM-XXXX'].dataLayer.reset() purges GTM\u0026rsquo;s data model, removing all stored keys.\nPreview mode 29. Preview mode works with a cookie on www.googletagmanager.com in the preview browser When you enter GTM\u0026rsquo;s Preview Mode, you are transported through the domain www.googletagmanager.com (the same domain that serves the gtm.js library), during which a cookie is written in your browser for that domain.\n  When you then visit your website, the request for the gtm.js library identifies that you have the Preview mode cookie written on www.googletagmanager.com, and the preview container library is returned instead. So what you\u0026rsquo;re basically dealing with is a third-party cookie, even though the cookie isn\u0026rsquo;t set while browsing the site itself.\n30. Shows the state of tags, triggers, variables, and Data Layer at each Data Layer message Preview mode is a great way to understand how Google Tag Manager works. The navigation in the left column is a chronological (oldest at the bottom) list of messages that have been pushed into dataLayer. By selecting a message, you can see if any tags fired during that message, and you can see the state of tags, variables, and triggers at the time of the message.\n  What you see is what you get. If the variable does not have a value at the time of the message, it means that any tags that fire for that message will not have access to any value if using that variable. This is why it\u0026rsquo;s important to understand that if you want to use a variable, it must have a value when the message that triggers the tag is pushed into dataLayer.\n31. Summary shows the state at the latest message Summary is not a message itself. It\u0026rsquo;s a recap of what the state of the container is after the latest message has fired. Note that if you have Summary (or any other message, for that matter) selected, and you select a tag that fired in an earlier message, the tag might have different values than what you\u0026rsquo;d expect. That\u0026rsquo;s because when you select a message (or Summary), the variables reflect what their values are at the time of the selected message. This way tags can show different values from those that were actually used.\nThat\u0026rsquo;s why it\u0026rsquo;s really important to start debugging by selecting the message that fired the tag. Any other message and you might see confusing data.\n32. Variables are resolved multiple times - at least once per message If you\u0026rsquo;ve ever created a variable with side effects and then gone to preview mode, you might have been surprised at what happens. For example, create a Custom JavaScript Variable with this:\nfunction() { window._testCount = window._testCount || 1; return window.alert(window._testCount++); }  Now when you go to Preview mode, you\u0026rsquo;ll see a bunch of alerts with a number that increments with each alert. Depending on how many messages are pushed into dataLayer and how many tags use this variable, you might see a huge number in the last alert box.\nThis is because GTM resolves variables in Preview mode multiple times. Preview mode needs to resolve the variables at least once per message pushed into dataLayer. Why? Because Preview mode must be able to tell you the value of each variable in each tag, trigger, variable, and message.\nIn a live container, variables won\u0026rsquo;t be resolve this many times. Most likely they are only resolved when they are directly invoked, e.g. in triggers and tags upon injection.\n33. Preview can be minimized The Preview mode panel can be visually obstructive, so it\u0026rsquo;s a good thing the developers added a minimize button some time ago:\n  After clicking it, you can bring the panel back up by clicking the small DEBUG ^ icon in the lower right corner of the window.\n34. To quit preview, you need to exit preview mode via the GTM UI The easiest way to quit Preview mode is to go to the Google Tag Manager user interface and click the \u0026ldquo;Leave preview mode\u0026rdquo; link:\n  You can also go to your browser\u0026rsquo;s content settings, and delete all cookies written on the www.googletagmanager.com domain. This works with Shared Preview, too.\n  Wouldn\u0026rsquo;t it be handy if you could just quit Preview mode from the panel itself on the site? Yes, I think so too.\n35. To quit a shared preview, you need to follow the original link If you want to quit Preview mode that has been shared with you, you should follow the original Share Preview link and click \u0026ldquo;Exit preview and debug mode\u0026rdquo;.\n  Note that you can also delete the cookies as described in the previous tip.\n36. Problems with the preview mode not showing correctly are most typically due to CSS conflicts Sometimes you might not see a Preview mode on a website at all. Other times the panel might be buggy, such as being partly transparent or completely white.\nIn these cases, it\u0026rsquo;s most often a CSS conflict with the site code. GTM loads the panel on the website itself, so style conflicts can arise if they share the same namespace.\nIf this happens, your best bet is to contact the developer team via the Send Feedback link in the UI, or by posting the issue in the Product Forums.\n  37. You can also preview without the debug panel Note that you can also preview a container on the site without the benefit of the debug panel. Why you\u0026rsquo;d want to do this when you can minimize the debug panel escapes me, but to do so you need to click the Share Preview link in the GTM UI, uncheck \u0026ldquo;Turn on debugging when previewing\u0026rdquo;, and then follow the link in your browser. This sets your browser into Preview mode without showing the debug panel.\n  38. Preview must be refreshed after every change GTM doesn\u0026rsquo;t auto-refresh the Preview mode when you save changes in your container. You need to click the \u0026ldquo;Refresh\u0026rdquo; link to update the preview mode for yourself and anyone with the preview link.\n  Universal Analytics 39. GTM creates a new tracker with every tag instance Unlike on-page Universal Analytics (analytics.js), Google Tag Manager creates a new, unique tracker object with every single tag that fires, even if they use the same template.\n  This might not be the most elegant technical design ever, but it\u0026rsquo;s necessary in how GTM structures Universal Analytics tags. Basically each tag is its own sandbox, and settings are not shared from tag to tag.\n40. Settings are not shared across tags Because each tag has a unique tracker, no settings are shared from tag to tag. This is very much unlike on-page Universal Analytics, where you create a single tracker and then invoke that tracker in commands like ga('trackerName.send', 'pageview');.\nIf you want to share settings of a single tag with other tags, currently you need to set the Tracker Name field in the tag settings. But before you do, read the next tip.\n41. You can set a tracker name, but most often this is risky and unnecessary If you do set the Tracker Name, you are likely to run into a host of problems. First of all - ALL settings are shared across the two tags. This is because GTM sets all fields and Custom Dimension / Metrics on the tracker object itself rather than just the hit. So you\u0026rsquo;ll need to take great care to reset any fields that you don\u0026rsquo;t want values to leak into.\nUntil GTM introduces some type of shared tag settings feature, I suggest avoiding the tracker name setting and working with GTM variables instead. If you want a setting to apply across two or more tags, just replicate the setting in each tag and use a variable to populate the same value in all the tags.\n42. Use Fields to Set for setting any analytics.js fields You can use Fields to Set to set any analytics.js fields. These fields are set on the tracker object itself (see previous tip), but will work as if set on the hit itself.\nYou can also add Measurement Protocol parameters to Fields to Set, but this is, in most cases, unnecessary.\n43. If a field has the variable icon, you can use variables in it Fields in Google Tag Manager support adding a variable if the field has the variable icon next to it.\n  By clicking the icon, a list of all available variables pops up. You can also use the auto-complete feature by typing {{ into the field, after which an auto-complete menu shows, and you can continue typing to find the variable you\u0026rsquo;re looking for.\nEnhanced Ecommerce 44. Use Data Layer option uses Version 1 of the Data Layer Variable When you select the Use Data Layer option in your Enhanced Ecommerce enabled Universal Analytics tags, GTM uses the Version 1 of the Data Layer Variable to locate the most recently pushed ecommerce key from the Data Layer.\n  Read that again. GTM only has access to the most recently pushed Enhanced Ecommerce payload in dataLayer. This means that if you first push impressions, for example, but don\u0026rsquo;t fire a tag, and then you push a Product Detail View which does fire a tag, that tag will only access the Product Detail View data. The impressions data is lost in cyberspace, due to no tag firing when it was pushed to dataLayer. To avert this, either make sure you always add an event to all your Enhanced Ecommerce pushes, and always use a Custom Event Trigger to fire an Enhanced Ecommerce enable tag.\nAlternatively, you can use the far more flexible Custom JavaScript variable method.\n45. Requires Data Layer object to be syntactically flawless Enhanced Ecommerce is a bit different from how Data Layer typically works. Generally, you can push any key-value pairs into Data Layer, because you can always transform and mutate them in the GTM UI later on. However, when working with Enhanced Ecommerce, either via \u0026ldquo;Use Data Layer\u0026rdquo; or the Custom JavaScript Variable method, the payload must be syntactically accurate. It must have all the required keys, it must be structured correctly, and it must obey certain limitations to the structure (more details about structure).\nYou should always make sure you\u0026rsquo;re following the official developer guide to the letter.\n46. The Currency type is just a string with a monetary value If you read the official Enhanced Ecommerce developer guide, you might have noticed references to a type called \u0026ldquo;currency\u0026rdquo;.\n  Well, there\u0026rsquo;s no such data type in JavaScript. What the guide means is a string that has a monetary value (without currency symbol). Don\u0026rsquo;t use a thousand separator (e.g. \u0026ldquo;1 045.99\u0026rdquo;), and use the period as the decimal character.\nA valid \u0026ldquo;currency\u0026rdquo; type would be \u0026quot;1045.99\u0026quot;. Invalid types would be \u0026quot;1 045.99\u0026quot; and \u0026quot;1045,99\u0026quot;. Due to loose typing in JavaScript, you could just as well pass it as a number 1045.99, but that will definitely lead to problems if the number is incorrectly formatted.\n47. Product-scoped Custom Dimensions and Metrics need to be formatted correctly Product-scoped Custom Dimensions and Metrics need to be formatted in a certain way to work. With regular Custom Dimensions and Metrics, all you need to do is add them to the tags under the respective tag settings.\nHowever, in Enhanced Ecommerce, all the information must be in the payload. With Product-scoped Custom Dimensions and Metrics, this data must be in the products array, under each individual product you want to add the dimensions and metrics to. The dimensions and metrics must be named dimensionX and metricX where X is the index number for the given custom variable.\n{ ecommerce: { purchase: { actionField: { ... }, products: [{ id: \u0026#39;1\u0026#39;, name: \u0026#39;Shirt\u0026#39;, dimension1: \u0026#39;Red\u0026#39;, metric1: 132, quantity: 1, price: \u0026#39;10.99\u0026#39; },{ id: \u0026#39;2\u0026#39;, name: \u0026#39;Pants\u0026#39;, dimension1: \u0026#39;Black\u0026#39;, dimension2: \u0026#39;Adidas\u0026#39;, metric1: 133, quantity: 1, price: \u0026#39;13.99\u0026#39; }] } } }  48. Custom JavaScript variable method is more flexible than Use Data Layer I always implement Enhanced Ecommerce using the Custom JavaScript variable method. It gives me so much more flexibility, as I can simply create the original dataLayer object as semantically unambiguous as possible, and then use the Custom JavaScript variable to mutate the object into the state the Enhanced Ecommerce requires. Why? Because I have plenty of other platforms that need the ecommerce data, too, and they might not be happy with the way that Google Tag Manager enforces a specific structure.\nfunction() { var order = {{DLV - Order}}; return { ecommerce: { purchase: { actionField: { id: order.orderId, revenue: order.price.totalWithTax, tax: order.price.taxValue, affiliation: order.store.name }, products: [order.productsForGTM] } } }; }    The Custom JavaScript variable itself is simple. All you need to do is make sure it returns a valid Enhanced Ecommerce object as required by Google Tag Manager.\nTriggers 49. Variables can only be used to check against This is perhaps slightly oddly worded, but what I mean is that you can only use a variable as the thing in the trigger whose value you are checking. You can\u0026rsquo;t use a variable as the condition value itself.\n  50. Use a Custom JavaScript variable to check for dynamic values If you DO want to check against dynamic values in your triggers, you can always use a Custom JavaScript variable. Let\u0026rsquo;s say you want to check if the clicked URL contains the current page hostname. Why? Because you want a trigger that fires only for clicks on links that take the user away from the website. This is what the Custom JavaScript variable might look like:\nfunction() { return {{Click URL}}.indexOf({{Page Hostname}}) \u0026gt; -1; }  This variable returns true if the clicked URL contains the current page hostname, and false otherwise. Now you can use a trigger like this:\n  51. 'event' is implicit in all but the Custom Event trigger All triggers require an event key in dataLayer to fire. Thus, when you create a trigger, they check for the value of event, and if there\u0026rsquo;s a match the trigger fires. Only the Custom Event trigger requires you to explicitly state the value of event you want to fire against. Here are the basic trigger types and their implicit event values:\n DOM Ready - gtm.dom\n Page View - gtm.js\n Window Loaded - gtm.load\n Click / All Elements - gtm.click\n Click / Just Links - gtm.linkClick\n Form submission - gtm.formSubmit\n History Change - gtm.historyChange\n JavaScript Error - gtm.pageError\n Timer - gtm.timer\n Scroll Depth - gtm.scrollDepth\n YouTube Video - gtm.video\n  52. Multiple trigger conditions are AND, multiple triggers are OR Multiple conditions in a single trigger must ALL match for the trigger to fire. Thus a trigger like this should never work:\n  Why won\u0026rsquo;t it work? Because the hostname of the current page can\u0026rsquo;t be two things at once.\nIf you add multiple triggers to a tag, then any one of these will fire the tag. So, if you want your tag to fire when the page hostname is either www.domain.com or www.other-domain.com, you can create two triggers, one for each hostname, and add both to the tag.\n53. Use regular expressions or Custom JavaScript variables to add optionality in a single trigger There\u0026rsquo;s an easier way to introduce optionality, though. First, if it\u0026rsquo;s a simple string check, you can always use regular expressions.\n  If you have more complex logic, a Custom JavaScript variable is your best friend, again.\nfunction() { var hn = {{Page Hostname}}, ut = {{DLV - userType}}; if (hn === \u0026#39;www.mydomain.com\u0026#39; \u0026amp;\u0026amp; ut === \u0026#39;visitor\u0026#39;) { return \u0026#39;visitor\u0026#39;; } if (hn === \u0026#39;www.mydomain.com\u0026#39; \u0026amp;\u0026amp; ut === \u0026#39;member\u0026#39;) { return \u0026#39;member\u0026#39;; } if (hn === \u0026#39;www.other-domain.com\u0026#39; \u0026amp;\u0026amp; ut === \u0026#39;loyal\u0026#39;) { return \u0026#39;loyal\u0026#39;; } return \u0026#39;other\u0026#39;; }  Auto-event trigger 54. Just Links listens to clicks on \u0026lt;a\u0026gt; elements and their descendants When you create a Just Links trigger, it listens to clicks on \u0026lt;a\u0026gt; elements and their descendants. When a click is registered, Google Tag Manager checks if there is a link node wrapping the clicked element, and if there is, GTM stores a reference to the link in the dataLayer.\nFor example, say the page HTML looks like this:\n\u0026lt;div id=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;https://www.google.com/\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Google\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; If someone clicks on the link, the click actually falls on the \u0026lt;span\u0026gt; element, but the Just Links trigger propagates the click to the \u0026lt;a\u0026gt; element, and returns that for you to leverage with Auto-event variables.\n55. All Elements listens to all clicks All Elements, on the other hand, listens to all clicks and returns the element that was actually clicked. In the HTML example above, the All Elements trigger would return the \u0026lt;span\u0026gt; element because that\u0026rsquo;s the element that was actually clicked.\n56. Form listens to a submit event dispatched by a \u0026lt;form\u0026gt; element The Form trigger only works with an actual \u0026lt;form\u0026gt; element submitted with default HTML form functionality. This means that there actually needs to be a submit event dispatched by the form, and it must be allowed to bubble up.\nAny custom server-side validation, suppressing of the submit event, or customized form handling will result in the Form trigger not working. Thus, the Form trigger is typically the trigger you\u0026rsquo;ll have the most difficulties with due to the ridiculously diverse number of ways that forms can be handled with JavaScript.\n57. History Change listens to interactions with the browser history API The History Change trigger listens for the following browser history API events: hashchange, pushState, replaceState and popstate.\nTypically these are used on single-page websites, where page transitions are done without a page refresh.\nWhen creating History Change triggers, you\u0026rsquo;ll typically want to work mainly with pushState and replaceState, as those are managed by the by the site code itself. popstate and hashchange can be triggered automatically by the web browser (and there are differences between browsers), which might lead to inaccuracies in your tracking.\n58. Error listens to uncaught JavaScript exceptions The Error triggers listens to uncaught JavaScript errors that occur on the website. If there\u0026rsquo;s a try...catch block anywhere in the error path, this trigger will not react to it.\nDo note that Custom JavaScript variables automatically catch all exceptions, so this trigger will not help you debug errors in Custom JavaScript variables.\n59. All triggers but the Click / All Elements trigger require that the original event bubble up Google Tag Manager attaches its auto-event listeners to the document element of the page. This is the highest node in the web document. The reason GTM does this is because it allows you to handle events that take place anywhere on the page, even for elements that don\u0026rsquo;t exist when GTM first loads.\nFor this type of event delegation to work, the event must bubble up to the top of the document. It\u0026rsquo;s surprising how often bubbling is cancelled, leading to GTM\u0026rsquo;s events not working.\nThe only exception is the All Elements trigger, which uses the capture phase of the event path. This means that even if bubbling is stopped, the capture phase can still record the click. So if you find your Just Links trigger isn\u0026rsquo;t working, you can recreate the same logic with an All Elements trigger and some clever CSS selector / Custom JavaScript variable work.\nFor more information, see e.g. this article on GTM listener issues, and this on element capturing with the All Elements trigger.\n60. Check Validation checks for event.preventDefault() If you have Check Validation checked in your Just Links or Form trigger, the trigger will only fire if the event\u0026rsquo;s default action is not cancelled.\n  This is a useful feature to leverage, since often the default action of a link (redirect) or a form (submit) is prevented due to the link simply changing a content tab, or the form being incorrectly filled, for example. In these cases, you\u0026rsquo;ll want to have Check Validation checked, because you probably don\u0026rsquo;t want to track clicks on links that don\u0026rsquo;t redirect or submissions of forms that don\u0026rsquo;t actually submit.\n61. Wait for Tags pauses the original event, but be careful If you use the Wait for Tags option in the Just Links or Form triggers, Google Tag Manager halts the action of the link or form, respectively, to wait until all tags that use the trigger have fired. After tags signal completion, GTM allows the original event to continue.\nThis is a great feature. It mitigates the risk of losing data due to the link or form redirecting the user to a new page before the tags that use the trigger have fired.\nHowever, there are many ways to do custom link redirects and form submissions. When GTM pauses the event, it\u0026rsquo;s not 100% reliable GTM understands what the custom behavior was. Thus, when GTM then proceeds with the paused action, it might be a different action altogether that GTM resumes.\nThis is typical in single-page apps, where internal links have a lot of complex logic added to them to prevent links from redirecting the user to new URLs.\nSo, when you use the Wait for Tags option, always remember to test the pages where the trigger is active. Test links and forms, both, to make sure that their functionalities are not compromised. If you are in doubt, simply uncheck Wait for Tags and accept a certain level of inaccuracy in your tracking.\n62. Enable this trigger when\u0026hellip; vs. This trigger fires on\u0026hellip; If you do check Wait for Tags or Check Validation, you\u0026rsquo;ll see the \u0026ldquo;Enable this trigger when\u0026hellip;\u0026rdquo; option appear in the trigger settings.\n  The \u0026ldquo;Enable this trigger when\u0026hellip;\u0026rdquo; option is for determining on which pages the trigger should listen to actions. Thus you can use it to have the trigger listen only on pages where you have thoroughly tested the trigger doesn\u0026rsquo;t mess with site functionality.\nIt\u0026rsquo;s a good idea to start with a generic Page URL contains / condition here, as it will simply set the trigger to listen to user actions on all pages of the site. If you do run into trouble, you can modify this condition to only activate the trigger on a specific subset of pages.\nThe \u0026ldquo;This trigger fires on\u0026hellip;\u0026rdquo; option is for determining what conditions OTHER than the trigger event itself need to exist for any tags which use the trigger to fire. This is where you\u0026rsquo;ll add your \u0026ldquo;Click URL\u0026rdquo; and \u0026ldquo;Form ID\u0026rdquo; conditions, for example.\n63. Data Layer object composition of an auto-event When an auto-event trigger fires, the following items are pushed into dataLayer:\n event - gets the value of the trigger event that was registered.\n gtm.element - reference to the HTML element that was the target of the event.\n gtm.elementClasses - string with the value from the class attribute of the target element (if any).\n gtm.elementId - string with the value from the id attribute of the target element (if any).\n gtm.elementTarget - string with the value from the target attribute of the target element (if any).\n gtm.elementUrl - string with the value from the href or action attribute of the target element (if any).\n gtm.triggers - a regular expression which determines if the trigger that activated is enabled on the current page.\n  In addition to these, you might see variables like gtm.uniqueEventId, eventCallback, eventTimeout and eventReporter. These are internal to GTM, but suffice to say that they govern how the Wait for Tags option works, among other things.\n64. Auto-event variable If you\u0026rsquo;re not satisfied with the Built-in variables (Click / Form) for auto-events, you can create your own. Google Tag Manager has a user-defined variable type called Auto-Event Variable, which lets you analyse pretty much any part of the auto-event target element you want.\nFor example, if you\u0026rsquo;ve added a custom data attribute data-gtm-cta=\u0026quot;Subscribe call to action\u0026quot;, and you want to check if the clicked link has this data attribute, you can create a new Auto-Event Variable that looks like this:\n  This comes in very handy, as you won\u0026rsquo;t be limited to the rather small number of available built-in variables.\n65. Matches CSS selector with the Click / Form Element built-in variable The matches CSS selector is one of the most effective ways you can create triggers in Google Tag Manager. When combined with the Click / Form Element Built-in variable, it gains a whole new level of awesomeness.\nYou can write complex CSS selectors to check whether the element that was the target of the auto-event matches what you expect. For example, let\u0026rsquo;s say you have the following HTML structure:\n\u0026lt;div id=\u0026#34;products\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;a href=\u0026#34;some-product.html\u0026#34;\u0026gt;Product/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;services\u0026#34;\u0026gt; \u0026lt;div\u0026gt; \u0026lt;div\u0026gt; \u0026lt;a href=\u0026#34;some-service.html\u0026#34;\u0026gt;Service\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Now, you only want your Just Links trigger to fire when the user clicks the \u0026ldquo;Product\u0026rdquo; link. However, as you can see, the HTML structures between \u0026ldquo;Product\u0026rdquo; and \u0026ldquo;Service\u0026rdquo; are almost identical, making it difficult to pinpoint the exact element without having to resort to suboptimal selection mechanisms. Well, CSS selectors to the rescue. The following Just Links trigger will only fire when the click is on a link that is the descendant of a div with the id \u0026quot;products\u0026quot;:\n  Just remember: matches CSS selector only works against an HTML element. So don\u0026rsquo;t try to match a selector against the Click ID or Click URL variables, for example. Only Click / Form Element will do.\nCustom HTML tags 66. Code is automatically minified Custom HTML tags automatically minify / uglify the JavaScript, so no need to do so yourself.\n  67. Code is injected to the end of \u0026lt;body\u0026gt; When you write HTML code in a Custom HTML tag, the entire code block is always injected to the end of \u0026lt;body\u0026gt; when the trigger fires for the tag.\nIf you want to place the HTML code somewhere else, you need to write JavaScript (within the Custom HTML tag) that creates a new HTML element with your specifications, and then uses DOM methods to place it wherever you like on the page.\n68. Can be used to add any HTML elements You can use the Custom HTML tag to add any supported HTML5 code to the page. This means that tags such as these are all supported: meta, link, style, video, script, and so forth.\nNaturally, with some JavaScript DOM magic, you can also modify existing elements or even remove them entirely from the page.\n69. The document.write option is fixed to prevent the site from breaking If you are adding a script which makes use of document.write to place elements on the page, you will need to check the \u0026ldquo;Support document.write\u0026rdquo; option in the Custom HTML tag editor.\n  If you don\u0026rsquo;t check this option, you run the risk of the document.write command clearing the entire page of all contents because of how document.write works post-page-load.\nDan Wilkerson has written a great guest post on this topic, so remember to check it out for more information.\n70. Variables are automatically renamed in Custom HTML tags, too Did you know that when you create a variable reference in GTM with {{Variable Name}} and you then change the variable name to {{Some Other Variable Name}}, all references are automatically updated?\nWell this applies to Custom HTML tags, too, so you don\u0026rsquo;t have to worry about syntax errors when renaming variables. The new name will be automatically applied to all places in the container where the variable is referred to.\nBuilt-in variables 71. Need to be enabled The only Built-in Variables enabled by default in your web container are Event, Page URL, Page Path, Page Hostname and Referrer.\nTo enable others, go to Variables and click the red CONFIGURE under the heading \u0026ldquo;Built-In Variables\u0026rdquo;.\n  In the overlay that flies out, check the box next to each Built-in variable you want to enable. Only after enabling the variables will they be available in variable selection drop-downs.\n72. Click and Form variables are copies of each other You might have noticed that there\u0026rsquo;s a very similar set of six auto-event Built-in variables: Click/Form Element, Click/Form ID, Click/Form URL, Click/Form Target, Click/Form Classes, Click/Form Text.\nThese are identical in functionality, so you really only need to enable either Click or Form Built-in variables.\nCustom JavaScript variables 73. Must be anonymous functions When you create a Custom JavaScript variable, it should be an anonymous function. Yes, you can name it, but it doesn\u0026rsquo;t matter since there\u0026rsquo;s no way to call the variable with its name, as it\u0026rsquo;s locally scoped to whatever execution context invokes the variable when your container needs to do so.\n// Not ideal: function clickTextLowercase() { return {{Click Text}}.toLowerCase(); } // Use this: function() { return {{Click Text}}.toLowerCase(); }  To avoid any potential namespace conflicts, just use an anonymous function, since you call GTM\u0026rsquo;s variables with the syntax and not with whatever name you give the method itself.\n74. Must have a return statement All Custom JavaScript variables must have a return statement or Google Tag Manager will throw an error when you try to create a version of the container.\n// Will not work: function() { if (true) {} } // Works: function() { if (true) {} return; }  75. Can be used to return another function Remember that a Custom JavaScript variable is just regular JavaScript, and as such you can use it to return another function. This is also called returning a closure.\nFor example, let\u0026rsquo;s say I want to create a utility function that takes a string as an argument and reverses all letters in it. First, I\u0026rsquo;d create a Custom JavaScript variable like this:\nfunction() { return function(str) { return str.split(\u0026#39;\u0026#39;).reverse().join(\u0026#39;\u0026#39;); }; }  Then, when I want to use this utility in a Custom HTML tag or another variable, I can pass any string to the GTM variable as an attribute:\n\u0026lt;script\u0026gt; (function() { // Create a reference to the Custom JavaScript variable we just created  var reverseString = {{JS - ReverseString}} window.dataLayer.push({ event: \u0026#39;reverseComplete\u0026#39;, reversedString: reverseString(\u0026#34;Reverse me!\u0026#34;) }); })(); \u0026lt;/script\u0026gt; This Custom HTML tag calls the function returned by the Custom JavaScript variable with the string \u0026ldquo;Reverse me!\u0026rdquo;, resulting in a dataLayer.push() where the key reversedString will have the value \u0026ldquo;!em esreveR\u0026rdquo;.\n76. Should avoid side effects Custom JavaScript variables should avoid side effects. In other words, they shouldn\u0026rsquo;t do anything except process an input and produce an output. Any transformations or mutations should happen in local scope alone.\nIf you don\u0026rsquo;t respect this, you might run into all sorts of issues due to the fact that Google Tag Manager\u0026rsquo;s resolution of variables is unpredictable and can\u0026rsquo;t be counted on to only happen once per tag.\nHere are some things to avoid:\n Modifying, creating, or deleting items in the global window namespace.\n Creating or processing custom HTTP requests.\n Setting or removing items in globally available APIs, such as dataLayer, google_tag_manager, document.cookie and localStorage.\n  If you do want to modify global state, use Custom HTML tags or closures instead.\n77. Can refer to other variables This might seem like a no-brainer, but you can freely refer to other variables in Custom JavaScript variables, too.\nfunction() { var hostname = {{Page Hostname}}; return hostname === \u0026#39;www.domain.com\u0026#39; ? \u0026#39;Main domain\u0026#39; : \u0026#39;Other domain\u0026#39;; }  Tag sequencing 78. Setup and cleanup are fired with the main tag, regardless of their own triggers When you add a Setup or Cleanup tag to a sequence with a main tag, the Setup and Cleanup will be fired with the main tag regardless of what triggers they might actually have themselves.\nSo here\u0026rsquo;s a tip: When creating Setup and Cleanup tags, use them only for that purpose and do not add any triggers to them. This way you will never run the risk of these tags firing when they shouldn\u0026rsquo;t, as they are strictly bound to whatever sequence they are in.\n79. Use onHtmlSuccess() and onHtmlFailure() to signal that the sequence can continue When you have a Custom HTML tag as a Setup or Main tag, you can let Google Tag Manager know if the tag completed successfully or failed by using the onHtmlSuccess() and onHtmlFailure() methods.\nFor these to work, you first need to enable Built-in variables Container ID and HTML ID.\nHere\u0026rsquo;s an example of a Custom HTML Setup tag, where we wait for the asynchronous POST request to complete before telling GTM to continue to the main tag. If the asynchronous request fails, we tell GTM that the Setup tag was a failure.\n\u0026lt;script\u0026gt; (function($) { $.post(\u0026#39;/test.php\u0026#39;) .done(function() { google_tag_manager[{{Container ID}}].onHtmlSuccess({{HTML ID}}); }) .fail(function() { google_tag_manager[{{Container ID}}].onHtmlFailure({{HTML ID}}); }); })(jQuery); \u0026lt;/script\u0026gt; If you didn\u0026rsquo;t have the onHtmlSuccess/Failure() methods there, Google Tag Manager would simply signal completion as soon as it reaches the last line of code in the tag. Thus the browser won\u0026rsquo;t wait for any asynchronous requests to complete, and you might end up with a nasty race condition if you need the request to complete before proceeding with the Main tag.\n80. Use dataLayer.set() to change Data Layer variable values mid-sequence If you want to change some value in GTM\u0026rsquo;s Data Layer while in the middle of a sequence, you can\u0026rsquo;t use dataLayer.push(), because GTM freezes its state for the duration of each message that is pushed into dataLayer.\nHowever, there\u0026rsquo;s a workaround. You CAN update the value of GTM\u0026rsquo;s Data Layer variables, even though the same dataLayer message is still being processed. To do this, you need to use the google_tag_manager[{{Container ID}}].dataLayer.set('keyName', 'value') interface you learned of here.\nTag settings 81. Once per page is once per page load, once per event is once per GTM event There are three options in the Tag firing options menu that you can find at the end of each tag\u0026rsquo;s settings.\n  Unlimited means the tag will fire whenever its triggers fire - no restrictions.\nOnce per event means that the tag will fire just once per the trigger event that caused it to fire. Thus if you have, for example, multiple Click triggers attached to the tag, and there\u0026rsquo;s a chance that some of these have overlapping trigger conditions, Once per event ensures that the tag fires just once per click.\nOnce per page means that the tag will fire only once per page load. No matter what triggers you have attached to it - if the tag fires on the page, it will not fire again until the page is reloaded from the web server. Tag Sequencing respects this, too, so if a Setup or Cleanup tag are set to fire just once per page, they will not fire multiple times even if the main tag does.\n82. Tag priority is for a single GTM event - doesn\u0026rsquo;t necessarily mean tags are completed in the given order The Tag priority field can be used to establish an order execution for tags that fire on the same trigger event. When a trigger event happens, Google Tag Manager executes tags in order of priority.\nNote that Tag priority only establishes the order in which tags begin execution. It has no implications on when they complete. Thus, even if a tag starts its execution first, it might have a long, complex, asynchronous process involved, and it still ends up completing only after tags later in the priority order have already finished.\nWorkspaces 83. You will always have at least one workspace Workspaces have come to stay, and it\u0026rsquo;s impossible to use Google Tag Manager without a workspace.\nThus, even if you try to delete all workspaces, GTM will always leave you with one.\n84. When you create a version out of a workspace, that workspace is deleted Workspaces are ephemeral - they only exist until a version is created from them. Once you create a version, it\u0026rsquo;s as if the workspace never existed. Thus workspaces shouldn\u0026rsquo;t be used as permanent container subsets that you could, for example, delegate to a certain user group only. Instead, workspaces should be approached as branches of a version control system. When you start working on a new feature, create a workspace first so that any changes you make are contained until you choose to create a version and merge the changes to the latest container version.\n85. You don\u0026rsquo;t have to update your workspace until you are ready to create a version When someone else updates the latest container version, all the workspaces in the container need to be updated. You\u0026rsquo;ll know this has happened when you see the following notice in the GTM UI:\n  You don\u0026rsquo;t have to update the workspace the minute you see this warning. You can bide your time, and only sync the changes once you are ready to create a version out of your workspace.\nNevertheless, the sooner you update the better. Why? Because once merges start piling up, you\u0026rsquo;ll have a hard time resolving all the conflicts at once.\nAMP container 86. No Custom JavaScript or Custom HTML Accelerated Mobile Pages place some pretty strict restrictions on what you can use Google Tag Manager for. You can\u0026rsquo;t execute arbitrary JavaScript code anymore, nor can you simply inject HTML via Google Tag Manager. In fact, all dynamic operations need to be handled server-side in GTM, because all that GTM returns is the AMP configuration JSON object, which has very limited capabilities for any advanced tracking.\nSo no Custom JavaScript variables or Custom HTML tags in the AMP container, unfortunately.\n87. AMP is very restricting As said, AMP is very restricting. Only JavaScript sanctioned by AMP and provided as an AMP module can be executed. This means that the development of the GTM AMP container is bound very closely to the roadmap of AMP itself. Any attempts to deviate would result in an invalid configuration JSON, which would, in turn, lead to an invalid AMP page.\nIt\u0026rsquo;s a good idea to closely follow the amp-analytics project, as it contains the latest release details for the amp-analytics module. This is the module used by Google Tag Manager\u0026rsquo;s AMP container.\n88. Client ID is (currently) ambiguous Universal Analytics\u0026rsquo; Client ID is problematic with AMP, especially when run through the GTM container. There are actually four different Client ID scenarios for AMP analytics.\n When visiting the regular site (no AMP): _ga cookie stores the Universal Analytics Client ID.\n When visiting the regular site (AMP): AMP_ECID_GOOGLE cookie stores a randomly generated AMP Client ID.\n When visiting the site via the AMP cache: the AMP client ID is stored in localStorage on the ampproject.org domain.\n When visiting the site via Google search: the AMP client ID is stored on google.com and ampproject.org in localStorage.\n  In all of these scenarios, it\u0026rsquo;s possible that the Client ID is different, which means that you\u0026rsquo;ll have quite a bit of difficulty in tracking the same user across AMP and non-AMP sites, or between Google search and direct access to the site.\nSome time ago, Dan Wilkerson and I wrote a hack around this, which does require some web server muscle, but it will make sure that all the scenarios above use the same Universal Analytics client ID in the _ga cookie.\n89. New triggers, e.g. scroll AMP introduces a bunch of really useful triggers, which I hope we\u0026rsquo;ll see in GTM for web soon, too.\n  Since you can\u0026rsquo;t execute arbitrary JavaScript, AMP provides stuff like scroll and visibility tracking out-of-the-box with amp-analytics. Google Tag Manager gives you a way to easily configure the triggers, but it should be noted that there\u0026rsquo;s not much room to configure the triggers. AMP is restricted in this way, too.\n  For example, I would like to configure the scroll trigger to track scroll-to-element rather than scroll-to-percentage. Unfortunately, this is not possible.\n90. Can be augmented with the on-page JSON configuration Remember that even if you use the AMP Google Tag Manager container, you can also add a JSON configuration block to the page. You can use this extra configuration to complement the tracking you setup via Google Tag Manager.\n... \u0026lt;!-- AMP Analytics --\u0026gt;\u0026lt;script async custom-element=\u0026#34;amp-analytics\u0026#34; src=\u0026#34;https://cdn.ampproject.org/v0/amp-analytics-0.1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;amp-analytics config=\u0026#34;https://www.googletagmanager.com/amp.json?id=GTM-XXXXX\u0026amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt;\u0026lt;/amp-analytics\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;pageType\u0026#34;: \u0026#34;profile\u0026#34;, \u0026#34;userType\u0026#34;: \u0026#34;member\u0026#34; } } \u0026lt;/script\u0026gt; This is a pretty simple way to add some web server logic to your GTM AMP container.\nGTM for mobile 91. Not the same as GTM for web Let\u0026rsquo;s address the elephant in the room first. If AMP was restricted, then GTM for mobile is doubly so. Why? Because you\u0026rsquo;re no longer working with a website that self-corrects any JavaScript mistakes you happen to have in the site code. When working with mobile apps, the app needs to be well-formed without exceptions, and you can\u0026rsquo;t add runtime code to it without it being sanctioned by the platform the app is running on.\nAlso, since this isn\u0026rsquo;t the web anymore, there\u0026rsquo;s no \u0026ldquo;Custom HTML\u0026rdquo; or \u0026ldquo;Custom JavaScript\u0026rdquo; here, either. Android apps use Java, and iOS relies on Swift and Objective-C.\nDue to these restrictions, it\u0026rsquo;s a valid concern to raise whether you need Google Tag Manager at all. It takes pretty much the same effort as simply using the analytics SDK directly.\n  The benefit of using GTM is that it will always leverage the latest analytics SDKs. Also, with the Firebase integration you have access to the entire Firebase suite of services, and most of them are really useful for app developers.\nFinally, GTM is still GTM. You can implement tracking tags without having to worry too much about how the app itself works. Support for different tag templates isn\u0026rsquo;t too impressive yet, but this will surely change in the future.\n92. An SDK you need to download and add to the project Google Tag Manager isn\u0026rsquo;t a container file that is just fetched from the web and then everything works nicely. No, it\u0026rsquo;s actually a combination of SDKs (software development kit) and container binaries / JSON files that you need to integrate into the app itself.\nWith the latest version of Google Tag Manager for mobile (Firebase), implementing GTM to a project is really simple. You basically need to include just two podfiles: Firebase/Core and GoogleTagManager. The rest is added automatically via dependencies.\n  The app fetches the latest container version if a \u0026ldquo;fresh\u0026rdquo; container is available. You can\u0026rsquo;t always trust that a fresh container can be fetched, so it\u0026rsquo;s a good idea to always keep a recent version of the container in the app assets. So, when publishing a new release of the app, make sure to check if there\u0026rsquo;s an updated container version that needs to be added to the project before going live.\n93. GA tracker object is not exposed Google Tag Manager doesn\u0026rsquo;t expose the GA tracker object in the same way that GTM for web does. In other words, if you want to check what the user\u0026rsquo;s Client ID is, for example, there\u0026rsquo;s no command that lets you dig that information from the available GTM interfaces.\nA hacky but working solution in these cases is to create a dummy tracker using the regular Google Analytics SDK, and mining tracker-specific information from this to be used in your Google Tag Manager setup.\n94. GTM legacy uses dataLayer GTM for mobile, before Firebase, is now called \u0026ldquo;Legacy\u0026rdquo;. If you\u0026rsquo;re used to GTM for web, the legacy SDK should be quite familiar to you, since it also uses a dataLayer construct to pass messages to Google Tag Manager. As before, there is the event key you need to use to fire the triggers, and there are Data Layer Variables you can use to access values in this message queue.\n  Note that unlike with GTM for web, there is no differentiation between dataLayer the message queue and GTM\u0026rsquo;s internal data model. The dataLayer structure acts as both.\n95. Latest version of GTM for mobile uses Firebase The most recent incarnation of GTM for mobile uses Firebase. Firebase is a cloud-based application framework that provides a number of services your apps can use, such as Firebase Analytics.\n  When you want to use GTM with Firebase, you need to actually use Firebase. You add tracking using regular Firebase Analytics tracking methods, which means that unless you use GTM to radically change the tracking, you will end up using Firebase Analytics in addition to the other analytics tools you want to track via Google Tag Manager.\n96. You can intercept Firebase events using GTM The way that Google Tag Manager works with Firebase is that it listens to all the events you log into Firebase. Once it detects an event, it goes through the triggers and tags you\u0026rsquo;ve configured in the container, and if a tag is set to fire on a specific Firebase event, it will go off.\n  And as with Google Tag Manager for web, the more tag endpoints you have, the more useful GTM becomes. You can use a single event stream (the logged Firebase events) to send data to multiple endpoints, such as Google Analytics, Firebase, and AppsFlyer.\n97. Firebase GTM has (imperfect) support for GA Enhanced Ecommerce At the time of writing, you can\u0026rsquo;t configure Universal Analytics Ecommerce tags via Firebase GTM. The reason is that GTM\u0026rsquo;s data model does not support array structures, which is how you\u0026rsquo;d need to send product data to Google Analytics.\nHopefully we\u0026rsquo;ll see support for Ecommerce soon. Until then, if you need to collect Ecommerce data to Google Analytics, you might want to use the GTM Legacy SDK or GA SDK.\nUpdate: Support for Enhanced Ecommerce has finally reached Firebase (iOS and Android). Still missing product-scoped custom dimensions and metrics, though! (Thanks Yuhui for the tip in the comments).\nOther stuff 98. Debugging is a complex process End-to-end debugging with Google Tag Manager isn\u0026rsquo;t just a case of opening up Preview mode and being satisfied with what you see. It\u0026rsquo;s a complex process, involving not only front-end conflicts in your site code, but also things like race conditions, unresponsive tag endpoints, and dataLayer automated tests.\nI recommend you take a look at this article: #GTMTips: Debugging Tag Execution Properly. Make sure you familiarize yourself with the Network tab of your browser\u0026rsquo;s developer tools. If Preview mode says that your tags fire but you don\u0026rsquo;t see any evidence in the endpoint you are looking at (e.g. Google Analytics reports), take a look at the Network tab to see if you are dispatching hits to /collect correctly. Google Tag Assistant Recordings is your friend, too, for all Google-related tagging issues.\nFinally, I recommend adding dataLayer to your organization\u0026rsquo;s quality assurance process. This would mean writing unit tests and browser tests that verify dataLayer has a predictable composition with each new release of the site or app. I\u0026rsquo;ve written a simple framework for running automated tests against dataLayer, and you can read about it here.\n99. Load sequence of GTM\u0026rsquo;s default events is important to understand When Google Tag Manager loads on a site, it pushes three default events into dataLayer: gtm.js, gtm.dom and gtm.load.\ngtm.js is pushed in the container snippet itself. Thus it introduces a state which contains all the Data Layer variables pushed before or at the time when the container snippet runs. This event is used by the Page View trigger. In other words, if you have tags that fire on the Page View trigger (or All Pages), any Data Layer variables you want to use need to be pushed into dataLayer before the container snippet is executed by the browser. Typically this means to physically add your dataLayer initialization in the page template above the GTM container snippet.\n\u0026lt;script\u0026gt; // Always use this syntax to initialize dataLayer  window.dataLayer = window.dataLayer || []; window.dataLayer.push({ userType: \u0026#39;member\u0026#39;, loyaltyLevel: \u0026#39;premium\u0026#39; }); \u0026lt;/script\u0026gt; ... \u0026lt;script\u0026gt; // GTM container snippet here \u0026lt;/script\u0026gt; gtm.dom is pushed into dataLayer when the browser signals the DOMContentLoaded event has taken place. This browser event happens when the browser has read the HTML template and built the Document Object Model (DOM) using the structure within. Thus, if you have tags which refer to DOM elements, you might want to make sure they don\u0026rsquo;t fire before the gtm.dom event. The trigger which uses this event is DOM Ready, so any tags firing on this trigger will have access to any elements described in the page HTML.\ngtm.load is pushed into dataLayer when the browser signals the load event, which means that the entire page, and all linked assets such as images, scripts (both asynchronous and synchronous), and videos have completed downloading. This is the event you\u0026rsquo;d need to use if you want your tags to access the result of some asynchronous process, such as the download of the jQuery library (if downloaded asynchronously, as you should). The trigger which uses this event is Window Loaded.\nIt\u0026rsquo;s important to understand how these three events work. They are not fired at the exact time the underlying browser event takes place. For example, gtm.js will fire triggers only after the GTM library has downloaded, and this might be seconds after the browser originally reads the event in the page template. Thus these events don\u0026rsquo;t describe the time something happens but rather the state. gtm.js describes the state of GTM\u0026rsquo;s data when the container snippet was first read by the browser, gtm.dom reflects GTM\u0026rsquo;s state when the browser signalled DOMContentLoaded, and gtm.load is the state of GTM when the entire page had completed loading.\n100. Some ad and content blockers block GTM from loading Call it a feature or symptom of today\u0026rsquo;s web browsing behavior, but ad and content blockers are making life for web analysts difficult. Firefox, for example, offers Tracking Protection out-of-the-box, and it blocks Google Analytics by default.\nPopular browser extensions like Ghostery and AdBlock Plus make it easy to block Google Tag Manager, too.\nWhether you like this or not, it\u0026rsquo;s a common practice and you should therefore accept a certain level of inaccuracy in your data.\nWith Google Tag Manager, however, you can actively modify and extend the site experience with Custom JavaScript. If the user\u0026rsquo;s browser doesn\u0026rsquo;t load Google Tag Manager, these modifications will not be executed.\nThus, be very wary of potential GTM blocking when running code via Google Tag Manager. Never rely on GTM to handle your link redirects or form submissions, and never use GTM to fix on-site issues that should be fixed in front-end code. You are depriving an ever-increasing subset of your visitors of a full experience, and at worst destroying the site user experience altogether for them.\n101. Use undefined to clear individual keys from Data Layer (upepo mwindaji) The first guest tip comes from upepo mwindaji. You can clear individual values from GTM\u0026rsquo;s data model by pushing the keys with the value undefined. This effectively resets the value of the key.\nwindow.dataLayer.push({ event: \u0026#39;userLoggedOut\u0026#39;, loginStatus: \u0026#39;loggedOut\u0026#39;, userId: undefined, memberStatus: undefined });  The code above, for example, clears the values of userId and memberStatus from GTM\u0026rsquo;s data model because the user logged out.\n102. You can track to multiple Universal Analytics properties in the same container This guest tip is from samgabell. Since GTM creates a unique tracker with every Universal Analytics tag, you can freely track to multiple Universal Analytics properties in the same container. There will be no interference between sets of tags tracking to different properties.\nThe only thing that will cause issues is if one set of tags is configured for cross-domain tracking with the allowLinker field set to true. In this case, a linker parameter in the URL will overwrite the Client ID stored in the _ga cookie, impacting all trackers on the site - even those that should ignore cross-domain tracking. You can read about a solution to this issue here.\nSummary So that was my 100 tips. Some of them were indeed very simple and obvious, but I\u0026rsquo;ve run into enough people having issues with all of the things covered here to justify my adding them to the list.\nGoogle Tag Manager turns 5 years old this year. It\u0026rsquo;s been a colorful journey, and I\u0026rsquo;m sure the popularity of the tool has changed the landscape for all tag management solutions for the better. Via GTM, so many new people have had the pleasure to (or have been forced to) get acquainted with the wonderful world of JavaScript, and have thus accumulated new skills to help them on their digital journeys.\nNow is your turn - are there invaluable tips that you\u0026rsquo;d want to share with the readers? I\u0026rsquo;d love to add them to the end of the list. Thank you!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/mixcloud-player-integration-google-tag-manager/",
	"title": "Mixcloud Player Tracking In Google Tag Manager",
	"tags": ["api", "Google Tag Manager", "JavaScript", "mixcloud"],
	"description": "How to setup embedded MixCloud player tracking in Google Tag Manager.",
	"content": " A couple of years ago I wrote an article on tracking interactions with the SoundCloud widget via Google Tag Manager. When a platform provides a JavaScript embed API, it\u0026rsquo;s surprisingly easy to track interactions with the player. You\u0026rsquo;ve seen this with YouTube, with SoundCloud, with JWPlayer, and now you\u0026rsquo;ll see how to do this with the Mixcloud player.\n  If you don\u0026rsquo;t know what Mixcloud is, well it\u0026rsquo;s a hugely popular streaming service for DJs, podcasts, radio shows, and other published radio media. Since they offer a handy embed solution for any show you like, it makes sense to start tracking if people are actually using the widget, right?\nHow to set it up First, you need to add the player widget to your site. To do this, select the show you want to embed, and click the Share button.\nAn overlay should open with both a Share and an Embed option. Choose the latter.\nSetup the player visuals however you wish. Once you\u0026rsquo;re done, uncheck the box next to Wordpress, after which the text box should contain an iframe embed tag.\n  This iframe tag is what you need to add to your website. It\u0026rsquo;s important that you use the exact format provided, so that the JavaScript API works without any problems.\nOne thing you\u0026rsquo;ll want to add to the tag, however, is a unique ID attribute. This makes it MUCH easier to target the correct player. So, if the iframe looks like this:\n\u0026lt;iframe width=\u0026#34;100%\u0026#34; height=\u0026#34;60\u0026#34; src=\u0026#34;https://www.mixcloud.com/widget/iframe/?feed=https%3A%2F%2Fwww.mixcloud.com%2Fdj_umek%2Fbehind-the-iron-curtain-with-umek-episode-294%2F\u0026amp;hide_cover=1\u0026amp;mini=1\u0026amp;light=1\u0026#34; frameborder=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; Add id=\u0026quot;myPlayer\u0026quot; like this:\n\u0026lt;iframe id=\u0026#34;myPlayer\u0026#34; width=\u0026#34;100%\u0026#34; height=\u0026#34;60\u0026#34; src=\u0026#34;https://www.mixcloud.com/widget/iframe/?feed=https%3A%2F%2Fwww.mixcloud.com%2Fdj_umek%2Fbehind-the-iron-curtain-with-umek-episode-294%2F\u0026amp;hide_cover=1\u0026amp;mini=1\u0026amp;light=1\u0026#34; frameborder=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; Now this particular player can be identified with the myPlayer identifier.\nThe Google Tag Manager Custom HTML Tag The whole tracking solution is contained within a single Custom HTML Tag. So, create a new Custom HTML Tag, and add the following code within:\n\u0026lt;script src=\u0026#34;//widget.mixcloud.com/media/js/widgetApi.js\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; (function() { /* Change the CSS selector within document.querySelector to capture * the correct player iframe. * * Available events are \u0026#39;progress\u0026#39;, \u0026#39;buffering\u0026#39;, \u0026#39;play\u0026#39;, \u0026#39;pause\u0026#39;, * \u0026#39;ended\u0026#39; and \u0026#39;error\u0026#39;. If you want to stop tracking any one of these, * just remove them from the events Array. */ var playerIframe = document.querySelector(\u0026#39;#myPlayer\u0026#39;), events = [\u0026#39;progress\u0026#39;, \u0026#39;buffering\u0026#39;, \u0026#39;play\u0026#39;, \u0026#39;pause\u0026#39;, \u0026#39;ended\u0026#39;, \u0026#39;error\u0026#39;]; if (playerIframe) { var player = Mixcloud.PlayerWidget(playerIframe); var key = \u0026#39;\u0026#39;; var sendDataLayer = function(event, key, currentProgress) { window.dataLayer.push({ event: \u0026#39;mixcloud\u0026#39;, mixcloudEvent: { name: event, key: key, progress: currentProgress } }); }; player.ready.then(function() { events.forEach(function(event) { try { player.events[event].on(function(progress, duration) { player.getCurrentKey().then(function(key) { var currentProgress; if (progress \u0026amp;\u0026amp; duration) { if (progress === Math.round(duration * 0.25)) { currentProgress = \u0026#39;25%\u0026#39;; } else if (progress === Math.round(duration * 0.5)) { currentProgress = \u0026#39;50%\u0026#39;; } else if (progress === Math.round(duration * 0.75)) { currentProgress = \u0026#39;75%\u0026#39;; } } if (event !== \u0026#39;progress\u0026#39; || !!currentProgress) { sendDataLayer(event, key, currentProgress); } }); }); } catch(e) {} }); }); } })(); \u0026lt;/script\u0026gt; Set this tag to fire on a Page View / DOM Ready trigger, and if you only want to fire this on certain pages, you can modify the trigger accordingly. Here\u0026rsquo;s an example:\n   How it works This tracker adds a listener to the given player for all the events you specified in the events Array. Whenever such an event is registered by the page, a dataLayer.push() takes place with the following structure:\n{ event: \u0026#39;mixcloud\u0026#39;, mixcloudEvent: { name: \u0026#39;\u0026#39;, key: \u0026#39;\u0026#39;, progress: \u0026#39;\u0026#39; } }  As you can see, the progress event measures how far along the show the user is. It has triggers for 25%, 50% and 75%. I didn\u0026rsquo;t add one for 100%, as the ended event is the same thing.\nTriggers and variables Next thing you\u0026rsquo;ll need to do is create a Custom Event trigger for the mixcloud event. It\u0026rsquo;s dead easy, and the trigger should look like this:\n  Finally, you\u0026rsquo;ll need three Data Layer variables. One for mixcloudEvent.name, one for mixcloudEvent.key, and one for mixcloudEvent.progress.\n  Now you should have everything you need to start tracking interactions with the widget.\nA typical Google Analytics Event tag might look like this:\n  For example, when a progress event for hitting the half-way mark is recorded, the event would look like this:\nEvent category: Mixcloud\nEvent action: progress: /syte/subfm170217/\nEvent label: 50%\nYou can make it even more versatile with Custom Dimensions and Custom Metrics.\nSummary This was (hopefully) a simple tip to get you along with Mixcloud player tracking. With a robust JavaScript API it really is easy to do.\nThe Mixcloud JavaScript API works with promises, so the functional approach exhibited in the Custom HTML Tag might look messy, and as such, there is room for improvement via refactoring.\nIf you have more than one widget on the page that you want to track, you\u0026rsquo;ll need to duplicate the relevant code for each player on the page. For example:\n... var player = document.querySelector(\u0026#39;#myPlayer\u0026#39;); var player2 = document.querySelector(\u0026#39;#myPlayer2\u0026#39;); ... if (player) { player.ready.then(function() { ... }); } if (player2) { player2.ready.then(function() { ... }); } ...  Have fun listening and tracking those tracks!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtmtips-test-multiple-urls-triggers/",
	"title": "#GTMTips: Test Against Multiple URLs In Your Triggers",
	"tags": ["Google Tag Manager", "gtmtips", "trigger"],
	"description": "Test current page URL against a list of URL strings when using Google Tag Manager&#39;s triggers.",
	"content": " The beauty of #GTMTips, at least how I\u0026rsquo;ve envisioned them, is that they can be really simple or crazy complex. The important thing is that the idea is conveyed clearly enough. That\u0026rsquo;s why so many of these tips have originated from discussions in our Google Tag Manager Google+ community, the Product Forums, and in private email correspondence with people asking for help. Today\u0026rsquo;s tip, for example, originated from a back-and-forth with Süleyman Okan, so thank you for the inspiration!\nThis tip lets you take list of seemingly unrelated URLs, and group them together so that any given trigger will only activate if the current page URL contains one of these URL strings.\nTip 55: Test current page URL against a list of URL strings   First, why is this necessary? Well, let\u0026rsquo;s say you have the following URLs, and you want your trigger to only fire when the page the visitor is on matches one of these:\n /page/login.html\n /login/\n /my-account/\n mydomain.com/users/signin/\n mydomain.co.uk/en/profile/  Your first impulse would be to create a trigger that looks like the following. This will not work, because in a trigger with multiple conditions, all of the conditions must match.\n  So unless the current URL looks something like http://www.mydomain.com/users/signin/login/my-account/mydomain.co.uk/en/profile/page/login.html, this trigger will not work.\nAn alternative would be to write a long regular expression, since in regular expressions you can indicate optional patterns with the pipe symbol (|):\nPage URL matches RegEx (ignore case) /page/login.html|/login/|/my-account/|mydomain.com/users/signin/|mydomain.co.uk/en/profile/\nBut the problem with this approach is that the trigger itself becomes quite difficult to maintain, as any changes would require that you dig in to this single field value.\nThe third option would be to create a trigger for each of the URL variations individually (or maybe you can save some effort by grouping logically similar URLs together), but this is cumbersome to maintain as soon as you have more than one tag that needs these triggers.\nSo, my suggestion is to leverage a Custom JavaScript Variable to check against a list of URLs that you provide, and then it will return true if the current URL contains any one of the URL strings in the list, or false otherwise. This is what the variable might look like:\nfunction() { var urlsToTest = [ \u0026#39;/page/login.html\u0026#39;, \u0026#39;/login/\u0026#39;, \u0026#39;/my-account/\u0026#39;, \u0026#39;mydomain.com/users/signin/\u0026#39;, \u0026#39;mydomain.co.uk/en/profile/\u0026#39; ]; for (var i = 0; i \u0026lt; urlsToTest.length; i += 1) { if (document.location.href.indexOf(urlsToTest[i]) \u0026gt; -1) { return true; } }; return false; }  This code was updated thanks to David Porter in the comments below. The original code had some flaws which prevented this from working.\nIn the urlsToTest array, you provide a comma-separated list of strings that you want to test the current URL against. They can be just page paths, or they can even be complete URLs with protocol, domain name, query string, and hash in place.\nThe variable loops through each member of the list, and if the current page URL contains any one of these URL strings, the function returns true.\nTo include this in your triggers, all you need is something like:\n  Here, I\u0026rsquo;ve named the variable {{URL is login page}}, and you can see how easy it is to add this as a trigger condition.\nAnd that\u0026rsquo;s all there is to it! There are many ways to make this even more useful, such as changing from a string method (indexOf()) to regular expressions (match()). This way you\u0026rsquo;ll have more power over things like case-sensitivity, or whether the URL should match the string from the beginning, from the end, or from anywhere.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/capturing-the-correct-element-in-google-tag-manager/",
	"title": "Capturing The Correct Element In Google Tag Manager",
	"tags": ["css", "custom javascript", "dom", "Google Tag Manager"],
	"description": "A simple DOM traversal method to find the correct element when some other element is clicked using Google Tag Manager.",
	"content": " Google Tag Manager provides us with a bunch of handy triggers, designed to make capturing user interactions on the website much easier. These triggers are part of a paradigm called auto-event tracking, which comprises the Click, Form, History, and JavaScript Error trigger types.\n  Now, I\u0026rsquo;ve covered GTM\u0026rsquo;s triggers many, many times before. If you need a refresher, take a look at the following articles:\n Trigger Guide For Google Tag Manager\n Auto-Event Tracking In GTM 2.0\n Fix Problems With GTM Listeners\n Why Don\u0026rsquo;t My GTM Listeners Work?  In this article, I want to tackle a specific aspect of Click triggers. If you\u0026rsquo;ve used them before, you\u0026rsquo;ll know (at least) two things:\n1) The Just Links trigger captures the link element (\u0026lt;a/\u0026gt;) that is the nearest wrapping link of the clicked element.\n2) The All Elements trigger captures the clicked element itself.\nIn other words, the Just Links trigger actually climbs up the document until it finds a link element, and returns that for GTM to process. The All Elements acts more like a regular handler: it simply returns the element that was clicked.\nIn this article, I want to show you how to leverage especially the All Elements trigger more effectively. Basically, you might want to use the All Elements trigger, but then mimic the Just Links trigger to find some nearest wrapping element, and return that for GTM to use.\nWhy use All Elements? Well, there\u0026rsquo;s one obvious reason: There are all sorts of elements on the page you might want to track. Even though links are a very popular tracking item, there are many elements that have nothing to do with links.\n  Perhaps you want to track a button, or a form field, or an image. In these cases, you will need the All Elements trigger.\nAnother reason you might not be aware of is very significant: The All Elements trigger uses the capture phase of the event path. The Just Links trigger, as well as pretty much all other GTM triggers, utilize the bubble phase.\nAnd why is this significant? Because event propagation is most often cancelled in the bubble phase! Many people have come across forms and links that simply refuse to fire their respective triggers in Google Tag Manager. The reason is that other JavaScript on the site can prevent the event from climbing up the document to where Google Tag Manager\u0026rsquo;s listeners are waiting.\nBut when you use the All Elements trigger, you are using the capture phase, which is cancelled far less often.\nIn other words, you can actually use the All Elements trigger to apply link tracking for links that do not create a GTM event when using the Just Links trigger!\nThe only problem with this approach is that the All Elements trigger returns the actual element that was clicked. For example, let\u0026rsquo;s say you have HTML like this on the site:\n\u0026lt;div id=\u0026#34;contact-us\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;mailto:simo@example.com\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Send me mail\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; If you used a Just Links trigger, and event propagation wasn\u0026rsquo;t stopped, clicking the link will pass the \u0026lt;a href=\u0026quot;mailto:simo@example.com\u0026quot;/\u0026gt; to Google Tag Manager as the target element of the event. But if you\u0026rsquo;re using the All Elements trigger, GTM captures the \u0026lt;span/\u0026gt;, because it\u0026rsquo;s what the click actually landed on!\nSo how do we get the benefit of All Elements with its capture phase handler, but still be able to capture any element up the DOM tree?\nWith some Custom HTML Tag and Custom JavaScript variable magic, of course!\nThe solution The solution comes in two parts. First, we need to create a Custom HTML Tag that introduces a polyfill (read: workaround) for older browsers which might not support the method we\u0026rsquo;re going to use.\nNext, we\u0026rsquo;ll use a Custom JavaScript variable to create a generic function to which we can pass a CSS selector. This function, in turn, climbs up the document tree and returns the element that matches the selector.\nNote that you can achieve most of this easily with jQuery or something similar. However, I want to show the native JavaScript way of doing it, since it\u0026rsquo;s not actually that complex.\nThe Custom HTML Tag The Custom HTML Tag should fire as early as possible on the page, so you can use the All Pages trigger, if you wish. This is what it holds:\n\u0026lt;script\u0026gt; if (!Element.prototype.matches) { Element.prototype.matches = Element.prototype.matchesSelector || Element.prototype.mozMatchesSelector || Element.prototype.msMatchesSelector || Element.prototype.oMatchesSelector || Element.prototype.webkitMatchesSelector || function(s) { var matches = (this.document || this.ownerDocument).querySelectorAll(s), i = matches.length; while (--i \u0026gt;= 0 \u0026amp;\u0026amp; matches.item(i) !== this) {} return i \u0026gt; -1; }; } \u0026lt;/script\u0026gt;  This is a good addition to the site code in general, so if possible to add it to the regular JavaScript of the site, I recommend you do!\nThe polyfill is gratefully copied from the Mozilla Developer Network pages.\nThe script checks if the browser supports the method Element.matches() or any of its alternatives. If no match is found, then it\u0026rsquo;s fixed with a custom method that scrolls through the document elements and checks if any of them matches the given CSS selector.\nOnce this is running, you can start using it!\nThe Custom JavaScript variable To make things work, we need a little utility Custom JavaScript variable. So create a new Custom JavaScript Variable, and name it {{Find closest}}. This is the code you need to put within:\nfunction() { return function(target, selector) { while (!target.matches(selector) \u0026amp;\u0026amp; !target.matches(\u0026#39;body\u0026#39;)) { target = target.parentElement; } return target.matches(selector) ? target : undefined; } }  This function takes two parameters: target and selector. The first is an HTML element such as the {{Click Element}} built-in variable. The latter is a CSS selector string. The CSS selector is what you use to tell GTM the following:\n Starting from target, start climbing up the wrapping DOM structure until you find an element that matches selector. If such an element is found, return it. If such an element is NOT found, return the original event target.\n The idea here is that even though the click landed on the element you wanted to target, you might actually want to access some other element relative to the original event target. For this, the matches() workaround is invaluable, as it lets you traverse element-relative paths.\nHow to use it Once you\u0026rsquo;ve set up the polyfill and the Custom JavaScript Variable, you can leverage the variable in all your Google Tag Manager JavaScript with the following syntax:\nvar elementFound = {{Find closest}}(someHTMLElement, 'someCSSselector');\nFor example, let\u0026rsquo;s say you have an HTML structure that looks like this:\n\u0026lt;div id=\u0026#34;product_12345\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;details\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;Product 1\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;link\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;product1.html\u0026#34;\u0026gt; Product 1 \u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; Now, you\u0026rsquo;ve set up a Click - Just Links or Click - All Elements trigger to capture clicks on the \u0026lt;a/\u0026gt; element. Now, however, you also want to grab the value of the id attribute from the very top-most div (\u0026ldquo;product_12345\u0026rdquo;). To get that, you could use a Custom JavaScript Variable like this:\nfunction() { var el = {{Find closest}}({{Click Element}}, \u0026#39;div[id^=\u0026#34;product\u0026#34;]\u0026#39;); return typeof el !== \u0026#39;undefined\u0026#39; ? el.id : undefined; }  This Custom JavaScript Variable takes {{Click Element}} (the element that was originally clicked), and then starts walking up the DOM until it finds a div whose id attribute begins with the string \u0026ldquo;product\u0026rdquo;. If such an element is found, it returns the value of the id attribute in question. If the element isn\u0026rsquo;t found, it simply returns undefined.\nSummary Traversing the Document Object Model with CSS selectors can be a very good friend to you, indeed. Click handlers are usually too accurate, as they return elements we didn\u0026rsquo;t expect them to return, or they return elements too deep in the DOM to matter.\nThat\u0026rsquo;s why it\u0026rsquo;s good to have a tool that lets you access the DOM structure more deliberately. Traversing the DOM with the {{Find closest}} workaround is a nice way to achieve the type of freedom using native JavaScript that is typically found only within frameworks like jQuery.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/automated-tests-for-google-tag-managers-datalayer/",
	"title": "Automated Tests For Google Tag Manager&#39;s dataLayer",
	"tags": ["Google Tag Manager", "JavaScript", "testing"],
	"description": "An open-source library to help you write automated functional tests against Google Tag Manager&#39;s dataLayer object.",
	"content": " One of the biggest fears I have as a Google Tag Manager user is a broken release of the website (or app) on which I have deployed GTM. Far too often, lack of proper communication practices within an organization lead to a release being pushed out without thoroughly testing how this release impacts any existing tracking solutions.\n  Luckily there are ways to mitigate this. The most significant and impactful precautions you can take are all about process:\n Be active in the daily development team work.\n Introduce \u0026ldquo;analytics\u0026rdquo; as an item in the definition of done of each release.\n Educate the developers on what Data Layer is and how a proper GTM deployment hinges on a stable Data Layer.\n  In addition to these, there are technical measures you can employ to further eliminate the risk of things breaking down when a new release is pushed into the wild.\n  Unit tests should be used to test the code itself, verifying that a given input always produces an expected output. When testing dataLayer, this is especially important for any objects you write into the page template, as they are mostly code-driven and do not depend on user input.\nHowever, if you only ran unit tests it would be difficult to cover the variety of things that can happen in the web browser. That\u0026rsquo;s where functional tests come into play, and those will be the focus of this article.\nWith functional tests, you are actually running tests on a \u0026ldquo;real\u0026rdquo; implementation of the website. Typically this means having a version of the site running on localhost or a staging environment, and then using a \u0026ldquo;virtual\u0026rdquo; browser, typically deployed via a framework such as Selenium, to perform the actual test steps.\nTo save you time and trouble, I have written an open-source, self-contained functional test suite for Google Tag Manager\u0026rsquo;s dataLayer called, imaginatively, gtm-datalayer-test.\n  Visit the GitHub repo for gtm-datalayer-test.\nThe rest of this guide covers how the solution works.\nCredit First credit where credit is due. The solution proposed in this article isn\u0026rsquo;t ground-breaking in any way, shape or form. Using JSON to control processes is very common in the development world, and there are many test frameworks that directly support JSON validation for tests.\nA direct inspiration to this article is Jan Exner\u0026rsquo;s work with a TDD setup for Adobe Analytics and DTM. You should take a look at the related GitHub repo, where you\u0026rsquo;ll find that it has many similarities to gtm-datalayer-test.\nAs often happens, David Vallejo\u0026rsquo;s been an important brainstorming partner for building the test suite. I hope he will be a regular contributor to the project!\nElevator pitch The elevator pitch for this solution is this:\n gtm-datalayer-test is a functional testing solution for the global window.dataLayer queue used by Google Tag Manager. Tests are defined, executed, and reported using a special JSON configuration file, which validates against the latest draft of the JSON Schema standard. The solution can be used to manually or automatically test if window.dataLayer has an expected structure. This is crucial especially when new releases of the website are pushed live.\n 1. Get it up and running First, let\u0026rsquo;s get things up and running. Before you start, you will need the following things:\n NodeJS and NPM installed (here)\n Latest version of Java (here)\n  Once you have these installed, you should be able to run the following commands in your terminal and get a valid result for each:\n java -version\n npm -v\n node -v\n    Once you\u0026rsquo;ve installed these successfully, you can get gtm-datalayer-test up and running by executing the following commands. Run the first command (git clone) in a directory where you want the gtm-datalayer-test project directory to be established.\n git clone https://github.com/sahava/gtm-datalayer-test.git\n cd gtm-datalayer-test\n npm install\n npm test\n  When running the final command, you should see something like this:\n  With git clone ..., you pulled the source code from my GitHub repo into a directory named gtm-datalayer-test, which is where you then navigated to in the second step.\nNext, by running npm install, npm (package manager for Node) runs through all the dependencies listed in the package.json file, and installs them locally to the project. This is very important, as without these dependencies the code itself is useless.\nFinally, by running npm test, you are executing an npm script specifically written for this project. It first starts a simple web server, after which it runs the automated dataLayer tests against a mock index.html file on that server. Finally, it outputs the results of the test into the console.\nThe following chapters explore each of these steps in more detail.\n2. Technology stack Node.js and npm give you a wealth of pre-built modules to work with when building your web application. I mean, you could write everything from scratch, but you\u0026rsquo;ll end up spending more time, energy, and hair trying to do the stuff that existing npm packages already perform much more efficiently.\nThis project uses the following technologies / dependencies / packages:\n Node.js and npm as the server tech and package manager, respectively.\n Java to run Selenium.\n ajv for validating the custom test JSON Schemas.\n chai as the test assertion library.\n chai-json-schema to provide custom assertions for JSON Schema validation.\n chai-subset for performing subset checks against window.dataLayer.\n http-server to act as a light-weight HTTP server for testing purposes.\n wdio as a test runner, built on webdriverio.\n wdio-mocha-framework to enable Mocha as a test framework.\n wdio-phantomjs-service for installing and running the PhantomJS headless browser.\n wdio-selenium-standalone-service for installing and running the Selenium framework.\n wdio-spec-reporter (forked from the original) as a custom spec test reporter.\n webdriverio for running Selenium via Node.js.\n  You don\u0026rsquo;t have to know what these modules do, but by looking at the list, one thing should jump out: I\u0026rsquo;m gunning for a self-contained solution here. I\u0026rsquo;m sacrificing customization for ease of use, but even in doing so the modularity of gtm-datalayer-test hasn\u0026rsquo;t been compromised. All the packages above contribute to the framework I have built, but nothing\u0026rsquo;s stopping you from extracting just some components and integrating them into your own test suite. In fact, I strongly recommend you do so if you already have a functional testing framework set up!\nAs you might have gathered, the whole thing runs on JavaScript. There\u0026rsquo;s not much you need to customize, but if you do wish to get your hands dirty, some knowledge of JavaScript, especially ECMAScript 6 and Node.js, is required.\n3. How it works Each test setup comprises some moving parts. There\u0026rsquo;s the wdio configuration file you feed to wdio, there\u0026rsquo;s the JavaScript test spec itself, and then there\u0026rsquo;s a configuration JSON you use to define your expectations for each test.\n3.1. wdio configuration file This solution uses WebdriverIO to manage much of the legwork. WebdriverIO offers a bunch of bindings we can use together with the virtual browsers operated by Selenium. Together with Selenium, WebdriverIO gives us all the tools we need to define, execute, and report on tests we want to run on any given application or web property.\nTo make running WebdriverIO as smooth as possible, we use a module called wdio to run the tests. The great thing about wdio is that it\u0026rsquo;s very extendable, and there are already lots of great modules and plugins we can use with it to make our setup purr.\nThe wdio configuration JavaScript is basically what runs this whole show. The JavaScript exports a config object, which holds all the settings you want to define for the test. This includes what browser drivers you want to use, in which directories to look for spec files, what test runner to use, etc.\nYou can find the example configuration, used when running npm test, in the ./examples directory, with the name examples.conf.js. Here\u0026rsquo;s what it looks like:\nconst enhancedEcommerceSchema = require(\u0026#39;../lib/enhancedEcommerceSchema.json\u0026#39;) exports.config = { specs: [ \u0026#39;./examples/spec/basic_example.js\u0026#39; ], maxInstances: 10, capabilities: [{ maxInstances: 5, browserName: \u0026#39;phantomjs\u0026#39;, \u0026#39;phantomjs.binary.path\u0026#39;: \u0026#39;./node_modules/phantomjs-prebuilt/bin/phantomjs\u0026#39; }], sync: true, logLevel: \u0026#39;silent\u0026#39;, coloredLogs: true, bail: 0, waitforTimeout: 10000, connectionRetryTimeout: 90000, connectionRetryCount: 3, services: [\u0026#39;selenium-standalone\u0026#39;], seleniumInstallArgs: { version: \u0026#39;3.0.1\u0026#39; }, seleniumArgs: { version: \u0026#39;3.0.1\u0026#39; }, framework: \u0026#39;mocha\u0026#39;, reporters: [\u0026#39;spec\u0026#39;], mochaOpts: { ui: \u0026#39;bdd\u0026#39; }, before: function() { const chai = require(\u0026#39;chai\u0026#39;); chai.use(require(\u0026#39;chai-json-schema\u0026#39;)) chai.use(require(\u0026#39;chai-subset\u0026#39;)) chai.tv4.addSchema(\u0026#39;/enhancedEcommerceSchema.json\u0026#39;, enhancedEcommerceSchema) global.expect = chai.expect global.assert = chai.assert } }  First, be sure to check here for the full range of options you can set in the configuration file. It\u0026rsquo;s a good idea to familiarize yourself with the available options, since you\u0026rsquo;ll definitely need to modify some of them when extending these examples to your actual use cases.\nconst enhancedEcommerceSchema = require(\u0026#39;../lib/enhancedEcommerceSchema.json\u0026#39;)  This command loads a custom Enhanced Ecommerce JSON Schema which you can refer to when you want to test if your dataLayer has valid Enhanced Ecommerce objects within. There\u0026rsquo;s more on this in a later chapter.\nspecs: [ \u0026#39;./examples/spec/basic_example.js\u0026#39; ]  Use the specs keyword to list the locations with test files you want wdio to run through. Whenever you run wdio without the --spec command-line parameter, it will run through all the tests listed in this array.\nYou can use wildcards, too. For example, all my tests are stored in various places within a directory named /spec/. To get wdio to run through all tests within, regardless of directory or file name, my specs configuration looks like this:\nspecs: [ \u0026#39;./spec/**/*.js\u0026#39; ]  This means that in the director /spec/, look through all the files and directories for any items that have the .js extension, and use them as test specifications.\ncapabilities: [{ browserName: \u0026#39;phantomjs\u0026#39; },{ browserName: \u0026#39;chrome\u0026#39; }]  This is where you define the browser instances you want to fire with each test. Basically, any browser you list here will be launched when the test runner starts, and the tests will be run through each respective browser. Chrome, Firefox and PhantomJS have support out of the box in gtm-datalayer-test.\nBy the way, PhantomJS is a very popular headless browser. Basically, it\u0026rsquo;s a browser without a graphical user interface. It\u0026rsquo;s thus a very lightweight, quick solution for running your tests on. However, with every major release you should probably run the tests through \u0026ldquo;real\u0026rdquo; browsers, too.\nframework: \u0026#39;mocha\u0026#39;, reporters: [\u0026#39;spec\u0026#39;]  Here you define that you want to use Mocha as the test framework, and spec as the reporter. With wdio, you can also use Jasmine or Cucumber instead of Mocha. You also have a bunch of reporters to choose from, or you can build your own (quite simple, actually). For more details, see here for test frameworks and here for reporters.\nbefore: function() { const chai = require(\u0026#39;chai\u0026#39;); chai.use(require(\u0026#39;chai-json-schema\u0026#39;)) chai.use(require(\u0026#39;chai-subset\u0026#39;)) chai.tv4.addSchema(\u0026#39;/enhancedEcommerceSchema.json\u0026#39;, enhancedEcommerceSchema) global.expect = chai.expect global.assert = chai.assert }  The before hook is executed before any test specs are run. In this hook, I basically tell wdio to use Chai as the assertion library of choice. Chai is a very popular assertion library, and it\u0026rsquo;s often used together with Mocha to provide a more expressive language for describing your tests. You can use any assertion library you want, or you can use the default Node.js assertion library, if you wish.\nAgain, remember to read through the wdio documentation. It\u0026rsquo;s very important to understand what you can customize and how. I hope to add more examples to the GitHub repo in the future, but I still recommend you take a look at the documentation.\n3.2. JavaScript test specification Because this is a self-contained solution (or so I hope), you don\u0026rsquo;t really need to touch the JavaScript test spec at all. The whole thing is orchestrated with the wdio configuration file and the JSON configuration file.\nEach JavaScript test specification executes its respective configuration JSON, running a bunch of tests against the window.dataLayer object on any page it visits.\nIf you want to run multiple specifications, you will need to copy both the test specification JavaScript (e.g. basic_example.js) as well as the configuration JSON (e.g. basic_example.conf.json) to the spec directory. You can also have all your spec files in a single directory, if you wish. The wdio configuration file simply looks through the /examples/spec directory for any JavaScript test files.\nI\u0026rsquo;m not going to walk you through the entire file, but there are some things you should know about.\n// Set the file in require() to point to this test\u0026#39;s configuration JSON const dataLayerConf = require(\u0026#39;./basic_example.conf.json\u0026#39;)  If you create a new test specification, the JSON file name you point to in the require() method should refer to the configuration JSON you\u0026rsquo;ve created for this test.\nThe test specification runs through two main suites of tests:\n \u0026ldquo;Generic\u0026rdquo; tests for window.dataLayer, where certain keys should be found on every page the test visits.\n \u0026ldquo;Page-specific\u0026rdquo; configurations, where you test window.dataLayer on each given page for page-specific key-value pairs.\n  All the reports are generated automatically based on certain values in the configuration JSON. Before the test runs, however, the configuration JSON itself is validated against what I\u0026rsquo;ve defined as a valid JSON Schema for this particular project (you can find this in /lib/validTestConfSchema.json). If anything is missing or incorrectly encoded, the test reporter will stop with an error.\n3.3. JSON configuration file The JSON configuration is what the whole test hinges on. All the parameters you provide govern not only which pages the test loads in the virtual browser, but also what you expect to find in window.dataLayer on any given page.\nThis is what a fully loaded JSON configuration might look like:\n{ \u0026#34;baseUrl\u0026#34; : \u0026#34;https://www.simoahava.com\u0026#34;, \u0026#34;dataLayerName\u0026#34; : \u0026#34;dataLayer\u0026#34;, \u0026#34;multipleContainers\u0026#34; : true, \u0026#34;dataLayer\u0026#34; : [{ \u0026#34;@json\u0026#34; : false, \u0026#34;visitorLoginState\u0026#34; : \u0026#34;logged-out\u0026#34; },{ \u0026#34;event\u0026#34; : { \u0026#34;pattern\u0026#34; : \u0026#34;^gtm.dom$\u0026#34; } },{ \u0026#34;event\u0026#34; : { \u0026#34;pattern\u0026#34; : \u0026#34;^gtm.load$\u0026#34; } }], \u0026#34;page\u0026#34; : [{ \u0026#34;path\u0026#34; : \u0026#34;/gtm-tips/10-useful-css-selectors/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have basic article variables\u0026#34;, \u0026#34;pageAttributes\u0026#34; : { \u0026#34;enum\u0026#34; : [[\u0026#34;css-selectors\u0026#34;, \u0026#34;google-tag-manager\u0026#34;, \u0026#34;gtmtips\u0026#34;]] }, \u0026#34;pageCategory\u0026#34; : { \u0026#34;enum\u0026#34;: [[\u0026#34;gtm-tips\u0026#34;]] }, \u0026#34;pagePostType\u0026#34; : { \u0026#34;pattern\u0026#34; : \u0026#34;^post$\u0026#34; }, \u0026#34;pagePostType2\u0026#34; : { \u0026#34;pattern\u0026#34;: \u0026#34;^single-post$\u0026#34; }, \u0026#34;postCountOnPage\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34; }, \u0026#34;postCountTotal\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34; } },{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have article impressions\u0026#34;, \u0026#34;event\u0026#34; : { \u0026#34;pattern\u0026#34;: \u0026#34;^impressionsPushed$\u0026#34; }, \u0026#34;ecommerce\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;impressions\u0026#34;: { \u0026#34;$ref\u0026#34; : \u0026#34;/enhancedEcommerceSchema.json#/definitions/impressions\u0026#34; } }, \u0026#34;required\u0026#34; : [\u0026#34;impressions\u0026#34;] } },{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have clientId\u0026#34;, \u0026#34;event\u0026#34; : { \u0026#34;pattern\u0026#34; : \u0026#34;^trackerReady$\u0026#34; }, \u0026#34;cid\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34;, \u0026#34;pattern\u0026#34; : \u0026#34;[0-9]+\\\\.[0-9]+\u0026#34; } },{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have product detail view\u0026#34;, \u0026#34;ecommerce\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;detail\u0026#34; : { \u0026#34;$ref\u0026#34; : \u0026#34;/enhancedEcommerceSchema.json#/definitions/detail\u0026#34; } }, \u0026#34;required\u0026#34; : [\u0026#34;detail\u0026#34;] } }] }] }  Here are the main keys you can work with:\n baseUrl (required) - a string containing the full protocol, domain, and port of the site where all the tests are run in this specification. Note! Leave the trailing slash out (https://www.simoahava.com, NOT https://www.simoahava.com/).\n dataLayerName - if you\u0026rsquo;re using some other name for the global dataLayer object than \u0026ldquo;dataLayer\u0026rdquo;, remember to specify it here. You can leave this out otherwise (the test defaults to dataLayer).\n multipleContainers - set this to true if you have multiple containers on the page. Otherwise leave this out.\n  In addition to this, there\u0026rsquo;s dataLayer, which is an array of objects you expect to find on every single page the test visits (generic configuration).\nThere\u0026rsquo;s also page, which is where you specify each page you want the test to visit, with any page-specific dataLayer configurations defined within.\nThere\u0026rsquo;s more on the configuration file in the following chapter.\n4. JSON configuration Picking up where we left off in the previous chapter, let\u0026rsquo;s focus on the two important configuration arrays we haven\u0026rsquo;t covered yet: dataLayer[] and page[].\n4.1. Generic dataLayer The dataLayer key in the root of the JSON configuration is where you list objects you expect to find on every single page the test visits. These are so called \u0026ldquo;generic\u0026rdquo; keys. So, let\u0026rsquo;s say you expect to find an object that contains the key-value pair \u0026quot;event\u0026quot; : \u0026quot;gtm.dom\u0026quot;, as well as an optional object where they key is \u0026quot;visitorLoginState\u0026quot; whose value is any string, this is what the generic object might look like:\n{ ... dataLayer : [{ \u0026#34;@json\u0026#34; : false, \u0026#34;event\u0026#34; : \u0026#34;gtm.dom\u0026#34; },{ \u0026#34;visitorLoginState\u0026#34; : { \u0026#34;@rootRequired\u0026#34; : false, \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; } }] ... } Let\u0026rsquo;s see what these keys mean.\n@json is a special configuration that can only have the false value. Any other value and the schema will not validate. If a dataLayer object has this key in the configuration, it means that any key-value pairs within that object will be looked for verbatim within the global window.dataLayer object. In other words, if window.dataLayer doesn\u0026rsquo;t have at least one object with the exact key-value pair \u0026quot;event\u0026quot; : \u0026quot;gtm.dom\u0026quot;, the test will fail.\nYou can thus use the \u0026quot;@json\u0026quot; : false setting to run simple subset checks. You can define complex objects, arrays, or any available data types, but they need to be found in that exact format within window.dataLayer. This subset check is a great way to test key-value pairs which you expect to be immutable across releases.\nIf you don\u0026rsquo;t provide the @json key, the test will be validated against JSON Schema logic. JSON Schema is a (draft) standard used to describe JSON documents. The window.dataLayer object can be stringified into an imperfect JSON representation, though it\u0026rsquo;s typically good enough to run JSON validation tests against.\nJSON Schema gives you a lot of tools to work with when describing the complexity of window.dataLayer. You can create tests where you expect keys to have a certain range of values, a certain data type, optional or required parameters, et cetera.\nIn the example above, \u0026quot;visitorLoginState\u0026quot; is simply defined as an optional string. You don\u0026rsquo;t require window.dataLayer to have it, but if it is found, you expect it to be a string. Thus the test would fail if window.dataLayer had an object with \u0026quot;visitorLoginState\u0026quot; : false.\nThe special @rootRequired key is used only for keys in the root of the dataLayer object. If you add this key with value false, it means that the parameter it\u0026rsquo;s attached to is optional. You don\u0026rsquo;t require window.dataLayer to have that key in the root of any object. The default is that each key you define in the root of the dataLayer object is required, so using \u0026quot;@rootRequired\u0026quot; : false is the only way to impact this. For keys deeper in the structure you can use regular JSON Schema syntax (e.g. \u0026quot;required\u0026quot; : [\u0026quot;someProperty\u0026quot;, \u0026quot;someOtherProperty\u0026quot;]).\n4.2. Page-specific configurations The page-specific configurations contain one extra configuration level, after which you define their own dataLayer objects using the methods you read about in the previous chapter.\nThe first page-specific key you need to define is path. This should be in the root of each object in the page array. The value should be a proper URL path, starting with \u0026ldquo;/\u0026rdquo;. For example, to visit three different pages in the test, you would configure the page object like this:\n{ ... \u0026#34;dataLayer\u0026#34; : [{ .... }], \u0026#34;page\u0026#34; : [{ \u0026#34;path\u0026#34; : \u0026#34;/first-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ ... }] },{ \u0026#34;path\u0026#34; : \u0026#34;/second-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ ... }] },{ \u0026#34;path\u0026#34; : \u0026#34;/third-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ ... }] } } For each given page object, you can define the dataLayer composition you expect to find on that particular page. The configuration of each dataLayer object is exactly the same as explored in the previous chapter with one important addition.\nIn the root of each dataLayer object, you need to define the key @expect with a textual description of this test. In other words, use this key to describe why you are expecting this particular dataLayer object to be found in the global window.dataLayer.\nWhatever you type in this string will be prefixed with the verb \u0026ldquo;expect\u0026rdquo;, so you can thus use a partial sentence. This is what your configuration might look like:\n{ ... \u0026#34;dataLayer\u0026#34; : [{ .... }], \u0026#34;page\u0026#34; : [{ \u0026#34;path\u0026#34; : \u0026#34;/first-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have the userState key\u0026#34;, \u0026#34;userState\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;string\u0026#34; } }] },{ \u0026#34;path\u0026#34; : \u0026#34;/second-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to optionally contain userCount\u0026#34;, \u0026#34;userCount\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;number\u0026#34;, \u0026#34;@rootRequired\u0026#34; : false } }] },{ \u0026#34;path\u0026#34; : \u0026#34;/third-page-to-test/\u0026#34;, \u0026#34;dataLayer\u0026#34; : [{ \u0026#34;@expect\u0026#34; : \u0026#34;dataLayer to have the Enhanced Ecommerce detail object\u0026#34;, \u0026#34;ecommerce\u0026#34; : { \u0026#34;type\u0026#34; : \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34; : { \u0026#34;detail\u0026#34; : { \u0026#34;$ref\u0026#34; : \u0026#34;/enhancedEcommerceSchema.json#/definitions/detail\u0026#34; } }, \u0026#34;required\u0026#34; : [\u0026#34;detail\u0026#34;] }] } } See the last object? Interesting, eh? First, you expect the global window.dataLayer structure to contain an object named ecommerce with one required property: detail. Next, you\u0026rsquo;re using the $ref JSON Schema keyword to link to an external definition. In fact, in the directory /lib/ you can find the schema named enhancedEcommerceSchema.json, which I created to make it easier to describe a valid Enhanced Ecommerce object.\nYou can link to the definitions within from your test configuration JSON files. Hopefully we\u0026rsquo;ll have more schemas for other complex objects soon, and nothing\u0026rsquo;s stopping you from creating and linking your own custom JSON for schemas you expect to use over and over again!\n5. Running your tests If you\u0026rsquo;ve been modifying the basic_example.conf.json, you can use the predefined npm script npm test to run your setup. When you execute that command, the following things happen:\n The script fires up an http-server instance on http://localhost:8080, which loads the index.html file from ./examples/.\n The script runs ./node_modules/.bin/wdio ./examples/examples.conf.js\n The test runner automatically starts an instance of the Selenium server, which then proceeds to fire up a phantomjs browser driver.\n The test runner starts reading your basic_example.js test specification, and opens the test browser on URL http://localhost:8080/index.html.\n The test runner proceeds to run through all the tests on this URL, keeping tabs on which tests passed and which failed.\n The test runner then reports the results of the test, using green checkmarks for passed tests and red numbers for failed tests.\n If any tests failed, they are reported as AssertionErrors with each error associated with its respective test number.\n Finally, wdio automatically shuts down the Selenium instance, and http-server is killed, too.\n    Once you\u0026rsquo;ve graduated beyond the basic_example.js file, you might want to create your own tests, store them in their own folders, and create new wdio configuration files for each.\nThe command for running wdio against your own wdio configuration files is this (executed in the root of your project):\n./node_modules/.bin/wdio \u0026lt;wdio configuration file\u0026gt;\nThis runs the wdio executable against your configuration file, which in turn passes each specification defined in the configuration for the test runner. The test runner, then, starts the browser instances you have selected, running the tests, and channeling the output to the test reporter.\nYou might want to start using a task / workflow runner such as Grunt or Gulp to manage your test suites. It will make it easier to run arbitrary tests, as you can specify things like custom parameters, and you can chain multiple tests together, if you wish.\n6. Contribute This is an open-source project. I don\u0026rsquo;t expect you to contribute, but if you do I am very grateful indeed.\nTo contribute, head on over to the GitHub repo. You can fork the repo, make modifications, and then submit those modifications as Pull Requests. It would be best, however, if you first introduce the thing you want to change as an Issue to make sure we all agree that it\u0026rsquo;s a good feature to focus on.\nAlternatively, you can add your ideas, questions, or bugs in the comments below. I\u0026rsquo;m fully aware this isn\u0026rsquo;t a \u0026ldquo;plug-and-play\u0026rdquo; solution for testing GTM, since I never intended it to be one. Thus I expect there to be issues that I haven\u0026rsquo;t considered (I should write tests for this, too!), and I would be very grateful if you\u0026rsquo;d let me know about any trouble you\u0026rsquo;ve come across with this solution.\nFinally, the latest version of this solution AND the documentation is only maintained in the GitHub repo. It\u0026rsquo;s possible that this article is already outdated as you\u0026rsquo;re reading this, so I hope you head on over to the repo to see the latest changes.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/10-useful-custom-javascript-tricks/",
	"title": "#GTMTips: 10 Useful Custom JavaScript Tricks",
	"tags": ["Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Introducing 10 useful Custom JavasScript tricks for Google Tag Manager.",
	"content": " I recently published a #GTMTips guide called 10 Useful CSS Selectors, and it was very well received. Inspired by the feedback, here\u0026rsquo;s the next instalment. This time, we\u0026rsquo;re going over some useful JavaScript tips and tricks that you can use to make your Google Tag Manager deployment even more efficient. I\u0026rsquo;ve written a lot about JavaScript in this blog, and I intend to keep on doing so in the future. As always, if JavaScript is somewhat of a mystery to you, I strongly recommend you take the Codecademy (free) course on JS, and take a look at the other available web technology tracks while you\u0026rsquo;re there!\nTip 54: 10 Useful Custom JavaScript Tricks   You can deploy these tricks in Custom HTML Tags or Custom JavaScript Variables, since they are the only contexts within Google Tag Manager where you can execute arbitrary JavaScript. Note that some of the tricks are just code snippets, so you will need to understand enough of how Google Tag Manager and JavaScript mesh together to be able to deploy them successfully.\nBefore adding any of these to your deployments, remember to use caniuse.com to check for browser compatibility, and the MDN JavaScript Reference to find alternative ways (AKA polyfills) for writing the unsupported methods.\n1. String methods String methods are utilities that you can use to modify any given string. Here are some of the most useful ones, in my opinion.\n// Use .trim() to strip leading and trailing whitespace from a string. \u0026#34; Oh no! Leading AND trailing whitespace!! \u0026#34;.trim(); // Result: \u0026#34;Oh no! Leading AND trailing whitespace!!\u0026#34;  // Use .replace() to replace characters or regular expressions with something else. // .replace() without a regular expression replaces the first instance. \u0026#34;Food\u0026#34;.replace(\u0026#39;o\u0026#39;, \u0026#39;e\u0026#39;); // Result: \u0026#34;Feod\u0026#34; \u0026#34;Food\u0026#34;.replace(/o/g, \u0026#39;e\u0026#39;); // Result: \u0026#34;Feed\u0026#34;  // Use .toUpperCase() and .toLowerCase() to change the case of the entire string \u0026#34;MixED CaSe String\u0026#34;.toLowerCase(); // Result: \u0026#34;mixed case string\u0026#34;  // Use .substring() to return only part of the string. \u0026#34;?some-query-key=some-query-value\u0026#34;.substring(1); // Returns: \u0026#34;some-query-key=some-query-value\u0026#34; \u0026#34;id: 12345-12345\u0026#34;.substring(4,9); // Returns: \u0026#34;12345\u0026#34;  // Use .split() to split the string into its constituents \u0026#34;get the second word of this sentence\u0026#34;.split(\u0026#39; \u0026#39;)[1]; // Returns \u0026#34;the\u0026#34;  Naturally, you can combine these in inventive ways. For example, to capitalize the first letter of any string you could do this:\nvar str = \u0026#34;capitalize the first letter of this string, please!\u0026#34;; str = str.replace(/^./, str.substring(0,1).toUpperCase());  Here we first identify the first letter of the string using a regular expression, after which we replace it with the first letter of the string that has been converted to upper case.\n2. Array methods Array methods are really powerful in any programming language. Mastering methods such as filter() and forEach() is critical if you want to make your JavaScript more compact and often more readable.\nfilter() filter() goes through each element in the Array, and returns a new Array for every element that passes the check you provide in the callback. Here\u0026rsquo;s the syntax:\nsomeArray.filter(function(eachItem) { return eachItem === someCondition; });  So eachItem is the variable where the iterator stores each member of the Array as it is processed. If the callback returns true, it means that the item is added to the returned, new Array. If it returns false, it\u0026rsquo;s dropped.\nHere\u0026rsquo;s an example:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;addMe!\u0026#39; },{ \u0026#39;event\u0026#39; : \u0026#39;doNotAddMe!\u0026#39; }); var newArray = window.dataLayer.filter(function(item) { return item.event === \u0026#39;addMe!\u0026#39;; }); // Returns: [{\u0026#39;event\u0026#39; : \u0026#39;addMe!\u0026#39;}]  The iterator checks every single item for the property event, and returns true if that property has value addMe!. Thus the returned array only has those elements that have the key-value pair \u0026quot;event\u0026quot; : \u0026quot;addMe!\u0026quot;.\nforEach() Remember the clumsy for-loop for iterating over an Array? Yuck! Instead, you can use the forEach() iterator.\nforEach() receives each item in the array one-by-one, and you can then do whatever you wish with this item. The syntax is very simple and intuitive, and thus should be preferred over the confusing for-loop.\nvar array = [\u0026#34;I\u0026#34;, 4, 2, true, \u0026#34;love\u0026#34;, [1,2,3], {chocolate: \u0026#39;too\u0026#39;}, \u0026#34;you\u0026#34;]; var newArray = []; array.forEach(function(item) { if (typeof item === \u0026#39;string\u0026#39;) { newArray.push(item); } }); newArray.join(\u0026#34; \u0026#34;); // Result: \u0026#34;I love you\u0026#34;  As you can see, it\u0026rsquo;s more readable than a for-loop, as you don\u0026rsquo;t have to access the original array in the iterator.\nmap() The map() iterates over each member in the array, again, but this time the code in the callback is executed against each member of the array, and a new array is returned with the results. Here\u0026rsquo;s how to set it up:\narray.map(function(item) { return doSomething(item); });  In other words, you are mapping each element in the array against the result of the callback function. Here\u0026rsquo;s are some examples:\nvar array = [1,2,3,4,5]; array.map(function(item) { return item * 2; }); // Result: [2,4,6,8,10]  var array = [\u0026#34; please \u0026#34;, \u0026#34; trim\u0026#34;, \u0026#34; us \u0026#34;]; array.map(function(item) { return item.trim(); }); // Result: [\u0026#34;please\u0026#34;, \u0026#34;trim\u0026#34;, \u0026#34;us\u0026#34;];  reduce() The reduce() method is often the most complex one, but it actually has a very simple principle: You provide the function with an accumulator, and each member of the array is then operated against this accumulator. You can also provide an initial value to the accumulator. Here\u0026rsquo;s what the basic structure looks like:\narray.reduce(function(accumulator, item) { accumulator.doSomethingWith(item); return accumulator; }, initialValue);  This time, it\u0026rsquo;s definitely easiest to learn via examples:\n// Example: calculate the sum of all even numbers in the array var array = [1,6,3,4,12,17,21,27,30]; array.reduce(function(accumulator, item) { if (item % 2 === 0) { accumulator += item; } return accumulator; }, 0); // Returns: 52  // Example, concatenate a string of all product IDs in array var array = [{ \u0026#34;id\u0026#34; : \u0026#34;firstId\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;T-shirts\u0026#34; },{ \u0026#34;id\u0026#34; : \u0026#34;secondId\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;Pants\u0026#34; },{ \u0026#34;id\u0026#34; : \u0026#34;thirdId\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;shoes\u0026#34; }]; array.reduce(function(accumulator, item) { accumulator.push(item.id); return accumulator; }, []).join(); // Returns: \u0026#34;firstId,secondId,thirdId\u0026#34;  3. Ternary operator The ternary operator is just a very simple shorthand for running conditional checks in JavaScript. Here\u0026rsquo;s an example:\n// BEFORE: if (something) { somethingElse(); } else { somethingDifferent(); } // AFTER: something ? somethingElse() : somethingDifferent();  The ternary operator is thus used to combine an if-statement into a simple expression. First you provide an expression that evaluates to a truthy or falsy value, such as me.name() === \u0026quot;Simo\u0026quot;. Then you type the question mark, after which you write an expression that is executed if the first item evaluates to a truthy value. Finally, you type the colon :, after which you type the expression that is executed if the first item evaluates to a falsy value.\n// BEFORE: if (document.querySelector(\u0026#39;#findThisId\u0026#39;) !== null) { return document.querySelector(\u0026#39;#findThisId\u0026#39;); } else { return \u0026#34;Not found!\u0026#34;; } // AFTER: return document.querySelector(\u0026#39;#findThisId\u0026#39;) ? document.querySelector(\u0026#39;#findThisId\u0026#39;) : \u0026#34;Not found!\u0026#34;; // EVEN BETTER: return document.querySelector(\u0026#39;#findThisId\u0026#39;) || \u0026#34;Not found!\u0026#34;;  As you can see, sometimes there are even more efficient ways to process JavaScript statements than the ternary operator. Especially when working with simple binary checks (if value exists, return it), it might be better to just use basic logical operators instead of complex statements or expressions.\n4. return {{Click URL}}.indexOf({{Page Hostname}}) \u0026gt; -1 This is very Google Tag Managerish. It\u0026rsquo;s a simple Custom JavaScript Variable that returns true if the clicked element URL contains the current page hostname, and false otherwise. In other words, it returns true if the clicked link is internal, and false if it takes the user away from the website.\nfunction() { return {{Click URL}}.indexOf({{Page Hostname}}) \u0026gt; -1; }  5. return {{Click URL}}.split(\u0026lsquo;/\u0026rsquo;).pop() Again, a simple Custom JavaScript Variable. This is especially useful when tracking file downloads, as it returns the actual filename of the downloaded item. It does this by returning whatever is in the clicked URL after the last \u0026lsquo;/\u0026rsquo;.\nfunction() { // Example: https://www.simoahava.com/downloads/download_me.pdf  return {{Click URL}}.split(\u0026#39;/\u0026#39;).pop(); // Returns: download_me.pdf }  6. Create a random, unique GUID Every now and then it\u0026rsquo;s useful to create a random ID in GTM. For example, if you want to measure session IDs, or if you want to assign a unique identifier to each page hit, you can achieve this with the following Custom JavaScript Variable.\nThe variable creates a GUID string (\u0026ldquo;Globally Unique Identifier\u0026rdquo;), and even though uniqueness isn\u0026rsquo;t guaranteed, it\u0026rsquo;s still very likely. There\u0026rsquo;s only a microscopically small chance of collision.\nThis solution is gratefully adapted from this StackOverflow post.\nfunction() { return \u0026#39;xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx\u0026#39;.replace(/[xy]/g, function(c) { var r = Math.random()*16|0, v = c == \u0026#39;x\u0026#39; ? r : (r\u0026amp;0x3|0x8); return v.toString(16); }); }  7. Return an ISO-formatted timestamp This is one of my favorite solutions, as it lets you convert the current client time to a proper, readable timestamp. In addition, it has the timezone offset included, so you\u0026rsquo;ll know just how much the users\u0026rsquo; local times differ from your own timezone. I send this to Google Analytics with every single hit, so that I can create a timeline of events when analyzing the data.\nThis solution is gratefully adapted from this StackOverflow post.\nfunction() { var now = new Date(); var tzo = -now.getTimezoneOffset(); var dif = tzo \u0026gt;= 0 ? \u0026#39;+\u0026#39; : \u0026#39;-\u0026#39;; var pad = function(num) { var norm = Math.abs(Math.floor(num)); return (norm \u0026lt; 10 ? \u0026#39;0\u0026#39; : \u0026#39;\u0026#39;) + norm; }; return now.getFullYear() + \u0026#39;-\u0026#39; + pad(now.getMonth()+1) + \u0026#39;-\u0026#39; + pad(now.getDate()) + \u0026#39;T\u0026#39; + pad(now.getHours()) + \u0026#39;:\u0026#39; + pad(now.getMinutes()) + \u0026#39;:\u0026#39; + pad(now.getSeconds()) + \u0026#39;.\u0026#39; + pad(now.getMilliseconds()) + dif + pad(tzo / 60)  + \u0026#39;:\u0026#39; + pad(tzo % 60); // Returns, for example: 2017-01-18T11:58:32.977+02:00 }  8. .matches() polyfill When working with the Document Object Model (DOM), being able to identify elements is crucial. We already have a bunch of wonderful CSS selectors at our disposal, but now we just need a method we can use to check if any given element matches one of these selectors.\nWell, there\u0026rsquo;s the Element.matches(someSelector) method that you can use, but it doesn\u0026rsquo;t have stellar browser support, even with prefixes. With this solution, you can always use .matches() without having to worry about browser support. This trick is called a polyfill, as it patches lack of feature support with a workaround using JavaScript that is universally supported.\nFirst, here\u0026rsquo;s how the method works in general:\n// Check if the parent of the clicked element has ID #testMe var el = {{Click Element}}; console.log(el.parentElement.matches(\u0026#39;#testMe\u0026#39;)); // RESULT: true or false, depending on if the parent element matches the selector.  To implement the polyfill, either ask your developers to add it to the site JavaScript as early as possible in the page load sequence, or use Google Tag Manager.\nIn Google Tag Manager, you\u0026rsquo;ll need a Custom HTML Tag that fires as early as possible in the container load sequence (i.e. All Pages trigger with a high tag priority).\nHere\u0026rsquo;s the code you need to add to the Custom HTML Tag. It\u0026rsquo;s gratefully adapted from this MDN reference page.\n\u0026lt;script\u0026gt; if (!Element.prototype.matches) { Element.prototype.matches = Element.prototype.matchesSelector || Element.prototype.mozMatchesSelector || Element.prototype.msMatchesSelector || Element.prototype.oMatchesSelector || Element.prototype.webkitMatchesSelector || function(s) { var matches = (this.document || this.ownerDocument).querySelectorAll(s), i = matches.length; while (--i \u0026gt;= 0 \u0026amp;\u0026amp; matches.item(i) !== this) {} return i \u0026gt; -1; }; } \u0026lt;/script\u0026gt; The polyfill modifies the actual prototype of the Element object, which all HTML and DOM elements inherit from. After modifying the prototype, you can use the matches() method with confidence in all your GTM and site JavaScript.\n9. DOM traversal Sometimes it\u0026rsquo;s necessary to climb up (or down) the Document Object Model. For example, if you\u0026rsquo;re using a Click / All Elements trigger, it always targets the actual element that was clicked. But that\u0026rsquo;s not always necessarily the element you want to track! Say you have an HTML structure like this:\n\u0026lt;a href=\u0026#34;takemeaway.html\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;clickMe\u0026#34;\u0026gt; \u0026lt;span\u0026gt;Click Me!\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;/a\u0026gt; Now, if you use a Click / All Elements trigger, the element that is captured in the click is the \u0026lt;span/\u0026gt;. But I\u0026rsquo;m guessing you actually want to use the \u0026lt;a href=\u0026quot;takemeaway.html\u0026quot;\u0026gt; element, since you\u0026rsquo;re more interested in knowing what happens after the click. So, you can use this Custom JavaScript Variable to return the nearest link above the clicked element in the DOM tree:\nfunction() { var el = {{Click Element}}; while (!el.matches(\u0026#39;a\u0026#39;) \u0026amp;\u0026amp; !el.matches(\u0026#39;body\u0026#39;)) { el = el.parentElement; } return el.matches(\u0026#39;a\u0026#39;) ? el : undefined; }  NOTE! This relies on the matches() method, so don\u0026rsquo;t forget to implement the polyfill from above, first!\nThis Custom JavaScript Variable climbs up the DOM until it reaches the first link element it finds ('a'), after which it returns this element. If it doesn\u0026rsquo;t find a link, it returns undefined instead.\n10. Set browser cookies with ease Cookies are a great, if somewhat outdated, way of storing information in the browser. Since Google Tag Manager operates in the context of a web page, it is essentially stateless. Thus any information you want to persist from one page to another must be stored either in the server or the browser itself. The latter is far easier to do, and with browser cookies it\u0026rsquo;s just a question of adding a couple of lines of code to your GTM deployment.\nFirst, you need a Custom JavaScript Variable. You can name it {{Set Cookie}}, for example.\nfunction() { return function(name, value, ms, path, domain) { if (!name || !value) { return; } var d; var cpath = path ? \u0026#39;; path=\u0026#39; + path : \u0026#39;\u0026#39;; var cdomain = domain ? \u0026#39;; domain=\u0026#39; + domain : \u0026#39;\u0026#39;; var expires = \u0026#39;\u0026#39;; if (ms) { d = new Date(); d.setTime(d.getTime() + ms); expires = \u0026#39;; expires=\u0026#39; + d.toUTCString(); } document.cookie = name + \u0026#34;=\u0026#34; + value + expires + cpath + cdomain; } }  This Custom JavaScript Variable returns a function that takes five parameters:\n name (required): the name of the cookie (string)\n value (required): the value of the cookie (string)\n ms: expiration time of the cookie in milliseconds. If unset, defaults to a Session cookie (expires when the browser is closed).\n path: the path of the cookie. If unset, defaults to the current page path.\n domain: the domain of the cookie. If unset, defaults to the current domain.\n  To use the cookie, you invoke it with:\n{{Set Cookie}}(\u0026#39;test\u0026#39;, \u0026#39;true\u0026#39;, 10000, \u0026#39;/\u0026#39;, \u0026#39;simoahava.com\u0026#39;);  The code above, when run in GTM, sets a cookie with name \u0026quot;test\u0026quot;, value \u0026quot;true\u0026quot;, expiration time of ten seconds, and it\u0026rsquo;s set on the root of the simoahava.com domain.\nWith this helper, setting cookies is a breeze. Remember that you can then use the handy 1st Party Cookie variable in GTM to retrieve values from set cookies.\nSummary Here I listed 10 JavaScript tricks that I use (almost) all the time. There\u0026rsquo;s plenty more to JavaScript, but with these methods you can get started on making your clunky Google Tag Manager deployment a thing of the past.\nDo you have any favorite methods, tips, or tricks you want to share? Please do so in the comments below.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/10-useful-css-selectors/",
	"title": "#GTMTips: 10 Useful CSS Selectors",
	"tags": ["css selectors", "Google Tag Manager", "gtmtips"],
	"description": "10 useful CSS selectors you can use in Google Tag Manager.",
	"content": " Without a doubt, the possibility to leverage CSS selectors in Google Tag Manager\u0026rsquo;s trigger conditions is one of the most useful features of the platform. It gives you an amazing amount of flexibility, especially when combined with GTM\u0026rsquo;s click and form triggers.\nEssentially, CSS selectors let you test an HTML Element against a selector string. This check verifies that the element matches the given selector. In practice, this would mean that when you use the click or form trigger, you can check if the Click Element or Form Element built-in variables match a specific selector, allowing you to confirm that the action happened on the correct element. I\u0026rsquo;ll explain this with more detail further down.\nIn this #GTMTips article, I\u0026rsquo;ll showcase ten useful CSS selectors which might come in handy in your Google Tag Manager setups.\nTip 53: 10 Useful CSS Selectors   Even though you can use CSS selectors in any JavaScript (or CSS) you deploy in your site or in GTM, I\u0026rsquo;m guessing your most typical scenario would be the matches CSS selector trigger condition.\nThis trigger condition is used when you want to evaluate the element that was clicked (or submitted, in case it was a form). In other words, to use a CSS selector against the clicked element, you would first need a trigger which records clicks or forms, and then you\u0026rsquo;d need to append it with a condition like so:\n  For example, the trigger above would only fire if the clicked element was a direct child of an element with the ID myDiv.\nAnd that\u0026rsquo;s how CSS selectors can be used with triggers. Note that CSS selectors are very useful in general, too. It goes without saying that you\u0026rsquo;ll need them in stylesheets, but they can also be used with the querySelector() and querySelectorAll() DOM methods, as well as with matches() (cross-browser support might need some tweaks).\nAnyway, without further ado, here are 10 useful CSS selectors for your viewing pleasure.\n1. Generic selectors The following selectors are used to pinpoint elements based on their attributes or their position in the DOM. Selectors can be combined by putting them one after the other. For example, div[title=\u0026quot;someTitle\u0026quot;][data-gtm-event=\u0026quot;someEvent\u0026quot;] would match any div element that has both the title and data-gtm-event attributes.\n .someClass - matches an element with class \u0026ldquo;someClass\u0026rdquo;, e.g. \u0026lt;div class=\u0026quot;someClass\u0026quot;\u0026gt;.\n #someId - matches an element with id \u0026ldquo;someId\u0026rdquo;, e.g. \u0026lt;span id=\u0026quot;someId\u0026quot;\u0026gt;.\n element - matches any HTML element named \u0026ldquo;element\u0026rdquo;. For example, \u0026ldquo;div\u0026rdquo; would match all div elements on page, and \u0026ldquo;div#myId\u0026rdquo; would match \u0026lt;div id=\u0026quot;myId\u0026quot;\u0026gt;.\n element element - matches any HTML element that is the descendant of the preceding element. Doesn\u0026rsquo;t need to be a parent-child relationship - the first element just needs to precede the second one in the same tree. For example, \u0026ldquo;span.myClass div#myId\u0026rdquo; would match any div#myId that is the descendant of a span.myClass. You can add as many links to the chain as you want: \u0026ldquo;div#main ol li\u0026rdquo;, for example, would match any li that is the descendant of an ol that is the descendant of div#main.\n element \u0026gt; element - matches any HTML element that is the direct child of the preceding element. For example, \u0026ldquo;div#myId \u0026gt; a#contactUs\u0026rdquo; would match \u0026lt;a id=\u0026quot;contactUs\u0026quot;\u0026gt; that is the direct child of \u0026lt;div id=\u0026quot;myId\u0026quot;\u0026gt;.\n selector, selector - two selectors separated by a comma are evaluated with EITHER-OR logic when used in a trigger. So you can specify multiple selectors, and as long as one of them matches, the trigger will fire.\n  These generic selectors are the basis for pretty much everything you do with CSS selectors, so it\u0026rsquo;s a good idea to learn how they work.\n2. a[href^=\u0026ldquo;tel:\u0026rdquo;] This selector matches any link element (\u0026lt;a\u0026gt;) whose href attribute begins with the string \u0026ldquo;tel:\u0026ldquo;, such as: \u0026lt;a href=\u0026quot;tel:01010101\u0026quot;\u0026gt;. This is useful for tracking clicks on telephone numbers that have been encoded to use the \u0026ldquo;tel:\u0026rdquo; protocol.\nYou can also make it work with email links: a[href^=\u0026quot;mailto:\u0026quot;], the SMS protocol: a[href^=\u0026quot;sms:\u0026quot;], and the outdated but still prevailing JavaScript protocol: a[href^=\u0026quot;javascript:\u0026quot;].\n3. a[href*=\u0026ldquo;simoahava.com\u0026rdquo;] This selector matches any link element whose href attribute contains \u0026ldquo;simoahava.com\u0026rdquo;. Thus I can use it to weed out (or include) clicks on internal links on my website.\n4. a[href$=\u0026ldquo;.pdf\u0026rdquo;] This selector matches any link element whose href attribute ends with \u0026ldquo;.pdf\u0026rdquo;. This is useful for tracking PDF links. To measure other filenames, you can simply replace \u0026ldquo;.pdf\u0026rdquo; with whatever filetype you want to track.\n5. div.someElement a I already covered this in the generic selectors, but there\u0026rsquo;s a very important use case I should highlight.\nWhen working with the Click / All Elements trigger, it\u0026rsquo;s a good idea to add a wildcard check for every element you want to track:\nClick Element matches CSS selector a[href*=\u0026quot;simoahava.com\u0026quot;], a[href*=\u0026quot;simoahava.com\u0026quot;] *\nIn other words, after the actual selector, add a second selector that matches any descendant of that selector. This is useful because the All Elements trigger captures the very element that was clicked. With a nested DOM structure, this might often be something unexpected. For example, if you have a link that looks like this:\n\u0026lt;a href=\u0026#34;mailto:some@email.com\u0026#34;\u0026gt; \u0026lt;span\u0026gt;some@email.com\u0026lt;/span\u0026gt; \u0026lt;/a\u0026gt; A click on the link element above will actually land on the \u0026lt;span/\u0026gt;. By setting the selector to a[href=\u0026quot;mailto:some@email.com\u0026quot;], a[href=\u0026quot;mailto:some@email.com\u0026quot;] *, you\u0026rsquo;re capturing clicks on the link element itself as well as any descendants (including the \u0026lt;span\u0026gt;).\n6. form#myForm option:checked You can use the pseudo-selector :checked to match any checked element. For example, form#myForm option:checked looks for any selected \u0026lt;option\u0026gt; element(s) in the form. This is useful when you want to identify which element in a drop-down list is currently selected.\n7. a:not() The :not pseudo-selector matches if the opposite of the given selector holds true. So, a selector like a:not([href*=\u0026quot;simoahava.com\u0026quot;]) will match clicks on any links that do not have \u0026ldquo;simoahava.com\u0026rdquo; in their href attribute value.\n8. ol \u0026gt; li:first-child The :first-child selector will match the given element that is the first child of its parent. So ol \u0026gt; li:first-child will match the first \u0026lt;li\u0026gt; element of an \u0026lt;ol\u0026gt; list.\nOther similar selectors are :last-child (matches the last child of its parent) and :nth-child(N) (matches the Nth child of its parent, so :nth-child(3) would match the element that is the third child of its parent).\n9. a[data-gtm-event] Square brackets denote attributes, and if you leave out the equals sign (=), you can simply check if an element has the given attribute. a[data-gtm-event] will match any link element that has the attribute data-gtm-event regardless of what the value of that attribute is.\n10. body \u0026gt; div.site-container \u0026gt; div \u0026gt; div \u0026gt; main\u0026hellip; ARGH This is actually a tip rather than a useful selector. Try to avoid really long, complex selector chains. The longer chain it is, and the more you insist on direct parent-child relationships (\u0026gt;), the more points of failure you introduce into the selector.\nAll it takes is one element to change along that DOM path and your selector will stop working. Thus, try to always find the most generic selector that is still specific enough to match exactly what you are trying to capture. This requires some knowledge of the HTML structure of your templates.\nThe long, complex selector in this post\u0026rsquo;s feature image could be replaced simply with:\nheader \u0026gt; h2 \u0026gt; a\nand it will be just as accurate, because I know for a fact that my HTML reserves that DOM sequence for the article titles you see on the main page.\nSummary And there you have it! These selectors should come in handy when you are tweaking your GTM setup.\nDo you have any other really useful selectors you\u0026rsquo;d like to share with others? If you do, please share them in the blog comments!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/change-management-workspaces/",
	"title": "#GTMTips: Change Management With Workspaces",
	"tags": ["Google Tag Manager", "gtmtips", "workspaces"],
	"description": "Guide and introduction to Google Tag Manager&#39;s Workspaces feature.",
	"content": " A while ago, the Google Tag Manager team published one of my favorite feature releases in the history of GTM: Workspaces. I was so thrilled by this release that I went ahead and published a guide on how to implement and leverage this new feature.\nWorkspaces is a very comprehensive feature in Google Tag Manager. This is because it changed the entire underlying data model. We no longer work directly with a single container draft. Instead, our work is done in a cordoned section of the container, protected from changes made to other workspaces until such a time that we choose to sync the latest container version to our workspace, or vice versa.\nThis #GTMTips article is short and simple: it\u0026rsquo;s a reminder and a nudge to leverage workspaces efficiently.\nTip 52: Use Workspaces To Keep Track Of Change   First of all, if workspaces are completely alien to you as a concept, please take a look at my Workspaces Guide. It\u0026rsquo;s long and probably quite confusing (as my guides typically are), but it should get you up to speed with this enterprise-friendly feature.\nIn a nutshell, workspaces provides you the opportunity to work on multiple container drafts at the same time. Once the feature set is complete in a single workspace, you can Create a Version or Publish the workspace, so that it becomes the new Latest Container Version. After the Latest Container Version is updated, all existing workspaces will be alerted of this change, and you will then need to synchronize these new changes into all the other workspaces.\nIf you\u0026rsquo;re using the free version of Google Tag Manager, you have three workspaces that you can use concurrently. In Google Tag Manager 360, you have an unlimited number of workspaces at your disposal. This article mainly targets the former group, since necessity is the mother of innovation. Nevertheless, even if you have access to GTM 360 you should consider utilizing workspaces in such a manner that best relieves friction in your Google Tag Manager process.\nWhat follows are some practices that I have found very useful when working with workspaces.\n1. Use workspaces for feature updates This might seem self-evident, but when workspaces was first released, a common reaction was to use them to isolate a part of the container for some team, and another part of the container for another team.\nWorkspaces isn\u0026rsquo;t a user management feature - it\u0026rsquo;s change management through-and-through. When you publish or create a version of your changes, the underlying workspace is deleted when the new version is created. This means that the feature doesn\u0026rsquo;t really lend itself for consistent use within a team.\nNothing\u0026rsquo;s stopping you from reserving one of the three workspaces to one team, another for some other team, and a third one for generic, incremental changes (see the next tip). However, you should be aware that the feature itself has no built-in functionality to support user management in that way, so you\u0026rsquo;ll have to make sure to use a naming convention \u0026ldquo;Team Name - Workspace Name\u0026rdquo;, for example, to make it clear that the workspace is for a specific team.\n2. Always have one workspace available for small, incremental changes One of the main benefits of workspaces is that you can finally commit your small change to a single tag and publish it without having to worry about taking a bunch of unfinished work with the update into the live container.\nFor this reason and for the sake of agility, it is important to always have one workspace available for small, incremental changes.\nOnce you\u0026rsquo;ve done the change, you can either Create a Version or directly Publish the workspace, depending on what the appropriate workflow is in your organization.\nThe best part about this is that even when you publish your small, incremental change, any other workspace in the container doesn\u0026rsquo;t need to merge the changes you made until they are ready to do so. This deferred synchronization is another great thing about the feature.\n3. Defer synchronization until you are ready to do so   When someone has updated the Latest Container Version by publishing their changes, you\u0026rsquo;ll see a small banner in the bottom of the screen as well as the \u0026ldquo;UPDATE\u0026rdquo; button in the Overview Dashboard (see image above).\nThis means that there are changes to the Latest Container Version that should be merged with your workspace before you can Publish or Create a Version of your workspace.\nIt\u0026rsquo;s good to know that you don\u0026rsquo;t have to do this until you\u0026rsquo;re ready to merge!. The note is there to remind you that you need to merge before you\u0026rsquo;re done with your workspace, but you might want to audit the changes before you sync them with your workspace.\nTo check what changes would be merged, click the \u0026ldquo;UPDATE\u0026rdquo; button in the Overview Dashboard. A new fly-out will appear, where you\u0026rsquo;ll see all the versions that have been created after your workspace was detached from the version branch. You can click these versions to see what changes have been done, and thus you can prepare your workspace to accommodate these disruptions if necessary.\n  Remember that even if there are conflicts, Google Tag Manager will warn you of these and force you to resolve them before the sync is complete. Even so, it\u0026rsquo;s still a good idea to briefly check each update to see if there\u0026rsquo;s something you should consider in your workspace, conflicts or not.\n4. Name your workspaces clearly I\u0026rsquo;m not usually one to froth at the mouth over naming conventions, but with workspaces I might consider an exception. By naming the workspace, you are actually giving a name to the version you\u0026rsquo;ll inevitably create from the workspace, too. Yes, you can rename the container version at any time, but it cuts one step out of the workflow if you name the workspace with the future version in mind.\nConsider naming the workspace with a compact but comprehensive description of what the feature increment that you\u0026rsquo;re doing is. Typically, if you find it difficult to come up with a name that covers all the changes introduced in the workspace, it means that you\u0026rsquo;re doing too much in a single go, and you might consider rethinking your approach in the future. I always prefer small, incremental changes over big, whopping, world-altering feature blasts. Small updates also make it easier to keep all other workspaces in sync.\nRemember that naming versions is purely for your own benefit. If you ever need to roll back, or if you need to find a specific version, the version name (and sometimes the description) is pretty much all you have to work with. Because of this, it\u0026rsquo;s important to name every single version you create so that anyone glancing at the version name would have even just a cursory idea of what was updated in that version.\nSummary It would be silly to say \u0026ldquo;I hope you\u0026rsquo;re using workspaces already\u0026rdquo;, since everyone using Google Tag Manager is, by default, using workspaces already.\nIt might be a bummer to some to only have three workspaces available in the free version of GTM. However, apart from initial implementation or larger, migration-level projects, three workspaces should always be enough for the type of iterative, agile change management that Google Tag Manager necessitates, at least in my experience.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/log-failed-google-analytics-requests-google-analytics/",
	"title": "Log Failed Google Analytics Requests In Google Analytics",
	"tags": ["debug", "ga spy", "google analytics", "Google Tag Manager"],
	"description": "You can use Google Analytics to collect information on other Google Analytics requests that failed to send correctly, for whatever reason.",
	"content": " UPDATE 20 December 2016: I made some fixes to the solution - be sure to grab the latest code snippet from below!\nHaving worked in all sorts of Google Analytics projects over the years, I\u0026rsquo;ve found myself more and more interested in the technical underpinnings of digital analytics rather than the actual analytical work. We all play to our respective strengths, I guess. For example, there are still many purely technical / technological mysteries surrounding Google Analytics, because much of the data processing is done server-side.\nOne of these mysteries is a proper feedback loop for request quality. When you send a request to Google Analytics such as a Page View hit, you can verify that it works in multiple ways:\n Google Tag Manager Debug mode\n Google Analytics Debugger\n Google Analytics Real Time reports\n Google Tag Assistant recordings\n Web browser\u0026rsquo;s own developer tools\n  I\u0026rsquo;ve covered much of Google Analytics debugging in this article.\nHowever, no matter how successful your own tests are, one thing is missing: a solid, reliable way of collecting data from all failed requests from your site visitors. Google Analytics doesn\u0026rsquo;t automatically log problems with data collection, even if Analytics notifications do reveal some issues.\nThis can, and should, lead to healthy doubt concerning the veracity of your data set - is it a representative sample of all hits sent from your digital property, or is some business critical information (such as Ecommerce) being dropped more than average?\nIn this article, I want to show a simple way of logging all failed requests in Google Analytics as new events. The solution builds on Stephen Harris\u0026rsquo; awesome GA Spy, and the technical approach is encapsulated in a single Custom HTML Tag in Google Tag Manager.\n  Read on, my friend!\nThe solution Here\u0026rsquo;s how it works.\n GA Spy to processes every single call to the ga() global function.\n For each call with the send command, send the hit payload to https://www.google-analytics.com/debug/collect (read more about the /debug/ endpoint).\n Don\u0026rsquo;t forget to send the regular hit to Google Analytics.\n If the /debug/ returns a failed request, push the error message and the failed hit payload into dataLayer.\n  In a nutshell, for every hit sent to Google Analytics, you\u0026rsquo;re also sending the same hit to the GA debug endpoint. This endpoint returns information on whether or not the request was a success, and if it wasn\u0026rsquo;t, what was wrong with it.\n{ \u0026#34;hitParsingResult\u0026#34;: [ { \u0026#34;valid\u0026#34;: false, \u0026#34;parserMessage\u0026#34;: [ { \u0026#34;messageType\u0026#34;: \u0026#34;WARN\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;The value provided for parameter \u0026#39;ev\u0026#39; is invalid. Please see http://goo.gl/a8d4RP#ev for details.\u0026#34;, \u0026#34;messageCode\u0026#34;: \u0026#34;VALUE_INVALID\u0026#34;, \u0026#34;parameter\u0026#34;: \u0026#34;ev\u0026#34; } ], \u0026#34;hit\u0026#34;: \u0026#34;...\u0026#34; } ], \u0026#34;parserMessage\u0026#34;: [ { \u0026#34;messageType\u0026#34;: \u0026#34;INFO\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Found 1 hit in the request.\u0026#34; } ] } From dataLayer, I\u0026rsquo;m actually sending this information to Google Analytics via GTM. This way you\u0026rsquo;ll end up with a report that looks like this:\n  Heck, you can even click one of the error messages to drill down to the actual payloads. For example, if I choose \u0026lsquo;ea\u0026rsquo; error, I can see the payloads and verify that indeed, there\u0026rsquo;s no Event Action parameter with these hits.\n  I can then go to GTM, find the offending tag, and fix it to always send some value in Event Action.\nDue to the abstraction of dataLayer, you don\u0026rsquo;t have to log this information in Google Analytics. In fact, you might not want to, since you might already have some sort of logging rig setup in your development process. Thanks to Google Tag Manager, you can push the data to any endpoint that supports JavaScript-generated data transfer (e.g. HTTP requests).\nHowever, I\u0026rsquo;ve elected to send the information to Google Analytics. Doing so, I can align these validation errors with all the other hits that this particular user has sent to GA, and I can thus potentially identify bigger issues that these validation errors might only be a symptom of. For example, it\u0026rsquo;s possible that an Ecommerce tag only fails if the user has followed a specific funnel on the site. By sending the validation error to Google Analytics, I can see if it occurred during one of these broken funnels, giving me more information to fix it in the end.\nHow to do it You basically need a Custom HTML Tag that fires on the All Pages trigger, with a higher Tag Priority than any of your Google Analytics tags that might also fire on this event.\nIt\u0026rsquo;s important that this code starts its execution before your Google Analytics tags have a chance to start up. This code overwrites the ga() method, and any tag that has already fired will not be debugged with this solution.\nYou\u0026rsquo;ll first need the actual code for GA Spy, and you can download the latest version from Stephen\u0026rsquo;s repository. You need to copy-paste the JavaScript into a Custom HTML Tag, and then add the custom listener below it. Here\u0026rsquo;s the full example, where I\u0026rsquo;ve minified the GA Spy code to make it more compact. Scroll down past the GA Spy part to find the actual magic.\n\u0026lt;script\u0026gt; /* Minified GA Spy starts */ window.gaSpy=window.gaSpy||function(b){var j,k,c=function(a){if(b=null,a.debugLogPrefix=a.debugLogPrefix||\u0026#34;gaSpy\u0026#34;,!a.callback||\u0026#34;function\u0026#34;!=typeof a.callback)throw new Error(\u0026#34;[\u0026#34;+a.debugLogPrefix+\u0026#34;] Aborting; No listener callback provided.\u0026#34;);return a.gaObjName=a.gaObjName||window.GoogleAnalyticsObject||\u0026#34;ga\u0026#34;,a.debug=!!a.debug,a}(\u0026#34;function\u0026#34;==typeof b?{callback:b}:b),d=c.gaObjName,e=window[d],f=window.console\u0026amp;\u0026amp;c.debug;?function(){var a=[].slice.call(arguments);a.unshift(\u0026#34;[\u0026#34;+c.debugLogPrefix+\u0026#34;]\u0026#34;),console.log.apply(console,a)}:function(){},g=function(a){var b,d={args:a,the:{}},e=d.the;return c.debug\u0026amp;\u0026amp;function;(b,c){for(b=\u0026#34;Intercepted: ga(\u0026#34;,c=0;c1?b[0]:\u0026#34;t0\u0026#34;,e.command=b.length\u0026gt;1?b[1]:b[0],b=b[b.length-1].split(\u0026#34;:\u0026#34;),e.pluginName=b.length\u0026gt;1?b[0]:void 0,e.pluginMethodName=b.length\u0026gt;1?b[1]:void 0,\u0026#34;require\u0026#34;===e.command||\u0026#34;provide\u0026#34;===e.command?(e.pluginName=a[1],\u0026#34;provide\u0026#34;===e.command\u0026amp;\u0026amp;(e.pluginConstructor=a[2])):(\u0026#34;send\u0026#34;===e.command\u0026amp;\u0026amp;(e.hitType=a[a.length-1]\u0026amp;\u0026amp;a;[a.length-1].hitType||a[1]),\u0026#34;object\u0026#34;==typeof a[a.length-1]\u0026amp;\u0026amp;(e.trackerName=a[a.length-1].name||e.trackerName))),f(\u0026#34;Run listener callback\u0026#34;,e),!1!==c.callback(d)},h=function(){var a=[].slice.call(arguments);if(c.debug){if(!g(a))return f(\u0026#34;Command blocked.\u0026#34;)}else try{if(!g(a))return}catch(a){}return f(\u0026#34;Command allowed:\u0026#34;,a),h._gaOrig.apply(h._gaOrig,a)},i=function(){var a,b=h._gaOrig=window[d];f(\u0026#34;Hijack\u0026#34;,b._gaOrig?\u0026#34;(already hijacked)\u0026#34;:\u0026#34;\u0026#34;),window[d]=h;for(a in b)b.hasOwnProperty(a)\u0026amp;\u0026amp;(window[d][a]=b[a])};if(f(\u0026#34;Config:\u0026#34;,c),e||(f(\u0026#34;Instantiate GA command queue\u0026#34;),e=window[d]=function(){(window[d].q=window[d].q||[]).push(arguments)},e.l=1*new Date),e.getAll)f(\u0026#34;GA already loaded; cannot see previous commands\u0026#34;),i();else{if(!e.l)throw new Error(\u0026#34;[\u0026#34;+c.debugLogPrefix+\u0026#34;] Aborting; `\u0026#34;+d+\u0026#34;` not the GA object.\u0026#34;);if(f(\u0026#34;Command queue instantiated, but library not yet loaded\u0026#34;),e.q\u0026amp;\u0026amp;e.q.length;){for(f(\u0026#34;Applying listener to\u0026#34;,e.q.length,\u0026#34; queued commands\u0026#34;),j=[],k=0;k -1; })[0] .description; var errorHit = data.hitParsingResult[0].hit; window.dataLayer.push({ event: \u0026#39;gaValidationError\u0026#39;, gaValidationError: { description: errorDescription, hit: errorHit } }); }; // If a \u0026#39;send\u0026#39; command is registered, start the process  if (typeof ga === \u0026#39;function\u0026#39; \u0026amp;\u0026amp; trackerName \u0026amp;\u0026amp; gaCommand === \u0026#39;send\u0026#39;) { ga(function() { tracker = ga.getByName(trackerName); if (!tracker.get(\u0026#39;debugDone\u0026#39;)) { originalSendTask = tracker.get(\u0026#39;sendHitTask\u0026#39;); tracker.set(\u0026#39;sendHitTask\u0026#39;, buildDebugHit); } }); } } catch(e) { // Error handling  } }); \u0026lt;/script\u0026gt; This solution uses Universal Analytics Tasks API to copy the hit payload sent to Google Analytics, and to send it then to the debugger endpoint.\nSince you\u0026rsquo;re actually \u0026ldquo;hijacking\u0026rdquo; Google Analytics here, it\u0026rsquo;s very important that you test this thoroughly. To see if it works, you should see a POST request to /debug/collect for each actual hit to /collect. You can find this in the Network debugger of your browser\u0026rsquo;s developer tools. Here\u0026rsquo;s what the output looks like in Chrome:\n   Again, remember to test it.\nSend the information to Google Analytics To send the validation error hits to Google Analytics, you\u0026rsquo;ll need a Universal Analytics tag, two Data Layer variables and a Custom Event trigger.\nThe Data Layer variables should point to variable names gaValidationError.description and gaValidationError.hit. They might thus look something like this:\n  Next, the Custom Event Trigger is a simple affair, and looks like this:\n  Finally, the Universal Analytics tag is your run-of-the-mill Event tag, with just one important modification. You need to set a custom Fields to set field to:\nField name: debugDone\nValue: true\nDon\u0026rsquo;t bother looking it up in the supported field reference for analytics.js, it\u0026rsquo;s not there. It\u0026rsquo;s a custom field I created only for this solution. It prevents two things: 1) Calls to the debug endpoint from multiplying when the same tracker is used, and 2) calls to the debug endpoint for the validation error events.\nHere\u0026rsquo;s what the Event tag might look like:\n  This particular tag will send each validation error as a non-interaction event to Google Analytics, with the error description as the Event Action and the broken hit payload as the Event Label.\nSummary This solution relies on the awesomeness of GA Spy. The script basically hijacks the GA global method, and copies all commands to the debug endpoint.\nWhat this solution does is give you yet another tool for validating your Google Analytics setup. When working with complex Google Tag Manager setups, it might be difficult to keep tabs on all the variables you are using. This might lead to problems in your tags, when a required field ends up with a blank value just because a variable didn\u0026rsquo;t resolve in an expected way. This solution lets you find these cases with ease, giving you a clear path to fixing them before they become a real data quality problem.\nIt would be pretty neat to have the /debug/ interface as a tool you could install locally. That way you wouldn\u0026rsquo;t need to do the trip to Google Analytics servers, and instead validate the hits in your own web server. On the other hand, the logic isn\u0026rsquo;t probably that complex, so having it as a dedicated JavaScript library would be great as well. In any case, the endpoint debugger is a really smooth tool, especially when combined with GA Spy as illustrated in this article.\nAnother thing that would make this whole thing easier was if the original request to /collect simply returned the debug payload automatically. That way you could just look at the responses to the GA requests without having to do the extra trip to /debug/. I understand this doesn\u0026rsquo;t exist because of latency and how most hits to GA are still done with a GET request. Still, Google could at least make it a configurable setting in the GA request.\n"
},
{
	"uri": "https://www.simoahava.com/spam-filter/",
	"title": "Spam Filter Insertion Tool",
	"tags": [],
	"description": "",
	"content": "I took my Spam Filter Insertion Tool down since it\u0026rsquo;s very ineffective for tackling referral spam in Google Analytics. There are far better ways to combat spam.\nYou can still download the source in the GitHub repository if you want to build the tool yourself.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-analytics-client-id-amp-pages/",
	"title": "Google Analytics Client ID In AMP Pages",
	"tags": ["amp", "client id", "dan wilkerson", "google analytics", "nodejs", "php"],
	"description": "How to setup Google Analytics Client ID bridging across AMP and non-AMP pages. You can use Google Tag Manager to set it up.",
	"content": " This article is a collaboration between Simo and Dan Wilkerson. Dan\u0026rsquo;s one of the smartest analytics developers out there, and he\u0026rsquo;s already contributed a great #GTMTips guest post. It\u0026rsquo;s great to have him back here sharing his insight on working with Accelerated Mobile Pages (AMP).\nSo, we\u0026rsquo;re back on AMP! Simo wrote a long, sprawling AMP for Google Tag Manager guide a while ago, and Dan has also contributed to the space with his guide for AMP and Google Analytics. Both of these guides touched upon a subject that might be one of the reasons to stay away from AMP for now: Client ID matching across AMP, your regular website, and any caches or CDNs that serve the AMP version.\n  Not only does AMP have its own, unique syntax for the Client ID, it also stores it in different ways. For example, in the AMP Cache (and thus via Google search, too), it\u0026rsquo;s stored in localStorage. If someone visits your site directly and accesses AMP pages, the Client ID is stored in the AMP_ECID_GOOGLE cookie. And then if someone visits a regular page on your site, the Client ID can be found in the _ga cookie.\nIn this article, Dan and Simo tackle this issue by showing how to serve the Client ID consistently from the _ga cookie written on your website\u0026rsquo;s actual domain. This way, AMP pages will use the same Client ID that regular Google Analytics uses, and you will be able to identify customer journeys that may pass through both your regular site as well as your AMP content.\nThe examples are provided in NodeJS and PHP (WordPress), but the methodology is universal and quite simple to do with any web server software.\nOverview To recap, Google Analytics stores a unique identifier for every user who visits your site within a first-party cookie. This value, in GA parlance, is called the Client ID, and the name of the cookie is _ga. Here\u0026rsquo;s what the entire cookie string looks like, with the actual Client ID bolded.\nGA1.2.1789536866.1471440764\nThe GA1 value denotes this is version 1 of the _ga cookie. The 2 denotes the number of dot-separated components in the URL the cookie is stored at. For example, if GA were instructed to store the cookie at shop.example.com, the number would be 3, instead.\nBecause AMP pages can be cached and served on many different domains, users who might have had a single Client ID could wind up being split into several users instead.\n  This appears to be at least part of the reason behind why Google Analytics officially recommends using a separate GA Property for AMP data.\nHowever, there\u0026rsquo;s a way to use only the _ga cookie for all sources that serve your web content. To do this, we\u0026rsquo;ll need to customize our amp-analytics component.\nCustom AMP configuration amp-analytics is the component that AMP uses for tracking user interactions. If you\u0026rsquo;d like to learn more about all the features it supports, check out the AMP for GTM guide in this blog; it should have all the information you need.\nFor our purposes, let\u0026rsquo;s focus on the config attribute. It\u0026rsquo;s an optional attribute that we can use to tell AMP: \u0026ldquo;Hey, we\u0026rsquo;ve got some additional configurations that we need to you fetch from this location\u0026rdquo;. This attribute should be set to a URL where additional analytics configurations should be retrieved from. In other words, you need to specify an HTTP request endpoint which returns a valid, AMP-compliant JSON configuration file.\n\u0026lt;amp-analytics config=\u0026#34;//example.com/analytics.config.json\u0026#34;\u0026gt;\u0026lt;/amp-analytics\u0026gt; Once the browser has loaded the AMP page, and the page is visible in the browser window, AMP will fetch this external configuration file and use it to supplement any configurations that might already be established on the page. Unlike other resources in your content, your amp-analytics config will always point to your server and the result isn\u0026rsquo;t automatically cached. When the request to your server comes in, it will include all of the cookies set on the user\u0026rsquo;s browser on your domain.\nNOTE! If, and when, your content is served through the Google AMP Cache, any external configuration must be downloaded from an HTTPS source. Thus if your web server is behind HTTP, you\u0026rsquo;ll need to either only serve your custom configuration when visitors are on your domain OR use just the default configuration template instead. Or, you know, switch to HTTPS as soon as possible.\nGrabbing the _ga cookie When the request for the custom AMP config is received by your web server, you can check the cookies in the HTTP request to see if a _ga cookie is already set for the user on the website domain. This would be the case if the user has visited your content before (and hasn\u0026rsquo;t flushed cookies). If the cookie is found, you can use a specific HTTP header (see below) in the response to pass this cookie to the domain where the request originated from, e.g. Google\u0026rsquo;s AMP cache.\nIf the cookie is not found, you can generate a new _ga cookie, following the same pattern analytics.js uses - a random unsigned 32-bit integer coupled with a timestamp rounded to the nearest second, like this:\n1789536866.1471440764\nYou can then leverage the Set-Cookie header in the HTTP Response, and instruct the browser to store the new Client ID in a _ga cookie, making sure to set the domain, path, and expiration date to match the domain the request originated from (e.g. cdn.ampproject.org), just like analytics.js does. You\u0026rsquo;ll need to add the same GA1.X. prefix that GA uses, too. Furthermore, you\u0026rsquo;ll need to do this on every single request, so that the lifetime of the _ga cookie continues to be extended on each page load. The Set-Cookie should end up looking something like this:\nSet-Cookie: _ga=GA1.1.18347199128.1478727498; Domain=example.com; Path=/; Expires=Sat, 10 Nov 2018 21:06:48 GMT;\nFinally, you can return the Client ID in the JSON response as a custom AMP variable for use with our AMP requests:\n{ \u0026#34;vars\u0026#34;: { \u0026#34;clientId\u0026#34;: \u0026#34;18347199128.1478727498\u0026#34; } } Checklist for setting up the request handler Of course, it\u0026rsquo;s not quite that simple. In addition to transposing our Client ID and setting it as a cookie, we need to ensure that we\u0026rsquo;ve dotted a few i\u0026rsquo;s. Here\u0026rsquo;s a handy checklist of the configuration steps that need to be taken to ensure everything works in the wild.\n In the site HTML:\n Add the amp-analytics script tag and amp-analytics component to your AMP templates.\n Configure component JSON for desired triggers and requests, using ${clientId} for the \u0026cid; parameter. Alternatively, you can use the pre-built Google Analytics vendor template by adding type=\u0026quot;googleanalytics\u0026quot; to the component.\n Point config attribute to an endpoint or API on your own server.\n Set data-credentials=\u0026quot;include\u0026quot;.\n  In your web server:\n In the request handler in your web server, extract the Client ID from the _ga cookie or generate a new one.\n Add the clientId parameter to the vars object in the JSON configuration. Set it to the Client ID from the _ga cookie.\n Add the Set-Cookie header with the _ga cookie, set to expire in two years.\n Set the Access-Control-Allow-Origin header to https://cdn.ampproject.org. Note: Wildcards (*) are invalid in this context.\n Set the Access-Control-Expose-Headers header to AMP-Access-Control-Allow-Source-Origin.\n Set the Access-Control-Allow-Credentials header to true.\n Set the header AMP-Access-Control-Allow-Source-Origin to the source domain of the document (e.g. https://mysite.com).\n Return the JSON configuration in the response body.\n   For a full example, check out this repository on GitHub. If you\u0026rsquo;re using the Google Analytics vendor configuration, this is all you need to do. If you\u0026rsquo;d like to combine this concept with Google Tag Manager, read on!\nGoogle Tag Manager proxy using NodeJS As Simo covered in his GTM/AMP guide, Google Tag Manager allows us to build Tags and Triggers in a web UI, then compile those down into a JSON configuration in the format AMP expects. If we used the standard GTM implementation, however, the container request is done directly to GTM\u0026rsquo;s server, which means our custom API wouldn\u0026rsquo;t be able to serve the proper Client ID. That said, you can still combine both techniques. You\u0026rsquo;ve just got to roll up your sleeves a little.\nHere\u0026rsquo;s a truncated example, using Node and Express. For the complete code, visit this GitHub repository.\napp.get(\u0026#39;/gtm-analytics.config.json\u0026#39;, (req, res) =\u0026gt; { const domain = req.headers.host.split(\u0026#39;:\u0026#39;)[0] const gaCookie = req.cookies._ga || generateGaCookie(domain) const clientId = parseClientIdFromGaCookie(gaCookie) const cookieString = generateCookieString({ name: \u0026#39;_ga\u0026#39;, value: gaCookie, domain: domain.replace(\u0026#39;www.\u0026#39;, \u0026#39;\u0026#39;), path: \u0026#39;/\u0026#39;, expires: new Date(1000 * 60 * 60 * 24 * 365 * 2 + (+new Date)).toGMTString() }) res.setHeader(\u0026#39;Set-Cookie\u0026#39;, cookieString) res.setHeader(\u0026#39;Access-Control-Allow-Origin\u0026#39;, \u0026#39;https://cdn.ampproject.org\u0026#39;) res.setHeader(\u0026#39;Access-Control-Expose-Headers\u0026#39;, \u0026#39;AMP-Access-Control-Allow-Source-Origin\u0026#39;) res.setHeader(\u0026#39;Access-Control-Allow-Credentials\u0026#39;, \u0026#39;true\u0026#39;) // AMP-specific header, check your protocol  res.setHeader(\u0026#39;AMP-Access-Control-Allow-Source-Origin\u0026#39;, \u0026#39;https://\u0026#39; + domain) request.get({ url: \u0026#39;https://www.googletagmanager.com/amp.json\u0026#39;, qs: req.query, json: true }, (err, response, data) =\u0026gt; { if (err) data = {\u0026#34;vars\u0026#34;: {}} // Add additional error handling here  data.vars.clientId = clientId data.requests = Object.keys(data.requests) .reduce((map, key) =\u0026gt; { map[key] = data.requests[key].replace(/(\u0026amp;cid=)[^\u0026amp;]+/, \u0026#39;$1${clientId}\u0026#39;) return map }, {}) res.json(data) }) })  Here\u0026rsquo;s another checklist, this time for combining your custom Client ID workaround with the Google Tag Manager AMP container. I\u0026rsquo;ve bolded the new steps.\n In your page HTML:\n Add the amp-analytics script tag and amp-analytics component to your AMP templates.\n Point config attribute to an endpoint or API on your own server.\n Set data-credentials attribute to include.\n  In your web server:\n In the request handler in your web server, extract the Client ID from the _ga cookie or generate a new one\n Request the container JSON from GTM, passing along all query parameters from the original amp-analytics request.\n Replace all instances of \u0026lsquo;CLIENT_ID(AMP_ECID_GOOGLE)\u0026rsquo; in the request with \u0026lsquo;${clientId}\u0026rsquo;.\n Add the clientId parameter to the vars object in the JSON configuration. Set it to the Client ID from the _ga cookie.\n Add the Set-Cookie header with the _ga cookie, set to expire in two years.\n Set the Access-Control-Allow-Origin header to https://cdn.ampproject.org. Note: Wildcards (*) are invalid in this context.\n Set the Access-Control-Expose-Headers header to AMP-Access-Control-Allow-Source-Origin.\n Set the Access-Control-Allow-Credentials header to true.\n Set the header AMP-Access-Control-Allow-Source-Origin to the source domain of the document (e.g. https://mysite.com).\n Return the JSON configuration in the response body.\n   In your site code you\u0026rsquo;ll need:\n\u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;amp-analytics config=\u0026#34;//www.yourdomain.com/gtm-analytics.config.json?id=GTM-XXXXX\u0026amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt;\u0026lt;/amp-analytics\u0026gt; Congratulations, you have created a web proxy that fetches the Google Tag Manager container from Google\u0026rsquo;s servers and modifies the JSON to leverage the value stored in the _ga cookie.\nGoogle Tag Manager proxy with WordPress This blog is running on WordPress, so Simo wanted to see how trivial it would be to create the endpoint. As it turns out, it\u0026rsquo;s very simple indeed.\nWordPress provides the rest_api_init hook, which lets you create an HTTP request endpoint on your web server:\n// REST API for GTM container add_action( \u0026#39;rest_api_init\u0026#39;, function() { register_rest_route( \u0026#39;amp-gtm\u0026#39;, \u0026#39;/amp.json\u0026#39;, array( \u0026#39;methods\u0026#39; =\u0026gt; \u0026#39;GET\u0026#39;, \u0026#39;callback\u0026#39; =\u0026gt; \u0026#39;retrieve_gtm_json\u0026#39;, ) ); }); That piece of code in your functions.php would create a GET request endpoint in your web domain path /wp-json/amp-gtm/amp.json. If a GET request to this endpoint is recorded, the callback function named retrieve_gtm_json is then invoked:\n// Generate random Client ID function generate_ga_client_id() { return rand(100000000,999999999) . \u0026#39;.\u0026#39; . time(); } // Set cookie to expire in 2 years function getCookieExpirationDate() { return date(\u0026#39;D, j F Y H:i:s\u0026#39;, time() + 60*60*24*365*2); } // Callback for the GET request function retrieve_gtm_json( $data ) { /* Get the hostname of the request origin, and parse it for the * pure domain name. */ $domain = explode(\u0026#39;:\u0026#39;, $data-\u0026gt;get_header(\u0026#39;Host\u0026#39;))[0]; $domainName = str_replace(\u0026#39;www.\u0026#39;, \u0026#39;\u0026#39;, $domain); // Get the number of parts in the domain name $domainLength = count(explode(\u0026#39;.\u0026#39;, $domainName)); /* Check if the browser already has the _ga cookie. * If not, generate a new cookie. */ $cid = $_COOKIE[\u0026#39;_ga\u0026#39;]; if (!isset($cid)) { $cid = \u0026#34;GA1.{$domainLength}.\u0026#34; . generate_ga_client_id(); } /* Store the actual Client ID (last two numbers) of the * _ga cookie value in the $cidNumber variable */ $cidNumber = preg_replace(\u0026#39;/^GA.\\.[^.]+\\./\u0026#39;,\u0026#39;\u0026#39;,$cid); // Get all HTTP request parameters $query = $_SERVER[\u0026#39;QUERY_STRING\u0026#39;]; /* Fetch the actual GTM container, by passing the valid query parameters from * the original request. */ $container = file_get_contents(\u0026#34;https://www.googletagmanager.com/amp.json?{$query}\u0026#34;); // Replace the \u0026amp;cid; parameter value with ${clientId} $container = preg_replace(\u0026#39;/(\u0026amp;cid=)[^\u0026amp;]+/\u0026#39;,\u0026#39;${1}${clientId}\u0026#39;, $container); // Add the clientId to the \u0026#34;vars\u0026#34; object in the container JSON. $container = json_decode($container); $container-\u0026gt;vars-\u0026gt;clientId = $cidNumber; // Build a new HTTP response from the modified configuration file. $response = new WP_REST_RESPONSE( $container ); // Add the required headers (Set-Cookie, most importantly) to the Request $response-\u0026gt;header( \u0026#39;Set-Cookie\u0026#39;, \u0026#34;_ga={$cid}; Path=/; Expires=\u0026#34; . getcookieExpirationDate() . \u0026#34; GMT; Domain={$domainName};\u0026#34;); $response-\u0026gt;header( \u0026#39;Access-Control-Allow-Origin\u0026#39;, \u0026#39;https://cdn.ampproject.org\u0026#39;); // Remember to check the protocol and change to http if that\u0026#39;s where your domain is $response-\u0026gt;header( \u0026#39;AMP-Access-Control-Allow-Source-Origin\u0026#39;, \u0026#34;https://{$domain}\u0026#34;); $response-\u0026gt;header( \u0026#39;Access-Control-Expose-Headers\u0026#39;, \u0026#39;AMP-Access-Control-Allow-Source-Origin\u0026#39;); // Return the HTTP response. return $response; } This is the API script that handles requests for the Google Tag Manager container. The proxy fetches the GTM container, and replaces the default Client ID with the AMP variable ${clientId}. This, in turn, is added to the configuration JSON with the value retrieved from the _ga cookie. If the _ga cookie doesn\u0026rsquo;t exist, a new one is generated.\nIn your site code, you\u0026rsquo;ll need:\n\u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;amp-analytics config=\u0026#34;//www.yourdomain.com/wp-json/amp-gtm/amp.json?id=GTM-XXXXX\u0026amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt;\u0026lt;/amp-analytics\u0026gt; This request is then passed to your endpoint, and the process described above will take place.\nGoogle Analytics setup Not much has to be done in Google Analytics, but you will want to add ampproject.org into the Referral Exclusion List of your Google Analytics property settings. Otherwise, if the user follows any link from the cached AMP page to the rest of your site, the click will start a new session with a referral from ampproject.org.\nThanks to Adrian Vender for this tip!\nSummary This is a fairly technical topic, but we, the authors, found it necessary to point out this potential flaw in how doing analytics in Accelerated Mobile Pages might be detrimental to your overall tracking plan.\nThe fact that AMP doesn\u0026rsquo;t automatically leverage the _ga cookie if the request is to Google Analytics, for example, is a bit odd. Similarly, Google Tag Manager defaulting to AMP_ECID_GOOGLE is weird too, considering how much easier things would be if you could provide a cookie name or an AMP variable for the Client ID in the request.\nBecause Google\u0026rsquo;s AMP cache is a different domain from your own, there\u0026rsquo;s really no way around Client ID stitching that wouldn\u0026rsquo;t involve the type of third-party cookie scheme as described in this guide. The request must be allowed to process the cookies written on your domain, so that the same _ga cookie value can be used on the pages in the external domain.\nLuckily the technical solution to this dilemma is not too complicated. The proxy you create in your web server is simple, and should be easy to configure with any web server software. You might want to add some enhancements of your own, such as caching the Google Tag Manager container locally, and we\u0026rsquo;d love to hear your tips and experiences in the comments below.\nWe hope this article gets your stAMP of approval, and that you\u0026rsquo;ve learned an AMPle amount of new things. Sorry for the puns.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/accelerated-mobile-pages-via-google-tag-manager/",
	"title": "Accelerated Mobile Pages Via Google Tag Manager",
	"tags": ["accelerated mobile pages", "amp", "google analytics", "Google Tag Manager", "mobile"],
	"description": "Guide on how to set up Accelerated Mobile Pages (AMP) tracking using Google Tag Manager&#39;s new AMP container.",
	"content": " Google Tag Manager recently published support for Accelerated Mobile Pages (AMP). This support comes in the form of a new Container type in Google Tag Manager.\n  When you create an AMP container in GTM, you are actually setting up an external configuration for AMP, which leverages AMP\u0026rsquo;s own analytics module. As befits Google Tag Manager, creating the configuration is done in the familiar Google Tag Manager user interface, and you have (almost) all the tools of regular Google Tag Manager at your disposal.\n  In this article, I want to go over how AMP and GTM mesh together to provide your mobile pages with improved tracking capabilities.\n1. AMP Overview Accelerated Mobile Pages is an open-source project, and you can read all about it at https://www.ampproject.org/. In a nutshell, it\u0026rsquo;s a set of structural instructions for building web pages, where focus is on speed and performance, without sacrificing too much UI/UX along the way.\nAMP is based on a number of design principles that might ring true to you if you\u0026rsquo;ve ever pondered about website performance. Things like asynchronous resource loading, inline CSS styling, web font optimization and optimized pre-rendering of pages are some of the features that AMP relies on to provide users with content super fast.\nCreating an AMP site Creating an AMP version of your site isn\u0026rsquo;t just a plug-and-play affair. You need to rewrite the HTML, JavaScript, and CSS styles to match the AMP design principles. If you\u0026rsquo;re using a platform like WordPress, there are plugins available that do most of the configuration for you. And here\u0026rsquo;s a great tip for AMP development work: anytime you are browsing an AMP page, you can add the URL hash #development=1 to the URL to validate your AMP page, outputting the result of the validation into your browser\u0026rsquo;s JavaScript Console.\n  AMP and Google search Finally, if you\u0026rsquo;ve setup your site with AMP pages, it\u0026rsquo;s a good idea to follow the Google Search Guidelines for informing the search engine about your site\u0026rsquo;s new mobile structure. Google will attempt to direct mobile searches of your site to the corresponding AMP pages, thus providing mobile visitors with fast, optimized access to your precious content.\nIf you want to see what AMP pages look like, you can visit any article on this site, and add /amp/ to the end of the URL (e.g. https://www.simoahava.com/analytics/accelerated-mobile-pages-via-google-tag-manager/amp/.\n2. AMP Analytics The Google Tag Manager AMP container leverages the amp-analytics component. This component, developed within the AMP project, provides a light-weight framework for analytics requests sent either via a number of built-in vendor templates, or to a custom endpoint of your choosing.\nThe amp-analytics framework is managed by a JSON configuration object, where you specify details of the endpoint you want to send the data to, as well as variables and triggers (sound familiar?) that govern what analytics requests are sent and when.\nEven though the amp-analytics documentation isn\u0026rsquo;t particularly long or complex, there\u0026rsquo;s still many things to consider when configuring a custom tracking scheme. That\u0026rsquo;s why it\u0026rsquo;s very useful to have pre-built templates for a number of analytics vendors (e.g. Google Analytics, Adobe Analytics, Snowplow Analytics).\nAdd amp-analytics to your website To add support for the analytics component on your site, you need to add the following line of code into the \u0026lt;head\u0026gt; of your document:\n\u0026lt;script async custom-element=\u0026#34;amp-analytics\u0026#34; src=\u0026#34;https://cdn.ampproject.org/v0/amp-analytics-0.1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; This loads the AMP analytics library, and instructs the page to look for an element named \u0026lt;amp-analytics\u0026gt;. This custom element is where you introduce the JSON configuration object that will eventually govern how the site is tracked.\nGoogle Analytics has a great developer guide for setting up the JSON configuration object manually. For example, to send a Page View hit to Google Analytics when the page is loaded, you\u0026rsquo;d add the following element to the \u0026lt;body\u0026gt; of the site:\n\u0026lt;amp-analytics type=\u0026#34;googleanalytics\u0026#34; id=\u0026#34;analytics1\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;account\u0026#34;: \u0026#34;UA-XXXXX-Y\u0026#34; }, \u0026#34;triggers\u0026#34;: { \u0026#34;trackPageview\u0026#34;: { \u0026#34;on\u0026#34;: \u0026#34;visible\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;pageview\u0026#34; } } } \u0026lt;/script\u0026gt; \u0026lt;/amp-analytics\u0026gt; As you can see, you\u0026rsquo;re using the custom element \u0026lt;amp-analytics\u0026gt; that you specified when adding the initial script loader to the \u0026lt;head\u0026gt; of your page. The type parameter of the element specifies that you are using the built-in googleanalytics vendor template.\nBe sure to check out LunaMetrics\u0026rsquo; excellent guide for Google Analytics and AMP integration!\nLoad the JSON configuration object as an external resource You can also load the JSON configuration object from an external source (as long as the request adheres to AMP CORS security guidelines). For example, the Google Tag Manager \u0026ldquo;container\u0026rdquo; is actually a request to an external config file that you specify like this:\n\u0026lt;amp-analytics config=\u0026#34;https://www.googletagmanager.com/amp.json?id=GTM-XXXXXX\u0026amp;amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;someCustomAmpVar\u0026#34;: \u0026#34;someValue\u0026#34; } } \u0026lt;/script\u0026gt; \u0026lt;/amp-analytics\u0026gt; This downloads a file named amp.json, specified by using your container ID, and the data-credentials attribute allows the resource request to read and write cookies as needed. The \u0026lt;script\u0026gt; block within the amp-analytics element can be used to use your own custom AMP variables on the page.\nNote that the external config file download will only begin if the page is visible in the viewport! For example, if you open an AMP page with a remote configuration link in a new browser window without making that window active, the configuration file download will wait until such a moment that the page becomes visible. This means that your analytics tracking will not commence until the page is visible in the browser.\nAnyway, back to the JSON configuration object. It details what interactions and events are tracked to the analytics endpoint of your choosing, when they are tracked, and how. I recommend you read through the AMP Analytics documentation, as it sheds quite a bit of light on how the GTM AMP container works, too.\nAMP Analytics with its JSON configuration object is quite far removed from the dynamic execution context of JavaScript and the Document Object Model. However, you should respect the fact that all compromises are done in favor of improved performance. I hope some of the AMP Analytics methodology would rub off on the bloated, performance-killing, dynamic mess that \u0026ldquo;modern\u0026rdquo;, JavaScript-based web analytics so often is.\n2.1. Client ID Before we move on to how the GTM AMP container works, we need to talk about Client ID. You can skip this chapter if all you want to do is get Google Tag Manager up and running on your AMP site.\nGoogle Analytics uses the Client ID parameter to align hits with the users who sent the hits. This ID is stored in a first-party cookie named _ga. Thus, every time you visit a website running Google Analytics, this cookie is used to make sure all the hits you send are tied together with your previous visits.\nFirst-party cookies can only be written on the domain you are currently on. Consequently, if you want to travel from one domain to another and still maintain all your hits under the same Client ID, you will need to somehow pass your cookie value from one domain to another without violating the restriction outlined in the first sentence of this paragraph.\nClient ID and AMP With AMP, things are slightly more difficult. AMP Analytics does not use the _ga cookie by default, even though you can set it up so that AMP falls back to _ga if one is found. But even if you do set it up to use _ga, what if the user browses the AMP page via Google search or the AMP CDN? Both cache your content in an external domain (www.google.com and cdn.ampproject.org, respectively), which means that they will not be able to access any cookies written on your domain. Also, AMP\u0026rsquo;s default Client ID syntax is vastly different from the one used by Google Analytics.\nThis all means that even if you did manage to use your existing _ga cookie as the Client ID in AMP pages on your site, it\u0026rsquo;s not enough. You see, if the user lands on your AMP page via Google search, which is probably the most typical use case, they\u0026rsquo;ll actually visit a cached version of your page on www.google.com. This means that no _ga cookie is found, and AMP defaults back to a random, unique ID.\nHacking to create a single, unified Client ID There are workarounds, and thanks to some brainstorming with the inimitable Dan Wilkerson from LunaMetrics (who already wrote an excellent guide for Google Analytics and AMP), here\u0026rsquo;s one suggestion that I\u0026rsquo;ll probably expand in a later article.\n  Here\u0026rsquo;s how this particular solution works:\n Instead of fetching the GTM container directly, the request is sent to a custom HTTP endpoint you need to set up on your website\u0026rsquo;s domain.\n This API serves a cached version of the GTM container, or fetches the most recent version if the cache has expired.\n Instead of using the default, random Client ID which AMP Analytics uses, Client ID is retrieved from the _ga cookie written on the domain of the REST API, i.e. your website.\n If no cookie is found, a new one is created.\n The _ga value is returned in the Set-Cookie HTTP Response Header, so that the cookie will be written on the domain which originated the request (e.g. www.google.com or cdn.ampproject.org).\n The HTTP Response also contains the JSON configuration object (with the new Client ID) used by the site to set AMP Analytics up.\n  In other words, you\u0026rsquo;re creating a proxy on your web server, which relays requests for the Google Tag Manager container, while modifying the container so that it includes (or creates) the Client ID used by Google Analytics.\n  It\u0026rsquo;s convoluted, yes, and there might be easier ways to handle this, but for now it lets you stitch together AMP traffic with other on-site traffic, such as desktop visits to non-AMP pages. For some publishers, and especially for ecommerce sites, this is vital.\n3. Create and implement GTM/AMP container As mentioned earlier, the Google Tag Manager AMP container is essentially a remote JSON configuration object that AMP Analytics uses for tracking interactions on your page.\nAlso, there is no dataLayer. Any custom variables you want to pass from the page to the JSON configuration object need to be included in the \u0026lt;script\u0026gt; block within the amp-analytics element:\n\u0026lt;amp-analytics config=\u0026#34;https://www.googletagmanager.com/amp.json?id=GTM-5BH2HM\u0026amp;amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;gaTrackingId\u0026#34;: \u0026#34;UA-12345-1\u0026#34; } } \u0026lt;/script\u0026gt; \u0026lt;/amp-analytics\u0026gt;   The benefit of using Google Tag Manager is that you can use the trusted user interface to configure your AMP container just as you\u0026rsquo;d configure your web container. All the supported vendor templates are available as tags, so creating a request for your endpoint is quite simple.\n  Once you\u0026rsquo;re done configuring, you need to hit the PUBLISH button, and the AMP Analytics JSON configuration object will be updated automatically for all web visitors.\nAMP containers are a new selection option in the container creation dialog:\n  Once you\u0026rsquo;ve created the container, you might want to click the PUBLISH button, and publish a base container version. It\u0026rsquo;s OK that you\u0026rsquo;re not serving any tags yet; you just need to publish the container once to make sure it doesn\u0026rsquo;t respond with a 404 when accessed by your site.\nNow that you\u0026rsquo;ve created your AMP container, you need to deploy it.\nDeploying the AMP container AMP Analytics consists of two parts: the amp-analytics JavaScript library and the JSON configuration object. To deploy AMP Analytics via Google Tag Manager, you will need to implement both in your page templates.\nFirst, the library. In AMP, it\u0026rsquo;s actually called an Extended Component of the AMP HTML schema. For AMP Analytics to work, you must deploy the following in the \u0026lt;head\u0026gt; of your website:\n\u0026lt;script async custom-element=\u0026#34;amp-analytics\u0026#34; src=\u0026#34;https://cdn.ampproject.org/v0/amp-analytics-0.1.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; This loads the AMP Analytics library asynchronously. As you can see, you are also foreshadowing the existence of a custom AMP HTML element named amp-analytics.\nThe next thing you need to do is tell the page where to load the remote JSON configuration object from. If you recall, this is your Google Tag Manager AMP container, so you must add the following code into the  of your website:\n\u0026lt;amp-analytics config=\u0026#34;https://www.googletagmanager.com/amp.json?id=GTM-5BH2HM\u0026amp;amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;someAmpVariable\u0026#34;: \u0026#34;someValue\u0026#34; } } \u0026lt;/script\u0026gt; \u0026lt;/amp-analytics\u0026gt; This is the custom amp-analytics element we were just talking about. The value of the config attribute is a reference to your GTM container, and the data-credentials=\u0026quot;include\u0026quot; part is important, as it gives permission for the downloaded configuration to read and write cookies on your domain. You can pass custom AMP variables to the JSON configuration object by using the embedded \u0026lt;script\u0026gt; block as shown.\nNote that if you went ahead and implemented the Client ID hack I introduced earlier (if even possible from my crazy complicated description), you\u0026rsquo;d need to replace the reference to Google Tag Manager\u0026rsquo;s servers with your own custom endpoint, e.g.:\n\u0026lt;amp-analytics config=\u0026#34;https://www.simoahava.com/wp-json/amp-gtm/amp.json?id=GTM-5BH2HM\u0026amp;amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt;\u0026lt;/amp-analytics\u0026gt; Do not forget gtm.url The \u0026amp;gtm.url parameter is important. By adding SOURCE_URL as its value, you are instructing AMP to resolve a platform variable as the value of the gtm.url parameter. This particular platform variable is automatically substituted with the URL of the website from which the request was made. If the page is served from a known proxy, such as the AMP Cache, it will still resolve to the actual URL of the website whose content is being served.\nThis parameter is significant, as it provides a source URL for the GTM container, which you can then utilize the enable triggers only on certain pages of your site.\nOnce you\u0026rsquo;ve done these steps, you are ready start configuring your tracking! On the surface and in the UI, things might seem all too familiar. You\u0026rsquo;ll create your tags just as you used to, filling the fields as before, so it\u0026rsquo;s as if nothing\u0026rsquo;s changed.\nBy the way, if this is all new to you, remember to check out these excellent GTM learning resources.\nThere are lots of differences compared to GTM for the web, however. For one, there really is no dataLayer anymore, since AMP doesn\u0026rsquo;t let you run arbitrary JavaScript. This severely delimits what you can do with triggers and variables.\nOn that note, most of the triggers and variables that are available to you are either completely new or behave differently from before. Also, the way the container is built and validated server-side has changed dramatically.\nThe following sections of this guide will take a closer look at all these changes.\n4. Triggers To understand how AMP triggers work, you must unlearn most of what you know about Google Tag Manager\u0026rsquo;s triggers.\nIn ye olde Google Tag Manager, triggers are dynamic conditions that react to dataLayer.push() commands. If the dataLayer.push() had a specific key-value structure, the trigger would \u0026ldquo;fire\u0026rdquo;, executing any tag to which it was attached.\nThis meant that the GTM container contained all the tags that had any trigger attached to them.\nIn the AMP GTM container, the JSON configuration object only includes those tag requests whose triggers pass a server-side validation check! In other words, you can forget any triggers whose enabling conditions depend on a dynamic value. No more \u0026ldquo;Data Layer variable equals this\u0026rdquo; or \u0026ldquo;Custom JavaScript variable returns that\u0026rdquo;. The only Built-In variables you can check against in a trigger enabling condition are:\n Container ID\n Container Version\n Environment Name\n Page Hostname\n Page Path\n Page URL\n Random Number\n  The User-defined types (in addition to e.g. Random Number and Container Version, which are also variable types) you can utilize are URL (as long as it uses Page URL as the source), Constant and Lookup Table.\nWhy just these? Because all of these (and only these) can be resolved server-side by Google when the HTTP request for the JSON configuration object comes in. In other words, you can only use variables whose value is known by Google when the request for the JSON configuration object is received. This rules out all AMP variables, for example, as they are resolved in the browser.\nBecause validation is done server-side, GTM does not have access to the URL of the page that made the request automatically. You need to explicitly add this information into the container snippet!\nLet me show you an example. Say you create a trigger like this in your AMP container:\n  Any tag that has this trigger attached to it will be added to the JSON configuration object if the HTTP Request for the AMP configuration has the current domain in the gtm.url parameter. If you remember, you need to add this parameter to the container request, and set its value to SOURCE_URL.\n  The SOURCE_URL AMP variable is resolved to the actual URL of the page when the request for the container JSON is made. Without this parameter, server-side validation against the Page Hostname, Page Path, and Page URL variables will not most likely not work as you expect them to.\nIf at least one trigger that you have added to the tag passes server-side validation, the end result is something like this in the JSON configuration object:\n\u0026#34;5\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.pageview\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;visible\u0026#34; } This simply means that on the initial page load, this trigger should fire request number \u0026ldquo;2\u0026rdquo;, which is the Page View tag turned into a request to GA. As you can see, there\u0026rsquo;s nothing about trigger conditions in this JSON block.\nIn fact, all the five (at the time of writing) available trigger types have the same binary setting:\n  If the trigger does not pass server-side validation, the tag is dropped from the JSON configuration object, and there\u0026rsquo;s no way to dynamically alter page conditions to fire it in the browser.\nI\u0026rsquo;ve spent quite a bit of time with this change in the basic functionality of GTM triggers, but deservedly so. Server-side validation is a huge difference to how GTM used to work. Again, this ensures that AMP pages are lightning-fast, as the JSON configuration object is basically just a few lines of code. That\u0026rsquo;s light-weight compared to the complexity of a \u0026ldquo;regular\u0026rdquo; GTM container.\nNow, let\u0026rsquo;s take a look at the available triggers themselves.\n4.1. Click The Click trigger in the AMP container is pretty much the same thing as the All Elements trigger in regular Google Tag Manager. In other words, the target of the click (if valid) is the element that is captured. The Just Links trigger, on the other hand, does not exist in the AMP container, and you need to configure link capturing yourself.\n  The Click trigger has just one setting: CSS Selector. With this setting, you specify which clicks you want to listen to. If you want a quick refresher on CSS Selectors, read my article on the topic, or check out this excellent CSS Selectors Reference.\nTo help you get going, here are some useful CSS Selectors for you:\nOutbound Link Clicks\na:not([href*=\u0026quot;mydomain.com\u0026quot;]), a:not([href*=\u0026quot;mydomain.com\u0026quot;]) *\nMailto: Link Clicks\na[href^=\u0026quot;mailto:\u0026quot;], a[href^=\u0026quot;mailto:\u0026quot;] *\nTel: Link Clicks\na[href^=\u0026quot;tel:\u0026quot;], a[href^=\u0026quot;tel:\u0026quot;] *\nWhen you add a tag that fires on a click to a container, this is what the ensuing JSON looks like:\n\u0026#34;triggers\u0026#34;: { \u0026#34;11\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;selector\u0026#34;: \u0026#34;:not(*)${gtm_css_2_0}\u0026#34;, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.click\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;click\u0026#34; } }, \u0026#34;vars\u0026#34;: { \u0026#34;gtm_css_2_0\u0026#34;: \u0026#34;,a:not([href*=\\\u0026#34;simoahava.com\\\u0026#34;]), a:not([href*=\\\u0026#34;simoahava.com\\\u0026#34;]) *\u0026#34; } The selector is included in the trigger JSON with the following syntax: :not(*)${gtm_css_2_0}. The part in the curly brackets is an AMP variable substitution, which refers to a key in the \u0026quot;vars\u0026quot; object further down the JSON. So, if you replace ${gtm_css_2_0} with the value of vars.gtm_css_2_0, you get the following string:\n:not(*),a:not([href*=\u0026quot;simoahava.com\u0026quot;]), a:not([href*=\u0026quot;simoahava.com\u0026quot;]) *\nThe first selector, :not(*), clears the selector chain, matching no element on the page. After that, the selectors you specified for the trigger are included. The amp-analytics code then listens for clicks on the page, matching them against the selector, and fires the respective request if the clicked element matches the selectors you have defined for each request.\n4.2. Page View The Page View trigger is very simple. If you have All Page Views selected, or the Some Page Views condition matches the value retrieved from the gtm.url parameter of the incoming HTTP Request, then any tags attached with the Page View trigger will be included in the JSON configuration object. The Page View trigger has no \u0026ldquo;DOM Ready\u0026rdquo; or \u0026ldquo;Window Loaded\u0026rdquo; differentiation any more - it will fire as soon as possible (see below).\n  When the trigger passes server-side validation, it is added to the JSON configuration object like this:\n\u0026#34;triggers\u0026#34;: { \u0026#34;5\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.pageview\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;visible\u0026#34; } } The \u0026quot;on\u0026quot;: \u0026quot;visible\u0026quot; is quite literal - if the page is visible in the current browser window, the trigger will fire as soon as the AMP analytics JavaScript has loaded. Otherwise, the trigger will wait until such a moment as the page becomes visible. Some time ago, I wrote a custom visibility trigger setup for regular Google Tag Manager, so I\u0026rsquo;m very happy to see it on by default in AMP containers.\nThere\u0026rsquo;s more on the Visibility trigger below.\n4.3. Scroll The Scroll trigger is a very useful little tool. It lets you trigger tag requests on certain scroll thresholds, which are represented by percentage of vertical or horizontal scrolling. The percentage is calculated from the maximum available height or width of the page, respectively.\nScroll tracking has been instrumental in content engagement measurement over the years, so it\u0026rsquo;s a welcome addition to the default trigger set in amp-analytics, and Google Tag Manager by extension.\n  It\u0026rsquo;s very simple to set up. A single Scroll trigger can handle all the thresholds that you indicate with a comma-separated list of percentages. For example, to fire the Scroll trigger for each 25% increment of vertical scrolling, you would add 25, 50, 75, 100 into the respective field. This will naturally work for both mobile and desktop browsing.\nWhen you add a scroll trigger, it looks like this in the JSON configuration object:\n\u0026#34;triggers\u0026#34;: { \u0026#34;3\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;scrollSpec\u0026#34;: { \u0026#34;verticalBoundaries\u0026#34;: [25, 50, 75, 100], \u0026#34;horizontalBoundaries\u0026#34;: [100] }, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.scroll\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;scroll\u0026#34; } } The problem with the Scroll trigger is that there are no dynamic variables in the AMP GTM container that you can use to detect which increment triggered the tag. So if you have a single Scroll tracker for 25%, 50%, 75%, and 100%, your tag will trigger four times on the page, but you can\u0026rsquo;t simply use a variable to tell you directly which increment it was that triggered the tag.\nNow, AMP knows how far you scrolled by calculating a bunch of document and event properties. Each threshold in your Scroll trigger is checked against the following calculation:\n(scrollTop + viewportHeight) / scrollHeight\nCoincidentally, all of these are available as AMP variables. Here, scrollTop is the number of pixels the top of your viewport is from the top of the document, viewportHeight is the height of the current viewport in pixels, and scrollHeight is the height of the entire document in pixels.\nSo the calculation checks how far from the top of the page the current viewport bottom, i.e. the very bottom edge of the content page you see in your browser window, is. If it hits 25%, the tag is triggered, and then again at 50%, 75% and 100%.\nIf in your analytics solution you want to know which of these thresholds was crossed, here are some solutions:\n Create a separate tag and trigger for each threshold. So if you want to track 25%, 50%, 75%, and 100%, you would end up with four triggers (one per threshold), and four tags. In each of the tags, you can now tell precisely which threshold was crossed.\n Use just a single trigger, but send the scrollTop, viewportHeight and scrollHeight as Custom Dimensions (Google Analytics example), and then do the calculations in a spreadsheet or something else where you export the data to.\n  There\u0026rsquo;s a nifty AMP variable named counter, which lets you create a counter which increments each time the variable is resolved. This would be the solution for tracking the thresholds, but unfortunately it isn\u0026rsquo;t supported in the GTM AMP container (yet).\n4.4. Timer The Timer trigger is something you might be intuitively familiar with if you\u0026rsquo;ve ever worked with Google Tag Manager. When the container is loaded, any Timer triggers in the JSON configuration object are initiated. The firing pattern is determined by the settings you input into the trigger:\n  Interval is the number of seconds that needs to pass before the trigger is fired.\nLimit is the maximum amount of time that the trigger loops.\nFire Immediately When Triggered when checked fires the request once as soon as the container is loaded.\nThe Interval and Limit can be quite confusing. First of all, if you want the Timer to have an unlimited amount of activations, just leave the Limit field empty. Otherwise, you should use a multiple of Interval in the Limit field, so that you can specify how many times the trigger goes off.\nFor example, if you\u0026rsquo;ve set the Interval to 10 seconds, and you want the trigger to fire six times, you would set the Limit to 60.\nThe Fire Immediately When Triggered setting governs whether or not the first iteration of the trigger should fire as soon as the container is downloaded (checked), or whether the trigger should wait for one interval before firing (unchecked).\nNote that the same caveat about visibility that applied to the Page View trigger is relevant here, too. The Timer trigger will only fire a request if the page is visible. However, the timer will not pause while the page is not visible. Thus, all the timer hits that should have fired within the limitations of the Interval and Limit settings, but were deferred due to the page not being visible, will be fired the moment the page becomes visible again.\nWhen you create a Timer trigger, it will look like this in the JSON configuration object:\n\u0026#34;triggers\u0026#34;: { \u0026#34;3\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;timerSpec\u0026#34;: { \u0026#34;interval\u0026#34;: 10, \u0026#34;maxTimerLength\u0026#34;: 20 }, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.timer\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;timer\u0026#34; } } If you left the \u0026ldquo;Fire Immediately When Triggered\u0026rdquo; unchecked, under \u0026quot;maxTimerLength\u0026quot;: 20 you would have the setting \u0026quot;immediate\u0026quot;: false.\n4.5. Visibility Now here\u0026rsquo;s an interesting trigger! The Visibility trigger lets you fire a tag when a specific element has been visible in the browser window a set amount of time. Heck, you can even define that a certain minimum amount of the element has to be visible for the trigger to fire. That\u0026rsquo;s really useful for ad impression tracking!\n  Element ID is the unique identifier of the element. It\u0026rsquo;s required, so you can\u0026rsquo;t track the visibility of an element without an ID attribute.\nMinimum Percent Visible is the minimum amount of the element that needs to be visible in the browser viewport for the trigger to be valid for firing. If you leave this out, it means that the trigger will fire even if the element is not in the viewport! Kind of defeats the purpose, so try to remember to have at least 1 in this field.\nMaximum Percent Visible is the maximum amount of the element that can be visible in the browser viewport. So if you set 10 as the Minimum Percent Visible and 50 as the Maximum Percent Visible, the trigger will only fire when you have between 10 and 50 percent of the element in the viewport.\nMinimum Continuous Time is the minimum amount of time in one stretch that the element must be visible in the viewport (in milliseconds). So if you have 2000 in this field, it means that the element must be in the viewport for 2 seconds without interruption for this condition to pass.\nMinimum Total Time is the minimum total time that the element needs to be visible in the viewport. If you have 2000 in this field, it\u0026rsquo;s enough to have the element visible for a total of 2 seconds, but it doesn\u0026rsquo;t have to be continuous. The user can reveal the element for 500 milliseconds a time, and after four such times the Minimum Total Time of 2000 has been reached.\nAll of these conditions stack. So, let\u0026rsquo;s say you have a trigger that looks like the one in the screenshot above. What it translates to is this:\nAn element with ID AMP_2 must have at least 10 percent of its total area in the browser viewport for at least 5 seconds altogether. Also, the trigger will only fire if the element is in the viewport without interruption for at least 1 second.\nWhen you publish a trigger like this, it will translate into the following JSON:\n\u0026#34;triggers\u0026#34;: { \u0026#34;3\u0026#34;: { \u0026#34;request\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;visibilitySpec\u0026#34;: { \u0026#34;selector\u0026#34;: \u0026#34;#AMP_2\u0026#34;, \u0026#34;visiblePercentageMin\u0026#34;: 10, \u0026#34;continuousTimeMin\u0026#34;: 1000, \u0026#34;totalTimeMin\u0026#34;: 5000 }, \u0026#34;vars\u0026#34;: { \u0026#34;gtm.event\u0026#34;: \u0026#34;gtm.visible\u0026#34; }, \u0026#34;on\u0026#34;: \u0026#34;visible\u0026#34; } } I hope that support for other CSS selectors than just IDs would become available for selecting the element. I guess the reasoning is that such a complex trigger would be difficult to maintain consistently if it matched multiple elements on the page.\n5. Variables AMP Analytics supports two types of variables: platform and page-defined variables. Platform variables are default variables that do not need to be specified in the JSON configuration object. They are automatically resolved based on information available in the Document Object Model.\nPage-defined variables are added to the JSON configuration object. They can be defined in multiple places, such as a remote configuration file, top-level of an embedded configuration object, trigger-specific configuration, or even in special data attributes configured in elements themselves. There is an order of priority in variables which share the same name, and they are resolved in the following order of importance:\nRemote configuration file \u0026gt; element level data attributes \u0026gt; triggers \u0026gt; top-level of configuration object \u0026gt; platform.\nSo if you had \u0026amp;cid=${clientId(some-cid-cookie)} in your request to Google Analytics (platform variable), and also \u0026quot;vars\u0026quot;: {\u0026quot;clientId\u0026quot;: \u0026quot;12345\u0026quot;} in the root of the amp-analytics configuration object, you\u0026rsquo;d end up with \u0026amp;cid=12345 in the actual request, since the configuration object trumps platform variables in priority.\nAll variables are resolved when the request to any given endpoint is compiled, so they might well have different values for each request.\nIn the AMP Google Tag Manager container, you can create variable references to these AMP Analytics variables using the AMP variable type. However, there are other variables at your disposal, too, and we\u0026rsquo;ll take a look at these as well in this chapter.\n5.1. Built-In Variables The Built-In variables in the GTM container are variables that you do not need to manually create. To enable them, you need to go to Variables in the container, and under the \u0026ldquo;Built-In Variables\u0026rdquo; heading click the large red CONFIGURE button to enable / disable any variables. It\u0026rsquo;s weird that the Built-In variables aren\u0026rsquo;t all enabled by default, since there\u0026rsquo;s no harm in having them all available. In regular GTM, enabling Built-In variables meant some extra clutter in the Google Tag Manager library, but here they are only available in the UI to make it easier to configure your tags.\n  Here are all the Built-In variables with a short description of each.\n Total Engaged Time (AMP variable): The total time the page has been visible in the viewport in seconds.\n Scroll Width (AMP variable): Total width of the page in pixels.\n Scroll Top (AMP variable): Number of pixels between the top of the viewport and the top of the page.\n Scroll Left (AMP variable): Number of pixels between the left edge of the viewport and the left edge of the page.\n Scroll Height (AMP variable): Total height of the page in pixels.\n Screen Width (AMP variable): Total width of the screen. Does not take into account stuff like widgets, scroll bars, etc.\n Screen Height (AMP variable): Total height of the screen. Does not take into account stuff like bookmark and address bars.\n Random Number: Generates a random number between 0 and 2147483647. Note that this number is generated server-side by GTM. Once the JSON configuration object is downloaded, any references to this variable will have the same generated number.\n Page View ID (AMP variable): Random number that is unique per user, URL, and day. Each refresh of a page sets a new random number.\n Page URL: This is the URL passed to GTM with the gtm.url=SOURCE_URL query parameter in the GTM container snippet. This, Page Path, and Page Hostname are the only variables you can use in GTM to delimit tags from triggering only on certain pages.\n Page Path: Returns the path (e.g. /analytics/accelerated-mobile-pages-via-google-tag-manager/) of the URL in the gtm.url query parameter of the GTM container request.\n Page Load Time (AMP variable): This is the entire load time of the page in milliseconds. It is calculated from the moment the previous page started its unload to the moment the current page has fully loaded. If there is no previous page, the timer starts from the moment when the HTTP request for the page content was ready to dispatch.\n Page Hostname: Returns the hostname (e.g. www.simoahava.com) of the URL in the gtm.url query parameter of the GTM container request.\n Page Download Time (AMP variable): Time in milliseconds from the moment the request for the page content was dispatched to the moment the last byte of the document was downloaded from the web server.\n Environment Name: The name of the custom created GTM Environment (if any) that the current GTM JSON configuration object is downloaded from. Yes, Environments work in the AMP container, too.\n Document Title (AMP variable): Title of the current document.\n Document Referrer (AMP variable): The URL of the page the user navigated from. This variable will resolve to an empty string if no referrer information is available.\n Container Version: The version number of the container that received the request. If you are in Preview mode, it returns QUICK_PREVIEW.\n Container ID: Returns your GTM Container ID (GTM-XXXXX).\n Client Timezone (AMP variable): Returns the timezone offset in minutes from UTC based on client\u0026rsquo;s system time. For example, if you are in New York City, Client Timezone would return 300, because New York is 5 hours behind UTC. In Helsinki, which is two hours ahead of UTC, Client Timezone would return -120.\n Client Timestamp (AMP variable): Returns the number of seconds that have passed since Jan 1, 1970 (epoch time).\n Canonical URL (AMP variable): Returns the full canonical URL of the page. Typically this should be the URL without /amp/ or any other AMP parameter.\n Canonical Path (AMP variable): Returns just the pathname of the canonical URL of the page.\n Canonical Host (AMP variable): Returns the complete host of the canonical URL of the page (e.g. http://www.mydomain.com:9000).\n Browser Language (AMP variable): Returns the language of the browser UI, e.g. en-us or fi.\n AMP Event (AMP variable): Returns the name of the event that triggered the tag. GTM automatically adds event names like gtm.click (Click trigger) and gtm.pageview (Page View) to this variable.\n  Once you\u0026rsquo;ve enabled these variables, you can refer to them in your tags, triggers, and variables by using the {{Variable Name}} syntax.\n5.2. User-Defined variables In addition to Built-In variables, you can also create variables of your own. These can be added in the variables page of your container, under the heading \u0026ldquo;User-Defined variables\u0026rdquo;.\nRemember that you can reference any GTM variable with the {{Variable Name}} syntax.\nAt the time of writing, here are the variable types you can configure.\nURL URL variables exist in regular Google Tag Manager, too. However, in AMP, the URL variable can only be used to provide data about the URL included in the container HTTP request. If you remember, this URL is resolved in the gtm.url=SOURCE_URL parameter of the request. There are already Built-In variables for Page Hostname, Page URL, and Page Path, so the component types that you could configure variables for are Protocol (e.g. http or https), Port, and Query (e.g. ?test=true).\nAMP variable Jump to the next section to read more about AMP variables.\nConstant This should be familiar from regular Google Tag Manager. A Constant variable can be set to any string value you wish, and any time this variable is referenced, the string you input into the field will be returned.\n  A typical use case would be to set your Google Analytics tracking ID as a Constant String variable.\nEnvironment Name This isn\u0026rsquo;t particularly useful, as there already is a Built-In variable for this. It returns the name of the Google Tag Manager Environment where the JSON configuration object is loaded from.\nLookup Table The Lookup Table variable is a staple from regular Google Tag Manager. It\u0026rsquo;s very useful, as it lets you do value transformations with dynamic input variables.\nHowever, in AMP GTM it\u0026rsquo;s not that useful anymore. The Lookup Table must resolve server-side, because AMP doesn\u0026rsquo;t support the type of dynamic calculation that a Lookup Table would require if resolved in the client. Thus, the only types of input variables you can use are those which have a value within the Google Tag Manager container. This is, unfortunately, a very short list:\n Container ID\n Container Version\n Environment Name\n Page Hostname\n Page Path\n Page URL\n Random Number\n  One use case would be to send Preview hits to another tracking endpoint. For that, the Lookup Table would look like this:\n  If you add this variable to the Tracking ID field of your Google Analytics tag, it will return \u0026ldquo;UA-12345-2\u0026rdquo; if Google Tag Manager is in Preview mode, and \u0026ldquo;UA-12345-1\u0026rdquo; otherwise.\nRandom Number Redundant. There already is a Built-In variable for this. It returns a random number between 0 and 2147483647.\nContainer ID Redundant. There already is a Built-In variable for this. It returns the ID of the GTM container (GTM-XXXXX).\nContainer Version Redundant. There already is a Built-In variable for this. It returns the version of the published GTM container, or QUICK_PREVIEW if in Preview mode.\n5.3. AMP variables I\u0026rsquo;ve already mentioned AMP variables here and there. They are built into the AMP Analytics framework, and comprise two types of variables: platform variables and page-defined variables. Platform variables are sort of \u0026ldquo;built-in\u0026rdquo; variables for AMP, in that you don\u0026rsquo;t need to manually specify them in the JSON configuration object. Page-defined variables, on the other hand, need to be included in the JSON configuration object itself.\nTo refer to AMP variables, you need to use the syntax ${variableName}. Naturally, Google Tag Manager does this for you when you create a user-defined variable of type AMP variable.\n  When you add an AMP variable to your Google Tag Manager tag, it becomes part of the request when the JSON is downloaded.\n  An AMP variable added like this to a Custom Dimension field in a GA tag would look like this in the JSON configuration object:\n\u0026#34;requests\u0026#34;: { \u0026#34;4\u0026#34;: \u0026#34;https://www.google-analytics.com/r/collect?...\u0026amp;cd1=${backgroundState}\u0026#34; } As you can see, the variable name is still in the request itself, meaning that it isn\u0026rsquo;t resolved when the JSON configuration object is downloaded. Only once the actual request dispatches will the AMP variable be resolved, which means, in turn, that its value is generated dynamically.\nMost of the useful AMP variables are already available as Built-In variables in GTM. In fact, I find it curious that Built-In variables don\u0026rsquo;t simply include all the pre-defined AMP variables, as that would cut down time required to configure the container.\nCreating custom AMP variables If you want to create your own AMP variables, you can. It\u0026rsquo;s sort of similar to working with dataLayer, in the sense that you are passing semantic information from the page to Google Tag Manager. However, the difference is that you won\u0026rsquo;t be able to utilize these Variables within GTM itself. So you can\u0026rsquo;t create trigger conditions based on AMP variables, nor can you use Lookup Tables with AMP variables as the input variable.\nTo create custom AMP variables, you include them like this:\n\u0026lt;amp-analytics config=\u0026#34;https://www.googletagmanager.com/amp.json?id=GTM-XXXXXX\u0026amp;gtm.url=SOURCE_URL\u0026#34; data-credentials=\u0026#34;include\u0026#34;\u0026gt; \u0026lt;script type=\u0026#34;application/json\u0026#34;\u0026gt; { \u0026#34;vars\u0026#34;: { \u0026#34;someAmpVar\u0026#34;: \u0026#34;someValue\u0026#34;, \u0026#34;someOtherAmpVar\u0026#34;: \u0026#34;someValue\u0026#34; } } \u0026lt;/script\u0026gt; \u0026lt;/amp-analytics\u0026gt; So you include them in the \u0026quot;vars\u0026quot; block as key-value pairs. Once you\u0026rsquo;ve done this, you can create AMP variables for these keys, and then include the custom AMP variables in tag fields.\n  The thing to remember about AMP variables and GTM is that AMP variables are resolved in the client when the requests are dispatched. Thus you can\u0026rsquo;t use them in any operations within GTM that would require server-side validation. The most notable cases are trigger enabling conditions and the Lookup Table variable.\n  There\u0026rsquo;s a great reference guide for all the available AMP variables in the GitHub project itself: AMP HTML URL Variable Substitutions. Read through that document, and create User-Defined variables for any AMP variables that don\u0026rsquo;t already exist as Built-In variables.\n6. Other Google Tag Manager quirks Google Tag Manager is pretty smooth with AMP. The fact that it compiles the configuration object for you is a huge plus, and the ease of creating a tracking schema for your AMP pages is very much in line with how \u0026ldquo;regular\u0026rdquo; Google Tag Manager works, too.\nThere are some hiccups, though. Most notably, server-side validation can be a difficult thing to come to terms with. GTM needs to build a configuration object dynamically, but because the object is built within Google\u0026rsquo;s servers, it doesn\u0026rsquo;t have any access to the variables that would exist on your page. Thus the only dynamic variables it has access to need to be passed in the URL request for the container, gtm.url being the most notable one.\nGoogle Tag Manager for AMP does not support the Debug mode we\u0026rsquo;re used to with regular Google Tag Manager. The debug panel would require that the AMP page supported the type of JavaScript that is very performance-killing.\nHowever, GTM does work in Preview Mode. So when you enter Preview Mode in Google Tag Manager, once you reload the site with the same web browser you entered Preview Mode in, the container that is downloaded from Google Tag Manager will actually be the one you are previewing and not the one that is published.\nThis is very useful, even though I know you\u0026rsquo;ll miss having the excellent Debug panel at your disposal.\nBecause Preview Mode doesn\u0026rsquo;t have any verbose logging or anything like that, you should get familiar with other debug tools at your disposal.\n7. Summary I\u0026rsquo;m a big fan of Google Tag Manager\u0026rsquo;s AMP container. It\u0026rsquo;s not just because I\u0026rsquo;m such a fanboy (I am), nor because I\u0026rsquo;m typically devoid of a critical voice when it comes to GTM (I am this, too). The reason I really like it is because it does what GTM has always done best: it abstracts a somewhat complex operation of compiling the JSON configuration object, and lets you create it using GTM\u0026rsquo;s UI, knowing full-well that whatever you create will be syntactically valid for AMP.\nThat\u0026rsquo;s the modus operandi for GTM, and it\u0026rsquo;s refreshing to see how it\u0026rsquo;s still respected by the development team. On top of that, AMP introduces a number of triggers and variables that I really hope will make their way into regular GTM, too. The scroll and visibility triggers alone would be really useful in regular Google Tag Manager.\nMost of my issues with the AMP container have to do with AMP rather than with GTM. Managing a single Client ID across your website and the available AMP proxies is a pain, and I really hope that AMP introduces some methods to facilitate extending a single Client ID (e.g. _ga) across your website and the various proxies AMP might be served through.\nI foresee some great applications for AMP through GTM, and I also look forward to some feature leakage to regular Google Tag Manager, too.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/fix-rogue-referral-problem-single-page-sites/",
	"title": "#GTMTips: Fix The Rogue Referral Problem In Single-Page Sites",
	"tags": ["google analytics", "Google Tag Manager", "gtmtips", "referral", "tracker"],
	"description": "How to fix referrer issues, especially when recording paid vs. organic search sessions, in Google Analytics when using Google Tag Manager on single-page sites.",
	"content": " Single-page sites (or single-page apps) typically have just one page load. When navigating the site, subsequent content is either uncovered from the DOM, where it\u0026rsquo;s been in a hidden state, or loaded from the server using HTTP requests that do not invoke a new page refresh. This behavior, however, has some implications for Google Analytics tracking, especially when configured via Google Tag Manager.\nThe crux of the problem is this: When you create a Google Analytics tracker, the URL of the page (without a possible #hash) from when the tracker was created is sent as the value of the Document Location field with every hit that uses this tracker. This is used for a number of things, most significantly attributing the session to the campaign specified by URL parameters such as gclid (AdWords) or utm_source, utm_medium.\nNow, on single-page sites you send \u0026ldquo;virtual\u0026rdquo; pageviews whenever new content is loaded from the server. The reason this works fine with on-page GA is because you\u0026rsquo;re always using the same tracker object to send the hits. Google even recommends this in their developer guide. Thus the Document Location field stays the same, and campaigns are attributed correctly.\nWith Google Tag Manager, every single Universal Analytics Tag that fires on the site creates a new, unique tracker object. This means that the Document Location field is updated with every Tag you fire, which is a problem if the URL changes due to browser history manipulation. Thus you can end up with a situation where the first Universal Analytics Tag has gclid in the URL, attributing the session to AdWords, but the next pageview doesn\u0026rsquo;t have this in the URL anymore, as you would not include it in the \u0026ldquo;virtual\u0026rdquo; pageview path names. Instead, since gclid is no longer in the URL, GA looks at the HTTP referrer of the page to see what the previous page was for attribution. It finds google.com, as you came from the search engine (HTTP referrer is not updated when manipulating the URL with the browser History API). Thus a new session starts with attribution to Google Organic! I\u0026rsquo;ve dubbed this as the Rogue Referral problem.\nThere are ways to combat this. David Vallejo\u0026rsquo;s written a great article on setting the Tracker Name in your GTM Tags. This will effectively work like on-page GA, maintaining the initial value of Document Location throughout the page load. However, there are some risks with the tracker name setting, so I wanted to offer an alternative.\nTip 51: Manually Set Document Location To Prevent Rogue Referrals   The way this works is that you store the initial page URL in a global variable such as dataLayer, and then manually set the Document Location field in all your Universal Analytics tags to use this variable.\nThe most robust way to do this would be to have the following in the page HTML before the GTM container snippet:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ originalLocation: document.location.protocol + \u0026#39;//\u0026#39; + document.location.hostname + document.location.pathname + document.location.search });  This would store the original URL of the page (without #hash) into a dataLayer variable named originalLocation. Then, you\u0026rsquo;d add this to all your Universal Analytics tags by browsing to Fields to Set and adding a new field:\nField name: location\nValue: {{Data Layer Variable - originalLocation}}\nHere, {{Data Layer Variable - originalLocation}} would be a Data Layer Variable you\u0026rsquo;ve created, pointing to the originalLocation you store when the page is first loaded.\n(UPDATE: Note that if you add the location field, you must also specify the page, or else all pages will use what\u0026rsquo;s stored in location as the page path sent to GA! If you have a single-page site, you probably already have the page field set to a virtual page path, but if not, you can always use something like:\nField name: page\nValue: {{JS - Get Page URL}}\nWhere the variable {{JS - Get Page URL}} is a Custom JavaScript variable with:\nfunction() { return document.location.pathname + document.location.search; }  This would send the current page pathname with any query parameters as the virtual page path dispatched with your GA Tags. Thank you Brian Clifton for pointing out that query parameters should be sent, too.)\nIf you can\u0026rsquo;t or don\u0026rsquo;t want to edit the page HTML, you can also use Tag Sequencing. First, you would need to create a Custom HTML Tag with the same code as above (enclosed in \u0026lt;script\u0026gt; and \u0026lt;/script\u0026gt; tags). Then, you would need to identify the first Universal Analytics Tag that fires on the site. This would typically be a Page View Tag with something like All Pages or some other Page View Trigger attached to it. Then, you\u0026rsquo;d need to add the new Custom HTML Tag to this Page View Tag\u0026rsquo;s sequence, by firing it before the Page View Tag.\n(UPDATE: Read the following Caveat chapter if you choose to do this all via GTM and not the page template!)\n  That way the original URL is stored into dataLayer before the Page View Tag fires, and is thus available for all the Universal Analytics tags that fire on the page.\nCaveat If you\u0026rsquo;re pushing the originalLocation via GTM and not the page template, there might be a race condition between when the originalLocation variable is pushed into dataLayer, and when Tags try to access it. In these cases, analytics.js does not default to the current URL, resulting in a missing Document Location field! To fix this, instead of adding {{Data Layer Variable - originalLocation}} directly to the location field in your GA Tags, you might want to add a Custom JavaScript Variable instead:\nfunction() { return {{Data Layer Variable - originalLocation}} || window.location.protocol + \u0026#39;//\u0026#39; + window.location.hostname + window.location.pathname + window.location.search; }  This returns either {{Data Layer Variable - originalLocation}} or, if that hasn\u0026rsquo;t been set yet, the current URL without hash.\nSummary If you have a single-page site and you\u0026rsquo;re sending \u0026ldquo;virtual\u0026rdquo; pageviews, you might want to check if you have the rogue referral problem. A quick way to identify it is to use the new User Explorer reports, looking for sessions which start with an AdWords hit, but then quickly turn into a new session with Google Organic as the campaign.\nActually, if you\u0026rsquo;re using Google Tag Manager and you\u0026rsquo;re sending virtual pageviews, you will most certainly suffer from the rogue referral problem, unless you\u0026rsquo;ve set the Tracker Name or the Document Location as instructed in this guide.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/site-speed-sample-rate-multiple-page-views/",
	"title": "Site Speed Sample Rate And Multiple Page Views",
	"tags": ["data quality", "Google Tag Manager", "site speed", "universal analytics"],
	"description": "If you&#39;re collecting page timings automatically to Google Analytics, you might have some data quality issues especially if collecting virtual page views using Google Tag Manager.",
	"content": " Google Analytics\u0026rsquo; Site Speed reports are pretty darn great. They report automatically on various milestones in the process the browser undertakes when rendering content. These reports leverage the Navigation Timing API of the web browser, and they are (typically) collected on the first Page View hit of a page.\nAnd this is all fine. As I said, it\u0026rsquo;s a great feature of Google Analytics, and lends itself handily to spotting issues in the quite complex client-server negotiation that goes on when your web browser requests content from the web server.\n  However, there\u0026rsquo;s a glitch. These automatic page timings are collected once per tracker instance per page, meaning if you have multiple trackers on the page, each set to collect site speed samples, you might inadvertently send the same page speed data multiple times. This will naturally inflate the numbers that Google Analytics reports on, and your data will be ruined, as deduplication is really difficult.\n  So if you have any of the following in place, you might be in the risk group:\n Single-page site where you send \u0026ldquo;virtual\u0026rdquo; Page Views to Google Analytics\n Multiple trackers on the page, each collecting to the same Universal Analytics property (UA-XXXXX-Y)\n Manually set site speed sample rate (e.g. at 100%)\n Google Tag Manager with a Page View Tag that has multiple Triggers attached to it\n  If any of these rang true, you might have a data quality issue that should be fixed immediately.\nFraming the problem By default, 1% of Page View hits are sampled for page timings. So if you have the following code on the site:\nga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;);  There\u0026rsquo;s a 1\u0026frasl;100 chance that upon the first time command is executed, this particular request will grab the available Navigation Timing data and send it to Google Analytics. And, again, this is fine. That\u0026rsquo;s what we want. Now if you have the following code:\nga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;, {page: \u0026#39;/some-custom-page/\u0026#39;});  That\u0026rsquo;s two separate Page View hits firing on the same page, you\u0026rsquo;re still fine. Since they use the same tracker object (the default tracker), even if you win the odds and manage to hit the 1\u0026frasl;100 twice on the same page, the page timing data is only sent once, since Universal Analytics only sends timing data once per tracker per page.\nHowever, if you have this:\nga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); ga(\u0026#39;secondTracker.send\u0026#39;, \u0026#39;pageview\u0026#39;, {page: \u0026#39;/some-custom-page/\u0026#39;});  If both these trackers collect to the same Google Analytics property (UA-XXXXXX-Y), and if both trackers manage to somehow make the 1\u0026frasl;100 cut, you will be sending the same page timing data twice, just for different page paths. And that will warp your data!\nIt gets worse\u0026hellip;\nThe problem with Google Tag Manager Google Tag Manager, for all the good it does, has one complication that makes a lot of things difficult: it assigns a unique tracker object for every single tag that fires - even if it\u0026rsquo;s the same tag firing multiple times.\nTake another look at the image at the beginning of this article. There you have a Page View Tag which has the siteSpeedSampleRate set to 100%, which means that every single time the Page View hit is sent, it should be used to sample page timing data. It also has a Trigger which fires whenever a Custom Event is pushed into dataLayer. So this is your typical \u0026ldquo;virtual\u0026rdquo; Page View (man I hate that term - all Page Views are virtual!) Tag, set to fire with a custom page path whenever the event triggers.\nNow, here\u0026rsquo;s the issue: because it has siteSpeedSampleRate set to 100, and because it will fire multiple times on the page, and because each time it fires it will have a unique tracker name:\nEvery single time this Page View Tag fires, it will send the same page timing data to Google Analytics!\nThat\u0026rsquo;s multiplication on a grand level! It\u0026rsquo;s even more confusing since the same page timing data is sent to multiple page paths, making deduplication in the reports really difficult to do.\nFixes Here are some obvious fixes to this issue.\n1. Only sample a single tracker This is pretty easy if you\u0026rsquo;re using the Universal Analytics snippet. Set siteSpeedSampleRate to a proper value in only one tracker, and set all other trackers to 0.\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {siteSpeedSampleRate: 100}); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {name: \u0026#39;secondTracker\u0026#39;, siteSpeedSampleRate: 0});  This would ensure that only a single set of page timings is sent per page.\nIn GTM, by default, this would be impossible, because each tag has its own unique tracker name.\n2. Only sample the first pageview This is irrelevant in Universal Analytics, as only the first pageview per tracker is sampled anyway. In Google Tag Manager, however, this might just fix the issue for you.\nFor this to work, you need to fire the first Page View hit of a page using a unique trigger. Typically, you\u0026rsquo;d have the \u0026ldquo;All Pages\u0026rdquo; Trigger on the Page View Tag, and then another Trigger for the custom Page View. Thus, a single-page app might have the following Tag catering for all Page Views:\n  Now, this Tag will be problematic if left like this, since the Page Timing sample will be sent every single time the Tag fires - once for the All Pages Trigger, and each time the Custom Event Trigger fires.\nTo fix this, use this Custom JavaScript Variable as the value of the siteSpeedSampleRate field:\nfunction() { return {{Event}} === \u0026#39;gtm.js\u0026#39; ? 100 : 0; }  So your Tag looks like this:\n  This JavaScript returns 100 for the All Pages Event (that\u0026rsquo;s the gtm.js event name), and 0 for all other Triggers.\nIn other words, only the All Pages Trigger will send the site speed sample, ensuring it is only sent once on the page.\nIf you don\u0026rsquo;t have the means to distinguish the first Page View from all the subsequent triggerings, you could also add hitCallback to your Page View Tag, which sets a global flag (or even a dataLayer variable) to true, indicating that the tag has fired (at least) once. Then you can use this flag as a condition for the siteSpeedSampleRate field, only sending the 100 value if this flag is false.\n3. Set the Tracker Name in your GTM Tag This is the most risky but also the most effective way to fix it. Remember how GTM uses a unique tracker name for every instance of a Tag? Well you can always set the Tracker Name field with some value to make sure that every time the Tag fires it uses the same tracker object. Thus the page timing sample is only sent once. To do this, you\u0026rsquo;d have to configure one of the settings in the Page View Tag:\n  You can set it to whatever value you wish, though I advice against leaving it blank. If you do leave it blank, it uses the default Universal Analytics tracker and can lead to issues, unless you are really on top of your site\u0026rsquo;s GA implementation.\nThere are risks when setting the Tracker Name field, and I recommend you read my article on the topic before proceeding with the method.\nSummary The Site Speed reports are really great, but you might want to go over your Universal Analytics implementation to make sure you\u0026rsquo;re not involuntarily collecting bogus data.\nAs long as you keep in mind that the page speed sample is collected once per page per tracker, you should be able to identify if there are issues in your setup. In this article, I have outlined three different things you can try, but there are other methods you can employ too, with just a little creativity.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/restrict-custom-html-tag-scope/",
	"title": "#GTMTips: Restrict Custom HTML Tag Scope",
	"tags": ["custom html", "Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Always remember to restrict the scope in your Google Tag Manager Custom HTML tags, so that your locally defined variables don&#39;t pollute the global namespace.",
	"content": " What better way to celebrate the 50th #GTMTips article than, well, a really useful Google Tag Manager tip?! This tip is so useful and simple; it encapsulates everything that I had in mind when starting this series. The tip is about restricting scope of Custom HTML Tags. This is an important concept, because it\u0026rsquo;s possible that you\u0026rsquo;re stuffing your page\u0026rsquo;s global JavaScript namespace with all sorts of junk, and thus inadvertently causing conflicts.\nTip 50: Restrict Custom HTML Tag Scope   The tip is very simple. Whenever adding JavaScript code in a Custom HTML Tag between \u0026lt;script\u0026gt; and \u0026lt;/script\u0026gt; tags, add the following code around whatever you\u0026rsquo;ve written:\n(function() { // Your JavaScript here  })();  What you\u0026rsquo;re doing is creating an immediately invoked function expression, or IIFE for short. By wrapping the function() {...} in parentheses, you\u0026rsquo;re instructing the browser to treat the code within as an expression rather than a declaration. In other words, you\u0026rsquo;re instructing the browser to invoke the function, making it syntactically valid by adding the empty parentheses at the end (so that the browser knows it\u0026rsquo;a a function expression). This executes whatever code is within the \u0026lt;script/\u0026gt; block.\nSo if it does exactly what it would do even without the IIFE, why do it?\nWell, JavaScript scopes variables to their execution context. This means that if variables are declared within a function, they are only accessible inside that function. Furthermore, JavaScript has a global namespace which in the web browser is defined by the window object. If you didn\u0026rsquo;t have the IIFE around your code, then any variables you declared would be hoisted to the global window namespace, thus creating potential for conflict.\nTake a look at this example:\n\u0026lt;script\u0026gt; // No IIFE  var ga = \u0026#34;My secret \u0026#39;ga\u0026#39; code\u0026#34;; console.log(ga); // Results in an error  window.ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; By overwriting ga with your own nifty little string, you just broke Universal Analytics. Congratulations.\nWhereas if you did this:\n\u0026lt;script\u0026gt; (function() { // IIFE  var ga = \u0026#34;My secret \u0026#39;ga\u0026#39; code\u0026#34;; console.log(ga); })(); // Works  window.ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; This time you\u0026rsquo;re protecting your own little ga variable and, more importantly, you\u0026rsquo;re protecting the global ga function by declaring your variable in an IIFE.\nJust remember the following additional tips:\n Always declare variables in GTM using the var keyword. This way they will be restricted to the current scope. If you omit this keyword, then JavaScript automatically adds them to the global window namespace. NOTE! This also applies to Custom JavaScript Variables, not just Custom HTML Tags!\n Always refer to global variables using the window. prefix. That will make your code more readable and will prevent you from causing conflicts by accident.\n  And that\u0026rsquo;s it!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/introducing-ga-spy-for-google-analytics/",
	"title": "Introducing GA Spy For Google Analytics",
	"tags": ["google analytics", "Google Tag Manager", "JavaScript", "tracker", "universal analytics"],
	"description": "Introducing the GA Spy tool built by Stephen Harris. It lets you hijack the Google Analytics global function so that you can insert and execute custom code in the hit build process.",
	"content": "   _This is a guest post by Stephen Harris from Seer Interactive . He was kind enough to share his awesome solution in this blog, so I\u0026rsquo;m very grateful indeed for his contribution._\nIf Google Tag Manager is loaded as the primary instrument for tracking on a webpage (as it should be), then all webpage tracking could and should be configurable via GTM. But we don\u0026rsquo;t always control the circumstances, and it\u0026rsquo;s not uncommon to face hardcoded Google Analytics tracking outside of GTM.\nPerhaps GA tracking cannot be removed from the website source code quickly enough. Maybe the website is on a publishing schedule that doesn\u0026rsquo;t suit measurement needs, or maybe the folks responsible for the website don\u0026rsquo;t have sufficient resources. Whatever the reason, you got a \u0026ldquo;no\u0026rdquo; when you requested insisted on removal. (You did insist on removal, didn\u0026rsquo;t you?)\nOr what about when there are hardcoded GA commands in a platform or plugin? It could be screwing with your data. But chances are it\u0026rsquo;s not doing anything at all (because it\u0026rsquo;s tracking to the nonexistent default GA tracker) and there seems to be no way to get it to work through GTM.\nAnd even when all tracking runs through Google Tag Manager, some things can be difficult (or impossible) to implement using the tag templates (such as adding GA plugins, or defining Universal Analytics tracker field defaults).\nHere\u0026rsquo;s a solution.\n1. Spying On GA You can grab the code on GitHub. Copy-paste it either into a Custom HTML Tag in Google Tag Manager, or load it in the page template proper.\nIt\u0026rsquo;s called GA Spy because it can silently hijack and control all tracking that relies on Google\u0026rsquo;s Universal Analytics library (analytics.js). Effectively, this is a Google Analytics listener that does karate.\n  To put this in layman\u0026rsquo;s terms, the script listens for interactions with the ga() interface, returning the arguments passed to the function for you to process for whatever purpose you want. For example, you can automatically copy all calls to ga('send'...) to dataLayer.push() syntax, allowing you to fluently replicate hardcoded Universal Analytics tracking in Google Tag Manager.\nThis blog post is written assuming the hardcoded tracking is for Universal Analytics, but there is a version of the script for the async GA library (ga.js), to which the same core concepts apply.\n Source code for ga-spy.js\n Source code for ga-spy_async.js\n README\n  1.1. Spy Code 101 Let\u0026rsquo;s walk through the script logic. Before implementing, it\u0026rsquo;s important to get a basic idea of what this script actually does. Once you understand the basics, you\u0026rsquo;ll also understand why this should be considered a temporary solution. Indeed, you should document the use of this solution, so that when the hardcoded Universal Analytics code is eventually removed from the site, you won\u0026rsquo;t be left hanging dry with methods that don\u0026rsquo;t really do anything.\nThis section also explains this script\u0026rsquo;s biggest caveat: GA Spy is not guaranteed to intercept (or even detect) tracking that fires while the page is loading (e.g. the standard GA snippet) if the hack is deployed via GTM. Capturing these requests requires that you deploy the script on the page template itself, which unfortunately might detract from the usefulness for those without developer resources handy.\nFor a more technical breakdown, check out the README.\n1.2. A Good Spy Starts With Research Let\u0026rsquo;s start with an overview of how the Universal Analytics tracker works on the page.\nMany GA users are familiar with the JavaScript namespace ga. It\u0026rsquo;s the global object for tracking with the Universal Analytics library (analytics.js). When the browser loads the page, this object is actually processed twice. First, it\u0026rsquo;s created by the Universal Analytics snippet, and it queues all commands to ga() while waiting for the library to load. Then, once the library has loaded, the namespace is converted to a full interface which processes each command as it is executed.\n  So the standard Universal Analytics snippet instantiates ga as a tiny function that saves all the arguments you pass to it as an Array in ga.q. This is called the command queue. It\u0026rsquo;s created by the second line of the GA install snippet function, shown here (beautified with more readable variable names):\nwindow[gaObjName] = window[gaObjName] || function() { ( window[gaObjName].q = window[gaObjName].q || [] ).push( arguments ) }, ga.l = 1 * new Date();  Aside: Notice any similarities to the recommended format for data layer pushes?\n( window.dataLayer = window.dataLayer || [] ).push( { } )  Once this queue is established, the snippet creates a script loader, which starts an asynchronous request to download the analytics.js library from Google\u0026rsquo;s servers.\nOnce analytics.js loads, it will run the commands in the command queue and replace the queue function ga with much more robust object, which we call the ga object or function. Once this happens, ga stops keeping track of previously called commands, and will run commands as soon as they are called.\n1.3. Spy Moves The core of this script is the hijack function. What it does is simple: it saves a private reference to the global ga object, then updates the global reference (window.ga or simply ga) to point to a custom function, which we\u0026rsquo;ll call our \u0026ldquo;proxy\u0026rdquo; function. Note that if you\u0026rsquo;ve chosen to rename the global function as something other than ga, it will still work nicely with GA Spy.\nfunction hijack(){ // The current global GA object (could be GA command queue or loaded GA object).  var gaOrig = window.ga; // Replace global GA object with a proxy.  window.ga = proxy; // Maintain references to GA\u0026#39;s public interface.  for( k in gaOrig ) if( gaOrig.hasOwnProperty( k ) ) proxy[k] = gaOrig[k]; }  The proxy function mimics the data members and methods of the original ga function. Thus it behaves like the original, which we accomplish by passing its arguments back to the ga function (and returning the result). But, only if we so choose. We can reject the message, simply by not sending the message to the original ga function, and thus intercept and block the hardcoded GA from running its requests altogether.\nfunction proxy(){ // Grab all arguments as an array.  var args = [].slice.call( arguments ); // Unless processArgs() returns false ...  if( processArgs( args ) ) // ... pass through to original GA object.  return gaOrig.apply( gaOrig, args ); };  The processArgs function simply delegates the processing and filtering of all commands to you (via the custom listener function).\nfunction processArgs( a ){ // Call listener, return false only if listener returns false.  return listener( a ) !== false; }  1.4. Time To Spy As soon as GA Spy is run, it will instantiate the command queue if it doesn\u0026rsquo;t already exist, just as the Universal Analytics snippet would. Both in this script and in the Universal Analytics snippet, we\u0026rsquo;re careful not to blindly set a new variable and lose any previous data.\nif( ! window[gaObjName] ){ // If global object doesn\u0026#39;t exist ...  ga = function(){ if( ! window[gaObjName].q ) window[gaObjName].q = []; window[gaObjName].q.push( arguments ); }; ga.l = 1 * new Date(); window[gaObjName] = ga; }  Note: the above code does the exact same thing as the second line of the GA install snippet function, shown beautified under A Good Spy Starts With Research above.\nThen, regardless of whether it already existed or was just initiated, GA Spy hijacks ga.\nIf ga is found to be the fully-formed Universal Analytics tracking method, then analytics.js has already loaded and we will be tapped into all subsequent calls to ga until the page is unloaded. Job done. Since the global ga object does not keep track of previously run ga() commands, we cannot access the information passed in those commands. It\u0026rsquo;d be useful if we could access the command history, but we still would not be able to block those hits, since JavaScript does not support time reversal (not gonna work: setTimeout( hijack, -5 )).\nHowever, if GA Spy finds the command queue instantiated in ga, then we know that if/when analytics.js loads, it will replace the hijacked command queue (our proxy) with the actual Universal Analytics tracking method. We can easily hijack it again, but timing is important. We want the global ga object to be in existence for as short a period as possible to avoid missing any commands before we manage to hijack it.\nAny function in the command queue will be executed as soon as the ga object is ready. So we add the hijack function, thereby setting a trap the ga object will trigger immediately upon loading, and put our proxy in its place before the ga object is even available to other scripts.\nThe only other thing we need to do is run the stack of existing commands through the listener, and when it returns false just filter that command out of the queue.\n2. Reliability And Caveats This should be an extremely reliable solution. In fact, the method of listening by \u0026ldquo;hijacking\u0026rdquo; a function is used by a number of Google libraries, including GTM\u0026rsquo;s own Data Layer and Autotrack. Note that it\u0026rsquo;s possible GA Spy can be broken by an update to analytics.js, but the ga interface GA Spy relies on is wholly defined in the standard Universal Analytics install snippet, so breakage due to unannounced library updates is highly unlikely.\nNevertheless, there are some important caveats to note before using this.\n2.1. Uncommon Behavior For A Common Library Whenever this is used to modify or block a ga command, I would consider this a \u0026ldquo;hacky\u0026rdquo; solution. Although the code is sound, such usage modifies the typical behavior of the global ga() function, making it work differently than it works on 99% of other websites. This can impede troubleshooting and confuse those who are new to Google Analytics or JavaScript.\nTip: You can tell that you\u0026rsquo;re dealing with hijacked GA by checking for the presence of the property _gaOrig in the global Google Analytics object. By default it would be: window.ga._gaOrig.\nIn some cases, hijacking the GA function is necessitated by third-party vendors that require their JavaScript to be implemented with a hardcoded GA tracker.\nIn other cases, such as when completing a migration from hardcoded Google Analytics to Google Tag Manager, this treatment should be acceptable only as a short-term solution.\n2.2. Cannot Intercept Hardcoded Pageviews From GA If GA Spy runs before analytics.js loads, you will be able to access and block 100% of the commands queued to analytics.js. But if GA Spy runs after, then it has zero insight into what hits (if any) were previously fired. So if you want to intercept all hardcoded commands, GA Spy needs to be deployed directly on the page. However, for many purposes, this is not necessary at all.\nUnfortunately, in some cases where deploying on-page is necessary, the inability to make on-page changes is the very problem that prompted the need for GA Spy in the first place, making this solution a catch-22. For GTM migrations, one way to mitigate this is to request to have GA Spy placed on the page at the same time that GTM is added.\nNote, if synchronous loading of Google Tag Manager is ever supported, hardcoding GA Spy will no longer be required, but still recommended, because loading anything synchronously in the \u0026lt;head\u0026gt; will degrade page loading speed.\n2.3. Incomplete Currently, GA Spy only intercepts GA commands that are called upon the global ga object, but there are other ways to send commands to analytics.js. Many GA plugins and some custom implementations call commands directly upon the tracker object (i.e. ga.getAll()[0].send('event')). Support for intercepting these commands may be added in the future.\nAnother limitation is that GA Spy can process only the values passed to GA commands. It doesn\u0026rsquo;t provide access to the default values for all the fields that are populated by analytics.js.\nOne effect of these two facts is that GA Spy will not pick up hit modifications (or extra hits) done by GA plugins (and other implementations using the Tasks API). This is by design and no support for this planned. (If you see a need for this, describe the use case and upvote this enhancement here.)\n2.4. More Code! As a developer I have many protests against the following statement, but I can\u0026rsquo;t deny it\u0026rsquo;s essential truth: code is bad. Meaning, no matter how good the code, no code is better. Code leads to bugs which lead to more code, which leads to more bugs. Even bullet-proof code requires some degree of maintenance. Perhaps the biggest issue is that a code-based solution imposes a higher skill barrier on managing and customizing the solution. As a general rule, we should avoid custom code whenever there is a sound alternative.\n3. Usage 3.1. Placement If you need to intercept GA commands that run upon page load or shortly thereafter (such as the tracker creation or 'pageview' in the base GA install snippet), then you\u0026rsquo;ll need deploy GA Spy in an inline script tag or external script (with no async or defer attributes) above the first GA command (usually in the base GA snippet).\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; ... // GA Spy: \u0026lt;script\u0026gt; ;window.gaSpy = window.gaSpy... \u0026lt;/script\u0026gt; // Universal Analytics snippet: \u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m)... \u0026lt;/script\u0026gt; ... \u0026lt;/head\u0026gt; If the commands you need to intercept are triggered by user action, then this is not an issue and you can deploy GA Spy using GTM.\n  3.2. Your Listener This script will not do anything on its own. You need to implement all actions in your custom listener callback function. You can do things like:\n Access and modify the arguments sent to ga().\n Access information about the command scope (tracker name, hit type, etc.)\n Block the hit by returning false (returning merely \u0026ldquo;falsy\u0026rdquo; values like 0 or undefined will not block the hit).\n And everything else you can do in JavaScript :)\n  In many cases, we\u0026rsquo;ll want to push the hit values onto the dataLayer so they can be accessed in GTM.\n\u0026lt;script\u0026gt; gaSpy(function(obj) { // Do something with the arguments to ga():  var args = obj.args; // Do something with details about the tracker itself:  var details = obj.the; }); \u0026lt;/script\u0026gt; Naturally, any calls to gaSpy() need to be timed so that they take place after you\u0026rsquo;ve loaded the GA Spy code itself.\nSee the README file for more details on what data is passed to the callback function, as well as additional GA Spy configuration options.\n3.3. Listening From GTM If using GA Spy in GTM, the listener should typically ignore all commands from GTM. Failure to do this could result in blocking GTM hits or in an infinite loop. We can do this by checking the tracker name. GTM uses tracker names starting with \u0026ldquo;gtm\u0026rdquo; followed by the timestamp of when the tracker was created.\nHowever, this method will not work when callbacks are passed in place of a GA command. GTM does not appear to use these currently, but we cannot do much with a them anyway, so as a precaution any listener should ignore callbacks too.\nUse the this code at the top of your callback function to avoid issues:\ngaSpy( function( ev ){ if( ev.the.callback ) return; if( ev.the.trackerName \u0026amp;\u0026amp; ev.the.trackerName.substr( 0, 3 ) == \u0026#39;gtm\u0026#39; ) return; // Your code here });  This is not foolproof, but it\u0026rsquo;ll work unless hardcoded tracking is using a tracker name starting with \u0026ldquo;gtm\u0026rdquo; (or if the tracker names in GTM are customized, which is probably done as an alternative to this solution). For example, this method will not work for Wistia\u0026rsquo;s built-in tracking, because Wistia\u0026rsquo;s code (erroneously) sends hits through every named tracker on the page.\n4. Examples 4.1. Log GA Commands Logging GA commands is a useful way to easily see what commands are being picked up by GA Spy, letting you see which things GA Spy can block and/or latch on to in order to execute custom behavior. Compared with browser extensions and the verbose analytics_debug.js, GA Spy logging can be very minimalistic. You could even log using only emojis if you wanted! And it has the advantage of working even when the hit does not fire (such as when using GA opt-out or tracking blockers).\nThis listener callback will print ga() arguments exactly as they are given:\ngaSpy( function gaSpy_cb_( ev ){ console.debug.apply( console, ev.args ) });  Or check out one of the examples on GitHub for something a bit more robust:\n  Since this is all one script, you could turn this into a bookmarklet. This could also block all hits, so it serves as a \u0026lsquo;test mode\u0026rsquo; bookmarklet, which both logs and prevents any hits from being fired.\n4.2. Access Hardcoded GA Command Data Via GTM If you know exactly what you\u0026rsquo;re looking for, you can simply look for that format and send it to dataLayer. Remember to define an event name in the dataLayer.push(), so you can create a GTM trigger based on the event. Here\u0026rsquo;s an example that clocks hardcoded events from the social sharing plugin ShareThis and forwards them to GTM:\ngaSpy( function gaSpy_cb_( ev ){ var a = ev.args; if( a[0] == \u0026#34;send\u0026#34; \u0026amp;\u0026amp; a[1] == \u0026#34;event\u0026#34; \u0026amp;\u0026amp; a[2] == \u0026#34;ShareThis\u0026#34; ){ dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;spy.ga.socialPlugin\u0026#39;, \u0026#39;spy.ga.socialPlugin\u0026#39; : { \u0026#39;network\u0026#39; : a[3], \u0026#39;url\u0026#39; : a[4] } }); } return false; });  Here\u0026rsquo;s a more robust example that sends all non-GTM commands to dataLayer.\n  Most of the code necessary for this simply normalizes the command arguments (since GA commands have a flexible format for defining field values). It also handles data scope (different trackers, plugins) and also wipes hit-only fields after the relevant GTM event.\n5. Next Steps Even though this is a reliable and relatively simple method for working with hardcoded GA tracking, hopefully this was not your first choice. Even though this fixes real data issues and helps consolidate your implementation in GTM, it\u0026rsquo;s an awkward way of doing so. You can get the same result with a much simpler configuration: no hardcoded tracking, and no spying! Don\u0026rsquo;t be satisfied with getting tracking working; pursue a clean implementation. Even if it will take a while, plan to have the hardcoded tracking removed.\nYour script is making your Universal Analytics code work differently than it would work on virtually every other website, confusing troubleshooters and learners. So, even if you believe hardcoded tracking removal is imminent, be sure to note your use of GA Spy (prominently) in your tracking documentation.\nIf you are using GA Spy to deal with code from a third party platform or plugin, contact the developers. Let them know their script is not compatible with GTM. (Actually, you should do that before implementing GA Spy; they might be responsive and fix their code quickly!)\n6. Feedback This method was designed to be flexible and was tested with various setups, but that\u0026rsquo;s not to say it\u0026rsquo;s bulletproof. On the contrary, I\u0026rsquo;m eager to discover bugs, incompatibilities with browser plugins, and similar issues. Naturally, I admit it\u0026rsquo;d be nicer to find out there are none :)\nPlease post any problems or suggestions as a new issue on GitHub if it has not already been added. Be sure to upvote fixes and enhancements you want to see implemented (by clicking the little thumbs-up icon)!\n7. Summary (by Simo) This is some top-notch JavaScript right here! What Stephen has built is a swiss-army knife that lets you take full control over how analytics.js functions as a tracking interface on your website. Even though translating the hardcoded ga() calls to dataLayer.push() commands is the obvious choice, there are lots of use cases for this library, and you can check some of the examples out here.\nOne of the things this enables is what we\u0026rsquo;ve been waiting for so long with Google Tag Manager: the ability to intercept and modify the payload sent by GTM\u0026rsquo;s Tags to Google Analytics. There\u0026rsquo;s no way to add your own custom plugins, for example, but this library with its hijack function lets you modify the tracker object between its creation and when the data is dispatched. It\u0026rsquo;s not entirely trivial, but I might just have an article in the pipeline showing some cool uses cases for this particular library, so stay tuned!\nIn any case, thank you so much to Stephen for sharing this incredible resource with the community. If you have implementation trouble with the library or any other type of feedback to share, please sound off in the comments. And please respect Stephen\u0026rsquo;s wishes when he requested any actual bugs and issues to be contributed to the issue tracker in GitHub.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/debug-change-history-gtm/",
	"title": "#GTMTips: Debug Change History In GTM",
	"tags": ["change history", "debug", "Google Tag Manager", "gtmtips"],
	"description": "Understand what changes have been made and when in the Google Tag Manager user interface.",
	"content": " Google Tag Manager can be quite the hierarchical mess. You have accounts which comprise containers. Containers are split into container versions, and you use workspaces to create new versions. Phew! Trying to keep tabs on all the activity within these layers can be quite the chore.\nIn this #GTMTips article, I\u0026rsquo;ll do a quick walkthrough of (almost) all the places where you can review changes made in your Google Tag Manager account and container.\nTip 49: Debug Change History In GTM   Let\u0026rsquo;s start from the top and make our way all the way to the smallest increments.\nAccount Activity What it shows: Changes to user permissions (both Account and Container level)\nYou\u0026rsquo;ll find Account Activity by browsing to Admin in the GTM user interface, and looking in the Account column.\n  When you click this link, you\u0026rsquo;ll see a list of all changes made on the Account level. These include:\n Containers created and deleted\n User permissions created, modified, and deleted\n    Note that if you have \u0026ldquo;No Access\u0026rdquo; as your permission level for any given container, you will not see its changes in this list.\nContainer Activity What it shows: Container Version, Workspace, and Environment activity.\nYou\u0026rsquo;ll find Container Activity under the Container column of GTM\u0026rsquo;s Admin interface.\n  Under Container Activity, you\u0026rsquo;ll find:\n Container Version creation and restoration\n Workspace deletion\n Environment creation and deletion\n    I think list is oddly lacking. There\u0026rsquo;s nothing about Workspace creation nor anything about Container Version deletion. I\u0026rsquo;d also like to see more granular changes, such as when an Environment link is reset.\nContainer Versions What it shows: Container Versions, with details about when they were created and published.\nThis should be a pretty familiar list. You\u0026rsquo;ll find it by clicking Versions in the main navigation.\n  In the Versions list, you\u0026rsquo;ll find:\n Each Container Version, numbered in sequence\n Which Environment (if any) the Version is published to\n Who created the Version and (if published) who published it\n When the Version was published\n Actions menu for the version\n    Note also the Show deleted button in the top right corner. By clicking that you can see deleted container versions, and by choosing Undelete from the Actions menu you can, surprise surprise, undelete the respective container version.\nBy clicking a version in this list, you will be taken to the dedicated page for debugging the changes with more detail (see below).\nI would really like to see the Workspace name from which the version was created here, too. It would help draw a line through container activity history from the version to the draft.\nVersion Changes / Activity History What it shows: Version Changes shows the list of assets (Tags, Triggers, Variables) that were modified in this Container Version. By clicking any one of these assets, you can see what changes were made between this version and what was then the Latest Version. Activity History gives you more information about who made the changes.\nYou\u0026rsquo;ll find these details by clicking any version either in the Versions list (see above) or from the Workspace Overview screen by clicking either \u0026ldquo;Live Version\u0026rdquo; or \u0026ldquo;Latest Version\u0026rdquo;.\n  Under Version Changes you\u0026rsquo;ll see:\n What was changed\n How do the changes compare with the Latest Version at the time when this version was created (click an asset to see this information)\n  When clicking Activity History an overlay flies out with:\n Who made what changes\n Who published the version\n    Oddly enough, the Activity History doesn\u0026rsquo;t tell you who created the container version itself. So only the Publish activity is enumerated in this list.\nWorkspace Changes What it shows: List of assets that have been modified in this Workspace draft, when compared to the Latest Container Version.\nThis is the list you\u0026rsquo;ll see in the Workspace Overview screen.\n  This list will give you the following details:\n What assets were created, modified or deleted in this workspace\n Who made the changes and when\n What the changes were compared to the Latest Container Version\n  By clicking the dot menu at the end of each line, you can Abandon Changes you\u0026rsquo;ve made to the asset, or you can View Changes, which lets you analyze what modifications were done compared to the Latest Container Version.\nNote that \u0026ldquo;Last Edited\u0026rdquo; is quite literal. Removing something isn\u0026rsquo;t \u0026ldquo;Editing\u0026rdquo;, so in the list itself the \u0026ldquo;Last Edited\u0026rdquo; doesn\u0026rsquo;t reflect the time when the asset was deleted.\nRemember to read my Workspaces guide for more information about debugging Workspace activity!\nActivity History What it shows: A chronological list of changes to each asset. \u0026ldquo;Workspace Changes\u0026rdquo; only has the latest state listed, but \u0026ldquo;Activity History\u0026rdquo; shows you previous states, too. Also, any changes to the Workspace itself (e.g. sync with Latest Container Version) are listed here.\nYou\u0026rsquo;ll find the link to Activity History just below Version Changes.\n  When you click the link, an overly flies out with the following details:\n Creation, deletion, modification, and restoration of individual assets\n Workspace synchronization\n Workspace creation\n    Summary These are the \u0026ldquo;obvious\u0026rdquo; places for debugging activity in your Google Tag Manager domain. There are some glaring omissions (especially under Container Activity in Admin), but with the current tools you can already get pretty far in pinpointing who made what changes and when.\nOne thing I miss from the pre-Workspace era is a master list of all changes to a container. So one place which puts all the above together, in chronological sequence. A sort of \u0026ldquo;Activity History\u0026rdquo; for the entire container, with all the details in one, long list. Right now there\u0026rsquo;s a bit too much bouncing about the place if you\u0026rsquo;re trying to align individual actions within the timeline of the entire container.\nThis wasn\u0026rsquo;t an exhaustive list for debugging container activity. Do you have your own tips and tricks for uncovering more details about what\u0026rsquo;s going on your precious container?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/10-javascript-concepts-for-web-analytics-implementation/",
	"title": "10 JavaScript Concepts For Web Analytics Implementation",
	"tags": ["education", "google analytics", "Google Tag Manager", "JavaScript"],
	"description": "Ten JavaScript concepts that are important to understand when working with web analytics implementations.",
	"content": " I\u0026rsquo;ve already written extensively about JavaScript in web analytics implementation. Suffice to say, understanding at least the basics is absolutely necessary to survive in the technical medium of the web browser.\n  This article expands on a conference talk I gave at MeasureCamp IX, London a short while ago. I\u0026rsquo;ve always been quite single-minded about the importance of JavaScript in web analytics development, and it was a pleasure for me to get some of that off my chest. So I want to go over the ten concepts introduced in my conference talk with a little more detail, especially in the context of Google Tag Manager.\n  Get the basics right JavaScript is not the quirky animation tool from two decades ago anymore - it\u0026rsquo;s a programming language if there ever was one. It hides a lot of complexity under its seemingly simple syntax, though in the web browser much of this complexity is either abstracted or removed entirely thanks to how the client-server infrastructure of the web works.\nTo get up to speed with JavaScript, I typically recommend the following resources. Codecademy especially is something you might want to devote time and effort to. It has lots of different tracks, and some that are extremely useful for web (analytics) developers.\n1. Codecademy   Codecademy is an amazing resource. The courses are free, fully interactive, and the service keeps track of your progress as you learn new skills along the way. Codecademy has lots of tracks for web developers, but I want to highlight the following as the bare minimum for web analytics:\n JavaScript\n HTML \u0026amp; CSS\n jQuery\n  I recommend making it habitual to always have a course active in Codecademy. Programming is not a skill you develop in silos - each new language and discipline you learn helps you become a better developer overall.\n2. Books   You might argue that books are not the best way to keep up-to-date with web technologies, but the following volumes have stood the test of time (with the exception of the last one which is brand new) marvellously, and even if some of the code samples might be outdated, the ideas behind the solutions remain as topical as ever.\n Nicholas Zakas: Professional JavaScript for Web Developers (3rd Edition)\n Cody Lindley: DOM Enlightenment\n Jonathan Weber: Practical Google Analytics and Google Tag Manager for Developers\n  Zakas\u0026rsquo; volume is a great, if somewhat intimidating, foray into how JavaScript and the web browser interact. Needless to say, it is a goldmine for understanding the technical stack you\u0026rsquo;re working with when implementing web analytics solution. It\u0026rsquo;s the book I would most recommend you to read once you have the basics of JavaScript down.\n3. Sandbox The only way you can really learn something is by doing it. All creative skills, programming included, need honing. The best way to learn programming is to actively practice it. So in addition to taking courses and learning by reading, remember to also create stuff! A great way to do it is to deploy Google Tag Manager on your own website. If you don\u0026rsquo;t have one, you can now create one with your new-fangled skills!\nPlay around with the JavaScript Console of your web browser\u0026rsquo;s developer tools. Implement scripts in Google Tag Manager, and see how they interact with your website. Use tools like JS Lint to understand what issues your code might have.\nWhatever you do, just keep coding.\n  In the context of Google Tag Manager, functions are arguably the most useful little things when customizing implementations. That\u0026rsquo;s because the Custom JavaScript Variable is basically a function call that you use to resolve a value.\nThe Custom JavaScript Variable has a very deliberate syntax when using Google Tag Manager, and some of the restrictions might sound odd to you, so I want to go over them with some detail in this chapter.\nAnonymous function with a return statement The Custom JavaScript Variable requires an anonymous function with a return statement. An anonymous function is exactly that: it\u0026rsquo;s a function without a named identifier that you could use to refer to it. Now, you can argue that it does have a name since the Variable itself has a name, but that\u0026rsquo;s GTM\u0026rsquo;s proprietary way of resolving the Custom JavaScript Variable and has nothing to do with the underlying JavaScript syntax.\nThe Custom JavaScript Variable doesn\u0026rsquo;t take any parameters, either. All values you want to process through it need to come from the internal data model of Google Tag Manager (GTM\u0026rsquo;s \u0026ldquo;Variables\u0026rdquo;), need to be created on the spot (local scope), or need to be available in the global namespace (global scope).\nFinally, all Custom JavaScript Variables need a return statement. They must always return some value, as they are invoked in situations where a value is required.\nSo this is the minimum viable Custom JavaScript Variable you could create.\nfunction() { return; }  When invoked with the {{Variable}} syntax, this function would return undefined.\nAvoid side effects Since the Custom JavaScript Variable is a value-returning function which does not accept parameters, it should only be used for input/output operations. Thus, the purpose of the Custom JavaScript Variable is to take some value, modify it, and then return the modified value.\nA function has side effects if it does something else except the input/output operation described in the previous paragraph. Typical side effects occur when a function is used to modify something in the global scope, or it\u0026rsquo;s used to set some value elsewhere, or, in the context of Google Tag Manager, it\u0026rsquo;s used to manipulate the Data Layer.\nYou should avoid side effects because Google Tag Manager can\u0026rsquo;t guarantee that the Custom JavaScript Variable is only resolved once per activation. In fact, in Preview mode, Custom JavaScript Variables can be resolved dozens of times per dataLayer.push(), which can lead to a confusing experience.\nfunction() { // AVOID THIS:  window.dataLayer.push({\u0026#39;event\u0026#39; : \u0026#39;JavaScript executed\u0026#39;}); return; }  The main problem with side effects is that they\u0026rsquo;re hard to trace if problems arise. Since the Custom JavaScript Variables are resolved at arbitrary times, having them modify the global scope can be hazardous and can easily lead to unwanted race conditions.\nUnderstand scope, utilize closures JavaScript in the web has two types of scope: local and global.\nLocal scope, also known as function scope, is what variables are restricted to when declared within a function. When you declare a variable in a function, it will only exist for the duration of the function call (though see the part about closures below), after which the garbage collector comes and whisks it away. Locally scoped variables cannot be referred to or invoked from outside the current function context.\nfunction() { // These variables all have local scope  var hello = \u0026#34;Hi, \u0026#34;; var myname = \u0026#34;Simo!\u0026#34;; return hello + myname; }  Global scope, on the other hand, comprises variables that are declared as properties of the window object. If you don\u0026rsquo;t use the var keyword when declaring a variable in a function, it is automatically elevated into global scope.\nWhen a variable is in global scope, you can refer to it anywhere. For example, the ubiquitous document property of the browser\u0026rsquo;s Document Object Model can be used anywhere since it\u0026rsquo;s actually a global property of the window object:\nwindow.document === document; // true  Closures are an exception to how locally scoped variables are ephemeral and inaccessible from the outside. When you create a closure, you are actually creating a simple interface that lets you access the locally scoped variable from outside the function!\nfunction() { var timeNow = new Date(); // Locally scoped  return function() { return \u0026#34;Time then was: \u0026#34; + timeNow; }; }  The closure is the return function() {...} statement. Because the function is declared within same context, it has access to the locally scoped timeNow variable. And because the function is the target of the return statement, you can actually call this returned function in code! In the example below, the Custom JavaScript Variable we just created above is named Time Then.\nvar timeThen = {{Time Then}}(); console.log(timeThen);  The parentheses at the end of the Custom JavaScript Variable are significant. If you simply had {{Time Then}}, the variable assignment would store the return value of the Custom JavaScript Variable (the closure) into the timeThen variable. The console.log() command would simply output the function description itself, and not the result. By adding the parentheses, you\u0026rsquo;re telling the browser to actually invoke the function returned by the Custom JavaScript Variable. Since the timeNow is only created once (when the Custom JavaScript Variable is first resolved), the closure will always return the same date-time string.\nModify state when you are in control of resolution There is one exception to Custom JavaScript Variables having side effects. When you are in full control of when the function is resolved, it\u0026rsquo;s fine to cause side effects, since you don\u0026rsquo;t have to worry about the function resolving an unknown number of times or in unknown contexts.\nOne such example is when using a closure in a callback. Callbacks (more on these later) are execution milestones which take place after some other process has completed. So if you indicate the closure of a Custom JavaScript Variable as the value of a callback, you can rest assured that the function is only called once - when the main process has completed.\nfunction() { // Return a function to be used by hitCallback  return function() { // It\u0026#39;s OK to modify state here!  window.dataLayer.push({\u0026#39;event\u0026#39; : \u0026#39;tagHasFired\u0026#39;}); }; }  This process is exemplified in the hitCallback feature of the Google Analytics tracker. The hitCallback function is called after the request to Google Analytics has completed. Thus, you can use the closure of a Custom JavaScript Variable to perform some state-altering thing in the hitCallback field itself! This is very useful if you want to chain tags in a sequence, for example.\nFURTHER READING Take a look at the following articles for more information on how functions work:\n w3schools: JavaScript Closures\n MDN: Closures\n Custom JavaScript Variable\n #GTMtips: hitCallback And eventCallback\n    In JavaScript, you have five value-carrying data types:\nvar something = 5; // number var something = \u0026#34;five\u0026#34;; // string var something = true; // boolean var something = {five: 5}; // object var something = function() { return 5; }; // function  It gets slightly messier than this, since there are actually lots of different types of objects (all JavaScript data types are actually an extension of \u0026ldquo;object\u0026rdquo; in its fundamental sense):\nvar something = {five: 5}; // Object var something = [5,5,5]; // Array var something = new Date(); // Date  And finally we have some mystic pseudo-types which don\u0026rsquo;t carry any value:\nvar something = undefined; // undefined var something = null; // null  Dynamic type Unlike some other programming languages (e.g. Java), type is dynamic in JavaScript. That means that you can reassign a variable with a completely different type without having to worry about type conversion.\nvar something = 5; something = \u0026#34;five\u0026#34;;  The above is possible in JavaScript, because the variable assignment itself doesn\u0026rsquo;t coerce the assigned value to any specific type. This can be a weakness in the code, because it requires you to test for type to avoid errors.\n// Works because something is a number var something = 5; var somethingMultiplied = something * 2; // Won\u0026#39;t work because something is suddenly a string something = \u0026#34;five\u0026#34;; somethingMultiplied = something * 2; // NaN: Not a Number  // So you need to test if (typeof something === \u0026#39;number\u0026#39;) { somethingMultiplied = something * 2; }  The further apart your variables are from their execution context, the messier it can get with all the type checks. So try to avoid exploiting dynamic type, and do your best to maintain type when creating and reassigning variables.\nLoose type JavaScript also does type conversion for you when needed. This means that the following is possible:\nvar something = \u0026#34;5\u0026#34;; var somethingMultiplied = something * 2; // 10  In the multiplication, JavaScript expects something to resolve to the number type. Even though something is a string, JavaScript detects the number within and automatically converts the variable to a number for the multiplication statement. The variable something itself is not modified, but the value held by it is converted automatically to make resolving somethingMultiplied possible.\nNote that there are some embarrassing exceptions. The plus operator (+) is not only used for mathematical statements but also for concatenating strings. So if you try to add a number to a string, you\u0026rsquo;ll end up with a concatenated string rather than a number!\nvar a = \u0026#34;5\u0026#34;; var b = 6; var c = a + b; // \u0026#34;56\u0026#34;!  // You need to use parseInt() to manually convert to number: c = parseInt(a) + b; // 11  Weird stuff I\u0026rsquo;ll just leave this list here. It\u0026rsquo;s just a handful off the odd behavior you get when working with loose and dynamic type.\ntypeof NaN; // number NaN === NaN; // false typeof NaN; // number isNaN(NaN); // true isNaN(null); // false typeof null; // object null instanceof Object; // false typeof undefined; // undefined undefined === null; // false undefined == null; // true {simo: true} === {simo: true}; // false  Undefined and Google Analytics Remember that the undefined type has a special function in Google Analytics (and Google Tag Manager). If you refer to a variable which returns undefined, that particular setting, field, or parameter is automatically dropped from the request to Google Analytics.\nIn Google Tag Manager, undefined can also be used to purge values from the Data Layer. This is extremely useful on single-page apps, where variables persist their values throughout the visit.\nwindow.dataLayer.push({ event: \u0026#39;GAEvent\u0026#39;, eventData : { cat: \u0026#39;Category value\u0026#39;, act: \u0026#39;Action value\u0026#39;, lab: undefined, val: undefined } });  FURTHER READING The following articles shed more light on data types in JavaScript:\n w3schools: JavaScript Data Types\n MDN: JavaScript data types and data structures\n #GTMtips: Undefined dimensions won\u0026rsquo;t get sent\n    When looking for things that can slow down the site, slow or poorly performing HTTP requests are usually the easy culprit to blame.\nThanks to asynchronous loading, most HTTP requests are done in such a way that they don\u0026rsquo;t block the page from rendering, but async itself doesn\u0026rsquo;t guarantee a smooth ride.\nLet\u0026rsquo;s take Google Tag Manager as an example. This is a typical container snippet:\n(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;:new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src=\u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f);})(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-W92WQQ\u0026#39;);  I\u0026rsquo;ve gone over this code in an earlier article, but suffice to say that the end result of all this code is this:\n  In other words, the minified code creates a new script HTML element, which instructs the browser to request for a file in Google\u0026rsquo;s servers, and the request is done asynchronously.\nThe script element, then, turns into an HTTP request, since the src attribute in the tag signals the browser to make an HTTP request to the URL value of the attribute.\n  So just by creating the script tag, the browser automatically executed an HTTP request to the given endpoint, and the result of this request is the gtm.js retrieved in the browser for immediate execution.\nThere are lots of elements that can produce an HTTP request. All scripts, images, and HTML files need to be retrieved from the web server, and the main channel of data transfer is the HTTP request. The following HTML tags (with the given attributes) also invoke HTTP requests:\n\u0026lt;input src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;input usemap=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;ins cite=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;object classid=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;object codebase=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;object data=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;object usemap=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;q cite=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;url\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;audio src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;button formaction=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;command icon=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;embed src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;html manifest=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;input formaction=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;source src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;video poster=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;video src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;applet codebase=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;area href=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;base href=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;blockquote cite=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;body background=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;del cite=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;form action=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;frame longdesc=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;frame src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;head profile=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;iframe longdesc=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;iframe src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;img longdesc=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;url\u0026#34;\u0026gt; \u0026lt;img usemap=\u0026#34;url\u0026#34;\u0026gt; Yeah. That\u0026rsquo;s quite a bunch.\nNote that HTTP requests can be created manually using e.g. XMLHttpRequest or jQuery.ajax(). In fact, when you send hits to Google Analytics, you\u0026rsquo;re actually using HTTP requests created by the analytics.js library.\n  FURTHER READING Here\u0026rsquo;s more information on HTTP requests:\n w3schools: AJAX - Create an XMLHttpRequest Object\n w3schools: HTTP Methods: GET vs. POST\n Measurement Protocol Reference: Transport\n    The difference between asynchronous and synchronous loading is subtle but significant.\nJavaScript in the web browser is single-threaded. That means that only one process can ever be running at a time, and thus every single line of JavaScript must be executed completely before the browser can proceed to the next line. If you make a synchronous HTTP request, it means that the browser will wait until the entire request (download, execution, render) is taken to completion before the browser proceeds to the next line of code in the page. It\u0026rsquo;s said that synchronous operations are thus blocking.\nTo counter this potentially devastating blow to page render and user experience, asynchronous loading was introduced to make the \u0026ldquo;expensive\u0026rdquo; part of the process, the download, happen so that it doesn\u0026rsquo;t block the browser.\nSo, when a request is made asynchronously, the browser initiates the download but then proceeds to the next line of code while the download goes on in the background. Only after the file is completely downloaded, does the browser return execution to this initial process, rendering the downloaded asset in the browser.\nThe problem with asynchronous execution is that even though you can pinpoint the exact moment when the request is initiated, as it\u0026rsquo;s governed by the order of the lines of code in the page template, you\u0026rsquo;ll never know the exact moment when it completes. And this can lead to something called a race condition.\nSo let\u0026rsquo;s say I have the following two lines of code in the page template:\n\u0026lt;script async src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script async=\u0026#34;\u0026#34; src=\u0026#34;https//www.googletagmanager.com/gtm.js?id=GTM-XXXXX\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; The browser starts loading the jQuery library before GTM, so I might expect jQuery to available to GTM as soon as the latter has finished downloading. But that\u0026rsquo;s not necessarily the case! The actual download of jQuery can end long after GTM has completed, because the jQuery library is more often than not quite a bulky thing. Also, if the CDN providing the jQuery library has latency, it might affect when jQuery becomes available.\nSo, if in Google Tag Manager I try to use jQuery, there can be a race condition where GTM expects jQuery to be available but it isn\u0026rsquo;t.\nTo combat the race condition, we can use tools like callbacks, promises or, in GTM, Tag Sequencing. You can always resort to synchronous downloading if you\u0026rsquo;re really concerned about race conditions, but remember that this can have a detrimental impact on user experience.\n\u0026lt;!-- Synchronous request --\u0026gt; \u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script async=\u0026#34;\u0026#34; src=\u0026#34;https//www.googletagmanager.com/gtm.js?id=GTM-XXXXX\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Callback --\u0026gt; \u0026lt;script\u0026gt; (function() { var el = document.createElement(\u0026#39;script\u0026#39;); el.src = \u0026#39;https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js\u0026#39;; el.async = true; el.addEventListener(\u0026#39;load\u0026#39;, function() { window.dataLayer.push({event: \u0026#39;jQueryLoaded\u0026#39;}); }); document.head.appendChild(el); })(); \u0026lt;/script\u0026gt; \u0026lt;!-- Tag Sequencing --\u0026gt; \u0026lt;script\u0026gt; (function() { var el = document.createElement(\u0026#39;script\u0026#39;); el.src = \u0026#39;https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js\u0026#39;; el.async = true; el.addEventListener(\u0026#39;load\u0026#39;, function() { window[\u0026#39;google_tag_maanger\u0026#39;][{{Container ID}}].onHtmlSuccess({{HTML ID}}); }); document.head.appendChild(el); })(); \u0026lt;/script\u0026gt; It\u0026rsquo;s better to be safe than sorry, so when working with potential race conditions, make sure to always check if the resources you are trying to use actually exist.\nif (typeof jQuery !== \u0026#39;undefined\u0026#39;) { // Use jQuery } else { // Use something else }  FURTHER READING Here are some useful links on race conditions, callbacks, and such.\n Callback Hell\n MDN: Promise\n Understanding Tag Sequencing in Google Tag Manager\n    Single-page web applications (SPA) utilize something called the History API to provide a multi-page experience with only one initial page load in the web server. Subsequent transitions from page-to-page are commonly done using the History API, by withdrawing content from the server without initiating a page refresh, and manually creating history entries in the web browser. Common frameworks for SPAs are e.g. React, AngularJS, and Backbone.js.\nSPAs have significant implications for web analytics. For example, an SPA can suffer from the rogue referrer problem, where URL query parameters that are used for campaign settings are overwritten by a subsequent page view hit. For Google Tag Manager, the problem of persistence rears its ugly head, where variables maintain the values you set earlier, leading to these values bleeding into subsequent tags.\nBrowser history is manipulated because when content is dynamically loaded, the site needs to tell the web browser that the user has entered a new page without the benefit of the page reload doing this automatically. Otherwise you wouldn\u0026rsquo;t be able to link to dynamic content, nor would the Back and Forward buttons of the browser find your dynamic content.\nThe two interfaces you\u0026rsquo;ll run into most often are pushState and replaceState. The former creates a new history entry in the web browser, and the latter replaces the current entry entirely. Here are examples of how to use them:\nwindow.history.pushState( {pageType: \u0026#39;formThankYou\u0026#39;}, \u0026#39;Form Success\u0026#39;, \u0026#39;/thank-you/\u0026#39; );  When you run this command, the URL changes to /thank-you/ without a page reload. The first two parameters add additional information about the state. If you now click the Back button of the browser, you are taken to the URL where you called pushState.\nwindow.history.replaceState( {pageType: \u0026#39;formThankyou\u0026#39;}, \u0026#39;Form Success\u0026#39;, \u0026#39;/thank-you/\u0026#39; );  When you execute this command, it actually replaces the current page in the browser history. In other words, when you click the browser\u0026rsquo;s Back button, you are taken to the page you were on before you entered the page from where you called replaceState.\nNote that if you simply add #someHash in the URL, it\u0026rsquo;s the equivalent of calling pushState without the benefit of the other parameters in the interface (e.g. the state object).\nIn Google Tag Manager, you have a really useful Trigger type called the History Change Trigger. It goes off whenever one of the following History events occur:\n pushState\n replaceState\n hashchange (when the #someHash in the URL appears/changes)\n popstate (when the active history entry changes)  For example, if you want to build pageviews around these history events, it\u0026rsquo;s quite simple to do with the History Change Trigger!\nFURTHER READING For more information on the Window History API, look no further than these articles:\n MDN: Manipulating the browser history\n w3schools: JavaScript Window History\n Google Tag Manager History Listener\n    The web page is stateless. With every page load, the entire page is built from scratch. All the variables, JavaScript libraries, HTML templates, CSS files and other resources are loaded again.\nIn other words, if the web browser needs to know something, anything, about what happened at any time in the past, you need to manually persist this information.\nYou can persist the information in the web server, and this is often quite a robust way to do it. However, because of how the web is built, you still need a way of aligning any given web browser (and thus, user) with the requests that are sent to the web server.\nThe web browser provides a number of ways to persist this information. The most common methods are browser cookies, Web Storage, and IndexedDB.\n  Browser cookies Browser cookies are useful for simple storage. The browser cookie is essentially a string stored by the web browser, and its accessible only by pages that share the same parent domain to which the cookie was written. So a cookie written on www.simoahava.com would, by default, only be available to pages on www.simoahava.com, but you could also write the cookie on simoahava.com, where it would be available to all subdomains.\nA cookie written on simoahava.com would not be available for pages on derekahava.com, because they do not share the same domain.\nCookies also survive transitions from the http:// protocol to https://.\nWeb Storage Web Storage (or DOM Storage) encompasses both localStorage (no expiration) and sessionStorage (expires when the web browser is closed). Web Storage is much more flexible than using cookies, because the entries are stored as a hash table, and lookups can be done on a key-by-key basis. With cookies, you need to unravel the entire cookie string just to find the value want.\n// TO SET if (window[\u0026#39;Storage\u0026#39;]) { localStorage.setItem(\u0026#39;subscribe\u0026#39;, \u0026#39;true\u0026#39;); sessionStorage.setItem(\u0026#39;subscribe\u0026#39;, \u0026#39;true\u0026#39;); } else { setCookie(\u0026#39;subscribe\u0026#39;, \u0026#39;true\u0026#39;); } // TO FETCH localStorage.getItem(\u0026#39;subscribe\u0026#39;); sessionStorage.getItem(\u0026#39;subscribe\u0026#39;);  Note that Web Storage does not survive the transition from http:// to https://. Both protocols have their own storage.\nIndexedDB IndexedDB is much more complex than the aforementioned methods, and is thus more suited for application logic on a much larger scale. For example, if you\u0026rsquo;re using Service Workers to maintain offline browsing capabilities, IndexedDB is an excellent utility to maintain state while waiting for the internet connection to come back up.\nCheckout the link to my article on persisting data in Google Tag Manager for more information (and some tips) on how to setup cookie and Web Storage persistence in GTM!\nFURTHER READING Check out the following links for more information:\n w3schools: JavaScript Cookies\n MDN: Web Storage API\n Two Ways To Persist Data Via Google Tag Manager\n    Locating elements on the page is one of the more obvious use cases for web analytics. Most commonly we want to know if some specific element was the target of a user action such as a click or form submission.\nIn Google Tag Manager, identifying an element is easy enough with CSS selectors, but what if we actually want to retrieve some element other than what GTM initially gave us?\n  There are many ways to retrieve an element relative to some other with JavaScript. A very clumsy way to do it would be to build a complete element chain all between the two elements. So if you wanted to retrieve the element at the top of the DOM in the image above, you could do something like this in a Custom JavaScript Variable:\nfunction() { // Please don\u0026#39;t do this:  return {{Click Element}} .parentElement .parentElement .parentElement .parentElement .parentElement; }  But please don\u0026rsquo;t do this. It\u0026rsquo;s clumsy and it has multiple points of failure. You\u0026rsquo;re basically expecting the DOM to have a certain structure without providing any redundancies or fallbacks. The longer the chain, the more sensitive it is to even minor changes to the page markup.A better way is to disregard the actual number of elements, and just climb up the DOM until you reach the very top.\nSo a more robust way of retrieving the element would be something like this:\nfunction() { var el = {{Click Element}}; while (el.className !== \u0026#39;content-sidebar-wrap\u0026#39; \u0026amp;\u0026amp; el.tagName !== \u0026#39;BODY\u0026#39;) { el = el.parentElement; } return el.tagName !== \u0026#39;BODY\u0026#39; ? el : undefined; }  This little script simply climbs up the DOM until it either reaches the element you wanted (.content-sidebar-wrap) or the \u0026lt;body\u0026gt; tag. If it reaches \u0026lt;body\u0026gt;, the assumption is that the element you were looking for was not found, and undefined is returned instead.\nNote that this script only works for direct ancestry. If you want to find sibling elements or elements which branch from the direct path between the original element and the root of the document, you might want to leverage frameworks like jQuery to make DOM traversal code more economic.\nFURTHER READING Follow these links to find more information on DOM traversal:\n w3schools: JavaScript HTML DOM Navigation\n DOM Enlightenment\n Node Relationships And GTM\n    When Google Tag Manager introduced the matches CSS selector Trigger operator a while ago, it eliminated a lot of complexity from validating Triggers to only fire for certain HTML element interactions. In a similar manner, the querySelector and querySelectorAll JavaScript DOM methods were just as impactful when they were introduced some years ago into the web browser API.\nIf you\u0026rsquo;ve built websites or worked with CSS (Cascading Style Sheets) styles before, you\u0026rsquo;ll know what selectors do. They let you select any element or group of elements on the page, and then apply a style to them. For example, the following style declaration would remove the default underline from all links (\u0026lt;a\u0026gt;) with class internal:\na.internal { text-decoration: none; } Because it\u0026rsquo;s such an effective way of selecting HTML elements, it\u0026rsquo;s not a big surprise that JavaScript introduced methods for using CSS selectors to find and retrieve HTML elements on the page:\n// Select every link with attribute data-gtm on the page: var gtmLinks = document.querySelectorAll(\u0026#39;a[data-gtm]\u0026#39;); // Select the first \u0026#39;h2\u0026#39; element on the page, which is the direct child of \u0026#39;section\u0026#39; var firstH2 = document.querySelector(\u0026#39;section \u0026gt; h2\u0026#39;); // Select the \u0026#39;span\u0026#39; with class \u0026#39;title\u0026#39; that is a descendant of the aforementioned \u0026#39;h2\u0026#39; var spanTitle = firstH2.querySelector(\u0026#39;span.title\u0026#39;);  Similarly, if you already have an HTML element, you can use the matches API to check if it matches a specific CSS selector:\nvar isElementLink = function(el) { return el.matches(\u0026#39;a\u0026#39;); }  The function above would return true or false, depending on whether the element passed as a parameter is a link or not. Note that matches isn\u0026rsquo;t widely supported yet, but there\u0026rsquo;s a polyfill you can use to make it work across all browsers.\nIn Google Tag Manager, the matches CSS selector is ridiculously useful. You can use it to fire your Triggers only when a specific element is the target of the interaction. For example, I could configure a Click / All Elements Trigger like the following to make it only fire when the clicked element is a specific \u0026lt;span\u0026gt; (or any of its nested descendants) on the page!\n  CSS selectors shave a crazy amount of time off your JavaScript, as you don\u0026rsquo;t have to write clumsy comparison queries using DOM traversal when trying to identify a specific element. Take a look at the further reading links below to learn more about CSS selectors!\nFURTHER READING More stuff about CSS selectors:\n w3schools: CSS Selectors Reference\n Matches CSS Selector Operator In GTM Triggers\n    jQuery is undoubtedly the most used JavaScript library in the world, and its contributions to standardizing the web experience across browsers and devices should not and do not go unnoticed. The framework provides such a wealth of utilities that trivialize and abstract many of the woes a web developer might have when developing their site to be as accessible across the splintered browser landscape as possible.\nIn short, jQuery is a library which provides a bunch of simple APIs to perform otherwise complex tasks. For example, let\u0026rsquo;s take the DOM traversal example from chapter 7 and rewrite it with jQuery:\n// Vanilla JS function() { var el = {{Click Element}}; while (el.className !== \u0026#39;content-sidebar-wrap\u0026#39; \u0026amp;\u0026amp; el.tagName !== \u0026#39;BODY\u0026#39;) { el = el.parentElement; } return el.tagName !== \u0026#39;BODY\u0026#39; ? el : undefined; } // jQuery function() { return jQuery({{Click Element}}).closest(\u0026#39;.content-sidebar-wrap\u0026#39;)[0]; }  So a single line of jQuery abstracted the previous implementation.\nSimilarly, here\u0026rsquo;s the difference between building a custom HTTP POST request using regular JavaScript versus using jQuery:\n// Vanilla JS var xhr = new XMLHttpRequest(); var payload = \u0026#39;v=1\u0026amp;tid=UA-12345-1\u0026amp;t=pageview\u0026amp;dl=https://www.simoahava.com/\u0026amp;cid=12345.12345\u0026#39;; xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;https://www.google-analytics.com/collect\u0026#39;); xhr.setRequestHeader(\u0026#39;Content-Type\u0026#39;, \u0026#39;application/x-www-form-urlencoded\u0026#39;); xhr.onload = function() { if (xhr.status === 200) { alert(\u0026#39;Yay!\u0026#39;); } else if (xhr.status !== 200) { alert(\u0026#39;Aww :(\u0026#39;); } }; xhr.send(encodeURI(payload)); // jQuery jQuery.post( \u0026#39;https://www.google-analytics.com/collect\u0026#39;, \u0026#39;v=1\u0026amp;tid=UA-12345-1\u0026amp;t=pageview\u0026amp;dl=https://www.simoahava.com/\u0026amp;cid=12345.12345\u0026#39; ) .done(function() { alert(\u0026#39;Yay!\u0026#39;); }) .fail(function() { alert(\u0026#39;Aww :(\u0026#39;); });  I hope you see the trend here. jQuery really makes things more elegant for both the developer as well as for anyone who wants to look at the code and quickly understand what it tries to do.\njQuery isn\u0026rsquo;t all-powerful, though, and relying too much on a framework can make your code weak. My suggestion is to always understand what a given jQuery method does before using it. That way you\u0026rsquo;ll know what the background process is, and you\u0026rsquo;ll learn to avoid nasty surprises such as how jQuery\u0026rsquo;s return false; in event handlers can break GTM\u0026rsquo;s listeners!\nRemember also to be wary of race conditions when loading jQuery.\n  If you load the library asynchronously, it might not be ready by the time you refer to it in your GTM Tags.\nFURTHER READING And here\u0026rsquo;s the scoop on jQuery:\n jQuery API Documentation\n Codecademy: jQuery\n    Finally, the Data Layer. If you\u0026rsquo;ve used GTM or any tag management solution, it\u0026rsquo;s probably you\u0026rsquo;ve had to really put some thought into understanding how tag management solutions leverage the Data Layer to communicate with the website or other digital property.\nIt\u0026rsquo;s not purely a JavaScript concept, so it\u0026rsquo;s kind of a black sheep in this mix. Nevertheless, the most typical implementation of a Data Layer, when it comes to tag management solutions, is an Array-type data structure in the global namespace.\nI\u0026rsquo;ve written about Data Layer quite a lot on this blog, so instead of repeating what I\u0026rsquo;ve already written far more extensively, I want to direct you to the links below and I strongly suggest you read through them to get a better idea of how the Data Layer works.\nFURTHER READING Be sure to check these links out for more information on the Data Layer:\n The Data Layer\n Google Tag Manager\u0026rsquo;s Data Model\n GitHub: google/data-layer-helper\n  Summary The ten JavaScript concepts introduced in this article are, what I consider, the most useful tools that any web analyst would need to know about. Heck, I consider these vital to anyone working with the web, not just analysts!\nThe thing is, we\u0026rsquo;re working in an extremely technical medium. The web browser is tantalizingly complex in all its machinations, and it doesn\u0026rsquo;t really help that all web browsers act slightly differently when it comes to producing the web document into our screens.\nWhen working with web analytics, we are trying to decipher the abstract signals sent by users, web servers, the browser itself, and background processes, as we do our best to align these signals with their real-world counterparts.\nIt\u0026rsquo;s not easy!\nTrying to deconstruct the enormously difficult concepts of \u0026ldquo;intent\u0026rdquo;, \u0026ldquo;engagement\u0026rdquo;, and \u0026ldquo;interaction\u0026rdquo; using a handful of JavaScript handlers seems like a fool\u0026rsquo;s errand, but it\u0026rsquo;s the only thing we can do when creating an implementation framework for any given web application.\nBut the more we know about JavaScript and the numerous APIs that the web browser lets us tap into, the more we can uncover about our visitors and their actions on the site.\nI hope you found these tips useful. Do you have other JavaScript concepts that you consider are absolutely essential for anyone working with the web to acquaint themselves with?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/revamped-user-interface-in-google-tag-manager/",
	"title": "Revamped User Interface In Google Tag Manager",
	"tags": ["Google Tag Manager", "user interface", "workspaces"],
	"description": "Reviewing the revamped user interface in Google Tag Manager.",
	"content": " It\u0026rsquo;s been a crazy week. Just crazy. Not only did Google Tag Manager introduce Workspaces, arguably one of its most important releases ever for GTM, but they also revamped the user interface! So very big changes have been underfoot, and I\u0026rsquo;m so happy to be writing about them, because in my completely biased opinion these changes are amazing and well worth the long wait.\nIn this article, I want to quickly walk you through what I think are the most meaningful changes in the interface. A lot has changed, but the underlying mechanisms of GTM are still the same. You\u0026rsquo;re still creating Tags, Triggers, and Variables, and you\u0026rsquo;re still debugging the container using Debug Mode. However, the new user interfaces enhances and streamlines the various creation processes in the container, and the new Abandon / View Changes feature allows you to debug and diff the changes you or your team has made.\n1. The overlays The new interface, starting with its flashy account selector menu, just reeks of Material Design. The added third dimension to navigation provides a completely novel experience for GTM veterans.\nA historical pet peeve in GTM had been that if you\u0026rsquo;re in the middle of the Tag creation process and you notice that you need to configure a new Trigger or Variable, you were taken away (or had to leave) the Tag view in order to configure the secondary asset in a separate part of the container. Even though this was largely fixed a while ago, it still leaves a clunky feeling with the page transitions and the staggered workflow.\nWith the overlays, you will never leave the location you are in. The overlays fly in so that they do not cover the whole page, so you\u0026rsquo;ll always know where you started off from.\n  Moving back in history is as easy as clicking the X in the top left corner of any overlay or just clicking the shaded area in the left-hand side of the screen.\nThis, in my opinion, will save time and grey hairs. These overlays will take time to get used to, but it\u0026rsquo;s well worth it. You can zip and zap through a Tag creation workflow in a fraction of the time it used to take.\n2. The Overview The Overview screen has been slightly revamped, especially if you\u0026rsquo;ve already started working with Workspaces.\n   It\u0026rsquo;s not \u0026ldquo;Container\u0026rdquo; anymore in the navigation bar, it\u0026rsquo;s \u0026ldquo;Workspace\u0026rdquo; now. Makes a lot of sense, since you will always be working in a Workspace.\n You don\u0026rsquo;t add notes to Versions anymore. Instead, you modify the Description of a Workspace.\n The center panel used to hold information about the current version. Now, it tells you what\u0026rsquo;s going on in the current Workspace.\n The panel to the right used to be solely about the Published Version. Now it\u0026rsquo;s split into two, giving you the run-down on the Live Version (i.e. the Published Version) as well as the Latest Container Version. The latter is very important for Workspaces, as the Latest Container Version is what your workspaces will merge to/with. Clicking either half will take you to the respective version page.\n The large center area is reserved for changes in your Workspace when compared to the Latest Container Version. Every change you make in Workspace is a divergence from the Latest Container Version.\n The Activity History used to be for the whole container, but now it\u0026rsquo;s just for the current Workspace. To see activity history for the container, you will need to go through the Versions section of the container.\n The PUBLISH menu is now red when you have pending changes, and next to it is a counter with the number of changes the current Workspace has introduced. If you click the Container ID (GTM-XXXXX), you\u0026rsquo;ll see an overlay with the container snippet and instructions for its installation.\n  Note also the \u0026ldquo;Current Workspace\u0026rdquo; selector in the left-hand navigation. There\u0026rsquo;s more details about this in my Workspaces guide.\n  3. Timestamps! This is minor but still major. You know how irritating it always was to just see relative timestamps instead of proper ones? \u0026ldquo;3 days ago\u0026rdquo; as a Last Modified time isn\u0026rsquo;t that informative, right? Well, we\u0026rsquo;ve been offered an olive branch. By hovering over any relative timestamp, you\u0026rsquo;ll see the actual timestamp in a tooltip.\n  You can argue that it would be better to only have the actual timestamp visible and none of this relative timestamp bullcrap, but this is a step in the right direction, definitely.\n4. Versions There\u0026rsquo;s just one important change to the Versions view itself. What used to be \u0026ldquo;Edit as New Version\u0026rdquo; is now \u0026ldquo;Set as the Latest Version\u0026rdquo;. This is, again, because of Workspaces.\n  When you set a version as the Latest Version, it has implications for all active Workspaces, as they will all need to be updated with the changes in this Latest Version. So don\u0026rsquo;t be cavalier when using this feature!\n  The biggest change to the Version page itself, apart from the new UI, is that there\u0026rsquo;s both \u0026ldquo;Version Changes\u0026rdquo; and \u0026ldquo;Activity History\u0026rdquo;. Version Changes describes the changes in this version compared the previous Latest Container Version. Activity History is a more detailed list of what things were done in the version and, importantly, by whom.\n  5. Tags So, now to the juicy part. As I said in the beginning, the workflow has been streamlined to the maximum. There\u0026rsquo;s lots of little changes here, so I\u0026rsquo;m sure I won\u0026rsquo;t be able to cover them all. These, however, are the ones I\u0026rsquo;ve found most meaningful.\n  Things have certainly changed! On top of the view, the underlined Undefined Tag is what you edit to modify the Tag name. Next to it is the Folder icon, which lets you assign the Tag to a folder.\nThe view is dominated by the two boxes. The first is where you create and configure the Tag itself, and the second is where you attach Triggers and Exceptions to the Tag.\nWhen you click \u0026ldquo;Choose a tag to being setup\u0026hellip;\u0026rdquo;, a new overlay pops out, offering you an impressive list of Tag templates to choose from.\n  After selecting the Tag type, the creation process itself is pretty much the same as it used to be.\n  As for Triggers, once you click the Trigger creation panel, a more complex overlay pops out. I\u0026rsquo;ll go over these steps in the next chapter.\nDo note that you will not be able to add an Exception until you have added at least one Trigger (makes sense).\n  Note that if you open any Tag, Trigger, or Variable for editing, and that asset has already been edited (or newly created) in this Workspace, you will see a new selection in the view, allowing you to Abandon and/or View the changes that have been committed to the asset.\n  I\u0026rsquo;ve covered Abandoning and Viewing changes in more detail in the Workspaces guide.\n  To save an asset, just click the blue SAVE button in the top-right corner of the overlay. Similarly, if you\u0026rsquo;ve opened a previously created asset, you can click the little dot menu next to the SAVE button to duplicate, delete, or view changes to the asset.\n6. Triggers Trigger selection is more robust now. The full table gives you all the information you need at a glance.\n  If you click anywhere on the Trigger row (except the little (I) icon to the right which opens the respective Trigger configuration), it will add the Trigger to the Tag.\nThe magnifying glass icon opens a search field which lets you do a filter search on the Trigger list.\nThe (+) button lets you create a new Trigger. When you click it, the process is very similar to creating a new Tag. You\u0026rsquo;ll see a new overlay with the same types of options you had when creating a new Tag.\n  When you choose the Trigger type, the iconography has been completely revamped.\n  I actually miss the color-coding GTM used to have for Triggers, but the icons are much clearer and easier to interpret.\nConfiguring a Trigger hasn\u0026rsquo;t had any real technical changes, but the user interface has changed for some of them, especially the ones which need a separate enabling condition (e.g. Just Links and Form Submit). Instead of the \u0026ldquo;Enable When\u0026rdquo; and \u0026ldquo;Fire On\u0026rdquo; steps, and actually instead of any steps, you just have a regular, straightforward form:\n  I\u0026rsquo;m not happy that they did away with the step numbers, as they made it easier to reference various parts of the Trigger configuration process. I also still wish they\u0026rsquo;d set the Page URL matches RegEx .* as the default for the \u0026ldquo;Enable When\u0026rdquo; step.\n7. Variables Variables have received a very similar treatment as Triggers and Tags. To start the Variable creation workflow, you can either go via the Variables page of the container (as you used to), or you can just click the little Variable icon wherever you see it.\n  Once you click that icon, you\u0026rsquo;re whisked to the Variable selection screen, which looks a lot like what you got with Triggers.\n  Note that the Built-In Variables are mixed together with the User-Defined Variables. The only way to tell them apart is to look for the (I) icon to the right, which opens the Variable configuration for User-Defined Variables. With Built-In Variables, you can\u0026rsquo;t do that.\nIf you want to add Built-In Variables to the list, you will need to enable them by clicking the little gear icon in the top-right corner. This opens a new overlay, where you can check the Built-In Variables you want included in the container.\n  Now, when you choose to create a new Variable, you get a list of the types you can create, with a new iconography (just as with Triggers).\n  There\u0026rsquo;s nothing new in this list, though I do like the fact that you see a short description after most of the Variable types.\nConfiguring a Variable is pretty much the same as it used to be, so I won\u0026rsquo;t dwell on that here.\nSo you are now able to complete the full workflow from the first time you create a Tag all the way to its Triggers and Variables without having to change your location in the container. Yes, the horizontal overlays might come as a shock to many, and it will take time to get used to the Material Design layout, but my personal opinion is that the changes are very welcome indeed. But that was predictable.\n8. Publish When you click the Publish button, it\u0026rsquo;s again, surprise surprise, delegated to an overlay.\n  The Version Configuration is more prominent than it used to be. Now you are recommended to give a proper name and description to the version. This has, in my mind, always been vital when creating versions in Google Tag Manager. You really want to make the version name as descriptive as possible.\nYou also have the option of publishing only to a specific Environment, as before.\nIn Workspace Changes, you can review the changes that have been done to the current Workspace. By clicking the menu at the end of each row of changes, you can choose to Abandon or View Changes one last time.\nFinally, the Activity History gives you a run-down of who did what in this current Workspace.\nBy clicking the big blue PUBLISH button you will consolidate the changes, create a new version, and make it the live version of the container, just as before.\nIf instead of Publish you chose Create Version, the screen will look almost the same, except you won\u0026rsquo;t have the Environment option, and instead of publishing the version as the Live version, you will only update the Latest Container Version.\n  Summary These were, in my mind, the biggest and most obvious changes to the new User Interface.\nAs I noted a number of times above, I\u0026rsquo;m certain this new UI will come as a shock to many. There\u0026rsquo;s always resilience to change, and even if the old UI was quite clunky, there was something consistent about the way you manoeuvred between different parts of the container.\nBut that\u0026rsquo;s all gone now. Instead, you have horizontal flyouts and overlays that keep in you in one location, allowing you to configure an entire workflow without ever leaving the asset you started from. This, I think, is very powerful and will definitely speed things up once you get the hang of the new UI.\nWorkspaces is very much present in the UI. You will be able to Abandon and View Changes at almost every turn, and the significance of creating a new version has increased. This, again, might lead to confusion in the early days, as the simple act of Publishing a container has implications to all the currently active Workspaces.\nThus, I want to repeat what I said at the end of my Workspaces guide:\nCommunication and good governance will always rule over any feature update.\nYou\u0026rsquo;ll still need a stable and healthy organization if you want to make the most out of Google Tag Manager.\nGood luck!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-workspaces/",
	"title": "Google Tag Manager Workspaces",
	"tags": ["Google Tag Manager", "user interface", "workspaces"],
	"description": "Guide to Google Tag Manager workspaces.",
	"content": " Well, well, well. Welcome to the Enterprise Game, Google Tag Manager! You know, if you took a look at all the feature requests and complaints that pass through the Google+ community or the Product Forums, you\u0026rsquo;d notice that a large portion of them revolve around lack of multi-user and multi-team support in the tool. Well GTM has taken a gigantic leap forward to soothe these concerns, with the release of its latest feature: WORKSPACES.\n  Now, not only did they roll out this new feature, but they completely revamped the Tag, Trigger and Variable creation and management process. This is so overwhelming that I\u0026rsquo;m not even going to complain how much work I have ahead of me, being forced to update all my current and future articles to align with the new interface. Anyway, I didn\u0026rsquo;t want to clog this post up with all the changes, so I wrote a short overview of the UI changes to GTM, where I walk you through some of the most meaningful changes to the user interface.\nGosh, I don\u0026rsquo;t even have a clue what Workspaces will do to my GTM Tools. Probably some sort of cosmic implosion. But it doesn\u0026rsquo;t matter. The new stuff is just so great that I can whine later.\nLet this article serve as an introduction and a guide to how Workspaces function. I\u0026rsquo;m sure there will be many other guides online soon, which is great as always, as I predict this to be a defining moment in Google Tag Manager\u0026rsquo;s release history.\nThere\u0026rsquo;s lots of things here, so let\u0026rsquo;s just jump in.\n1. What are Workspaces? To help wrap your mind around the new feature, think of GTM of the past having just one Workspace. Everybody working in GTM had to work on the same Container Draft, and when a Version was created and/or published, all changes were added to the Version at that moment, regardless of who worked on them or when.\nWith Workspaces, you\u0026rsquo;ll be working with multiple Container Drafts. In essence, when a Workspace is created, a new Container Draft is separated from the latest GTM container version, and this becomes your new Workspace. From that moment on, it will live a separate life as a draft, and you can edit it, Preview it, and Debug it to your heart\u0026rsquo;s content without interference from other Workspaces. There will still remain just one main branch of Versions, so you won\u0026rsquo;t be able to publish your Workspaces into a completely separate branch, only merging them at some distant point in the future (if even then).\nWork can be done in multiple Workspaces at the same time, as only once a Workspace is turned into a Version does it become part of the Google Tag Manager container. It follows that there\u0026rsquo;s no actual versioning of Workspaces themselves.\nWhen another Workspace is turned into a Version, all other Workspaces will get a notification that the Latest Container Version has changed. Any changes implemented in this new Container Version need to be synchronized with all other Workspaces before those can be turned into new Versions. You don\u0026rsquo;t have to do it immediately, but you will see the notification in the Container Overview reminding you that you need to update the current Workspace with changes in the Latest Container Version.\nPerhaps my amazing flow diagram will help you understand this better:\n   Container Version 1 (CV1) has two Workspaces created out of it: WS1 and WS2. Both are being actively worked on.\n WS2 is published, so its contents become the new Container Version 2 (CV2).\n Since WS1 was based on CV1, which is now replaced with CV2, WS1 gets a notification that the Latest Container Version has changed and a sync is required. WS1 is updated, and no conflicts arose. Next, WS1 is published, and it becomes the new Container Version 3 (CV3).\n Since WS2 was based on CV2, which is now replaced with CV3, WS2 gets the notification that it needs to be synced with the Latest Container Version. So WS2 is synced, no conflicts arose, and it\u0026rsquo;s published into the new Container Version 4 (CV4).\n A new Workspace is created (WS3), and since CV4 is the Latest Container Version, the Workspace and CV4 have identical contents. If no new work has been done to WS2 at this point, all three (WS2, WS3 and CV4) would be identical.\n  So it\u0026rsquo;s like an abstraction of a typical branching version control system. There\u0026rsquo;s just one version tree, but you can \u0026ldquo;branch\u0026rdquo; drafts out of it, merging changes in the version tree to these branches, and merging branches into new versions of the version tree.\n2. Managing (creating, saving, and deleting) a Workspace Creating a new Workspace is easy. Go to the Overview section of your Container, and click any one of the three options to \u0026ldquo;Manage Workspaces\u0026rdquo; you see in the image below.\n  Once you click one of those, you should enter the \u0026ldquo;Manage Workspaces\u0026rdquo; screen. To create a new Workspace, click the Plus icon in the top right corner to open the Workspace creation prompt.\n  By the way, notice the text saying 1 workspace left? In the free version of Google Tag Manager, you can have three Workspaces active at the same time. This might sound like a limitation, but it actually steers you into a more conservative approach to tag management. I\u0026rsquo;ll talk more about this in the last chapter of the post.\nOnce you click the plus icon, you can give your new Workspace a name and a description. I\u0026rsquo;m not one of those people who try to stick naming conventions down your throat, so I recommend you come up with a good schema all by yourself (or, preferably, within your team).\nEven though these screenshots don\u0026rsquo;t reflect it, I\u0026rsquo;m actually using the following naming convention:\n024 - AdWords Conversion Tracking - Ahava \u0026amp; Behava\nThe number would be the Version number the Workspace was created from, followed by the feature implemented in the Workspace, followed by the team working on the Workspace. A simple naming schema, with lots of information encoded within.\nIt\u0026rsquo;s a good idea to give a description to the Workspace, such as who\u0026rsquo;s working on it, what the goal is, when the expected publishing time is, etc. Once you\u0026rsquo;re done, just click Save in the top right corner.\n  You should see your fancy new Workspace in the list, and the Workspace you just created automatically becomes the draft that you\u0026rsquo;re currently editing.\nJust remember - the new Workspace is created off the Latest GTM Container Version, not the Workspace draft you had active when you created the new Workspace, nor the Published version (if different from the Latest Version)!\nNow, there\u0026rsquo;s no way to actually, explicitly save a Workspace. Since it\u0026rsquo;s a Container Draft, any Tags, Triggers, and Variables you save automatically become part of the draft. There are new, awesome ways to view and abandon any changes you\u0026rsquo;ve made in the current draft, and we\u0026rsquo;ll get to them shortly.\nTo delete a Workspace, you\u0026rsquo;ll need to open the Manage Workspaces overlay, and click the small info button next to the Workspace you want to delete.\n  In the view that appears, you can change the Workspace configuration (name, description), view its changes, and you can click the little menu in the top right corner to Delete the Workspace.\n  3. Switching between Workspaces, and Workspaces in Overview To switch between Workspaces is easy. In the left navigation is a new menu for Workspaces. Whenever you click that, an overlay flies out, which lets you switch between Workspaces simply by clicking the Workspace name in the list that appears.\n  The new menu item in the navigation serves a two-fold purpose: First, it lets you know which Workspace you\u0026rsquo;re currently working on. Second, it lets you quickly open the Workspace management overlay, where you can jump between Workspaces really smoothly.\nNow, head on over to Overview, and lets take a look at what\u0026rsquo;s changed.\n  There are some vital changes to the Overview dashboard, so let\u0026rsquo;s see what we find.\n The Description field is now the Description you entered when creating the Workspace.\n The whole central panel is reserved for Workspace-related information. The menu in the top-right corner of the box lets you either Update the Workspace or Manage Workspaces. The changes in this Workspace (compared to the Latest Container Version) are listed at the bottom.\n If there\u0026rsquo;s a newer Container Version than the one that the Workspace was created from, you\u0026rsquo;ll see an alert here AND at the bottom of the screen, reminding you to update the Workspace.\n Right next to the PUBLISH menu is another reminder of how many changes there are in the current Workspace when compared to the Latest Container Version.\n The orange Conflict bar can pop up after you\u0026rsquo;ve updated your Workspace to merge the changes in the Latest Container Version. If, in the current workspace, you\u0026rsquo;ve made modifications to any of the Tags, Trigger, or Variables that were included in the update, you will need to resolve the conflicts either in favor of the Latest Container Version or your current Workspace.\n A more detailed list of the changes in the current Workspace is here. By opening the menu aligned with each change, you can view what changes were made to each asset, and you can abandon the changes with the click of a button.\n  The usefulness of the Overview screen just multiplied by a zillion. I never used it before, now I find myself returning to it all the time.\n4. Viewing changes OK, get ready for pretty much the sweetest addition to the new user interface. In any of the places you can view changes to the Workspace, find the item you want to analyze and click open the menu next to the item. There are two options: Abandon Changes, which reverts any changes you made to that item back to their original settings (i.e. the values in the Latest Container Version), or View Changes, which lets you analyze all the changes you\u0026rsquo;ve made, and individually choose whether to keep or to abandon them!. Since the latter is more interesting, click \u0026ldquo;View Changes\u0026rdquo;.\n  What you see next can be pretty intimidating. Remember that \u0026ldquo;View Changes\u0026rdquo; is a completely optional operation. You don\u0026rsquo;t have to view any changes, nor do you have to accept any changes at any point when working with a Workspace. Indeed, once you\u0026rsquo;re happy with what you\u0026rsquo;ve done with the Workspace, you can just Create a new Version or Publish the Workspace without ever double-guessing your changes.\nBut if you DO want to check what you\u0026rsquo;ve (or someone else has) done, the overlay that opens is the perfect place to do so. Let\u0026rsquo;s first take a closer look at what we have here.\n  Here are the elements of this overlay:\n On the left is the column which represents the item in the Latest Container Version. On the right is the column which represents the modified version in the current Workspace. This is, essentially, a diff of the two versions.\n Up in the right you can see how many changes are yet to be resolved, and a disabled APPLY button, which you can click after you\u0026rsquo;ve resolved all the changes. Basically, any changes that you resolve in favor of the Workspace will remain as changes whenever you open this screen again, and any changes you resolve in favor of the Latest Container Version will be removed from the draft in your Workspace.\n In Red are items you\u0026rsquo;ve REMOVED from the Latest Container Version. By clicking the arrow, you have two options: keep the change you\u0026rsquo;ve made to the Workspace (the IGNORE icon), or copy the original value from the Latest Container Version back to your Workspace (the COPY icon).\n In green are NEW ADDITIONS to the current Workspace, which are absent from the Latest Container Version. You can click the arrow again to either abandon or keep the change.\n In blue are actual MODIFICATIONS to existing properties. In this example, the value for a Custom Dimension has changed. You can use the arrow icon again to validate your change.\n  Anyway, don\u0026rsquo;t be too confused with the View Changes screen. Remember, you don\u0026rsquo;t have to accept or abandon any changes if you don\u0026rsquo;t want to. You can simply use this screen to check what changes have been made, and then close the overlay without applying or changing anything.\nIt\u0026rsquo;s simply an incredibly convenient way of verifying what changes have been made to the container. I love it!\n5. Viewing changes item-by-item Another way to observe changes in items is to open an asset itself (Tag, Variable or Trigger). If any changes have been made in this Workspace, or if it\u0026rsquo;s a newly created item, the UI will inform you of this, and you have the option of Abandoning the Changes, or Viewing the Changes (for modified assets only).\n  See all that other cool stuff in the new UI? Read on!\n6. Creating a Version or publishing a Workspace I want to remind you again: Workspaces are just Container Drafts. Just as before, a Container Draft becomes a Container Version in any of two ways: you either choose \u0026ldquo;Create Version\u0026rdquo; from a relevant menu (most common is the red menu in the top right corner of the container), or you choose \u0026ldquo;Publish\u0026rdquo;, which first creates the version and then publishes it as the new, live container.\n  When you click the Publish (or Create Version) button, there\u0026rsquo;s a new overlay:\n  This is very convenient, as you have the options to:\n Set Version Name - very useful for making sense of the Versions view\n Set Description - same comment as above\n Choose Environment to Publish to\n Last chance to View / Abandon Workspace changes\n View the Activity History for the current Workspace\n  Note that if there are changes you need to sync from the Latest Container Version, you\u0026rsquo;ll see this warning in the Publish / Create Version overlay:\n  When you Create a Version or Publish the Workspace, it\u0026rsquo;s exactly as it was before Workspaces. The current draft becomes the Latest Container Version, and it\u0026rsquo;s now visible to all users in the Versions screen.\n  In this list, the Version name will match what you set when publishing the Workspace. You can, of course, rename it from the Actions menu as before. A feature update I\u0026rsquo;d like to see it the original Workspace name as a column of its own, so that I could make better sense of the publishing workflow (in the screenshot, the Version names are the respective Workspace names for clarity).\nRemember that when you create a new version from the Workspace, it automatically becomes the Latest Container Version, which means two things:\n Any new Workspaces will be automatically created from this Latest Version\n All other, existing Workspaces will need to sync the changes you made to the Latest Version, before they can create a version out of their Workspace\n  So even though Workspaces give you plenty of wiggle-room in terms of organization and management, it doesn\u0026rsquo;t and shouldn\u0026rsquo;t eliminate the need to periodically discuss your version plans, and it definitely doesn\u0026rsquo;t remove the need for proper governance. So make sure everybody knows when new versions are created, so that they aren\u0026rsquo;t blind-sided by a version update!\n7. Syncing a Workspace with an updated Latest Container Version Let\u0026rsquo;s say you\u0026rsquo;ve decided to start your work for the day, and you fire up GTM. In the Overview screen, you see an alert that an update is required!\n  There\u0026rsquo;s also the bar at the bottom of the page prompting you to update the Workspace, too.\nWhen you select to Update the Workspace (i.e. sync the changes with the Latest Container Version), a new overlay appears:\n  Here you\u0026rsquo;ll see which Versions need to be synced to the Workspace. So there might be multiple versions listed here, if there has been more than one update to the Latest Container Version since you\u0026rsquo;ve created the Workspace.\nRemember that updating the Workspace isn\u0026rsquo;t necessary right away. You can keep on working on your changes, only merging the changes from the Latest Container Version once you\u0026rsquo;re ready to create a version out of your Workspace. Nevertheless, it\u0026rsquo;s a good idea to do periodic merges, since the further away you diverge from the Latest Container Version, the more conflicts will arise once you do decide to go ahead with the merge.\nAnyway, when you select to Update the Workspace due to changes in the Latest Container Version, your Workspace files will be updated to reflect the modifications to the Latest Container Version. In other words, the very foundations of what you\u0026rsquo;ve been working on might have changed. It\u0026rsquo;s a good idea to closely research the Latest Version in the Versions view, so that you\u0026rsquo;ll know if any of the assets you have dependencies with have been changed.\n8. Resolving Conflicts in Workspaces Let\u0026rsquo;s say you did all the steps in the previous chapter, and happily clicked UPDATE to sync your Workspace with the Latest Container Version.\nBut something\u0026rsquo;s wrong, and a big, ominous, orange bar pops up in the screen, telling you that there was a conflict!\nA Conflict arises when a Tag, Trigger, or Variable was changed in the Latest Container Version, and you have also modified that same item in your current Workspace. For you to be able to synchronize your Workspace with the Latest Container Version, you will need to resolve each conflict either in favor of the Latest Container Version or your Workspace. You can see which items are in conflict by looking at the list of Workspace changes in the Overview screen. This is, again, a typical way to deal with branches in version control.\n  By clicking the RESOLVE button in the orange bar, you\u0026rsquo;re taken to the conflict resolution screen. So let\u0026rsquo;s take a closer look at that:\n  Conflict resolution is very similar to the View Changes interface I introduced earlier. Basically, each change is color-coded:\n Blue for items you\u0026rsquo;ve modified in your Workspace\n Green for items that you\u0026rsquo;ve added to the Workspace\n Red for items that you\u0026rsquo;ve removed from your Workspace\n  You can click the arrow by each conflict to choose whether to IGNORE the conflict (resolve in favor of your Workspace) or to COPY the change (resolve in favor of the Latest Container Version). In other words, if you click the COPY icon, the state of the field in the Latest Container Version will overwrite anything you had modified in your Workspace.\n  You can change from item to item in the top left of the screen, where you can see something like \u0026lt; 1 / 4 \u0026gt;, which would signify that there are altogether four assets (Tag, Trigger or Variable) with conflicts, and you\u0026rsquo;re resolving the first one.\nWhen you click SAVE, any conflict resolutions you have made will be saved, and they will no longer appear as conflicts. So make sure you have it right before clicking the button! It\u0026rsquo;s always nasty if your hard work is overwritten due to misunderstanding what change is being overwritten.\nIn the top right corner, the number of Decisions marks the number of conflicts you still need to resolve in the currently open asset. The number goes down as your resolve the conflicts.\nBy clicking Resolve All, you resolve all remaining conflicts in the current asset in favor of your Workspace. You can always click the toggle again to reset your decisions, and you can click each individual conflict to roll back the clock, too. Just remember that clicking SAVE really saves your decisions.\nYes, the interface can be quite intimidating, and conflict resolution can be quite a chore, especially if there are many items. However, this is a vast improvement to the complete blind-groping we used to have with Google Tag Manager. Finally there\u0026rsquo;s transparency to the changes made in a container.\nAgain, remember that you don\u0026rsquo;t have to resolve conflicts or even update your Workspace the minute you see the alert. You can keep on making your changes as you wish. You\u0026rsquo;ll only need to resolve the conflicts before you want to Create a Version or Publish your Workspace. Nevertheless, it\u0026rsquo;s a good idea to get it out of the way as soon as possible, so that the changes don\u0026rsquo;t pile up.\n9. New Workspace-related user permissions If you browse over to Admin / Container / User Management or Admin / Account / User Management, you can see some changes to the Container user permission levels. The new levels are:\n View - Read-only access to the container\n Edit - Can create and edit Workspaces, but can\u0026rsquo;t Create Versions or Publish them\n Approve - Can Create Versions of Workspaces\n Publish - Can Publish Workspaces\n  Basically, the Approve level is what Edit used to be, and the Edit level is completely new, allowing the user only to edit items in the Workspace, but nothing else.\n  The reason for this extra level of user access is simple: Creating a Version has new significance in Workspaces. It updates the main \u0026ldquo;branch\u0026rdquo; of the Container, prompting all active Workspaces to update with the changes. In other words, Creating a Version from a Workspace with sloppy code, or without being aware of the requirements of other Workspaces, can, at worst, result in major conflicts once the other Workspaces are updated.\n10. Summary I really, really love the feature (big surprise). Especially being able to view changes you\u0026rsquo;ve made on a granular level, and being able to compare between the Latest Container Version and your current Workspace is huge in allowing multiple users and teams to interact in the same Container.\nIndeed, what Workspaces bring to the table will certainly alleviate friction in any organization using GTM. Just remember that you don\u0026rsquo;t have to use Workspaces. In fact, it might be best to restrict them to small, incremental changes only. The reason for this is that they still rely on the Latest Container Version, and the longer you work on a Workspace, the further it can deviate from the main version. Having to periodically sync the Workspace isn\u0026rsquo;t fun, either.\nA good idea would be to work on features small enough that you can Create a Version from the Workspace without having to worry about it creating havoc in other Workspaces. And this is where the restriction of \u0026ldquo;just\u0026rdquo; three Workspaces in free GTM comes into play. Having so few Workspaces available forces you to be extra efficient when modifying the container. I was never a fan of implementations, where you create a zillion new things, and only then Create a Version or Publish the Container. It always resulted in a difficult traceback, if there were issues with the implementation. With only a handful of Workspaces available, and with the conflict resolution step initiated by a Latest Container Version update, you will have to be efficient and aware of what\u0026rsquo;s going on in the whole Container, and not just your own little corner of it.\nA natural extension of this would be user-specific access to Workspaces themselves, but whether this is something that\u0026rsquo;s coming or not is known only by the GTM developer team.\nAnyway, I don\u0026rsquo;t want to dole out any best practices (not my thing), but my suggestion is to be careful with Workspaces, even if they do bring a lot of great stuff to the table. They still won\u0026rsquo;t patch up a sick organization, nor will they miraculously improve your work in large projects with multiple stakeholders all wanting a piece of Google Tag Manager.\nCommunication and good governance will always rule over any feature update. If anything, Workspaces just makes this ever so much more important.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/troubleshooting-cross-domain-tracking-in-google-analytics/",
	"title": "Troubleshooting Cross-Domain Tracking In Google Analytics",
	"tags": ["cross-domain tracking", "google analytics", "Google Tag Manager"],
	"description": "A troubleshooting checklist for Google Analytics cross-domain problems.",
	"content": " Cross-domain tracking, in Google Analytics, is the process of passing information stored in browser cookies from one domain to another. Due to web browsers\u0026rsquo; same-origin policy, a browser cookie is only available to the domain it is written on and all its subdomains (by default). Since Google Analytics uses cookies to persist the Client ID, once the user moves from domain to domain it\u0026rsquo;s important to somehow pass this Client ID, too.\nCross-domain tracking isn\u0026rsquo;t the easiest thing to implement, though. At its easiest, especially if you use Google Tag Manager, it\u0026rsquo;s a question of configuring a couple of fields in your Google Analytics trackers and snippets. However, issues typically arise when your website uses unconventional link redirects, or when you want to persist the Client ID in an iframe loaded from another domain.\n  In this article, I thought I\u0026rsquo;d provide a short checklist to go through when issues with cross-domain tracking arise.\nHow to test if cross-domain tracking is working If cross-domain tracking is working, all traffic from one domain to another should be part of the same session, and thus attributed to the same Source / Medium dimensions.\nYou should not use Google Analytics\u0026rsquo; Real Time Reports to analyze the cross-domain pattern! Real Time Reports show each hit only with the dimensions and parameters carried by the hit itself. This means that you won\u0026rsquo;t be able to debug session-scoped stuff like Source and Medium using only what you see in the Real Time Reports.\nIn other words, you\u0026rsquo;ll need to wait for the hits to populate in the standard reports.\nThe easiest way to verify if cross-domain tracking is working in Google Analytics, is to browse to the first domain using custom UTM parameters, for example:\nwww.domainA.com/?utm_source=xdom_test\u0026amp;utm_medium=xdom_test\u0026amp;utm_campaign=xdom_test\nThen, while still browsing the first domain, click a link or open a page with the iframe to the second domain.\nAfter this is done, in the Google Analytics View which shows data from both domains, you can apply a segment to only include your custom campaign traffic:\n  Once the data hits the Google Analytics reports, you should find your single session when applying the segment. After that, go to the Behavior \u0026gt; Site Content \u0026gt; All Pages report. If cross-domain tracking is working properly, you should see both the pageview(s) from the source domain and the pageview(s) from the target domain in the report.\nIf cross-domain tracking isn\u0026rsquo;t working, you\u0026rsquo;ll only see the pageview(s) from the source domain. The following checklist should help in this case.\nThe Checklist For cross-domain tracking to work on your website and Google Analytics Property, the following things need to all be in place.\n All domains included in cross-domain tracking must collect data to the same Google Analytics Property - Jump to details\n All domains that are the source of cross-domain traffic, i.e. the traffic departs from these domains, need to be in the Referral Exclusion List of the Google Analytics Property settings - Jump to details\n When entering the target domain via a link in the source domain or an iframe, the URL of the page loaded in the web browser must have the _ga=1.234567.234567.234567 URL query parameter in place - Jump to details\n Any Google Analytics trackers or tags firing on the target domain need to have the allowLinker field set to true - Jump to details\n  These are the four basic steps you need to make cross-domain tracking work on your site. Note that steps (3) and (4) have complicated workarounds for when query parameters or the linker plugin won\u0026rsquo;t work, but in the majority of cases these four steps are enough.\nIn the following chapters, I\u0026rsquo;ll examine each step in more detail.\n1. Collect all data to the same Google Analytics Property A Property in Google Analytics is a tracking configuration that collects data from your digital applications such as your website. Each Property in Google Analytics has a unique identifier, known as the Tracking ID:\n  Every Property has its own table of data, which comprises all the hits that are sent to that particular Property. Thus, each Property has its own users, sessions, and aggregation buckets, and these data sets are unique to each Property.\nBecause of this, it\u0026rsquo;s important that when you collect cross-domain traffic across two separate domains, both domains will need to collect data to the same Google Analytics Property. There is no such thing as cross-domain traffic across Google Analytics properties, and the only way to even approach something like that would be to utilize the Roll-up Reporting feature of Google Analytics Premium.\n2. Domains in the Referral Exclusion List Universal Analytics starts a new session whenever a new referral is detected as a traffic source. Thus, if you first enter a site via Google\u0026rsquo;s organic search (google / organic), and then follow a cross-domain link from the source domain to the target domain, the target domain hit would be recorded as having originated from sourceDomain.com / referral, marking the start of a new session. And this is even if you have cross-domain tracking otherwise in place!\nBy utilizing the Referral Exclusion List, you\u0026rsquo;re telling Google Analytics to disregard referral traffic from the source domain, and to treat it as Direct traffic instead. Universal Analytics relies on Direct traffic for campaign attribution as well as session stitching. Each hit in the session, after the initial acquisition, is actually a \u0026ldquo;Direct\u0026rdquo; hit, and this is how Google Analytics knows that the session should still be kept alive.\n  So, Referral Exclusion List keeps the traffic from the source domain to the target domain part of the same session, which is crucial for you to make sense of cross-domain traffic. Thus make sure that you have all the possible source domains, i.e. domains that send traffic to other domains, in the Referral Exclusion List of your Google Analytics property settings.\n3. Linker parameter in the URL As I said in the very beginning of this article, Google Analytics relies on the Client ID to assign hits to specific sessions and users. The Client ID is stored in a browser cookie named _ga, which is, by default, written on the highest possible domain name the website has access to. On my website, for example, the _ga cookie would be written on simoahava.com, and thus it is available to simoahava.com and all its possible subdomains.\nWhen you move from domain to domain, this Client ID needs to somehow travel with the user, but due to the restrictions of the web browsers\u0026rsquo; same-origin policy, the target domain cannot simply fetch the cookie written on the source domain.\nFor this reason, Google Analytics has introduced the linker plugin. When you invoke the plugin, it returns a URL query parameter which includes the Client ID as well as a signature which is valid for 2 minutes. So, if you visit a different domain URL with the query parameter within the two minute window, cross-domain traffic could be setup between the two domains.\nThe two minute window exists to prevent linker parameters from persisting in shared links and browser history entries. Otherwise every time someone would follow a link with the linker parameter in place, they would be considered the original user who created the link. This would lead into a horrible mess, as it would be almost impossible to distinguish users from each other.\nA typical way of loading the linker plugin is by using the autoLink feature of the plugin. When you use autoLink, you provide it with domain names that you want to automatically decorate with the linker parameters. Then when the user clicks a link or invokes a form redirection that has the given domain name as its target, autoLink automatically decorates the URL with the linker parameters.\nIn Google Tag Manager, you\u0026rsquo;d edit the Auto Link Domains field:\n  You\u0026rsquo;ll know its working when you see the _ga=1.234567.234567.234567 query parameter in the URL.\n  If you don\u0026rsquo;t see the parameter in the URL, it means that for some reason the autoLink plugin failed. Instead, you\u0026rsquo;ll need to manually decorate the URLs. This is particularly the case when working with iframes, as the iframe must be loaded with the linker parameters in its src attribute, if you want cross-domain traffic to work between the parent page and the framed document.\nTo manually decorate the URLs, you or your web developer needs to write a piece of code which takes the linker parameter and appends it to the URL of the link or the iframe just before the document is loaded.\nSo, remember that for a basic cross-domain setup to work, the URL of the target page, whether opened by a link, redirected by a form, or loaded in an iframe, needs to have the linker parameter _ga=1.234567.234567.234567 in the URL.\n4. allowLinker in the target domain Now you\u0026rsquo;ve got the URL query parameters in place, the Referral Exclusion List has all the necessary source domains, and you\u0026rsquo;re collecting data from both the source and target domain to the same Google Analytics Property.\nJust one thing missing.\nFor the trackers in the target domain to respect the _ga=1.234567.234567.234567 linker parameter in the URL, you need to tell the trackers to allow the linker parameter to reset the Client ID on the target domain.\nYou do this by configuring the allowLinker field in the tracker object. In GTM, you\u0026rsquo;d simply add a new field:\n  This setting tells the tracker to use the Client ID embedded in the linker parameter rather than the one created by the tracker on the target domain.\nYou can verify that it\u0026rsquo;s working by opening the Network Tab in your web browser\u0026rsquo;s developer tools, and loading a page both on the source domain as well as on the target domain after following a cross-domain link, for example. All requests to /collect should have the parameter \u0026cid; use the same value. This tells you that the Client ID is the same across the domains.\n  Summary There are many ways in which cross-domain tracking can malfunction, but there are actually only four moving parts to it:\n All domains need to collect data to the same Google Analytics Property\n All source domains need to be listed in the Referral Exclusion List of the Google Analytics Property\n The target domain URLs opened via the source domain need to be decorated with linker parameters\n The target domain Google Analytics trackers need to have the allowLinker field configured\n  Once all four of these pass inspection, cross-domain tracking should work without a hitch.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/run-google-tag-manager-google-analytics-local-files/",
	"title": "Run Google Tag Manager And Google Analytics In Local Files",
	"tags": ["google analytics", "Google Tag Manager", "local", "localstorage"],
	"description": "Use this guide to configure Google Analytics and Google Tag Manager to run on your local files, i.e. files that have not been published to the world wide web.",
	"content": " Last updated 2 March 2018.\nEvery now and then you might be urged to run Google Tag Manager and/or Google Analytics locally, meaning without the benefit of a web server serving your files. In other words, you\u0026rsquo;re loading an HTML file from your computer in the web browser. You can identify a locally run file by the file:/// protocol in the address bar.\n  Now, deploying Google Tag Manager onto that file with the hopes of running Google Analytics requests locally isn\u0026rsquo;t quite simple. Well, actually, the deployment is fairly simple, but customizing it so that it actually sends useful hits requires some tweaking.\n Note! You will not be able to run Preview mode with local files. GTM automatically uses relative protocol when downloading the preview library, and relative protocol on local files falls back to file:/// for the HTTP requests. If someone comes up with an elegant workaround, please let me know in the comments!\n 1. Modify the GTM Container Snippet First of all, you need to modify the Google Tag Manager container snippet itself. It uses relative protocol in the script loader URLs, and since local files use the file URI scheme, you need to explicitly tell Google Tag Manager from where to fetch the library.\nSo, if this is the container snippet:\n\u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;noscript\u0026gt;\u0026lt;iframe src=\u0026#34;//www.googletagmanager.com/ns.html?id=GTM-XXXXX\u0026#34; height=\u0026#34;0\u0026#34; width=\u0026#34;0\u0026#34; style=\u0026#34;display:none;visibility:hidden\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/noscript\u0026gt; \u0026lt;script\u0026gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-XXXXX\u0026#39;);\u0026lt;/script\u0026gt; \u0026lt;!-- End Google Tag Manager --\u0026gt; You can see how the two URLs embedded within (//www.googletagmanager.com/ns.html... in the iframe and //www.googletagmanager.com/gtm.js... in the script loader itself) do not have an explicit protocol set. So, you need to change these two strings to become **https://**www.googletagmanager.com/ns.html... and **https://**www.googletagmanager.com/gtm.js..., respectively. That is the only change you need to make to load Google Tag Manager.\nSo, well done!\n2. Configure the Google Analytics Tag(s) The next step is to configure the Google Analytics Tags. GA places some restrictions on the web browser if loaded with its default settings:\n The host making the requests to GA needs to have either http or https as the protocol.\n The host must support storing the Client ID in browser cookies.\n The host must be able to pass a proper Document Location value (the URL) to Google Analytics.\n  Each one of these three is violated by local files. First, local files use the file:/// protocol, as stated earlier. Second, web browsers disable cookies when browsing local files. Third, the URL sent by the client to Google Analytics in the Document Location field is the one with the file URI scheme, again, meaning it\u0026rsquo;s not parsed correctly by GA into a proper page path.\nLuckily, Google Analytics has fields that you can set to make it pass all these three checks.\nFirst, you\u0026rsquo;ll need to create a helper Variable. It\u0026rsquo;s a Custom JavaScript Variable with the name Empty function and the following code within:\nfunction() { return function() {} }  Next, in your Google Analytics Tags, browse down to Fields to Set, and add the following fields and values:\nField name: checkProtocolTask\nField value: {{Empty function}}\nField name: storage\nField value: none\nField name: page\nField value: {{Page Path}}\nThe first field tells GA not to check for valid protocol (http or https) when making the request to /collect.\nThe second field tells GA not to use browser cookies for persisting the Client ID.\nThe third field tells GA to override the faulty Document Location with the page\u0026rsquo;s pathname.\n  And that\u0026rsquo;s it! With these steps, you can track your Pageviews and Events in your local files, if you are so inclined.\n3. Persist Client ID However, the downside of setting storage : none is that you won\u0026rsquo;t have a persistent Client ID anymore. Thus, every single page load will reset the Client ID, resulting in a new User and new Session with every single page.\nWe don\u0026rsquo;t want that.\nInstead, we can hack around that using the browser\u0026rsquo;s localStorage API to store the Client ID and fetch it with each request.\nYou\u0026rsquo;ll need two new Variables.\nThe first one is a Custom JavaScript Variable with the name JS - Set _clientId, and the following code within:\nfunction() { return function() { if (window.Storage) { window.localStorage.setItem(\u0026#39;_clientId\u0026#39;, ga.getAll()[0].get(\u0026#39;clientId\u0026#39;)); } } }  The second is a Custom JavaScript Variable with the name JS - Get _clientId, and the following code within:\nfunction() { if (window.Storage) { return window.localStorage.getItem(\u0026#39;_clientId\u0026#39;) || undefined; } return; }  The first Variable stores the Client ID in the browser\u0026rsquo;s localStorage, and the second Variable fetches it from the same place (or returns undefined if Client ID isn\u0026rsquo;t stored).\nFinally, in your Google Analytics Tags, go to Fields to Set again, and set the following two fields:\nField name: hitCallback\nField value: {{JS - Set _clientId}}\nField name: clientId\nField value: {{JS - Get _clientId}}\nAnd there you go! Now, the first time a Google Analytics Tag fires, it stores the Client ID created in the process into the browser\u0026rsquo;s localStorage. For each subsequent Tag, until localStorage is manually purged, the Tags fetch the stored Client ID from localStorage and send it with the requests. This way sessions and users stay intact, and you\u0026rsquo;ll be able to derive proper insights from the data.\nSummary This hack probably has only marginal use, but it\u0026rsquo;s still a valid way of tracking Google Analytics in local files. You don\u0026rsquo;t always have the benefit of (or the skills to deploy) a web server, so running files locally is, if nothing else, a hat tip to the Notepad + FTP content management systems from the 1990s.\nAlso, you can use the Client ID hack in your regular trackers, too, if you have some reason to avoid browser cookies for persisting data.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/use-eventtimeout-eventcallback/",
	"title": "#GTMTips: Use eventTimeout With eventCallback",
	"tags": ["datalayer", "eventcallback", "google analytics", "Google Tag Manager", "gtmtips"],
	"description": "Introducing the eventCallback and eventTimeout keys in dataLayer when using Google Tag Manager.",
	"content": " There are times when I\u0026rsquo;m disappointed with Google\u0026rsquo;s developer documentation, especially for Google Tag Manager. Most of the time they get it right, and I\u0026rsquo;d say around 80% of questions being thrown around the forums can be answered just by reading through the documentation. But there are some cases where the documentation is misleading or even downright dangerous. One of these cases is Enhanced Ecommerce.\nThis isn\u0026rsquo;t going to be a thorough critique of said documentation, but the tip in this post has to do with one of the examples that the documentation gives for measuring Product Clicks. In the comment it says:\n...This function uses the eventCallback dataLayer variable to handle navigation after the ecommerce data has been sent to Google Analytics... Well, that\u0026rsquo;s an excellent use case for eventCallback. After all, it\u0026rsquo;s sole purpose is to execute code after all Tags have completed for the given event in the dataLayer.push payload.\nHowever, the pain point here is that you\u0026rsquo;re using Google Tag Manager to defer a crucial, potentially UX- and business-hurting action: the link redirect. The point of the example is that the link redirect is cancelled, and only once the eventCallback is invoked will the redirect continue.\nThat, my friends, is not a good pattern.\nIf any of the Tags that fire on this payload fail, timeout, or in some other way fail to inform GTM that they have completed, the redirect will never happen, and the user is left confused since the link they\u0026rsquo;re trying to click doesn\u0026rsquo;t work.\nIMPORTANT UPDATE, 5 Jan 2018: Firefox\u0026rsquo;s latest update to its Tracking Protection in Private Browsing now blocks Google Tag Manager, too. So even setting eventTimeout won\u0026rsquo;t help. My suggestion is to not cancel clicks outside Google Tag Manager with the intention of doing the redirect via some Google Tag Manager -related method, such as eventCallback. (Update over).\nThis is especially important in the recent versions of the Firefox web browser! Firefox introduced something called Tracking Protection in Private Browsing a while ago, and one of its features is that it blocks Google Analytics from loading on the page. However, it does not block Google Tag Manager. In other words, Google Tag Manager loads, the dataLayer.push() is processed and everything, but if there\u0026rsquo;s even a single Google Analytics Tag with a dependency on the push, the eventCallback function is never called.\nTo fix this, here\u0026rsquo;s a tip:\nTip 48: Always add eventTimeout when you use eventCallback   Always add the eventTimeout when using eventCallback. The former takes a numerical value as its parameter, representing the number of milliseconds to wait before calling eventCallback anyway. In other words, even if your Tags stall and never signal completion, after two seconds eventCallback is invoked.\nSo, let\u0026rsquo;s imagine you have this, problematic code:\nvar processLinkClick = function(e) { e.preventDefault(); var targetUrl = e.target.href; window.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;processLink\u0026#39;, \u0026#39;eventCallback\u0026#39; : function() { window.location = targetUrl } }); };  It\u0026rsquo;s a function which grabs the event object, prevents its default action (redirect), does the dataLayer.push(), and finally in the eventCallback finalizes the redirect. But there\u0026rsquo;s no safeguard a) for when Google Tag Manager isn\u0026rsquo;t loaded, and b) if the Tags stall.\nSo here\u0026rsquo;s the fixed code:\nvar processLinkClick = function(e) { var targetUrl; if (window[\u0026#39;google_tag_manager\u0026#39;]) { e.preventDefault(); targetUrl = e.target.href; window.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;processLink\u0026#39;, \u0026#39;eventCallback\u0026#39; : function() { window.location = targetUrl }, \u0026#39;eventTimeout\u0026#39; : 2000 }); } };  As you can see, we\u0026rsquo;re now also checking for the existence of google_tag_manager, which is the interface created by the gtm.js library when it is executed. So if the Google Tag Manager library isn\u0026rsquo;t loaded, the dataLayer.push() is never executed. Sure, there might be a race condition where the library is still in the process of being loaded, but there are ways to mitigate this, too.\nFinally, the eventTimeout introduces a timeout of two seconds, after which the redirect is done. Thus even if any Tags that fire on the \u0026ldquo;processLink\u0026rdquo; event stall, the redirect is not blocked.\nI hope this tip was useful to you! There are many instances where you really need to be careful that you Google Tag Manager setup isn\u0026rsquo;t killing the usability of your website. This is one of them.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/attribution-enhanced-ecommerce-reports/",
	"title": "Attribution In Enhanced Ecommerce Reports",
	"tags": ["attribution", "enhanced ecommerce", "google analytics", "Google Tag Manager"],
	"description": "Guide to how attribution works in Google Analytics&#39; Enhanced Ecommerce data model.",
	"content": " Enhanced Ecommerce is a very useful set of reports in Google Analytics. They extend the standard Ecommerce funnel, which measures only purchases, and allow you to observe products from the very first impression, through various interactions, all the way to the purchase and even beyond, if the user wanted a refund. Google has some solid documentation on how to implement and interpret Enhanced Ecommerce, but if there\u0026rsquo;s one area that would deserve more illumination, it\u0026rsquo;s attribution.\n  In this case, I\u0026rsquo;m not talking about attribution in its profit-steering sense. Instead, I\u0026rsquo;m talking about how Enhanced Ecommerce treats the product in its nexus, and what parts of the Enhanced Ecommerce funnel persist and/or retroactively apply to all the other parts. This might sound cryptic, but I\u0026rsquo;ll try to make it clear in the subsequent chapters.\nUPDATE 25 July 2016: I originally completely overlooked the attribution associated with Internal Promotions. I updated this post to reflect this method of attribution, too. Thanks to Iain Duncumb for pointing this out in the comments!\n1. There is minimal attribution Wait, did I just spoil the entire article? No, I just wanted to catch your attention. Indeed, there is almost no attribution in the Enhanced Ecommerce funnel. If you send product details in, say, the Product Detail View step, you will need to send all the same details in the Add To Cart step, if you want to query any part of the payload across the two steps.\nAllow me to illustrate this. Let\u0026rsquo;s say the visitor views a pair of shoes in your online store. Upon loading the page, you send the following Product Detail View:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;ecommerce\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;s12345\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;Ahava Shoes\u0026#39;, \u0026#39;variant\u0026#39; : \u0026#39;Black\u0026#39; }] } } });  The user loves the shoes, so they add them to the cart. However, because you believe in attribution (why shouldn\u0026rsquo;t you?), you decide to cut some corners and only push the following Add To Cart action:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;ecommerce\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;s12345\u0026#39; }] } } });  Now, when querying this in the Google Analytics reports, you might expect to see an Add To Cart count for the product name \u0026ldquo;Ahava Shoes\u0026rdquo;, too, but sadly:\n  Because the primary dimension is Product (corresponds to name in the \u0026lsquo;products\u0026rsquo; object), you see only a Product Detail View for \u0026ldquo;Ahava Shoes\u0026rdquo;, because the \u0026ldquo;Ahava Shoes\u0026rdquo; product name was not included in the Add To Cart action!\nThis is crucial. If you want to query any product or any step of the funnel, you will need to add all the dimensions you want to query against in all the steps of the funnel.\nIn other words, there is no attribution in the Enhanced Ecommerce \u0026ldquo;Shopping Behavior\u0026rdquo; funnel. Sadly, that comprises most of the useful parts of Enhanced Ecommerce. However, I understand the design choice, since the data in Google Analytics is essentially one big table, where each row (i.e. hit) is self-contained. Adding attribution similar to how e.g. Session-Scoped Custom Dimensions work might be hazardous.\nAt the same time, this could be solved by adding more toggles to Enhanced Ecommerce options. Perhaps there could be a switch that would let you \u0026ldquo;freeze\u0026rdquo; payload attributes after sending them in a Product Detail View. So if you send a full payload of keys and values in the Product Detail View, it would be enough to just send the SKU in all the subsequent steps. But I\u0026rsquo;m still not sure how it would work.\n2. Product List and Internal Promotion Attribution However, there is attribution in Enhanced Ecommerce. Two kinds of it, in fact. The first one is Product List Attribution, and Google has recognized it in the support documentation:\nIn Enhanced Ecommerce, the Product List Performance report includes useful Product Attribution data. The report includes a \"last action\" attribute which gives product level credit to the last Product List (i.e. add to cart, checkout, or purchase) that the user interacted with prior to the conversion event. I want to show you how it works in practice.\nFirst, one detail that is missing from the documentation above. Product List Attribution only works against a Product SKU (\u0026lsquo;id\u0026rsquo;). It does NOT work with the Product Name (\u0026lsquo;name\u0026rsquo;). This is a very important distinction, as the developer documentation for Enhanced Ecommerce requires that each product payload have either \u0026lsquo;id\u0026rsquo; or \u0026lsquo;name\u0026rsquo; included, but if you want Product List Attribution to work, the payloads must share the \u0026lsquo;id\u0026rsquo; value.\nHere\u0026rsquo;s how Product List Attribution works in a nutshell:\n  As you can see, the list attribute is only added to the Add To Cart action. Nevertheless, all the subsequent actions against the same Product ID are attributed back to the list. That\u0026rsquo;s why you see 1 Product Checkout and 1 Unique Purchase for the Search Results list, even though that list attribute was not pushed in the checkout or purchase actions.\nActions, here, means the following Enhanced Ecommerce hit types:\n Product Click\n Product Detail View\n Add To / Remove From Cart\n Product Checkout\n Product Purchase\n  In other words, if you send the list attribute with any of these payloads, it will persist through all the subsequent Enhanced Ecommerce actions in the same session. However, if you send another list attribute in a subsequent action, the current attribution chain will break, and the new list will receive all the glory for the later actions.\nHere\u0026rsquo;s an illustration with actual data:\n  In the report above, each row describes a different action which was the last one to receive the list attribute. So the addWithList Product List, for example, is a list which was sent with all the Ecommerce payloads up to the Add To Cart action (i.e. \u0026lsquo;impressions\u0026rsquo;, \u0026lsquo;click\u0026rsquo;, and \u0026lsquo;detail\u0026rsquo;), and with no list for the remaining payloads (i.e. \u0026lsquo;checkout\u0026rsquo; and \u0026lsquo;purchase\u0026rsquo;).\nAs you can see, clickWithList, detailWithList, addWithList and checkoutWithList all attribute the full Enhanced Ecommerce journey to the list. With impressionWithList there is no attribution, because Product Impressions is not an Enhanced Ecommerce action.\nThe last two rows show how the attribution breaks with a new list. The list firstAddThenClickWithList_add is a list sent with a specific Product SKU in the Add To Cart payload. Then, the same product SKU is suddenly the target of a Product Click on some other list named firstAddThenClickWithList_click. This breaks the attribution for the first list, which is why you see no data for actions after the Add To Cart. Instead, the user finishes the journey all the way up to the purchase, and all the credit for the actions is attributed to the last list that was interacted with.\nThis isn\u0026rsquo;t a very typical scenario, though, but it might occur if you\u0026rsquo;re promoting products which the user has already added to the cart. So if they see a product listing for a product already in the cart, and they click this listing, it will break the attribution chain which initially added the product to the cart.\nI hope that made sense. The logic is very clear: for each Product SKU, the last Product List included in an Enhanced Ecommerce Action gets all the credit for subsequent Enhanced Ecommerce actions.\nThe other type of attribution in Enhanced Ecommerce is that of Internal Promotions, as kindly pointed out in the comments by Iain Duncumb. Ecommerce success is attributed to the most recent Internal Promotion Click, or if that doesn\u0026rsquo;t exist, all the Internal Promotion Views within the same session receive attribution for the transaction. There are more details about this here.\nSummary That\u0026rsquo;s about the gist of it. The key things to remember are:\n Outside Product Lists and Internal Promotions, there is not attribution of values across Enhanced Ecommerce payloads.\n In Product Lists, attribution revolves around Product SKUs and Enhanced Ecommerce Actions.\n For each Product SKU, the last Product List the user interacted with in an Enhanced Ecommerce Action is the one to which all subsequent actions within the same session are attributed.\n In Internal Promotions, Ecommerce success is attributed to the most recent Promotion Click, or lacking that, the most recent Promotion View.\n  In my own experience, especially product lists have received only a little attention in Enhanced Ecommerce, partly because not all online stores have what you would consider a consistent \u0026ldquo;list\u0026rdquo; setup. However, because of this powerful attribution feature, it might make sense to take a closer look at your online store to see if you could use it for something else, instead. Most of Google Analytics\u0026rsquo; power comes from taking a feature intended for A, and using it for B or maybe even C instead.\nThe same observation could be said for Internal Promotions, whose application might be difficult to figure out in a typical webstore. Nevertheless, the very fact that it has something resembling \u0026ldquo;post-view conversions\u0026rdquo; should already invite you to figure out ways of implementing Internal Promotions to your advantage.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtmtips-deploy-gtm-chrome-extension/",
	"title": "#GTMTips: Deploy GTM In Your Chrome Extension",
	"tags": ["chrome extension", "google analytics", "Google Tag Manager", "gtmtips"],
	"description": "Deploy Google Tag Manager in your Chrome extension.",
	"content": " Have you created a Chrome Extension, and now you\u0026rsquo;re dying to find out how users are interacting with it? Perhaps you want to see what features are (not) being utilized, or perhaps you\u0026rsquo;re just interested in knowing if people are actually using it.\nIn this article, I\u0026rsquo;ll show you how to configure Google Tag Manager, so that it works in the restricted sandbox of the Chrome Extension. You\u0026rsquo;ll need to make some tweaks, but it\u0026rsquo;s still perfectly doable.\nThis article was inspired by Mike Pantoliano\u0026rsquo;s question in the Google Tag Manager Google+ community. Thanks Mike!\nTip 47: How to make Google Tag Manager work in a Chrome Extension   This solution requires that your extension have a pop-up page. In other words, the extension needs to have actual HTML that the browser renders when you activate it.\n1. Deploy the Google Tag Manager container The first thing you\u0026rsquo;ll need to do is create a new JavaScript file. You can do it with any text editor. Within the file, add the following code:\n(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;https://www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-XXXXX\u0026#39;);  You probably recognize this as the JavaScript part of the regular Google Tag Manager container snippet.\nWe\u0026rsquo;re using a separate JavaScript file to load the container library, because the use of inline JavaScript is strongly discouraged in Chrome Extensions (well, almost universally in fact).\nThere are two things you\u0026rsquo;ll need to modify in this script.\nFirst, you need to explicitly load the gtm.js library using the HTTPS protocol. You can see this change in the line that has j.src='https://www.googletagmanager...'. So, the first thing to do is make sure you explicitly type https: in its rightful place, instead of the default relative protocol the snippet uses.\nThe second thing you need to do is change the GTM-XXXXX to match the container you will be using. Regular GTM stuff.\nOnce you\u0026rsquo;re done, save the file as gtm.js and store it in the extension folder.\n2. Load the file in your pop-up HTML Next, open the HTML file where your pop-up is loaded. Add the gtm.js file you just created as a reference, and place it in \u0026lt;head\u0026gt;. Why? Because it doesn\u0026rsquo;t make sense to load asynchronous libraries anywhere else but in \u0026lt;head\u0026gt; especially since you don\u0026rsquo;t need to worry about stuff like Search Console verification.\n\u0026lt;head\u0026gt; ... \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;popup.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;gtm.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt; \u0026lt;iframe src=\u0026#34;//www.googletagmanager.com/ns.html?id=GTM-W92WQQ\u0026#34; height=\u0026#34;0\u0026#34; width=\u0026#34;0\u0026#34; style=\u0026#34;display:none;visibility:hidden\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; \u0026lt;/noscript\u0026gt; ... If you really want, you can keep the \u0026lt;noscript\u0026gt; block which loads GTM for JavaScript-less users, but again I\u0026rsquo;m struggling to figure out a use case where you\u0026rsquo;d want to fire some pixels when people are using your Chrome Extension.\nThis change in the markup simply executes the JavaScript in the file gtm.js, which means that when this HTML is rendered by the browser, the Google Tag Manager library is also loaded in the extension.\n3. Modify manifest.json Next, you need to add a Content Security Policy to your extension\u0026rsquo;s manifest.json file. Basically, you\u0026rsquo;re telling the extension that requests to certain endpoints are OK, and the extension doesn\u0026rsquo;t need to panic when those requests take place. A Chrome Extension has the potential to do all sorts of vile things, so this level of additional security is definitely warranted.\nIn the CSP, you\u0026rsquo;ll need to tell Chrome that requests to https://www.google-analytics.com and https://www.googletagmanager.com must be allowed. If you\u0026rsquo;re firing any Tags to other endpoints, you need to list their hostnames here, too. Just remember that all communications must happen across HTTPS, or your extension will report an error when you try to upload it to your browser.\n{ \u0026#34;manifest_version\u0026#34;: 2, \u0026#34;name\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;content_security_policy\u0026#34;: \u0026#34;script-src \u0026#39;self\u0026#39; https://www.google-analytics.com https://www.googletagmanager.com; object-src \u0026#39;self\u0026#39;\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;...\u0026#34;, ... }  4. Modify your GTM Tags Finally, you\u0026rsquo;ll need to make some necessary modifications to your Google Tag Manager Tags.\nFor every Google Analytics Tag firing in the container, you need to make the following change.\nAdd checkProtocolTask : false to Fields to Set\nScroll down to Fields to Set, and add a new field:\nField Name: checkProtocolTask\nValue: false\nNormally, Google Analytics requires that the request to GA originate from either HTTP or HTTPS. If the requests originate from anywhere else, the process is cancelled. By setting the task named checkProtocolTask to false, we can prevent this check from happening, since the extension uses the custom chrome-extension:// protocol.\nNext, in your Page View Tags, make the following change.\nAdd a custom page to Fields to Set\nScroll down to Fields to Set, and add a new field:\nField Name: page\nValue: /some-custom-page-path/\nBecause the extension page doesn\u0026rsquo;t have a proper URL (at least in the typical sense), GA can\u0026rsquo;t decrypt the Document Location parameter for the page path. Page path is a required dimension in all Google Analytics requests, so you\u0026rsquo;ll need to manually add it to each Tag that fires.\nThese two modifications need to be in place for tracking to work. For non-Google-Analytics Tags, you might have to make similar (or additional) modifications to enable them in Chrome Extensions.\nAnd that\u0026rsquo;s it!\nSummary I hope this guide was helpful to you! Understanding the full breadth of security that Chrome Extensions implement can be daunting, so perhaps this illuminates some of the peculiarities of working in such a sandboxed environment.\nBy following these steps, you should be able to accumulate data in Google Analytics on how users interact with your extension. Remember, though, that the HTML is only rendered when the pop-up is clicked open, and each time the user clicks the pop-up open again, a new pageview is sent. So you can actually use Pageviews as a pretty reliable proxy for extension open rates!\nOn an only slightly related note, it came to my mind that it\u0026rsquo;s impossible to use a Chrome Extension like Ghostery to block other extensions (due to the sandbox). So even if the user has blocked Google Analytics and Google Tag Manager from their browser, it wouldn\u0026rsquo;t apply to the extension. This is something you might want to make clear in the privacy statement of your Chrome Extension!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/content-dashboard-klipfolio-google-analytics/",
	"title": "Content Dashboard With Klipfolio And Google Analytics",
	"tags": ["dashboard", "google analytics", "klipfolio"],
	"description": "How to build a content dashboard using Klipfolio with Google Analytics data sources.",
	"content": " I have very little against Google Analytics\u0026rsquo; default dashboards. The reason I shy away from them is because they lack the type of customization I\u0026rsquo;ve come to expect from a dashboarding tool. On top of that, they only let you look at GA data, and I learned early on in my career that focusing on just one vertical is one of the cardinal sins you can make as an analyst.\nFurthermore, over the years I\u0026rsquo;ve become more and more disenchanted with GA\u0026rsquo;s clunky user interface, and the less time I spend in it the better for my serotonin levels. In fact, GA\u0026rsquo;s excellent Core Reporting API combined with a platform like Tableau or Klipfolio to manage and manipulate the data stream has become invaluable in my everyday work.\nWell, in this article I want to show you a glimpse of a typical process I follow when creating a dashboard for my clients. My platform of choice is Klipfolio. It\u0026rsquo;s a pretty sweet dashboarding tool, with the added benefit of functioning as a low-level data store, where you can combine data from different data sources (and there are practically limitless integrations in the tool) as the input in your visualizations.\n  I shouldn\u0026rsquo;t even have to say this, as I don\u0026rsquo;t do commercials, but this article is in no way solicited or requested or paid for by Klipfolio. I\u0026rsquo;m just a fan of the tool, and I want to show you how it works.\nIn this guide, I\u0026rsquo;ll walk you through creating a single Klipfolio widget (or Klip) which pulls its data from Google Analytics. I\u0026rsquo;ll let you figure out the rest yourself. The data in the final dashboard (seen above) is pulled from a number of customizations I\u0026rsquo;ve done over the years, mainly:\n SERP Bounce Timing\n Content Interaction Time\n Content As Enhanced Ecommerce\n  I\u0026rsquo;m positive you don\u0026rsquo;t have all these customizations on your website, but perhaps the following steps will be useful to you when creating your own Klips and visualizations.\nHow Klipfolio works Klipfolio revolves around two data structures: the data sources themselves (which store the pulled-in data), and Klips (which are the widgets you add to your dashboards). This is a pretty self-sufficient system, as once you\u0026rsquo;ve created a data source, you can set it to refresh anywhere from never to every 15 minutes to every 24 hours. A refreshed data source shows up as a cool animation on the dashboard itself, so people looking at the tool will concretely see how the data set is being updated.\n  The Klips themselves offer you a handful of ready-made visualizations, with the option of writing your own HTML styling if you really want to customize the output. When you create a Klip, you add one or more data sources to it, so you can actually visualize data across data sets.\n  Creating a Klip is pretty much like working with Excel. You have flat tables of data (the data sources), and you transform and combine them with your typical spreadsheet functions. It\u0026rsquo;s pretty intuitive if you\u0026rsquo;ve ever worked with spreadsheet formulae, but if you haven\u0026rsquo;t, there\u0026rsquo;s definitely going to be a learning curve with creating new Klips.\n  Finally, the data sources themselves. Let me put it this way, you won\u0026rsquo;t run out of options! In addition to having integrations with some of the most popular SaaS platforms out there (e.g. Google Analytics, Dropbox, Facebook, Salesforce), you can integrate with any HTTP REST API, SQL database (with online access) and RSS feed. And if that isn\u0026rsquo;t enough, you can also send the data as email attachments, or upload it as CSV or Excel files, for example. Lots and lots of options!\n  In this article, we\u0026rsquo;ll only use the Google Analytics connector, and the Klip we\u0026rsquo;ll create is fairly simple and intuitive. But trust me, there are almost limitless possibilities for data transformations and visualizations with this tool!\nArticle performance table The Klip we\u0026rsquo;ll create is the easiest one. It\u0026rsquo;s a simple table with performance statistics on my articles over the last 30 days. The three things we\u0026rsquo;ll measure are:\n Pageviews\n Average Engagement Time\n Average Time On Page\n    Pageviews and Average Time On Page are GA\u0026rsquo;s built-in metrics. Average Engagement Time is a customization which measures the time users actually interact (move the mouse, click around, scroll, press keys) on each page. The reason this interests me is because Google Analytics\u0026rsquo; Time On Page metric is next to useless. It measures the difference in time between two pageviews. But this is a completely arbitrary time measurement, as it tells you absolutely nothing about how much time the user ACTUALLY spent on the page. They could have just opened it in a browser tab and left it be. With Average Engagement Time, we get an idea of how much the users are actively viewing the page.\nStep 1: Create the Data source Anyway, the first thing we need to do is create a data source. Since we only have one dimension (page title) and three metrics, we\u0026rsquo;ll manage with a single data source. In Klipfolio, go to Library -\u0026gt; Data Sources, and then click Create a New Data source.\n  Next, choose the Google Analytics connector. You will enter a screen where you need to first authenticate with Google to allow Klipfolio read-only access to your Google Analytics data. So, click Sign in to Google, and follow the prompts to authenticate Klipfolio with the Google account that has access to your data.\n  Once you\u0026rsquo;ve authenticated, you should find yourself in a screen where you can Configure your Google Analytics query. You could just use this interface to build the query, but I\u0026rsquo;ve got a better idea!\nBrowse to the Google Analytics Query Explorer. It\u0026rsquo;s an amazing tool that lets you test and build Google Analytics API queries on your data. Note! You might need to authenticate again, so that this tool, too, can access your GA data.\nSo, what you need to do first is build the query in this tool. You don\u0026rsquo;t have to worry about the Date parameters, so choose any dates which give you data. The query I\u0026rsquo;m building for the current Klip looks like this:\n  I can\u0026rsquo;t choose Average Engagement Time, since it\u0026rsquo;s a calculated metric and the Query Explorer doesn\u0026rsquo;t seem to support them yet.\nOnce the query is built, you can click Run Query and make sure it returns data.\n  So now that we know the query works, you can just scroll all the way to the bottom of the page, and copy the whole URL string within the API Query URI text box.\n  Now, go back to Klipfolio, and paste the copied URL into the Query URI box. You might need to select \u0026ldquo;Advanced\u0026rdquo; in the Mode menu first.\n  You can click Get Data to make sure that it returns the same data set you got when using the Query Explorer.\nBut some things were missing. First of all, we need to modify the date parameters to get only the last 30 days, and we also need to add the calculated metric into the mix.\nTo add dynamic date values, Klipfolio has those as built-in variables. You can read more about them here. For example, to change the \u0026amp;start-date; parameter in the query automatically to 30 days before the query was made, you\u0026rsquo;d use:\n{date.add(-30).format()}\nFor \u0026amp;end-date; we\u0026rsquo;ll just use Google Analytics\u0026rsquo; own shorthand yesterday.\nTo add the Average Engagement calculated metric, you need to get the metric\u0026rsquo;s external name. You\u0026rsquo;ll find this in the Calculated Metric settings of Google Analytics, by clicking open the entry you want to fetch into the query:\n  To add this metric to the query, add it after ga:pageViews, separated by a comma.\nThe final, complete query URL looks like this:\nhttps://www.googleapis.com/analytics/v3/data/ga?ids=ga:XXXXXXXX\u0026amp;metrics=ga:pageViews,ga:calcMetric_AverageEngagement3,ga:avgTimeOnPage \u0026amp;dimensions=ga:pageTitle\u0026amp;start-date={date.add(-30).format()}\u0026amp;end-date=yesterday\u0026amp;sort=-ga:pageViews\u0026amp;include-empty-rows=false\nIn English, the query is:\n\u0026ldquo;In the Google Analytics profile with ID XXXXXXXX, fetch me Page Views and the calculated metric Average Engagement 3, together with Average Time On Page. Query these against the Page Title dimension, and set the start date of the query to 30 days ago. The end date should be yesterday. Sort them by Page Views, in descending order, and do not include rows which do not have any values.\u0026rdquo;\nClick Get Data to make sure the data it returns is valid.\n  If you\u0026rsquo;re satisfied with the results, click the big Continue button in the bottom of the screen.\nFinally, give your new data source a descriptive name and set its refresh rate. Since in this example the \u0026amp;end-date; parameter is yesterday, you don\u0026rsquo;t need to refresh the data source all the time, just once per day should suffice. Nevertheless, I always choose a shorter refresh rate in case the timezones of Klipfolio and Google Analytics don\u0026rsquo;t match.\n  When you\u0026rsquo;re done, click Save, and you\u0026rsquo;ll be transported to the data source view for this new data set.\nNext up, building the Klip!\nStep 2: Create the Klip So now we have the data source, and we\u0026rsquo;re ready to turn it into a widget, also known as a Klip. While still in the data source view, click the big orange button labelled Build a Klip with this Data Source:\n  The first thing you need to choose is the component type. You can combine multiple component types in a single widget, but in this case we\u0026rsquo;re only interested in a Table, so choose that.\nYou\u0026rsquo;re taken to the Klip Editor. The editor lets you turn a data table into a visual representation thereof. You can use formulae to modify the data as it\u0026rsquo;s visualized in the graphs, and you can add data from multiple data sources into a single widget! This is an amazing feature, and turns Klipfolio into a light-weight Business Intelligence reporting tool.\n  It\u0026rsquo;s going to take some time to get acquainted with all the features of the editor, but once you get the hang of it, there\u0026rsquo;s a very simple flow to it. Here\u0026rsquo;s a great tutorial on how to use the editor.\nAnyway, it\u0026rsquo;s easiest to learn by doing. Select the leftmost column of the table by clicking either the column in the Preview screen or the top-most column in the hierarchy view in the left side of the editor.\nThe first thing we need to do is select data for this column. Because we want to align page titles with their respective pageview counts and engagement times, we\u0026rsquo;ll need to add the page titles to this first column. Thus, while having the first column selected, click the header A in the data table to select all the data in this column.\n  When you click the column, the following things happen automatically:\n The formula bar gets a single entry: A:A, which is spreadsheet language for \u0026ldquo;everything in the A column\u0026rdquo;\n The first column in the table is automatically filled with data in the same order as it is in the data source\n  So now you\u0026rsquo;ve created your first formula, congratulations! However, there\u0026rsquo;s a slight hiccup. As you can see, the header row (ga:pageTitle) is the first row in the chart. We don\u0026rsquo;t want that! To get rid of it, we need to apply a function to the A:A selection.\nSo, while still having the A:A column selected, click the Wrap Function button in the toolbar.\n  This lets you wrap a function around any part of the formula you have selected. You\u0026rsquo;ll see the function selector appear, and it has quite an impressive list of functions. Many of them should be familiar from spreadsheet tools, but you might want to bookmark Klipfolio\u0026rsquo;s function reference.\nAnyway, to get rid of the first row of data, simply select SLICE from the list. It automatically removes the first row of data from the widget. Note that you can specify start and/or end as parameters, but we don\u0026rsquo;t need to do that as SLICE removes the first row by default.\n  And that\u0026rsquo;s our first data column!\nNext, we\u0026rsquo;ll repeat these exact steps for the column with the header ga:pageViews in the second column of the table. If you do it correctly, you should see the following:\n  And then we\u0026rsquo;ll do the same for the two remaining columns, adding ga:calcMetric_AverageEngagement3 to the third column, and ga:avgTimeOnPage to the fourth and final column. So now you should see this:\n  So now we have our data, but it\u0026rsquo;s not looking good at all! For one thing, the data is unformatted, and this means that the duration metrics (average engagement and average time on page) are pretty indecipherable. So, let\u0026rsquo;s start formatting! Select the first column (the one with the page titles) in the Preview, and click the Properties tab.\n  Let\u0026rsquo;s start adding some bling to the widget. First, type \u0026ldquo;Page Title\u0026rdquo; into the Column Header field. You should see the change in the Preview immediately.\nNext, we want to make sure the Page Title has the largest width in the table, since all the other columns only contain numbers. So click the Fix column to a specific width\u0026hellip; checkbox, and type 50% into the field that appears. Again, you should see the change immediately. If you want to stretch the Preview table to better see how the widget will look on a full-screen dashboard, you can resize the table by dragging from the right side.\n  That\u0026rsquo;s better!\nNext, choose the second column, and go to Properties again. First, set the Column Header to \u0026ldquo;Pageviews\u0026rdquo;. Then, select Number from the Format As menu. This formats the numbers with commas as the thousands separator.\n  Finally, since it\u0026rsquo;s a column of numbers, make sure they\u0026rsquo;re right-aligned. If you don\u0026rsquo;t like this practice, you can of course leave it as it is. Now the table should look like this:\n  Next, choose the third column and click Properties. Set the Column Header to \u0026ldquo;Avg. Engagement Time\u0026rdquo;, and choose Duration from the Format As drop-down. This will automatically convert the numerical value in the data set to minutes and seconds. So 78.135353 in the data set, for example, would become 1m18s after the formatting change. Finally choose Right-alignment again to make sure the alignment matches the previous column.\n  Repeat these properties in the final column, though remember to change the Column Header in the final column to \u0026ldquo;Avg. Time On Page\u0026rdquo;.\nNow the table should look like this:\n  So now all that remains is to give the widget a descriptive name. Click the Untitled Table header to open the Klip Properties view.\nGive it a descriptive name, such as \u0026ldquo;Article performance\u0026rdquo;.\nAnd you\u0026rsquo;re done! You\u0026rsquo;ve just created your first Klip! If you\u0026rsquo;re satisfied with what you\u0026rsquo;re looking at, click Save. You can give the Klip a new name here, though it defaults to the Klip title you just edited. This name is what the Klip will have in your library. The dashboard will show the title you chose in the editor.\nWhen you\u0026rsquo;re done, you\u0026rsquo;ll be taken to the View Klip screen. Here, you can click the orange button labelled Add to Dashboard to add the widget to a dashboard. Here\u0026rsquo;s what a sample placement might look like:\n  Looking good, if I may say so myself! Check out the Dashboard Tour on the Klipfolio website for more information on the dashboard view.\nSummary All the steps above might seem quite complex, and I\u0026rsquo;m not trying to cheat you into thinking otherwise. Klipfolio isn\u0026rsquo;t a one-click, turnkey, simple, easy or fast solution for dashboarding. Nope, it replaces all that vacuous marketing jargon with one word: efficiency. It has an impressive feature set for its price point, and most importantly it lets you transform the incoming data stream.\nOn top of that, you can create your own intermediary data stores, join data across data sets, poll an impressive array of data sources, and get pretty much any data you wish into your dashboards.\nKlipfolio\u0026rsquo;s main shortcomings at this point are its multi-user functionalities. A single user only has one \u0026ldquo;My Dashboards\u0026rdquo; view, so you can\u0026rsquo;t create a separate dashboard view for each of your projects, for example. You can add multiple dashboards to the single view, and Klipfolio will very smoothly transition between the dashboards at the time interval of your choice (if you click the Play button). But if you want one project to only see dashboard set X, and give dashboard set Y to another project, you\u0026rsquo;ll need to have multiple Klipfolio Users in the same project.\nAnother thing that sucks is that the Library views have no folders or any other hierarchical representation. This is why I have to use a convoluted naming convention for each set of related data sources.\nKlipfolio have updated their pricing models with affordable options for agencies and users with multiple dashboard needs, so I\u0026rsquo;m definitely going to take a look at those soon.\nKlipfolio has a learning curve, as do all good things in analytics and life. If you\u0026rsquo;ve followed my writings over the years, you\u0026rsquo;ll know how disenchanted I am with the marketing messages that try to make everything \u0026ldquo;simple\u0026rdquo; and \u0026ldquo;just drag and drop\u0026rdquo; (yes, Google, I\u0026rsquo;m looking at you) without exposing the actual customization power of the underlying tech. I\u0026rsquo;m sure Klipfolio will at some point focus on explosive growth by adopting the same marketing tact, but for now it\u0026rsquo;s refreshing to know that there\u0026rsquo;s such a powerful platform at its price point.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/measure-google-tag-manager-event-duration/",
	"title": "Measure Google Tag Manager Event Duration",
	"tags": ["datalayer", "Google Tag Manager", "performance", "user timings"],
	"description": "How to measure how long it takes to complete each event you push into Google Tag Manager&#39;s dataLayer.",
	"content": " Google Tag Manager is a great tool. Yeah, you came all the way to this article to read that truism. It also performs really well, loading at a sweet, swift pace even on a slow connection, thanks to pretty decent response times from Google servers. On top of that, the library itself loads asynchronously, meaning the container download doesn\u0026rsquo;t interrupt the browser as it tries to make sense of your messy HTML.\n  However, after the container has downloaded, the rest is up to you. The Triggers you attach to Tags, the Variables you resolve in both Tags and Triggers, and all sorts of things like Tag Firing Priority can potentially bog down your site simply because they all represent complex JavaScript operations. Just because code is executed in the Google Tag Manager container doesn\u0026rsquo;t guarantee fast performance. The browser still needs to execute it line-by-line, using asynchronous requests where possible (such as when a call is made to the Google Analytics endpoint), but also relying on quite expensive operations such as DOM insertion.\nAnyway, being the experimenter that I aspire to be (how\u0026rsquo;s that for a circular statement), I wanted to measure just how much time it takes for GTM events to resolve. Here\u0026rsquo;s the result:\n  Interesting stuff! Out of the largest timing samples, it\u0026rsquo;s the most basic of events, gtm.js, which takes the longest time to complete! 2.5 seconds on average, phew! Here are the Tags on my site which fire on gtm.js:\n  There\u0026rsquo;s a tracker setup Tag, a little Konami code surprise, as well as some code to measure the SERP bounce time on my site. Each one of them has some dataLayer.push() methods executed, and the tracker setup does load the analytics.js library, so it\u0026rsquo;s not like it\u0026rsquo;s lightweight stuff. But still, 2.5 seconds? That\u0026rsquo;s a lifetime in Internet time!\nAnyway, this measurement has been quite eye-opening. It\u0026rsquo;s a good idea to be aware of what happens behind the scenes. Even asynchronous operations can be harmful to page performance, especially if there are many of them running one after the another. The reason for this is that the load event for the window object is delayed until the page and all its related resources (e.g. scripts and images) have completely loaded. This might lead to problems with frameworks like React, where many operations are executed only after the window.onload event has been dispatched in the browser.\nLet me quickly walk you through how I setup this measurement. It\u0026rsquo;s not a walk in the park, and if you want to try it yourself I urge you to test it in a staging environment first!\nLet\u0026rsquo;s hack the Data Layer To make it work, we need to hack the Data Layer.\nQueue ominous music.\nThat\u0026rsquo;s right, we need to do what Google Tag Manager has already done and hijack the dataLayer.push method to overwrite it with our own.\nSo, the following code needs to end up on your page template before the Google Tag Manager container snippet:\n\u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; var oldPush = window.dataLayer.push; window.dataLayer.push = function() { var e = [].slice.call(arguments, 0); if (e[0].event \u0026amp;\u0026amp; e[0].event !== \u0026#34;perfTime\u0026#34; \u0026amp;\u0026amp; [\u0026#34;gtm.linkClick\u0026#34;,\u0026#34;gtm.formSubmit\u0026#34;,\u0026#34;gtm.timer\u0026#34;].indexOf(e[0].event) === -1 \u0026amp;\u0026amp; document.readyState !== \u0026#34;complete\u0026#34;) { var t = (new Date).getTime(), a = e[0].event; e[0].eventStartTime = t, e[0].eventCallback = function(c){ window.dataLayer.push( { event : \u0026#34;perfTime\u0026#34;, \u0026#34;perfEvent.event\u0026#34; : a, \u0026#34;perfEvent.totalTime\u0026#34; : (new Date).getTime() - t, \u0026#34;perfEvent.containerId\u0026#34; : c } ) } } oldPush.apply(window.dataLayer, e); } \u0026lt;/script\u0026gt; Wow. That\u0026rsquo;s a beast. I\u0026rsquo;m not going to walk you through it line-by-line, but here\u0026rsquo;s how it works:\n When a dataLayer.push() happens, this code is first executed.\n It takes the object that was pushed, and if it contains an 'event' key and if it matches some other conditions, the following code is then run:\n A timer is started (the time when the event execution began) and stored in the key eventStartTime\n The [eventCallback](/gtm-tips/hitcallback-eventcallback/) of this object is set to a function, which basically pushes another dataLayer object, where a new timer calculates the difference between the event execution start and end times\n Finally, whatever was processed by this script (whether it be the modified object or the new \u0026ldquo;perfTime\u0026rdquo; object) is returned to the original dataLayer.push method, so that GTM can pick it up\n   Ah, that IS a beast. Perhaps it\u0026rsquo;s easier if I show you an example. When this code is running (i.e. before the page has completely loaded), a simple dataLayer.push() like this:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;testing\u0026#39;, \u0026#39;someVar\u0026#39; : \u0026#39;someVal\u0026#39; });  \u0026hellip;is automatically turned into:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;testing\u0026#39;, \u0026#39;someVar\u0026#39; : \u0026#39;someVal\u0026#39;, \u0026#39;eventStartTime\u0026#39; : 1464890512708, \u0026#39;eventCallback\u0026#39; : function(e) {...} });  And when all Tags which fire on 'event' : 'testing' have completed their execution, the following is, again, automatically pushed into dataLayer:\nwindow.dataLayer.push({ event : \u0026#39;perfTime\u0026#39;, \u0026#39;perfEvent.event\u0026#39; : \u0026#39;testing\u0026#39;, \u0026#39;perfEvent.totalTime\u0026#39; : 421, \u0026#39;perfEvent.containerId\u0026#39; : \u0026#39;GTM-W92WQQ\u0026#39; });  So my little hack is automatically measuring the time any 'event' takes to complete, as long as it happens before the page has loaded (as that\u0026rsquo;s the only performance I\u0026rsquo;m interested in).\nBy the way, you don\u0026rsquo;t really need to add the eventStartTime into the object, as you already have a locally scoped variable t which stores the start time in a closure. However, I prefer to keep it there in case I want to do further debugging, since with the start time I can also build a waterfall model out of the performance times, to see how much execution of these different pre-load events overlap.\nNOTE!! The script automatically excludes gtm.linkClick, gtm.timer and gtm.formSubmit, as these have their own uses for eventCallback (the Wait for Tags option). Similarly, if you\u0026rsquo;re already using eventCallback with some events, be sure to add them to the Array of excluded events, or you might break your site!\nRemember to test first, please!\nThe setup in GTM requires the following:\n A Data Layer Variable named DLV - perfEvent.event, pointing to variable name perfEvent.event\n A Data Layer Variable named DLV - perfEvent.totalTime, pointing to variable name perfEvent.totalTime\n A Custom Event Trigger named Event - perfTime, with Event name set to perfTime\n A Universal Analytics Tag of type Timing (see below)\n  Here\u0026rsquo;s the Tag:\n  And this Tag will send your hits as User Timings, after which you\u0026rsquo;ll find the report in Google Analytics, under Behavior -\u0026gt; Site Speed -\u0026gt; User Timings.\nI\u0026rsquo;ve given User Timings a thrashing before, since they\u0026rsquo;re really useless for timing ALL the hits on the site. But if you\u0026rsquo;re fine with just a sample, such as in this case, they work really well.\nSummary Remember kids, good performance is good. Bad performance can kill\u0026hellip; your site\u0026rsquo;s user experience, and other stuff, too!\nHowever you want to do it, it\u0026rsquo;s a good idea to keep an eye on the processes that take place before the window object has completely loaded on your site. You can use User Timings to measure all sorts of important milestones, such as just how long it takes for that awesome font library you paid hundreds of bucks for to download. Or how long your favorite JavaScript framework (rhymes with \u0026ldquo;lay brewery\u0026rdquo;) hinders your page load times. Or how long it takes for you to reach the end of these articles of mine. Well, the last one might need some creativity, but I\u0026rsquo;ll leave it in your capable hands!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/simple-tracker-duplication-universal-analytics/",
	"title": "Simple Tracker Duplication For Universal Analytics",
	"tags": ["JavaScript", "plugins", "tasks", "universal analytics"],
	"description": "How to duplicate all requests sent to Google Analytics using JavaScript and a Universal Analytics plugin.",
	"content": " First of all, I\u0026rsquo;m sorry about the title. I should really stop throwing the word \u0026ldquo;simple\u0026rdquo; around, since people always tell me that the stuff I claim to be easy and straightforward is rarely so. But since this is my blog, I reserve the right to use whatever stupid and misleading terminology I want. I maintain that what follows IS quite simple, especially when considering the amount of complexity it reduces in your Universal Analytics setup.\nNext, I want to direct your gaze to my latest Keynote / PowerPoint creation:\n  This piece of art is called \u0026ldquo;\u0026hellip;while waiting for the cosmos\u0026rdquo;. Note the enigmatic ellipsis in the beginning, the lack of capitalization, and the fact that the title has nothing to do with the image. Yes, friend. This is post-post-modernism at its best!\nSo, I guess my amazing art kind of gave away what I want to show to you in this article. In short, it\u0026rsquo;s a simple little plugin I\u0026rsquo;ve been using in projects I work on, which duplicates all hits sent to a Google Analytics property. These duplicated hits are sent to another Google Analytics property, whose property ID you specify when initiating the plugin.\nThis tutorial uses a Universal Analytics plugin (d\u0026rsquo;oh), which, in turn, utilizies the Tasks API.\nBefore I proceed, I want to direct you to David Vallejo\u0026rsquo;s blog, where he and a bunch of other people are working together on an open-source project which does similar stuff, but on a WAY more configurable level. The plugin I\u0026rsquo;m about to walk you through will simply make an exact duplicate of the hit you sent, without letting you modify the payload one bit.\nWhy, you may ask? Well, a surprisingly large number of projects I work with have a need for a \u0026ldquo;rollup\u0026rdquo; property, which collects data from all sites in the organization. The data sent to the rollup often mirrors whatever is collected in the local sites. It\u0026rsquo;s quite a chore to duplicate send commands across all trackers, so if the project is fine with simple duplication, I use this plugin.\nCAVEAT: This will best work with named trackers. Thus Google Tag Manager setting this up in Google Tag Manager is difficult, as you\u0026rsquo;ll have to mess with the Tracker name field. If you\u0026rsquo;re confident with your GTM implementation skills, feel free to do whatever you wish, of course. Nevertheless, in its current state, the plugin caters best to an on-page Universal Analytics implementation.\nModifying the tracking code For this to work, you will need to make a small change to your Universal Analytics tracking code. Let\u0026rsquo;s say the code looks like this now:\n\u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;https://www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; You\u0026rsquo;ll need to add the following modification:\n\u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;https://www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, \u0026#39;auto\u0026#39;); // ADD THIS LINE:  ga(\u0026#39;require\u0026#39;, \u0026#39;simolatorDuplicator\u0026#39;, {\u0026#39;newId\u0026#39; : \u0026#39;UA-12345-2\u0026#39;}); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; There\u0026rsquo;s a single addition: ga('require', 'simolatorDuplicator', {'newId' : 'UA-12345-2'});. This line invokes a plugin called simolatorDuplicator (I know! The awesomest plugin name in the UNIVERSE!), after which you pass an object with a single key-value pair: {newId : newTrackerId}. In place of newTrackerId, you place a String with the Google Analytics property ID to which you want to duplicate all the hits.\nThe plugin itself There are two quick and easy (sorry about those words again) ways to load the plugin. Either host it in its own JavaScript file which you then load with a \u0026lt;script\u0026gt;\u0026lt;/script\u0026gt; loader, or just run the code in the page template itself.\nWhat\u0026rsquo;s important is that the plugin code needs to be loaded AFTER the tracking code. The code looks like this:\n(function() { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]]; var GADuplicate = function(tracker, propertyId) { var o = tracker.get(\u0026#39;sendHitTask\u0026#39;); var temp; tracker.set(\u0026#39;sendHitTask\u0026#39;, function(model) { o(model); temp = model.get(\u0026#39;hitPayload\u0026#39;).replace(new RegExp(model.get(\u0026#39;trackingId\u0026#39;), \u0026#39;g\u0026#39;), propertyId.newId); if (temp) { model.set(\u0026#39;hitPayload\u0026#39;, temp, true); o(model); } }); }; ga(\u0026#39;provide\u0026#39;, \u0026#39;simolatorDuplicator\u0026#39;, GADuplicate); })();  So either write this in a file named something.js (feel free to replace something with something else), or just add the code in its own \u0026lt;script\u0026gt; block after the tracking snippet.\n\u0026lt;!-- METHOD 1 --\u0026gt; \u0026lt;script\u0026gt; // GA Tracking code here \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;something.js\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- METHOD 2 --\u0026gt; \u0026lt;script\u0026gt; // GA Tracking code here \u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; (function() { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]] || function() {}; var GADuplicate = function(tracker, config) { var o = tracker.get(\u0026#39;sendHitTask\u0026#39;); var temp; tracker.set(\u0026#39;sendHitTask\u0026#39;, function(model) { o(model); temp = model.get(\u0026#39;hitPayload\u0026#39;).replace(new RegExp(model.get(\u0026#39;trackingId\u0026#39;), \u0026#39;g\u0026#39;), config.newId); if (temp) { model.set(\u0026#39;hitPayload\u0026#39;, temp, true); o(model); } }); }; ga(\u0026#39;provide\u0026#39;, \u0026#39;simolatorDuplicator\u0026#39;, GADuplicate); })(); \u0026lt;/script\u0026gt; Both are equally fine, though to keep things nice and tidy I do recommend the first method.\nLet\u0026rsquo;s take a quick stroll through the code.\n(function() { var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;]] || function() {}; ... ga(\u0026#39;provide\u0026#39;, \u0026#39;simolatorDuplicator\u0026#39;, GADuplicate); })();  These lines wrap the plugin code in an immediately invoked function expression, which I use to protect the global namespace. No, you didn\u0026rsquo;t need to understand any of that.\nThe next line establishes the ga() interface locally, by scoping it to the global Google Analytics Object. This is so that the plugin still works even if you\u0026rsquo;ve renamed the global GA interface from ga to something else.\nAfter the plugin code (represented by the \u0026ldquo;\u0026hellip;\u0026rdquo;) we make the plugin available to the ga interface. This is a very important line, as it is the counterpart to the ga('require', 'simolatorDuplicator'...); command used in the tracking code. If you didn\u0026rsquo;t have this line, or if you had a typo in the plugin name, your GA code would not work at all! So remember to test, test, TEST.\nNext, the plugin constructor itself:\nvar GADuplicate = function(tracker, config) { var o = tracker.get(\u0026#39;sendHitTask\u0026#39;); var temp; tracker.set(\u0026#39;sendHitTask\u0026#39;, function(model) { o(model); temp = model.get(\u0026#39;hitPayload\u0026#39;).replace(new RegExp(model.get(\u0026#39;trackingId\u0026#39;), \u0026#39;g\u0026#39;), config.newId); if (temp) { model.set(\u0026#39;hitPayload\u0026#39;, temp, true); o(model); } }); };  Lots of things going on here.\nFirst, the function expression establishes a new function called GADuplicate, which takes two parameters: tracker and config. The tracker parameter is passed automatically by the plugin logic, and it contains a reference to the Universal Analytics tracker object which invoked the plugin. The config object is passed as a parameter in the modified tracking code. It\u0026rsquo;s the {'newId' : 'UA-12345-2'} which we covered earlier.\nNext, we make a copy of the original sendHitTask. This little method is actually the entire dispatch logic of analytics.js, so we\u0026rsquo;ll need it to send our data to Google Analytics.\nWe need it especially because on the very next line after the variable declarations we overwrite the sendHitTask of the tracker with a new one!\nFirst, the original sendHitTask, temporarily copied to the method o(), is used to send the regular hit to Universal Analytics. This is really important, as without this you\u0026rsquo;d just be sending your duplicate hit!\nThen, we take the hitPayload you just sent to GA, and we replace all instances of the current property ID with the new property ID that you configured in the tracking code! This is the main logic in this plugin. We take the payload, we send it first regularly, and then we modify it and send the modified version. By using model.set('hitPayload', temp, true); we\u0026rsquo;re rewriting the payload, which is then submitted with a new invocation of the o() method.\nI maintain that it\u0026rsquo;s really quite simple when you think about it, but naturally it does require some understanding of how the APIs work. So feel free to plunge into the documentation.\nAnd that\u0026rsquo;s it! That\u0026rsquo;s the code, the setup, and the implementation. Remember, you will need to modify the tracking code accordingly on all pages of your site where you want to use this plugin. You can use it with named trackers, too; just modify the plugin call to:\nga(\u0026#39;myNamedTracker:require\u0026#39;, \u0026#39;simolatorDuplicator\u0026#39;, {\u0026#39;newId\u0026#39; : \u0026#39;UA-12345-2\u0026#39;});  And yes, you can rename the plugin to something else than simolatorDuplicator, though I will love you slightly less if you do so.\nSummary Please remember, this is an exact hit duplication method. If you want to modify the payload, you\u0026rsquo;ll need to add some additional logic to the code, and I really recommend you check out the link to David Vallejo\u0026rsquo;s blog in the introductory chapter of this article.\nLet me know if you\u0026rsquo;re having problems with this, or if you have suggestions! Please do test this thoroughly before implementing it. You are messing with code that can potentially cripple your Google Analytics implementation.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/using-document-write-safely-gtm-tags/",
	"title": "#GTMTips: Using document.write Safely In GTM Tags",
	"tags": ["custom html", "dan wilkerson", "document.write", "Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Guest post by Dan Wilkerson on how the document.write setting in Google Tag Manager&#39;s Custom HTML tags works.",
	"content": " This article is a guest article by someone from the analytics community I really look up to. Dan Wilkerson is an analytics developer at LunaMetrics, a company I hold in high esteem. Dan is one of the smartest technical analytics experts out there, and a large bulk of the awesome scripts and hacks that LunaMetrics produces (almost on a daily basis) have been orchestrated by him. So I\u0026rsquo;m very pleased to give the floor to Dan, so that he can tell you all about using the pesky document.write() method in your Google Tag Manager Custom HTML Tags!\nTip 46: Safely using document.write in Google Tag Manager Tags   Often, 3rd party marketing tags make use of an archaic JavaScript method called document.write. This method has been the go-to for adding in dynamic tracking pixels and scripts because it is universally supported and predictable. However, document.write won\u0026rsquo;t play nicely with asynchronously loaded scripts. Since Google Tag Manager forces scripts to load asynchronously, and since many 3rd party marketing tags depend on document.write, there was a time when we couldn\u0026rsquo;t implement these tags in GTM. Fortunately, the engineers at Google added a clever solution which temporarily replaces document.write with a safe alternative while your tag executes.\nIn the past, document.write was meant to be used to add dynamic content using JavaScript in between when your browser first started to load the page and when the page completed loading. This content would execute synchronously by default, making the outcome predictable and implementation straightforward. Many ad tech vendors came to rely on this functionality to load in snippets and add in tracking pixels, instead of using more asynchronous-friendly methods. This made writing their tags simple and concise, but synchronously executing snippets would cause the browser to stop rendering and slow down the overall speed of the page on a site.\nUnfortunately, when document.write is called after the document is finished loading, the browser overwrites the existing document and replaces it with just the contents of the document.write call (read: your entire site becomes a blank page). In the past, this wasn\u0026rsquo;t a big deal; we\u0026rsquo;d hard code our handful of marketing tags straight into the HTML of the page.\nUnfortunately, modern front-end engineering best practices, the proliferation of tracking pixels, and tag management systems don\u0026rsquo;t play nicely with this paradigm. These days, it\u0026rsquo;s all about asynchronicity and speed. Thus, we see the crux of the issue: vendors want simplicity and reliability, and engineers want speed and efficiency.\nThe engineers at Google have implemented a solution to this problem for us in Google Tag Manager. When a Custom HTML Tag in Google Tag Manager requires document.write to run, Google Tag Manager temporarily replaces the default document.write function with a safe version of their own. When we want to use a tag that uses document.write, we simply need to check a box in the Custom HTML Tag creation interface. Enabling this feature will allow us to safely deploy any tags that use document.write, even after our page has loaded. Here\u0026rsquo;s where to do that in your tag:\n  Once the tag has finished firing, GTM then switches document.write back to the browser default. Wondering if you have a Tag that isn\u0026rsquo;t using this feature? If you see an error in your console like below:\n  you may have a tag in GTM that is firing asynchronously and attempting to use document.write. Try and track down this tag quickly and fix it. (Hint: if you click the line reference in the far right of the interface, Chrome will take you straight to the offending code):\n  Otherwise, your tracking pixels won\u0026rsquo;t work. GTM will even warn you proactively if you try and save a tag with document.write that doesn\u0026rsquo;t have this feature enabled:\n  This feature allows us to have our cake and eat it, too. Before, we\u0026rsquo;d have to deliver the tags synchronously. You deliver the same tags as before, and you can give your users a better experience.\nGTM\u0026rsquo;s replacement for document.write uses document.createElement and then appends the result into a hidden div at the bottom of the page. It negotiates the handoff by binding to the onload event or the onreadystatechange event of the element.\nAnd that\u0026rsquo;s all there is to it! Simply check the box, and your tag will load asynchronously and write to the document, as expected. Remember, if you see a warning in the Developer Tools, that means there may be a Custom HTML Tag with document.write that doesn\u0026rsquo;t have that box checked.\nSummary (by Simo) First of all, kudos to Dan for giving a thorough run-through of something most of us take for granted. The simple little checkbox in the Custom HTML Tag hides a wealth of complexity, engineered solely to make life easier for anyone who has to work with advertising pixels.\nIt\u0026rsquo;s kind of odd that something so crucial to businesses these days (ad revenue) hinges on a technology which is dubious at best. In my book, document.write is in the same bucket of nastiness as iframes, single-pixel image beacons, (third-party) browser cookies, and all other technologies designed to facilitate the spread of malware.\nBut this article wasn\u0026rsquo;t about advertising. This was about zooming in on yet another interesting technical manoeuvre that the Google Tag Manager engineers have done to make sure that the tool caters to all its target audiences (whatever they might be) with equal precision. So thank you, Dan!\nAs always, the comment section is here for you.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/timer-trigger/",
	"title": "#GTMTips: The Timer Trigger",
	"tags": ["gtmtips", "Guide", "timer", "triggers"],
	"description": "Build a custom timer trigger in Google Tag Manager. You can set it to start and stop whenever you like.",
	"content": " Google Tag Manager has a Trigger type which fires after a certain duration of time has passed on the web page: the Timer Trigger. The most common uses for the Timer Trigger seem to be either to send an event to Google Analytics after X seconds of dwell time (to kill the Bounce), or to defer a Tag from firing until some asynchronous request has completed with certainty.\nIn the previous version of Google Tag Manager, the Timer was a separate listener Tag, which meant that you could start a timer based on a user interaction such as a click. In the current version of GTM, this is no longer possible, as the Timer Trigger will only start when GTM is first loaded on the page. So, one of the tips in this article will be how create your own Timer, in case you want to start one based on some other stimulus than the Page View.\nTip 45: The Timer Trigger   The Timer Trigger itself has a simple operation mechanism. You specify three different fields when creating the Trigger:\n Event Name: This lets you customize the event name that GTM pushes to dataLayer. It\u0026rsquo;s most useful in the case where you want to fire multiple timers on the page.\n Interval: Here you specify how many milliseconds should pass between each activation of this Trigger.\n Limit: This option lets you choose how many times the Trigger fires before it is stopped.\n  Furthermore, you can delimit the Timer to only fire on specific pages using the Enable When option. You\u0026rsquo;ll need to provide some condition which is already present when GTM is first loaded, such as Page Path equals /home-page/, or something similar.\nIn Fire On you can fire a Tag based on some parameters of the Timer that fired. You might want to create a new Data Layer Variable for all of the following parameters:\n gtm.timerCurrentTime - The timestamp of the most recent Timer activation.\n gtm.timerElapsedTime - The time in milliseconds since the Timer started.\n gtm.timerEventNumber - The number of Timers that have activated on the current page (whatever you have in the Limit option is the maximum).\n gtm.timerId - A unique identifier number for the Timer. Each Timer you have on the page has a different ID.\n gtm.timerInterval - The value you set in the Interval option when creating the Timer.\n gtm.timerStartTime - The timestamp of when the Timer first started.\n  The gtm.timerId Data Layer Variable is definitely the most useful one. With that, you can stop a Timer even before it\u0026rsquo;s Limit is reached.\nTo do this, you need to run the following JavaScript command:\nvar timerId = {{DLV - gtm.timerId}}; window.clearInterval(timerId);  So executing window.clearInterval on the Data Layer Variable that points to gtm.timerId lets you halt the Timer. There\u0026rsquo;s no way to restart it once it\u0026rsquo;s halted on the page, though. The only way it starts again is with a page reload.\nThis is very useful on single-page apps, for example, where you might want to stop the Timer when a new page is loaded, but there\u0026rsquo;s no actual page refresh.\nNow, in case you DO want a timer to fire when the user does something (e.g. click), you\u0026rsquo;ll need to use a Custom HTML Tag with custom code. Here\u0026rsquo;s one way to do it:\n\u0026lt;script\u0026gt; (function() { // CHANGE THESE THREE:  var eventName = \u0026#39;custom.timer\u0026#39;; // The event name that is pushed into dataLayer  var interval = 5000; // The interval in milliseconds  var limit = 1; // The number of times the timer fires  // OTHER SETTINGS:  var timerNumber = 1; var startTime = new Date().getTime(); var fireTimer = function() { var timeNow = new Date().getTime(); window.dataLayer.push({ \u0026#39;event\u0026#39; : eventName, \u0026#39;custom.timerCurrentTime\u0026#39; : timeNow, \u0026#39;custom.timerElapsedTime\u0026#39; : timeNow - startTime, \u0026#39;custom.timerStartTime\u0026#39; : startTime, \u0026#39;custom.timerEventNumber\u0026#39; : timerNumber, \u0026#39;custom.timerId\u0026#39; : timerId, \u0026#39;custom.timerInterval\u0026#39; : interval, \u0026#39;custom.timerLimit\u0026#39; : limit }); timerNumber += 1; if (limit \u0026lt; timerNumber) { window.clearInterval(timerId); } }; var timerId = window.setInterval(fireTimer, interval); })(); \u0026lt;/script\u0026gt; It\u0026rsquo;s a very simple script, and it does pretty much exactly the same thing as the Timer Trigger. The difference is that you can use any Trigger you want to fire this custom Trigger. Also, the keys pushed into dataLayer differ in that the prefix is not gtm. but custom.. So gtm.timerId becomes custom.timerId and so forth.\nThat\u0026rsquo;s all for the Timer tips. I hope they were useful! Remember to test thoroughly whenever using custom scripts on your page. Accidentally setting the interval to 1 millisecond and the limit to 10000 can quickly destroy your page performance. Yes, this is something that happened to me\u0026hellip;sorry, my anonymous friend.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtmtips-10-blogs-10-articles-10-people-follow/",
	"title": "#GTMTips: 10 Blogs, 10 Articles, 10 People To Follow",
	"tags": ["google analytics", "Google Tag Manager", "gtmtips", "Guide", "resources"],
	"description": "10 blogs, 10 articles, and 10 people to follow if you&#39;re interested in Google Tag Manager.",
	"content": " Quite a while ago, I wrote an article on what I considered (then) to be my favorite Google Tag Manager resources. Many of them are still very valid, but I still wanted to write a follow-up. Times have changed, and GTM is very different from what it was two years ago when I wrote the post.\nSo in this article, I want to divert your attention to 10 blogs, 10 articles, and 10 people - all which are and/or share excellent Google Tag Manager content on a periodic basis.\nNow, I know I\u0026rsquo;m going to leave many amazing individuals and awesome resources out of this post. Please don\u0026rsquo;t read anything into it, and instead share these omissions in the comments section of this blog! These are not my \u0026ldquo;top 10\u0026rdquo; or \u0026ldquo;best of the best\u0026rdquo;, but rather individual works of art that I consider very relevant today.\nTip 44: My 10 x 10 x 10 Google Tag Manager resources today   Let\u0026rsquo;s start with blogs. There really aren\u0026rsquo;t any blogs devoted solely to Google Tag Manager, so I\u0026rsquo;m going to link to stuff that\u0026rsquo;s hugely useful for Google Tag Manager usage in general. This might include JavaScript tips or some excellent Google Analytics configuration stuff.\nAll the resources below are listed in alphabetical order.\n10 Blogs To Check Out There are many great analytics blogs out there, but only few produce content on a regular basis. In the following list, I\u0026rsquo;ve included blogs that I use or refer to almost daily. Not all of them have a regular publishing schedule, unfortunately, so hopefully if more people start reading them, the authors will pick up the slack!\n1. Analytics Ninja http://www.analytics-ninja.com/blog.html\nCheck it out: REAL Time On Page in Google Analytics\nYehoshua Coren publishes content quite rarely, but when he does, it\u0026rsquo;s just FULL of amazing information. He takes complicated, usually quite techy concepts, and translates them into a business context.\n2. Analytics Pros https://www.analyticspros.com/blog/\nCheck it out: Getting Started with Google Optimize\nAnalytics Pros are one of the better-known Google Partners, and they produce a lot of content especially around new product releases. They\u0026rsquo;ve done an excellent job at outreach, even if much of the content is geared towards the Google Analytics Premium audience.\n3. ConversionWorks http://www.conversionworks.co.uk/blog/\nCheck it out: Explain GTM - Google Tag Manager Containers in plain English\nConversionWorks do a great deal of outreach, especially in the small sphere of European Analytics events and conferences. They\u0026rsquo;ve written a bunch of free tools which are incredibly useful and value-adding in day-to-day GTM use. Their tall and extremely British leading man, Doug Hall, has also written an excellent book on GTM best practices and design patterns, which you can download (for free, of course) here.\n4. Digital Debrief http://www.kristaseiden.com/\nCheck it out: Step-by-Step: Adding a Second GA Property via Google Tag Manager\nKrista Seiden is an Analytics Advocate at Google, and certainly does her part in spreading the word of Google Analytics and Google Tag Manager around the globe. She occasionally writes extremely helpful guides and tip posts about GA and GTM in her blog, but she\u0026rsquo;s got a wealth of other, useful content for budding analysts, and women and men in tech.\n5. L3 Analytics http://www.l3analytics.com/blog/\nCheck it out: An alternative approach to GTM event tracking\nPeter O\u0026rsquo;Neill is one of the most industrious people in digital analytics, and his company L3 Analytics does a great deal of outreach in the form of blog posts and conference participation. The blog isn\u0026rsquo;t updated all that often (at least with cool GTM and/or GA articles), but when new content is published, it\u0026rsquo;s always very engaging. Usually, the articles offer alternative approaches or contrarian views to concepts we take for granted in the analytics world.\n6. Loves Data http://www.lovesdata.com/blog/\nCheck it out: A Beginners Guide to Google Tag Manager Environments\nLoves Data is a spectacular and wonderful company operating in Australia. Their outreach is impressive both in quantity and quality, and you\u0026rsquo;ll do well to follow them in social media channels as well. Many of their guides are geared towards beginners, but the comprehensiveness of these tutorials always manages to impress me.\n7. LunaMetrics http://www.lunametrics.com\nCheck it out: Instantiating \u0026amp; Using The Google Tag Manager dataLayer\nHonestly, this whole article could have been just about LunaMetrics. I have a huge crush on the whole company. The amount of content they produce is staggering, and they target all audiences from beginner to creepy JavaScript nerd. They\u0026rsquo;re humble and down-to-earth about what they do, and whenever I read their content I never get the feeling that they\u0026rsquo;re trying to pitch or sell anything. They only want to educate GA and GTM users. Thus, they\u0026rsquo;ve set an example that I strive to follow in every single article I write in my blog.\n8. MeasureSchool http://measureschool.com/\nCheck it out: Google Tag Manager for Beginners\nI don\u0026rsquo;t really know of any free courses or trainings for Google Tag Manager (apart from Google\u0026rsquo;s own, excellent Google Tag Manager Fundamentals), so I\u0026rsquo;m ecstatic about the work that Julian Juenemann has put into his own MeasureSchool. The content is free and ready for you to download and make use of! Be sure to check it out. He also has a YouTube channel full of great GTM content, so take a look at that, too.\n9. Online Behavior http://online-behavior.com/\nCheck it out: Google Tag Manager Injector: Painless Tagging\nOnline Behavior is Googler Daniel Waisberg\u0026rsquo;s love-child, and incidentally my all-time favorite Google Analytics blog. The amount of content he and his impressive cast of guest writers produce is impressive, but the quality of the articles is what really makes my head spin. There\u0026rsquo;s a wealth of information for both beginners and for advanced users.\n10. Thyngster http://www.thyngster.com/\nCheck it out: Tips for working with Custom HTML and Custom JavaScript tags in Google Tag Manager\nDavid Vallejo is a GTM wizard, and he really knows his way around JavaScript. His posts are always VERY techy, but he approaches them with a clear goal in mind: helping others combat issues they might have with complicated setups. Usually his solutions are simpler than they seem, and always, always tackle the problem handily and without turning your setup into a complete mess.\n10 People To Follow The following 10 people are very active in social media, sharing excellent content on a regular basis, responding to user questions, and inviting conversation around hot analytics topics whenever and wherever possible. I can\u0026rsquo;t recommend enough that you follow them and join in on the discussion wherever appropriate.\n1. Damion Brown   LinkedIn: https://www.linkedin.com/in/damionbrown\nTwitter: @datarunsdeep\nGoogle+: +DamionBrown\n2. Julien Coquet   LinkedIn: https://www.linkedin.com/in/juliencoquet\nTwitter: @juliencoquet\nGoogle+: +JulienCoquet\n3. Mark Edmondson   LinkedIn: https://www.linkedin.com/in/markpeteredmondson\nTwitter: @holomarked\nGoogle+: +MarkEdmondson\n4. Stéphane Hamel   LinkedIn: https://www.linkedin.com/in/shamel\nTwitter: @shamel67\nGoogle+: +StephaneHamel-immeria\n5. Phil Pearce   LinkedIn: https://www.linkedin.com/in/philpearce\nTwitter: @philpearce\nGoogle+: +PhilPearce\n6. Lea Pica   LinkedIn: https://www.linkedin.com/in/leasynefakispica\nTwitter: @leapica\nGoogle+: +LeaSynefakisPica\n7. Zorin Radovancevic   LinkedIn: https://www.linkedin.com/in/zorinatesc\nTwitter: @zorinatesc\nGoogle+: +ZorinRadovancevic\n8. Jeff Sauer   LinkedIn: https://www.linkedin.com/in/jeffsauer\nTwitter: @jeffsauer\nGoogle+: +JeffSauer\n9. Krista Seiden   LinkedIn: https://www.linkedin.com/in/kristaseiden\nTwitter: @kristaseiden\nGoogle+: +KristaSeiden\n10. Daniel Waisberg   LinkedIn: https://www.linkedin.com/in/danielwaisberg\nTwitter: @danielwaisberg\nGoogle+: +DanielWaisberg\n10 Excellent GTM Articles The following 10 articles are, in my opinion, hallmarks in Google Tag Manager writing. They exemplify all the goodness that content creation can inspire, and they are quite simply brilliant resources for any skill level.\n1. 7 Steps to Pushing JSON Structured Data using Google Tag Manager (Mike Arnesen) http://www.6dglobal.com/blogs/7-steps-pushing-json-structured-data-using-google-tag-manager-2015-03-04\nMike Arnesen\u0026rsquo;s article on how to inject SERP refinements through Google Tag Manager is an example of how to write a great content piece: produce a hypothesis, test it opaquely, and present the results. The article nicely shows how important Google Tag Manager is also in the organic search world.\n2. Complete Guide to Google Tag Manager (iPullRank) http://ipullrank.com/google-tag-manager/\nA thorough guide through (almost) all facets of Google Tag Manager. For a \u0026ldquo;complete\u0026rdquo; guide, some of the parts are lacking (e.g. GTM for mobile), but the guide steers you through all the most critical concepts of GTM, which any users would do good to learn.\n3. Creative uses of Google Tag Manager: site hacking / ripping (Julien Coquet) http://juliencoquet.com/en/2015/03/24/creative-uses-of-google-tag-manager-site-hacking-ripping/\nOne of the funniest GTM articles out there. Learn how Julien Coquet took up the battle against idiots who had ripped his entire site content onto their own site. With GTM, Julien turned the tables against the hackers.\n4. Easier Enhanced Ecommerce Product \u0026amp; Promo Tracking (Eivind Savio) https://www.savio.no/analytics/easier-enhanced-ecommerce-product-promo-tracking\nExcellent article by Eivind on how to automatically split your Enhanced Ecommerce payload if it surpasses the payload size limit of 8KB that Google Analytics imposes on the HTTP requests. A techy but critical article on how to fix a potentially disastrous data quality issue in Google Analytics.\n5. Google Tag Manager: A Step-by-step Guide (Online Behavior) http://online-behavior.com/analytics/google-tag-manager\nDaniel Waisberg\u0026rsquo;s Google Tag Manager guide is still one of the best out there, and he keeps the content fresh and up-to-date.\n6. GTM for Mobile: Updating Your iOS Application Through Google Tag Manager (Analytics Pros) https://www.analyticspros.com/blog/tag-management/gtm-for-mobile/\nNot much has been written about Google Tag Manager for mobile. In this article, Luka Cempre from Analytics Pros walks your through one of the more powerful use cases speaking for the adoption of GTM for mobile.\n7. How to setup Content Grouping in Google Analytics for your WordPress site (Daniel Carlbom) http://dcarlbom.com/google-analytics/content-grouping-with-wordpress-and-google-analytics/\nDaniel\u0026rsquo;s blog has a lot of great information for WordPress users tackling with Google Analytics and Google Tag Manager. This article is a prime example of how to use the power of the WordPress engine to fuel your site tracking.\n8. Track Brightcove Player with Google Tag Manager (Isaac Abramowitz) http://iabramo.com/2016/03/08/track-brightcove-player-with-google-tag-manager/\nIsaac\u0026rsquo;s article on utilizing the Brightcove API with Google Tag Manager shows how sometimes the simplest solution is the best one.\n9. Tracking Form Submissions in Iframes (LunaMetrics) http://www.lunametrics.com/blog/2015/10/21/google-analytics-iframes-form-submissions/\nA brilliant four-parter from LunaMetrics, tackling an extremely difficult topic: how to track interactions within Iframes.\n10. Understanding your Website Visitors: Prospects vs. Customers (L3 Analytics) http://www.l3analytics.com/2016/01/18/understanding-your-website-visitors-prospects-vs-customers/\nTypical to his style, Peter isn\u0026rsquo;t satisfied with just providing a nice, fun solution to improve your site\u0026rsquo;s data collection. Instead, he\u0026rsquo;s ambitious enough to show the business ramifications of the data collection method at hand. In this article, he walks you through a setup which allows you to segment your visitors in Google Tag Manager.\nSummary I hope you find these resources useful. I want to remind you that this is far from an exhaustive list. I left out many excellent blogs to subscribe to, people to follow, and articles to read. I wanted to keep things simple, and just give you a jumpstart on your journey to becoming a true GTM stalker.\nI don\u0026rsquo;t really need to even say this, but none of the references in this articles was paid for or solicited in any way, and no one coerced me to add them to the list. I genuinely think that these are excellent resources for you to keep up your GTM skills, and I truly hope you take a look at them!\nDon\u0026rsquo;t forget to follow the vibrant Google+ community, and if you have problems you can always share them in the Product Forums as well.\nPlease share YOUR favorite resources in the blog comments! Let\u0026rsquo;s spread the love.\n"
},
{
	"uri": "https://www.simoahava.com/blog-statistics/",
	"title": "Blog Statistics",
	"tags": [],
	"description": "",
	"content": "I started writing articles in May, 2013. The first couple of articles written during the first months of this blog\u0026rsquo;s life were not very good. Things picked up when I started focusing only on Google Analytics and Google Tag Manager articles.\nThe following statistics are powered by Google Data Studio.\n   "
},
{
	"uri": "https://www.simoahava.com/gtm-tips/track-javascript-errors-events/",
	"title": "#GTMTips: Track JavaScript Errors As Events",
	"tags": ["errors", "Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Guide for tracking unchecked JavaScript errors to Google Analytics as Google Tag Manager events.",
	"content": " Back back to the friggin\u0026rsquo; basics. Almost two years ago, I wrote a two-parter on how to have fun with Google Tag Manager: Part 1, and Part 2. The first part had a nice exercise for tracking JavaScript Errors as Google Analytics Events, using the recently published \u0026ldquo;JavaScript Error Listener\u0026rdquo; Tag.\nWell, that was in GTM V1. Now we\u0026rsquo;ve been smoothly sailing with the wonderful new interface for well over a year, and it\u0026rsquo;s time to update some of these nifty tricks. In this #GTMTips post, I\u0026rsquo;ll show you how to track uncaught JavaScript errors in the new interface, plus give you some tips on the overall process.\nTip 43: Track JavaScript Errors As Events   The process is actually really simple. Much easier than it was in the previous Google Tag Manager interface.\nBy the way, uncaught refers to an error which hasn\u0026rsquo;t been captured and handled by any of the scripts on the page. The most common way to catch an error is to use try...catch blocks around your code, which capture any errors which bubble up to the context where you have the block. If an error makes its way through without having been caught in any way, it will trigger the JavaScript Error Trigger. Thus it\u0026rsquo;s a good way to audit your current error detection methods, too!\nAnyway, you start by making sure the Built-In Variables are activated.\n  If you\u0026rsquo;re curious about these Built-In Variables, check the relevant section of my Variable Guide For Google Tag Manager.\nNext, head on over to Triggers, and create a new one:\n  I\u0026rsquo;m going to let the Trigger fire on \u0026ldquo;All JavaScript Errors\u0026rdquo;, but be sure to read to the end of this post for tips regarding this selection.\nFinally, you need a Google Analytics Event Tag, which collects and concatenates all this information. Here\u0026rsquo;s what I use:\n  An example result using these settings would be something like:\nEvent Category: JavaScript Error\nEvent Action: Uncaught ReferenceError: appear is not defined\nEvent Label: 1255: https://www.simoahava.com/scripts/bundle.js\nI\u0026rsquo;m sending the event as Non-Interaction: True, because it\u0026rsquo;s not a user interaction, and I don\u0026rsquo;t want it to be counted as such.\nAnd that\u0026rsquo;s it for the implementation!\nNow, there are some things you might want to consider when implementing this on your own website. The next chapter will tackle these issues.\nTips Tracking JavaScript Errors can be quite the bipolar experience. On the one hand, it\u0026rsquo;s just a good, solid developer attitude to want to know about what\u0026rsquo;s breaking up or already broken on your site. On the other hand, it can cause a deluge of Events in your Google Analytics profile, leading to sessions reaching their hit limits and severe sampling issues. So here are a couple of tips to manage it all.\n1. Track errors as Google Analytics Goals \u0026ldquo;Track ERRORS as GOALS, what has he been smoking?!\u0026rdquo; I hear you exclaim. Yeah, it\u0026rsquo;s not a business goal, but goals can also be negative goals. The reason I\u0026rsquo;m interested in this particular negative goal, is because I want to see a Conversion Rate for sessions with JavaScript Errors. This will allow me to do all sorts of cool analyses on how the error rates are fluctuating over time. To set up the goal, you can use the following settings:\n  Next, you can create an Alert, which sends you an email every time the number of JavaScript Errors has gone up significantly on your site:\n  Now you\u0026rsquo;ll get an email every time there\u0026rsquo;s a significant increase in the number of JavaScript Errors recorded on your site.\n2. Use Environments or the Debug Mode Tracking every single uncaught JavaScript error can lead to a deluge of hits. The modern website is best known for the number of errors it dispatches, not the fancy UI or the awesome new framework it utilizes. To keep the number of errors down, you might want to delimit them to only fire in a specific environment, or when in the Debug Mode. You could, for example, allow the Error Trigger to work only in the staging environment.\n  This way only errors triggered by your testers and developers will be recorded. The downside, of course, is that it\u0026rsquo;s not an authentic setting, and no matter how much you test and debug, you will always miss some things.\n3. Add manual sampling Another way to prevent every single error from dispatching is to manually sample the hits that are sent to Google Analytics. You could, for example, only let the Trigger fire for 50% of recorded errors. You can use the Random Number Built-In Variable here:\n  The trick is to only fire the Trigger when the Random Number Variable returns a number that ends in 0, 1, 2, 3 or 4. That\u0026rsquo;s 50% of the possible numbers it can end in.\nNaturally, the downside here is that you might miss some outlier errors, which only pop up every now and then. But you should still catch most of the significant ones.\n4. Script Error If your site is using JavaScript files loaded from external content distribution networks, the messages and line numbers of the errors dispatched in these external scripts are not exposed in the browser. This is a reality you\u0026rsquo;ll have to work with. There\u0026rsquo;s no way to identify where and what error took place, as the browser will only dispatch the nondescript \u0026ldquo;Script Error.\u0026rdquo; message with a line number of 0. The URL of the script is still exposed, though, and you can use that to narrow down the possible errors.\n  It\u0026rsquo;s a good idea to host as many scripts as possible on your own website. Not only will you know more about the errors that are thrown, but also being subservient to an external CDN can introduce security issues, if the third party decides to add some malicious or dangerous code to the library you\u0026rsquo;re using (or if they\u0026rsquo;re hacked).\nSummary I hope this tip has been useful. Tracking errors is one of the ways to make sure that your website is catering an optimized experience for your visitors. Google Analytics provides a great tool for tracking these errors, because it also lets you create session- and user-scoped segments around error events. With those segments, you can start analyzing the actual business impact of errors thrown on the site.\nAn error in the eCommerce checkout funnel can be destructive to your business, and using Google Analytics for detection can help you get on top of things before you\u0026rsquo;ve lost too much money.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/debug-google-analytics-on-your-mobile-browser/",
	"title": "Debug Google Analytics On Your Mobile Browser",
	"tags": ["debugging", "google analytics", "mobile"],
	"description": "Guide for debugging Google Analytics tracking when using your mobile phone&#39;s browser.",
	"content": " I\u0026rsquo;m currently at SMX München, which is still one of my favorite conferences in Europe. The quality of the talks is superb, and the organization is just perfect. So today, after my talk (joint session with the awesome Dave Sottimano), I was listening to the inimitable Mike King give an excellent presentation together with Ari Nahmani on technical skill prerequisites for all digital marketers today. Needless to say, I strongly agree with their view that digital marketing has always been a technical discipline, and the web is getting more and more complex each day that passes. The only way to address this flux is to hone your technical skills as much as you can.\nOne thing that Mike quickly visited was remote debugging for mobile devices. Now, debugging your website\u0026rsquo;s mobile experience is a pain, since the mobile browsers themselves give you only few tools to work with. For Google Analytics, for instance, it would be really interesting to know what requests your mobile browser is sending to GA, especially if you\u0026rsquo;re tracking stuff that\u0026rsquo;s idiosyncratic to the mobile experience. But you can\u0026rsquo;t just open a mobile browser and expect it to have the same awesome developer tools as your desktop browser.\nEnter remote debugging! You can simply plug in your iOS or Android device, and then open the web browser (Safari or Chrome, respectively) on your desktop, and in a few simple, easy-to-follow steps, you\u0026rsquo;ll be right there inspecting the DOM and analyzing the network requests! How awesome is that?\nThis isn\u0026rsquo;t a guide, just a \u0026ldquo;EUREKA\u0026rdquo; moment for myself, since it really makes it quite simple to debug your mobile browser. The steps I outline below are for the iPhone (since that\u0026rsquo;s what I use), but you can follow the steps in this guide to make it work on your Android device / Chrome combination as well.\niPhone instructions So, first of all, plug your iPhone into the USB port of your computer.\nNext, still in the iPhone, go to Settings -\u0026gt; Safari -\u0026gt; Advanced, and in the screen that opens, make sure Web Inspector is ON.\n  Open the Safari browser on the iPhone, and go to the website where you want to debug your mobile device on.\nNext thing to do is open your desktop Safari browser. In the Develop menu, you should now see your device, and when you open the device menu, you should see an entry for Safari, together with the URL of the site you\u0026rsquo;re viewing on the phone. Click that menu item.\n  TA-DA! You\u0026rsquo;re remotely debugging your iPhone, while it\u0026rsquo;s browsing the website! You can move your mouse button over the DOM elements in the Elements view to see how the Document Object Model is built on the phone.\n  You can open the Network Tab, find a request to collect (the Google Analytics endpoint), and then expand the Resource panel to view the parameters of the request and the HTTP headers and all that stuff!\n  Hell, you can even execute JavaScript in the mobile context! Want to check the state of dataLayer on your mobile browser? Easy! What about the User Agent string? Child\u0026rsquo;s play!\n  Honestly. Remote debugging. Where have you been all my life?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-content-engagement-part-2/",
	"title": "Track Content Engagement Part 2",
	"tags": ["calculated metrics", "content engagement", "custom metrics", "google analytics", "Google Tag Manager"],
	"description": "Second part of my content engagement tracking post for Google Analytics. This second part has some important clarifications to the lessons of the first one.",
	"content": " A couple of days ago, I wrote an article on tracking content engagement. Even though the solution itself works, and it\u0026rsquo;s a really neat trick if I can say so myself, it has its problems.\nAfter all the glory I showered on User Timings in Google Analytics, they have one serious flaw: they cap at 10,000 samples per day. What a ridiculous, arbitrary limit.\nIn any case, this means that if you have enough traffic to accumulate 10K user timing hits per day, it means that the solution I provided in the previous article will not work for you, as the Pageviews will not be capped, meaning the calculation of Total Engaged Time / Pageviews will be skewed.\nAfter awesome discussions with people like Al Wightman, Zorin Radovancevic, and Yehoshua Coren, this article is meant to replace the User Timings setup from the previous guide with a new solution, which utilizes Events and Custom Metrics. Since most of the article is still valid, please read the previous article all the way until you reach 4. User Timings. This is where this post will pick things up, and I\u0026rsquo;ll make sure to guide you all the way to the finish line, so you don\u0026rsquo;t have to refer back to the original article, unless you want to make sure you got all the initial steps right.\nBefore we get started Instead of User Timings, which measures milliseconds, this new solution will use a Custom Metric, which measures engagement time in seconds. This will be piggybacked on a non-interactive event hit.\nIn Google Analytics, we\u0026rsquo;ll create a Calculated Metric with the following formula:\nTotal Engaged Time / Pageviews\nSince each event is (or should) always be associated with a pageview, we can aggregate these nicely in a Custom Report we\u0026rsquo;ll build at the end of this tutorial.\nIn other words, this solution will use up a Custom Metric slot, and it will increase the event hit count for your site. If you\u0026rsquo;re already breaching the 500 hits per session limit, this might well take you over the top. But, let\u0026rsquo;s be honest, if you\u0026rsquo;re near the 500 hits per session limit, you\u0026rsquo;ve already fudged up something in your measurement plan, so don\u0026rsquo;t blame me for those mistakes!\n4. Custom JavaScript Variable Let\u0026rsquo;s pick up the steps of the previous guide with a new Custom JavaScript Variable. Name it JS - Get Engagement Time In Seconds (or something to that effect), and add the following code within:\nfunction() { return {{DLV - nonIdleTimeElapsed}} / 1000; }  This simply returns the nonIdleTimeElapsed key from the data layer divided by 1000, to get the number of seconds of engaged time collected by the script from the previous article.\n5. The Custom Metric (GA) Next, go to Google Analytics Admin. Open Custom Definitions under Property Settings, and click Custom Metrics.\nNext, create a new Custom Metric, by clicking the big red button.\n  Give the new Custom Metric a nice, descriptive name: Total Engaged Time. Make sure you\u0026rsquo;ve got Time selected as the Formatting Type, and you can keep all the other settings as they are.\n  Finally, click Save.\nMake note of the Index number assigned to the new metric. This is important!\n  That\u0026rsquo;s it for the metric!\n6. The Event Tag The Event Tag can have whatever values you want in the fields. For debugging reasons, I always include the value I\u0026rsquo;m piggy-backing on the hit (the Custom Metric in this case) as one of the fields.\n  To make this work, you will need the following:\n Values in Event Category and Event Action, since these are required fields\n A new field with name transport and value beacon to improve the accuracy of timing hits sent when the user is leaving the page\n A Custom Metric with the index number from the previous step, and the Custom JavaScript Variable you created earlier as the value\n Add the Custom Event Trigger you created in step 2 of the first guide to the Tag\n  The Custom Metric is naturally the most important part of this machine, but I strongly recommend adding the transport field as well.\n7. The Calculated Metric (GA) Almost done!\nNow, go to Google Analytics Admin, and under View Settings, click Calculated Metrics. Click the big red button with + New Calculated Metric, and make new metric look like this:\n  The important part to get right is the Formula. Instead of having to type in the brackets, you can just start typing \u0026ldquo;Total Engaged Time\u0026rdquo;, and the autocomplete should suggest the correct metric to you. Then, add the / to denote division, and finally start typing \u0026ldquo;Pageviews\u0026rdquo;, and again the tool should suggest the correct metric to you.\nGreat! Now we have our Calculated Metric, so we can build a nice, simple Custom Report to give us the low-down of our content engagement time.\n8. The Custom Report (GA) This is what my Custom Report setup looks like:\n  It\u0026rsquo;s very simple, but it yields a lot of interesting data. You can even juxtapose it with the default Average Time On Page to see the incredible discrepancy between just loading a page and actually interacting with it.\n  That\u0026rsquo;s a pretty big difference, wouldn\u0026rsquo;t you say?\nSummary Again, huge thanks to Zorin, Al, Yehoshua, and everyone else who pitched in. User Timings was a let-down, as it\u0026rsquo;s obviously not meant to be used as a data collection metric. However, I wish the sampling would be made more realistic. I perfectly understand why Page Timings are sampled, since you only need a sample to extrapolate a huge amount of useful information. But why not treat User Timings as regular hits, subject to the normal data collection limitations of the platform?\nOne of the caveats of using Custom Metrics and Events is the unpredictability of the session. For example, come midnight, the session will end, but the events will still continue collecting data in the next session, which might be without a landing page altogether! This is a problem on any site with a global audience (such as mine). However, the more data you collect, the more marginal stuff like this will be normalized out of the equation.\nIn any case, Custom Metrics lets you work around the problem of User Timings, since they can also be formatted for time. The combination of Calculated Metrics and Custom Metrics is a game-changer for Google Analytics, and has been instrumental in creating a huge amount of added value to all kinds of analytics setups.\nI hope this article has been helpful, and I\u0026rsquo;m sorry for making you pogo between two texts while trying to come up with the best way to measure content engagement on your website.\nLet me know if you have any comments or improvement suggestions!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-content-engagement-via-gtm/",
	"title": "Track Content Engagement Via GTM",
	"tags": ["calculated metrics", "content", "engagement", "google analytics", "Google Tag Manager", "user timings"],
	"description": "How to track the actual time users are engaging with your content using Google Analytics. You can use Google Tag Manager to setup the tracking.",
	"content": " When looking at Google Analytics reports, you\u0026rsquo;d think you get a pretty good idea of how people are interacting with your site, right? I mean, you\u0026rsquo;re tracking events here, pageviews there, and user timings, custom dimensions, custom metrics, and calculated metrics are all part of your daily lingo. But you\u0026rsquo;re also probably aware of how futile this tracking is. After all, all you\u0026rsquo;re seeing are numbers that reflect certain outcomes the visitors have produced on the website, and how these outcomes match against your preconceived goals and objectives, right? It\u0026rsquo;s difficult to wrap your head around the individual use cases that constantly take place on the site, and to draw overarching conclusions or unearth business trends on the basis of these data sets can be very problematic indeed.\nIn anticipation of my upcoming talk at SMX München, I thought I\u0026rsquo;d show a pretty nifty way of adjusting what content engagement means on an article-by-article basis, and how to encode this using Google Tag Manager.\nSince this blog is pretty much the only digital property I have a stake in, it\u0026rsquo;s very important to me to uncover meaning in the content data I\u0026rsquo;m looking at. I\u0026rsquo;ve done this numerous times before in articles such as:\n Track Content With Enhanced Ecommerce\n Use Page Visibility API With GTM\n Track Form Engagement With Google Tag Manager\n  And so on and so forth. But what I haven\u0026rsquo;t yet tackled, at least not really, is how much time users are actually spending engaged with my content. In other words, I want to see something like this:\n  I\u0026rsquo;m interested in knowing, among other things, out of all of the time users spend on the page, how much of it are they engaged with the page.\n!!! UPDATE !!! I\u0026rsquo;ve had to rewrite parts of this article due to a severe limitation in utilizing User Timings for data collection. Please read on until you reach step 4. User Timings. At the beginning of that step is another UPDATE, where I link you to the revised version of the article. The revised article picks up right after Step 3 and takes you all the way to the end, so you don\u0026rsquo;t have to jump back here unless you want to enjoy the comments. !!! END UPDATE !!!\nNow, this is a very difficult topic to breach, so I had to ground it somewhere. Enter Yleisradio (YLE; Finnish Broadcasting Company) and Chartbeat.\nYLE and Chartbeat A week ago I had the pleasure of visiting some friends at YLE with a group of like-minded people, all interested in analytics. What Jaakko Ojalehto, Leevi Kokko, and Sami Mattila, the guys from YLE, showed us, was how they\u0026rsquo;ve replicated Chartbeat\u0026rsquo;s research on engagement, and how they\u0026rsquo;re utilizing this data to feed their reporters and journalists with more actionable data about how their content is faring on this enormous digital property.\nChartbeat\u0026rsquo;s research showed, among other things, that the engagement window of a single user averages at around 5 seconds. So after interacting with the page with clicks, mouse movements, keyboard presses, and scrolls, the user would stay engaged for another 5 seconds, before starting to idle or changing to another window or browser tab:\nChartbeat’s JavaScript is constantly listening for acts of engagement on the in-focus webpage within an active browser (full list of events indicating engagement included below). These checks indicate when a user is actively engaged on the page and, based on a study conducted by Chartbeat, will likely remain so for five additional seconds. As this quote from their \u0026ldquo;Description of Methodology\u0026rdquo; page implies, engagement is something we can, and should, measure.\nSo I wanted to replicate what the YLE guys have been doing while replicating what Chartbeat have been doing. And I wanted to provide a simple means of doing so via Google Tag Manager. Thus the rest of this blog post will cover the steps required to send timing data to Google Analytics, where you\u0026rsquo;re measuring the cumulative time each visitor is engaged with any piece of content on your site.\nThis will give you a better understanding of active time spent on the page, as the Average Time On Page just doesn\u0026rsquo;t describe accurately the complexity of engagement. Time On Page is, after all, quite a complex and misleading metric, even if there are some excellent ways to improve it.\nWhat you\u0026rsquo;ll need To make it all work, you\u0026rsquo;ll need:\n Custom HTML Tag (GTM) - To setup the script which measures engagement time\n Custom Event Trigger (GTM) - To fire the User Timings Tag when the timings have been calculated\n Data Layer Variable (GTM) - To pick up the time engaged from dataLayer\n User Timings Universal Analytics Tag (GTM) - To send the timing data to Google Analytics\n Calculated Metric (GA) - To calculate the average time engaged per page\n Custom Report (GA) - To display the data correctly\n  Note that there are some caveats to what you can do in Google Analytics, which depend on whether you\u0026rsquo;re already using User Timings in your data collection. I\u0026rsquo;ll get back to those when discussing the calculated metric you need to create.\n1. Custom HTML Tag Create a new Custom HTML Tag, give it some fancy name, and copy-paste the following code within:\n\u0026lt;script\u0026gt; (function() { var startEngage = new Date().getTime(); var timeEngaged = 0; var idleTime = 0; var idle = true; var idleReport = false; var idleTimer, reportTimer; /* Set the user as idle, and calculate the time they were non-idle */ var setIdle = function() { idleTime = new Date().getTime(); timeEngaged += idleTime - startEngage; idle = true; }; /* Reset the 5 second idle timer. If the user was idle, start the non-idle timer */ var pulse = function(evt) { if (idle) { idle = false; startEngage = new Date().getTime(); idleReport = false; } window.clearTimeout(idleTimer); idleTimer = window.setTimeout(setIdle, 5000); }; // Utility function for attaching listeners to the window  var addListener = function(evt, cb) { if (window.addEventListener) { window.addEventListener(evt, cb); } else if (window.attachEvent) { window.attachEvent(\u0026#39;on\u0026#39; + evt, cb); } }; /* Push an event to dataLayer every 15 seconds unless the user is idle. Also, push an event when the user leaves the page */ var report = function(evt) { if (!idle) { timeEngaged += new Date().getTime() - startEngage; } // Push the payload to dataLayer, and only push valid time values  if (!idleReport \u0026amp;\u0026amp; timeEngaged \u0026gt; 0 \u0026amp;\u0026amp; timeEngaged \u0026lt; 3600000) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;nonIdle\u0026#39;, \u0026#39;nonIdleTimeElapsed\u0026#39; : timeEngaged }); } if (idle) { idleReport = true; } // Fix possible beforeunload duplication problem  if (evt \u0026amp;\u0026amp; evt.type === \u0026#39;beforeunload\u0026#39;) { window.removeEventListener(\u0026#39;beforeunload\u0026#39;, report); } timeEngaged = 0; startEngage = new Date().getTime(); reportTimer = window.setTimeout(report, 15000); }; addListener(\u0026#39;mousedown\u0026#39;, pulse); addListener(\u0026#39;keydown\u0026#39;, pulse); addListener(\u0026#39;scroll\u0026#39;, pulse); addListener(\u0026#39;mousemove\u0026#39;, pulse); addListener(\u0026#39;beforeunload\u0026#39;, report); idleTimer = window.setTimeout(setIdle, 5000); reportTimer = window.setTimeout(report, 15000); })(); \u0026lt;/script\u0026gt; Let\u0026rsquo;s take a look at the script, just briefly and superficially, so that you have an idea of what you\u0026rsquo;re doing.\nAt the very end, you have the following lines:\naddListener(\u0026#39;mousedown\u0026#39;, pulse); addListener(\u0026#39;keydown\u0026#39;, pulse); addListener(\u0026#39;scroll\u0026#39;, pulse); addListener(\u0026#39;mousemove\u0026#39;, pulse); addListener(\u0026#39;beforeunload\u0026#39;, report); idleTimer = window.setTimeout(setIdle, 5000); reportTimer = window.setTimeout(report, 15000);  Here, you\u0026rsquo;re binding the events mousedown (when a mouse button is depressed), keydown (when a key is depressed), scroll (when the page is scrolled), and mousemove (when the mouse is moved) to send a pulse that the user is engaged. If there\u0026rsquo;s a 5000 millisecond (5 second) delay between pulses, the user is set as idle.\nFinally, every 15 seconds the cumulative engaged time is sent to Google Analytics, resetting the time engaged for the next 15 second stretch.\nSo this is the heart of the script. The events are taken directly from Chartbeat\u0026rsquo;s study, and nicely cover pretty much all of the ways in which the user can tell the browser they haven\u0026rsquo;t fallen asleep. Whether or not they model engagement is another, more philosophical, question, but at least they model interaction.\nAs you can see, mobile-specific events such as touchstart and touchend are missing. This is because, first of all, the way you interact with a page while reading on your phone is different from the idle doodling you do while using a mouse. Secondly, following Chartbeat\u0026rsquo;s conclusions, creating arbitrary handlers for purely mobile browser events can be risky due to how browsers interpret touch interactions. So this is something to keep in mind when segmenting the data.\nThe three methods we use, setIdle, report, and pulse are described here:\n setIdle sets the user as idle every 5 seconds of non-interaction. When the user is idle, the timer calculating engagement will be paused. Also, only the first \u0026ldquo;report\u0026rdquo; to dataLayer will be pushed. After that, nothing is pushed to dataLayer until the user starts engaging with the page again.\n report pushes the current time engaged to dataLayer, and resets all necessary timers and variables.\n pulse is what keeps the user \u0026ldquo;active\u0026rdquo;. If the user was idle, it sets their idle status to false, and the 5 second idling timer is also reset at this point.\n  It might seem complicated (I sure hope it doesn\u0026rsquo;t), but it\u0026rsquo;s actually a very simple set of scripts.\nSet this Custom HTML Tag to fire on a Page View / DOM Ready Trigger. You want to start engagement calculations only after the page content can be interacted with.\n2. Custom Event Trigger To fire your User Timings Tag (coming to that soon) when the engagement time is pushed into dataLayer every 15 seconds, you only need a Custom Event Trigger. It should look like this:\n  Hooray, that was easy.\n3. Data Layer Variable You\u0026rsquo;ll need to grab the time engaged from dataLayer, so create the following Data Layer Variable:\n  Quite simple as well, right?\n4. User Timings Tag !!! UPDATE !!! User Timings has one major flaw: it has a daily limit of 10,000 hits, which includes Page Timings. This means that if your site is even marginally at risk of collecting this many timings altogether, the rest of this article will not work for you. In fact, I strongly recommend you stop reading the rest of the steps here, and jump instead to the revised steps I wrote, which utilize an Event Tag and a Custom Metric Tag. I\u0026rsquo;m sorry for making you jump between texts, but the truth is that User Timings have proven to be a subpar data collection method, even if I think they\u0026rsquo;re excellent in so many other ways. So, read the rest of this article at your own peril, as the actual average engagement you\u0026rsquo;ll be collecting might well be very much off the mark. !!! END UPDATE !!!\nSo now you\u0026rsquo;ll need a Tag which pulls all this information together, and dispatches it to Google Analytics.\nWe\u0026rsquo;ll use the amazing User Timings Tag Type for this. User Timings, if you didn\u0026rsquo;t know, are just about the coolest feature of Google Analytics, and ridiculously useful for collecting arbitrary time measurements. I\u0026rsquo;ve written about them before a number of times:\n Measure SERP Bounce Time With GTM\n Form Field Timing With Google Tag Manager\n Page Load Time In Universal Analytics\n  So, create the Tag and make it look something like this:\n  Remember to set the transport : beacon field in the Fields to Set. This is a very useful, albeit poorly supported, feature of Google Analytics, which attempts to preserve any hits that are sent while the user is leaving the page. I have, of course, written about this before, too.\nMake this User Timings Tag fire on the Custom Event Trigger you created earlier.\nAnd that\u0026rsquo;s it for data collection! Now Google Tag Manager will send a User Timings hit to Google Analytics every 15 seconds, where the timing value will be the time the user spent interacting with the page during that 15 second stretch.\nNow we\u0026rsquo;ll want to look at this data in Google Analytics, so that we can get an idea of how much people are interacting, by average, which each page on the site.\nCaveat There\u0026rsquo;s a very important caveat to discuss before proceeding. To calculate Average Engagement Time, you\u0026rsquo;d want to calculate the total milliseconds spent engaged with the Pageviews for each page. Unfortunately, User Timings are not bound to a Pageview, as they exist as their own hit type. In other words, it\u0026rsquo;s impossible to request only specific User timings per specific Pageviews in a calculated metric or by using a custom report with report filters.\nSo, the only way the following will work is if this is the only User Timing you\u0026rsquo;re measuring, because then you can create a calculated metric which calculates the average of all User Timings per all Pageviews, giving you what we\u0026rsquo;re after.\nIf this isn\u0026rsquo;t possible in your case, you might want to pull both Pageview and User Timings data out of Google Analytics, and join them together in Google Sheets or a tool like Klipfolio.\nIf you have a good idea on how to circumvent this problem in Google Analytics, I\u0026rsquo;m all ears. Using the default Avg. User Timing metric will not work, as that\u0026rsquo;s bound to the size of the User Timing Sample, and not Pageviews. Using Custom Metrics might work, but I\u0026rsquo;m having a hard time figuring out how to align them with Pageviews.\n5. The Calculated Metric Calculated Metrics are cool. No, they\u0026rsquo;re awesome. They let you do calculations! On metrics! COOL AND AWESOME!\nBefore you proceed, don\u0026rsquo;t forget to checkout some of the amazing articles my friends have written about Calculated Metrics:\n Analytics Pros - 25 Calculated Metrics For Google Analytics\n Lunametrics - New Calculated Metrics In Google Analytics\n Avinash Kaushik - Excellent Analytics Tip #27: Chase Smart Calculated Metrics!\n Peter O\u0026rsquo;Neill - A Powerful Use Case for GA Calculated Metrics\n Yehoshua Coren - Google Analytics Custom Metrics And Calculated Metrics\n  Honestly, seems like anybody who\u0026rsquo;s a somebody in web analytics has written about this feature, and that speaks heaps about how useful calculated metrics are!\nSo, the metric we\u0026rsquo;ll use will calculate the average user timing by the simple formula of total User Timing value / total Pageviews. Since the Time formatting type expects seconds as the input value, we\u0026rsquo;ll need to divide the total user timings value by 1000 to convert milliseconds to the required format. Anyway, the metric setup looks like this:\n  To find this screen, go to your View Settings in GA Administration, and choose Calculated Metrics (BETA). Next, click the ominous, big, red button labelled + New Calculated Metric, and make sure the settings match with the screenshot above.\n6. The Custom Report Finally, let\u0026rsquo;s pull it all together in a Custom Report. You can see a screenshot of the report itself at the beginning of this post, so here\u0026rsquo;s what the report settings would look like:\n  I\u0026rsquo;ve got Bounce Rate and Entrances there as well, so that I can get an idea of how sessions with these Page Views actually performed in terms of bounces and initial acquisition, but what\u0026rsquo;s important is the juxtaposition of Page Views, Average Engagement, and Average Time On Page.\nSummary Looking at Average Engagement versus Average Time On Page is illuminating. ATOP tells us how much time it took from one page view to another, but it doesn\u0026rsquo;t tell us anything about the quality of that time. With Average Engagement, we\u0026rsquo;re measuring the time user interacted with the page, i.e. kept it in focus and did something.\nDoes this tell us anything about whether the user read the page or how they digested the contents? No, of course not. We\u0026rsquo;d need a probe in their brain to uncover intent like that. But this data increases the significance and the meaning of the Time On Page metric, by describing actual, interactive time rather than just arbitrary time between two pageviews. It\u0026rsquo;s a far more powerful indicator than any of the out-of-the-box metrics in Google Analytics, and a crucial cog in the machine you\u0026rsquo;re building, whose job is to slowly, painfully open the lid on the can of worms, with the huge label of \u0026ldquo;USER INTENT\u0026rdquo; plastered on the side.\nAgain, huge thanks to the guys at YLE and to Chartbeat for the interesting and pioneering work they\u0026rsquo;ve done. I hope the steps within this tutorial will help you in uncovering yet another interesting aspect of the users\u0026rsquo; browsing behavior on your site!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-analytics-endpoint-debugger/",
	"title": "Google Analytics Endpoint Debugger",
	"tags": ["debug", "google analytics", "measurement protocol"],
	"description": "Guide to using the Google Analytics collection endpoint debugger.",
	"content": " This is a really cool feature for Google Analytics data collection, of which I\u0026rsquo;ve heard very, very little buzz. It\u0026rsquo;s a way to debug any and all hits sent to the Google Analytics endpoint at https://www.google-analytics.com/collect.\n  In all simplicity, you just need to copy the entire URL of the HTTP request to your clipboard, paste it into a web browser, and add /debug between the hostname and /collect.\nA few words on the Measurement Protocol Let\u0026rsquo;s take a quick step back and remind ourselves of one important thing. Every single time you\u0026rsquo;re sending a hit to Google Analytics, whether it be via mobile app SDKs, analytics.js on your website, or by using arbitrary HTTP requests, you\u0026rsquo;re using the \u0026ldquo;Measurement Protocol\u0026ldquo;. In other words, MP is not a discrete, isolated method of data transfer, but rather the underlying protocol that all the SDKs and libraries use as the method of dispatching payload data to GA.\nSo, when you hear a discussion along the lines of:\nJANE: Let\u0026rsquo;s just configure the ga('send'...) commands on the page to incorporate that feature. JACK: Nah, let\u0026rsquo;s use Measurement Protocol instead.\nThey\u0026rsquo;re actually talking about the same thing. However, what Jack is probably referring to is a manually built HTTP request to the /collect endpoint, using any of the zillions of different ways to do so. When you use the ga('send'...) syntax, you\u0026rsquo;re communicating with the analytics.js library, and abstracting the HTTP request build process with a simplified shorthand syntax.\nYou can verify this by browsing to a Universal-Analytics-enabled website, opening the browser\u0026rsquo;s debugging tools, and looking at the network requests the site is sending:\n  Why is this significant? Why am I quibbling on semantics? Well, for one, I love to nitpick. But also, especially with the whole phenomenon of referral spam, people have been condemning Measurement Protocol as it introduces an open, unauthenticated venue for spamming a Google Analytics reporting profile.\nWell, the reason it\u0026rsquo;s open and unauthenticated is because your website relies on the same protocol. If you were to add a layer of authentication there, it would need to happen server-side, as a spammer would be able to just visit your site, copy the payload request, and spam it until the authentication expires. Also, authentication would add latency, and that would affect Real Time reporting as well as the time for data to enter your reports.\nBut I\u0026rsquo;m sidetracking. Let\u0026rsquo;s get back on topic.\nUsing the debugger As I mentioned, this hasn\u0026rsquo;t really been advertised, for some odd reason, but it is there. In fact, there\u0026rsquo;s even a support page for this feature.\nSo let\u0026rsquo;s go back to the example of the browser\u0026rsquo;s developer tool, and inspecting the network request to /collect. Copy the entire request URL (in Chrome it\u0026rsquo;s right-click =\u0026gt; Copy Link Address on the request), and paste it into a new browser window.\nIf you now press Enter, your browser will simply send the request to GA. However, before you press Enter, add /debug into the URL, between the hostname and /collect, so it looks like this:\n  And now press Enter. You should see the response in your web browser:\n  Since you\u0026rsquo;re copying a request sent by your website, you should hope it\u0026rsquo;s valid. If it isn\u0026rsquo;t, start working on a fix!\nWhy it\u0026rsquo;s useful Well, for one, you can debug your hits and see if there\u0026rsquo;s something wrong with them. Common mistakes include when you\u0026rsquo;ve got a field value wrong in your code, or when you\u0026rsquo;ve forgotten to add a field which is required. For example, setting Event Value to a blank string or a decimal number would return an error, as if the field is in the request, it always needs to be an integer.\nAnother good use case is for when you\u0026rsquo;re actually using the Measurement Protocol in your custom setups. The debugger returns a response object, meaning you can debug your setup without actually sending data to Google Analytics! By parsing the response, you can easily identify if your custom payload is working or not.\nI know I\u0026rsquo;m in the geek camp with this, but this feature is definitely packing a kiloton worth of awesome in a small space. This is a perfect way to test your setups without sending actual data to Google Analytics, and the response object has lots of information, all missing from the actual request to /collect.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/check-if-dom-ready-or-window-loaded-have-fired/",
	"title": "#GTMTips: Check If DOM Ready Or Window Loaded Have Fired",
	"tags": ["Google Tag Manager", "gtmtips", "triggers"],
	"description": "When firing your tags, check if DOM Ready or Window Loaded events have already been triggered in Google Tag Manager.",
	"content": " Every now and then I run into a problem which needs some creativity to find a fix. When choosing a course of action, I tend to land first on an extremely complicated solution. However, if I\u0026rsquo;m patient enough, I manage to whittle it down to something far more manageable and efficient.\nIn this #GTMTips post, I\u0026rsquo;ll show you one of these extremely simple solutions to a problem which you might normally overcomplicate. The solution is a very well hidden feature of Google Tag Manager, buried deep in the bowels of the google_tag_manager interface.\nTip 42: Check if DOM Ready or Window Loaded have triggered   This tip is very, very simple. Basically, there are two flags in the google_tag_manager interface, and they are activated first when the \u0026ldquo;DOM Ready\u0026rdquo; event takes place, and then when the \u0026ldquo;Window Loaded\u0026rdquo; event takes place.\nIf you didn\u0026rsquo;t have access to these flags, your remaining options would be something horrible like going through the dataLayer Array, looking for the gtm.dom and gtm.load, or creating your own listeners for the DOM and window load events. Both have timing issues in Google Tag Manager, and both add extra complexity to a situation which could already be solved using something that is native to Google Tag Manager.\nAnyway, you can use these interface flags to make sure your Triggers don\u0026rsquo;t fire before either one of the page load Triggers have activated. A typical use case would be that you have a slowly loading site, and you don\u0026rsquo;t want a Trigger to go off before the DOM has completely loaded or all the linked resources (e.g. jQuery) have been downloaded.\nThis is how it works:\nwindow[\u0026#39;google_tag_manager\u0026#39;].dataLayer.gtmDom; // true when DOM Ready has fired window[\u0026#39;google_tag_manager\u0026#39;].dataLayer.gtmLoad; // true when Window Loaded has fired  These are the global flags. To get the data into GTM, create two JavaScript Variables:\n  Now you can check if these Variables return true, and use that in the Triggers to establish some order into the chaos of the page load.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/ga-snippet-and-ga-gtm-tag-on-the-same-page/",
	"title": "GA Snippet And GA (GTM) Tag On The Same Page",
	"tags": ["google analytics", "Google Tag Manager", "snippet", "tracker"],
	"description": "Guide to what happens if the Google Analytics JavaScript snippet and Google Tag Manager&#39;s container snippet coexist on a web page.",
	"content": " In this article, I\u0026rsquo;m going to tackle one of the most frequently asked questions out there:\nCan you run Google Analytics using the snippet AND using a Google Tag Manager Tag on the same page?\n  There are many facets to this query, so I\u0026rsquo;ll try to tackle as many of them as I possibly can.\nFirst, a terminology rant. You hear lots of talk about \u0026ldquo;on-page\u0026rdquo; and \u0026ldquo;inline\u0026rdquo; Google Analytics tracking, as that\u0026rsquo;s what\u0026rsquo;s used to describe the non-GTM way of tracking Google Analytics. Well, all the power to you, but I think they\u0026rsquo;re just adding to the confusion. GTM is just as \u0026ldquo;on-page\u0026rdquo; and \u0026ldquo;inline\u0026rdquo; as GA\u0026rsquo;s own snippet, as both are based on injecting an asynchronous HTTP request that downloads the respective library.\nI\u0026rsquo;ve chosen to use snippet-based tracking to describe Google Analytics tracking that\u0026rsquo;s outside GTM, and Tag-based tracking to describe Tags run through GTM. Note the capital \u0026rsquo;T\u0026rsquo;, as that\u0026rsquo;s the syntax I most commonly use in this blog to denote Google Tag Manager assets.\nI\u0026rsquo;m fully aware this distinction can cause confusion as well, but since I\u0026rsquo;d hesitate to ever call the ga('send',...) commands on the page \u0026ldquo;tags\u0026rdquo; of any kind, I think this makes a bit more sense.\nThe premise: what the problem really is Most often this question gets asked when migrating to Google Tag Manager. There was a crazy amount of questions about this in the Google Tag Manager Fundamentals course forums, where I was volunteering my help. There were so many questions about it that I felt the need to write the following intro to course participants:\n  I don\u0026rsquo;t know if it helped, but at least it let me jot some things down that would be helpful to anyone pondering about these issues.\nThe problem itself is usually a manifestation of the following, underlying queries:\n Will just adding Google Tag Manager to the site break my existing Google Analytics tracking?\n Will adding a Google Analytics Tag in GTM break my existing Google Analytics tracking?\n Can I run the bulk of my tracking via the Google Analytics snippet, and use Google Tag Manager Tags for tracking certain specific things?\n Can I run the bulk of my tracking via Google Tag Manager, and use ga('send',...) commands on the page to cover some, usually legacy, tracking needs?\n I\u0026rsquo;m just curious, how does snippet-based tracking differ from GTM\u0026rsquo;s Tag-based tracking?\n  The last question is just the best, I can\u0026rsquo;t wait to get to it!\nOK, I\u0026rsquo;ll start with it! That\u0026rsquo;s how crazy and unpredictable I am.\n5. Snippet-based vs. Tag-based tracking When you create your Google Analytics tracker using the given snippet, you have the option of providing a tracker name vs. using the default name.\nFor example, if you want to name the tracker SuperTracker, you\u0026rsquo;d use the following syntax in the tracker creation command:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;SuperTracker\u0026#39;});  This would give the tracker a name, after which you interact with it by prefixing all commands sent to the ga() queue with the tracker name: ga('SuperTracker.send', 'pageview);.\nIf you don\u0026rsquo;t provide a tracker name, you can use the naked ga('send',...) syntax, where you don\u0026rsquo;t use a tracker name prefix. However, the tracker does have a name: t0 (t-zero). So the following two commands do the same thing:\nga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); ga(\u0026#39;t0.send\u0026#39;, \u0026#39;pageview\u0026#39;);  This is clear, yes? The reason you\u0026rsquo;d want to rename the tracker is if you\u0026rsquo;re running multiple trackers on the page, or due to some very special edge cases I might or might not touch upon later in the article (I\u0026rsquo;m just making this stuff up as I go along).\nNow, with Google Tag Manager it\u0026rsquo;s a bit different. In GTM, whenever a Tag is injected, i.e. whenever a Tag \u0026ldquo;fires\u0026rdquo; (hate that terminology as well) due to some Trigger \u0026ldquo;firing\u0026rdquo; as well, a new tracker is created with a random, unique name:\n  So here the GTM tracker was created with the name gtm1454402957304. For you fellow nerds, look at the numbers in that string. Don\u0026rsquo;t they look vaguely familiar? That\u0026rsquo;s right, it resembles Unix time! So, in fact, the tracker name isn\u0026rsquo;t random, it\u0026rsquo;s just the exact timestamp of when the tracker was created, down to the millisecond. So it\u0026rsquo;s not deterministically unique, either, but having two Tags fire at the exact same millisecond is, as far as I know it, next to impossible.\n  So, now the major difference is spelled out for you: the GA snippet requires that you either use a fixed, default tracker name when creating the tracker, or you give it a custom name. This tracker name is then used when communicating with the tracker object.\nGTM, on the other hand, creates a new, unique tracker name for every single Tag on the page - even when the same Tag is injected multiple times.\nThis is, in fact, how GTM manages to navigate through one of the biggest flaws of the platform. I\u0026rsquo;ve outlined this in a previous article on the dangers of messing with the tracker name setting in GTM\u0026rsquo;s GA Tags. In a nutshell, GTM doesn\u0026rsquo;t let you assign settings, fields, custom dimensions and the ilk on the hit itself, but they\u0026rsquo;re always set on the tracker object. This means that they are \u0026ldquo;hit-scoped\u0026rdquo; by default, since each Tag has its own tracker, but if you mess with the tracker name you\u0026rsquo;ll run into some unexpected side effects.\nNow that we have the basics sorted out, let\u0026rsquo;s jump into the queries themselves.\n1. Will Google Analytics break if just Google Tag Manager is installed on the page? This is easy to answer:\nNO, IT WILL NOT!\nRemember, Google Tag Manager has nothing to do with Google Analytics when you add the container on the page. It\u0026rsquo;s just a container, a chassis, a receptacle, a vehicle, a vessel (making the most out of my thesaurus here) for your Tags and other arbitrary JavaScript you want to execute on the page.\nWhen you add the Google Tag Manager container snippet to the page, all it does is load a library from Google servers. It doesn\u0026rsquo;t create any Google Analytics trackers, it doesn\u0026rsquo;t mess with your tracking code, it doesn\u0026rsquo;t interfere with other JavaScript running on the site, or anything like that.\nIn other words, feel free to add the container snippet to the page the minute you\u0026rsquo;ve created the container.\n2. Will adding a Google Analytics Tag in GTM break my existing tracking? This is also easy to answer:\nNO, IT WILL NOT!\nNow, choose your favorite conjunct: \u0026ldquo;However\u0026hellip;\u0026rdquo; / \u0026ldquo;But\u0026hellip;\u0026rdquo; / \u0026ldquo;Unless\u0026hellip;\u0026rdquo;. I\u0026rsquo;ll go with the first one.\nHowever, if you\u0026rsquo;ve manually set the Google Tag Manager tracker name to the GA tracker name, and you don\u0026rsquo;t know what you\u0026rsquo;re doing, problems can arise.\nI\u0026rsquo;ve covered many of these cases in my tracker name rant.\nThe most important thing to note is that if the tracker name is shared between the snippet-based tracker and GTM\u0026rsquo;s Tag, each time a new tracker is created on the page (usually via GTM) with that name, any settings it has will overwrite all the previous settings on any of the trackers.\nSo, for example, let\u0026rsquo;s say you\u0026rsquo;ve created the snippet-based tracker with:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;);  And then you set the Tracker name in GTM to blank:\n  Now, since you only create the tracker once when using snippet-based GA tracking, any GTM Tag that shares the tracker name and fires after the snippet-based tracker will overwrite all the settings that were in the snippet-based tracker.\nSo, let\u0026rsquo;s say you\u0026rsquo;re tracking to UA-12345-1 in the snippet, using the ga('create','UA-12345-1') command to create the tracker. Then, you have an Event Tag in GTM, collecting data to \u0026lsquo;UA-12345-2\u0026rsquo;, and firing after 15 seconds of dwell time on the page. If this Tag has the same tracker name as the snippet-based tracker, any ga('send',...) commands you run on the page after this GTM Tag has fired will now use the settings in the GTM Tag, including the new property ID.\nYou can see how this is potentially a huge problem.\nBut like I wrote in the beginning of this chapter, if you don\u0026rsquo;t mess with the tracker name setting, there will be no interference. You can freely track via Google Tag Manager to a Google Analytics property, and then keep the snippet-based tracker collecting data to some other property, if you wish.\nThis is a great segue to the next question.\n3. Run the bulk of tracking via the snippet, and use GTM for specific things In this case, we want to combine snippet-based GA tracking with Google Tag Manager Tags.\nInteresting!\nWell, it\u0026rsquo;s certainly doable. You can easily have a snippet-based tracker track to UA-12345-1, and then add the occasional Tag via GTM to also track to UA-12345-1, and you don\u0026rsquo;t have to make any changes if working with default settings. Google Analytics uses a combination of Client ID found in the _ga cookie together with the UA-XXXXX-Y code to make sure hits are attributed to the same session and the same user.\nThere are some cases where you will need to make changes:\n If you\u0026rsquo;re using custom cookie settings in either, make sure they match between the snippet-based tracker and all the Google Analytics Tags you\u0026rsquo;re running via Google Tag Manager into the same GA property.\n If you\u0026rsquo;re using custom traffic source tracking, make sure you respect these in all the Tags and snippet commands sending data to the same Google Analytics property. For example, if you GA snippet is sending the ?utm-parameters with the page URL, but in GTM you\u0026rsquo;re overwriting the page name with something customized, it\u0026rsquo;s possible the GTM Tag will use the referrer instead, creating a new session since the traffic source changed.\n  All in all, try to make all fields and settings match between the trackers. This way you won\u0026rsquo;t run into surprises when one creates a session and the other one creates a new session immediately after due to a discrepancy in the tracker settings.\n4. Using GTM to drive tracking, and occasionally resorting to snippet-based commands This is a tricky one. Usually it\u0026rsquo;s because there\u0026rsquo;s a huge, sprawling legacy library for snippet-based tracking, and the user wants to migrate one command at a time.\nThe easiest way to make it work is to remember to have the Google Analytics snippet and tracker creation commands on each page as before. If you do this, there won\u0026rsquo;t be any conflicts as long as you respect the tips in the previous chapter.\nHowever, if you\u0026rsquo;re in a jam where you only have a ga('send',...) command here or there, without any tracker creation via the snippet, things get much more complicated. To make it work, the following things need to happen:\n The ga('send',...) cannot be run before the first GTM Tag has been added to the page. Before that, the ga() function doesn\u0026rsquo;t exist in the global namespace.\n The Google Tag Manager Tag needs to have its Tracker Name setting set to blank (if you\u0026rsquo;re using ga('send',...) on the page), or to a custom name, in which case the snippet-based commands need to use that name as well: ga('customName.send',...).\n  The first one is very difficult to respect, since the Google Tag Manager is downloaded asynchronously. To mitigate this, you can add this line to the \u0026lt;head\u0026gt; of each page, before any ga() functions are called:\n\u0026lt;script\u0026gt; window[\u0026#39;GoogleAnalyticsObject\u0026#39;] = \u0026#39;ga\u0026#39;; window[\u0026#39;ga\u0026#39;] = window[\u0026#39;ga\u0026#39;] || function() { (window[\u0026#39;ga\u0026#39;].q = window[\u0026#39;ga\u0026#39;].q || []).push(arguments) }; \u0026lt;/script\u0026gt; This is taken from the Universal Analytics snippet, and it basically creates a temporary data store for all ga() commands that exist before the analytics.js library has been created.\nIf you take all the previous tips into account, then there should be minimal problems with combining tracking methods like this. However, it\u0026rsquo;s still suboptimal, and can lead to unexpected problems due to the complexity of the code you need to manage and maintain.\nSummary What started as a simple foray into tracker discrepancies blossomed into a sprawling, overly complex account of how tracking works across the Google Analytics snippet and Google Tag Manager\u0026rsquo;s Tag templates.\nBottom line is, if you do want to combine tracking across the two methods, you need to make sure that tracker settings match across the board.\nOn the other hand, if you want to track each tracker method to a different Google Analytics property, you need to make sure that certain tracker settings do NOT match across the trackers.\nAll in all, you\u0026rsquo;ll commonly hear people suggesting that you move to Google Tag Manager in all your tracking needs. I tend to agree in general, but there are many, many solid reasons for keeping the snippet-based tracker, at least for a little while.\nWhenever I do a migration from snippet-based to Google Tag Manager -based tracking, I run the two simultaneously (to different properties) until I\u0026rsquo;m satisfied the migration has been a success.\nSimilarly, it\u0026rsquo;s not an altogether bad idea to keep the snippet-based tracker on the page for a while, just so you can benchmark the two different tracker setups in your data, and perhaps use the information to improve overall data quality.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/be-careful-with-the-tracker-name-setting/",
	"title": "#GTMTips: Be Careful With The Tracker Name Setting",
	"tags": ["Google Tag Manager", "gtmtips", "tracker", "universal analytics"],
	"description": "A word of caution if you want to modify the Tracker Name setting in your Google Tag Manager tags.",
	"content": " Hello friends! Today I want to direct your attention to a dangerous setting found within the bowels of the Universal Analytics Tag template in Google Tag Manager. In fact, GTM itself highly discourages you from meddling with it:\n  I actually agree with this warning. It should be highly discouraged, as modifying the tracker name introduces a potential hazard to your tracking plan, unless you know what you\u0026rsquo;re doing.\nBut I\u0026rsquo;m getting ahead of myself, let\u0026rsquo;s take a step back and look at just what we\u0026rsquo;re doing here.\nTip 41: One tracker name to rule them all   By setting the Tracker Name field, you can have multiple Google Tag Manager Tags use the same tracker name (for various purposes), or you can combine your on-page, traditional analytics.js tracking with tracking done via GTM\u0026rsquo;s Tag templates.\nDavid Vallejo\u0026rsquo;s written a great guide for tracking single-page sites. This solution relies on setting a Tracker name across your tag templates, and I consider it to be the only solid way of fixing the \u0026ldquo;rogue referral\u0026rdquo; problem that single-page sites have with GTM.\n(Just for reference, the problem with rogue referrals is that after the initial landing page hit with the UTM and/or GCLID parameters, any referrer information in the HTTP request will override these campaign settings due to how Universal Analytics processes referrals. In other words, after the landing page, any virtual pageview that does not have these UTM and/or GCLID parameters will, by default, be sent with the referrer as the campaign source, potentially starting a new session).\nHowever, before dashing to your GTM container (why would you do that anyway?), pause for a moment. Google Tag Manager, by default, uses a random, unique tracker name with each instance of a Tag, even if they\u0026rsquo;re injected by the same Tag template. This means that, by default, no two Tags fired via GTM ever share the tracker name.\nThis, in turn, means that settings you set in one GTM Tag will never be inherited by any other Tags. Thus you can\u0026rsquo;t make use of settings that would apply to multiple Tags simply by modifying the fields in one. You will need to replicate the settings across the Tags.\nTo solve the inheritance problem, all you need to do is set the multiple Tags to use the same Tracker name. This way, the settings you set in one Tag will affect the settings in all the subsequent Tags that share the Tracker name! How simple and beautiful. To fix the \u0026ldquo;rogue referral\u0026rdquo; problem in AJAX sites, you\u0026rsquo;d set the same Tracker name for each Tag, since now they\u0026rsquo;ll share the \u0026ldquo;Document Location\u0026rdquo; setting, meaning a possible referral will not override any UTM Tags or AdWords GCLID settings in the URL itself.\nWonderful.\nHowever, and this is a very emphatic \u0026ldquo;however\u0026rdquo;, setting the Tracker name will share all settings across the Tags! Yes, that\u0026rsquo;s right, even hit-scoped Custom Dimensions and any fields you set for one Tag alone. In GTM, at the moment, there\u0026rsquo;s no way to differentiate between fields you set for a hit and fields you set for the tracker. Only the latter exists in GTM.\nNaturally, if you do not touch the Tracker name setting, these fields are, in essence, \u0026ldquo;per hit\u0026rdquo;, since each Tag has a unique Tracker, right? But when you set the Tracker name across multiple Tags, they will share all the field settings whether you want them to or not.\nThis leads to some embarrassing situations, and it requires quite a hacky workaround. For example, if you set the Tracker name in Tag 1, and you also add a hit-scoped Custom Dimension that you want to apply to that Tag alone, in your next Tag with the same Tracker name, you\u0026rsquo;ll need to add a null-returning Custom JavaScript Variable to the same Custom Dimension field to ensure it isn\u0026rsquo;t inherited from the first Tag:\nfunction() { return null; }  That\u0026rsquo;s just clumsy.\nSo, my point is this. When you\u0026rsquo;re setting the Tracker name across your Tags, whether by design or because you\u0026rsquo;ve read the tip online somewhere, make sure you audit the fields you set in the Tags. If any of them should exist in one Tag alone, you will need to manually clear the those fields in all the other Tags that use the same Tracker name.\nI hope, no, I beg that Google Tag Manager would let you decide whether to set fields only for the Tag rather than for the Tracker name. This would solve a lot of issues.\nAlternatively, I wish analytics.js would take care of the \u0026ldquo;rogue referral\u0026rdquo; problem natively, making sure subsequent page views after the landing page (with the UTM parameters) would not utilize the HTTP referrer to override the currently active source/medium.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/data-layer-variable-versions-explained/",
	"title": "#GTMTips: Data Layer Variable Versions Explained",
	"tags": ["data layer", "data model", "Google Tag Manager", "gtmtips"],
	"description": "A guide to how the two versions (1 and 2) of Google Tag Manager&#39;s Data Layer variable work, and how they are different from each other.",
	"content": " Google Tag Manager\u0026rsquo;s Data Layer is something I\u0026rsquo;ve touched upon in pretty much all of my articles. It\u0026rsquo;s such an integral part of what makes a tag management solution great and applicable to a host of business scenarios. I\u0026rsquo;ve also talked at length about the internal data model of Google Tag Manager, and this #GTMTips post is very much related to this rather murky concept.\nIn this post, we\u0026rsquo;ll go over the Data Layer Variable Version selection, and I\u0026rsquo;ll try to explain just what this selector does.\nTip 40: The two faces of the Data Layer Variable   Let\u0026rsquo;s start by taking a step back. As a technical construct, the \u0026ldquo;Data Layer\u0026rdquo; in GTM is a JavaScript Array, which usually comprises a number of plain objects that have been pushed into its innards on a web page.\n  As you\u0026rsquo;ve learned from my data model article, GTM doesn\u0026rsquo;t actually access this Array when you create your Data Layer Variables. Instead, when an object is pushed into dataLayer, it\u0026rsquo;s made available to the data model of Google Tag Manager, and any Data Layer Variables you create will refer to these instances in the data model rather than directly accessing the Array itself.\nWhy? To decouple the Array from the internal mechanisms of the connected platform (GTM in this case). This is quite important, as the less GTM needs to rely on the abstract structure of dataLayer, which could be manipulated at any time by either sloppy code or another connected platform, the better.\nNow, when you select the Version of the Data Layer Variable, you\u0026rsquo;re instructing GTM to treat the values in the data model in two different ways.\nVersion 1 Version 1 of the Data Layer Variable has a very limited reach. Basically, the key-value pair that is pushed into dataLayer needs to be in the root of the object, as Version 1 doesn\u0026rsquo;t let you access nested keys.\nHere\u0026rsquo;s an example of what would happen with a Version 1 Data Layer Variable that points to key name 'product.price':\n// Works because the dots are in the key name, and the key is in the root: window.dataLayer.push({ \u0026#39;product.price\u0026#39; : \u0026#39;11.99\u0026#39; }); // Won\u0026#39;t work because \u0026#39;price\u0026#39; is nested in the \u0026#39;product\u0026#39; object: window.dataLayer.push({ \u0026#39;product\u0026#39; : { \u0026#39;price\u0026#39; : \u0026#39;11.99\u0026#39; } });  You could, though, access the nested object indirectly with a Version 1 Data Layer Variable by creating the variable for the key 'product', and then manipulating the returned object in a Custom HTML Tag or a Custom JavaScript Variable.\nAnd\u0026hellip;yeah. That\u0026rsquo;s all that Version 1 does. There\u0026rsquo;s no merging, no special data model functions, no nothing that you can use to further manipulate the retrieved object. So let\u0026rsquo;s take a look at what happens when I push two different values for the same key ('product'):\nwindow.dataLayer.push({ \u0026#39;product\u0026#39; : { \u0026#39;price\u0026#39; : \u0026#39;11.99\u0026#39; } }); window.dataLayer.push({ \u0026#39;product\u0026#39; : { \u0026#39;name\u0026#39; : \u0026#39;Tim Duncan Fan Club Membership\u0026#39; } });  In the example above, if I had my Version 1 Data Layer Variable pointing to 'product', it would return a plain object with {'price' : '11.99'} after the first push, and a plain object with {'name' : 'Tim Duncan Fan Club Membership'} after the second.\nIn essence, any information in the first push is completely overwritten (for this particular Data Layer Variable) by the second push with the same key name ('product').\nVersion 2 If you want more flexibility, use Version 2 of the Data Layer Variable. This treats objects more like you\u0026rsquo;d expect if you\u0026rsquo;re familiar with how JavaScript works.\nInstead of bulldozing over existing keys, Version 2 first checks whether a key with that name already exists in the data model. If it does, it recursively merges information in the new push with information in the existing object.\nLet\u0026rsquo;s see an example:\nwindow.dataLayer.push({ \u0026#39;product\u0026#39; : { \u0026#39;price\u0026#39; : \u0026#39;119.99\u0026#39;, \u0026#39;category\u0026#39; : \u0026#39;Membership\u0026#39; } }); window.dataLayer.push({ \u0026#39;product\u0026#39; : { \u0026#39;price\u0026#39; : \u0026#39;1199.99\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;Tim Duncan Fan Club Membership\u0026#39; } });  So, let\u0026rsquo;s say you\u0026rsquo;re using Version 2 of the Data Layer Variable, and you\u0026rsquo;re yet again pointing to the key with name 'product'.\nAfter the first dataLayer.push(), the variable would return a plain object with:\n{ \u0026#39;price\u0026#39; : \u0026#39;119.99\u0026#39;, \u0026#39;category\u0026#39; : \u0026#39;Membership\u0026#39; }  After the second push, the contents would be:\n{ \u0026#39;price\u0026#39; : \u0026#39;1199.99\u0026#39;, \u0026#39;category\u0026#39; : \u0026#39;Membership\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;Tim Duncan Fan Club Membership\u0026#39; }  Can you see what happened here? Another object with the same key name ('product') is pushed. Version 2 of the Data Layer Variable finds an instance of this key within the data model. Then, it recursively checks each key within this object to see if there are conflicts.\nFirst, it finds that 'price' is in both objects, so there\u0026rsquo;s a clash. Next, it checks if 'price' is also a plain object or an Array to see if it should perform yet another merge deeper in the structure. However, the value of 'price' is a String, which means that no recursive merge is performed, and the new value overwrites the old one.\nNext, it sees that 'category' does not have any conflicts, so it leaves it be in the object. Finally, it finds a completely new key in the second push, 'name', and it merges this key into the existing object in the data model.\nSo using Version 2 of the Data Layer Variable, resolution of conflicts in object key names is first attempted via a merge of the two objects, but if there are new \u0026ldquo;primitive\u0026rdquo; values for any pre-existing keys, their values are overwritten just as they would be with Version 1 of the Data Layer Variable.\nSo what? This information could lead to a number of conclusions, but I\u0026rsquo;m guessing many have the following two questions pop into their minds:\n Why does the Version 1 still exist? Its numbering alone would mean that it\u0026rsquo;s inferior.\n What on earth do I need recursive merge for?\n  One of the best use cases for Version 1 is with Enhanced Ecommerce. If you\u0026rsquo;re using the Custom JavaScript Variable method, which I seem to use almost exclusively, you probably want to use Version 1 of the Data Layer when interacting with the 'ecommerce' key. This way, GTM will only access the most recent push into dataLayer. And why is this significant? Take a look at the example below:\nwindow.dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;impressions\u0026#39; : [{ ... impressions ... }] } }); // Later on the same page window.dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { ... product detail view ... } } }); // And yet later on the same page window.dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { ... add to cart action ... } } });  If you used Version 2 of the Data Layer Variable to send the Enhanced Ecommerce payload using the Custom JavaScript Variable method, you\u0026rsquo;ll end up with three Impression payloads, two Product Detail Views, and one Add to Cart action. This is because of the recursive merge of the 'ecommerce' object! I\u0026rsquo;m guessing your intent is to only send each payload once.\nSo, if you instead use Version 1 of the Data Layer Variable to access the 'ecommerce' object, GTM will only access the payload that was most recently pushed into dataLayer. This way you\u0026rsquo;ll end up avoiding the payload multiplication problem.\nAs for the second point of what recursive merge is good for, there\u0026rsquo;s a whole universe of possibilities when it comes to merging of objects instead of overwriting previous instances. Examples include:\n Updating an object as more information is revealed, e.g. collecting a history of interactions on a single page.\n Updating an object as more information becomes available, e.g. updating a \u0026ldquo;user\u0026rdquo; object as certain API calls complete.\n Making a valid merge of two Enhanced Ecommerce payloads, such as combining 'impressions' with an 'add' object.\n  There are a host of other things you can do with Version 2 of the Data Layer Variable, and those are all detailed in my data model article.\nI hope this has been illuminating, and I hope it helps you understand the rationale of having both versions available for the Data Layer Variable.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/cookie-settings-and-subdomain-tracking-in-universal-analytics/",
	"title": "Cookie Settings And Subdomain Tracking In Universal Analytics",
	"tags": ["cookiedomain", "cookies", "google analytics", "Google Tag Manager", "universal analytics"],
	"description": "How the cookieDomain settings works in your Google Analytics tags, and what happens if you don&#39;t set it.",
	"content": " Welcome back my friends (to the show that never ends)! It\u0026rsquo;s been a couple of weeks since my last barrage of articles, and I think the time is ripe to do some testing!\nFirst things first, here\u0026rsquo;s a picture of me shovelling snow:\n  And now back to the topic at hand.\nOne of the things that seems to be a hot topic in Universal Analytics is cross-domain tracking. I\u0026rsquo;ve never really tackled the beast head-on, since there\u0026rsquo;s such a wealth of excellent articles about it out there. However, I have taken a plunge into the deep end with some specific stuff, such as iframe and subdomain tracking.\nI want to pick up where I left off in the subdomain article, and focus on something really cool but complicated: cookie settings.\nFirst, take a look at the official developer guide for Universal Analytics\u0026rsquo; cookie stuff. It\u0026rsquo;s an excellent resource to get started with.\nWhat I want to talk about is what are the implications of inconsistent field settings as well as leaving the cookieDomain field out entirely from your tracker settings.\n  I give you\u0026hellip;drumroll\u0026hellip;my epic, sugar-rush, pigeon-army, mudslide, Iron Man, lollapalooza, Han-shot-first, cookie-testing-extravaganza-MIND-EXPLOSION!\nSorry.\nWhat we know Let\u0026rsquo;s start at the beginning (always a good idea). This is what we, most likely, know about Universal Analytics\u0026rsquo; cookies.\n Universal Analytics uses a single _ga cookie to establish the user dimension.\n This cookie stores a unique Client ID in its last two segments (GA1.2.12345.23456).\n By default, i.e. without any settings, the cookie is written on the current subdomain and all even more nested subdomains thereof (.sub.domain.com, .www.sub.domain.com, .simo.rules.ok.sub.domain.com would all share the cookie written on .sub.domain.com, but www.domain.com or domain.com would not).\n By setting cookieDomain to auto, or manually setting it to the topmost possible domain name (i.e. .domain.com), all subdomains can use the cookie.\n  I hope that\u0026rsquo;s all clear.\nThis is why the \u0026ldquo;tracking snippet\u0026rdquo; for Universal Analytics always has the recommendation of including 'auto' as the third parameter of the 'create' command. That\u0026rsquo;s the equivalent of adding the field cookieDomain : 'auto' into the tracker object:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, \u0026#39;auto\u0026#39;); // is the same as ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;cookieDomain\u0026#39; : \u0026#39;auto\u0026#39;});  NOTE! The Universal Analytics Tag in Google Tag Manager does not add this field by default! The implications of leaving this field out are the focus of this test, so bear with me.\nThe test I want to test the following:\n What happens if 'cookieDomain' : 'auto' is missing from your tracker, and you move across subdomains?\n What happens if there are multiple _ga cookies, each written on different domains\n What is the air-speed velocity of an unladen swallow?\n  Let\u0026rsquo;s start with the first one.\n1. No 'cookieDomain' : 'auto' set I\u0026rsquo;ll browse to test.simoahava.com, make sure there are no pre-existing _ga cookies, and type in the following command:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;test1\u0026#39;});  So, no cookieDomain anywhere. This results in a new _ga cookie, written on .test.simoahava.com:\n  You can also see where the cookie is written on:\n  That\u0026rsquo;s all clear, right?\nNext, I browse to www.simoahava.com, and run the same command:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;test1\u0026#39;});  And this is what I\u0026rsquo;ll see:\n  The cookie itself is set on the parent domain (without www.):\n  Now, let\u0026rsquo;s go back to test.simoahava.com and see what happens:\n  This is expected, of course. We see both the cookie written on the subdomain in the first step, as well as the cookie written on the main domain in the second step. The latter cookie is available here as well, as since the cookie was written on the parent domain, it can be used by all subdomains as well.\nThis has one very important implication. If you don\u0026rsquo;t have 'cookieDomain' : 'auto', and the traffic is from the parent domain to subdomains, there\u0026rsquo;s no issue here. Two different _ga cookies will still exist on the subdomain, as they have different domain settings, but they will share the same Client ID, thanks to one of the core features of the Universal Analytics library, which copies the Client ID from both pre-existing _ga cookies as well as legacy __utma cookies. Here\u0026rsquo;s an example where I first landed on the parent domain and then entered the subdomain:\n  However, if the traffic lands on the subdomain first, and then moves to the parent domain, you will end up with different _ga cookies and different Client IDs on both domains, and thus the user will be different as well!\nThis is quite significant. I\u0026rsquo;ll return to the implications later.\n2. What happens if there ARE multiple _ga cookies? Now, if you DO end up with multiple _ga cookies, two things can happen:\n They share the same Client ID, i.e. the movement was from higher-level-domain to subdomain, and all is fine.\n They have different Client IDs, i.e. the traffic was from the subdomain to a higher-level (or same-level) domain.\n  The first case is just fine. All your Tags will share the same Client ID, you won\u0026rsquo;t have problems with some Tags firing starting new sessions or creating new users, and you can sleep soundly at night.\nThe second case is problematic. Let\u0026rsquo;s say you DO end up with two different _ga cookies, and that it\u0026rsquo;s, at least you claim it is, intentional. How do you choose which cookie you\u0026rsquo;ll interact with your trackers?\nWell, actually, it\u0026rsquo;s pretty straight-forward. When you create a tracker, it will use which ever _ga cookie shares the cookieDomain setting of the tracker.\nAllow me to explain.\nLet\u0026rsquo;s say you now have two different _ga cookies, one written on .simoahava.com, and one written on .test.simoahava.com. You are now on test.simoahava.com, and you want to use the Client ID of the cookie written on this subdomain. You need to create a tracker, which would write the cookie on .test.simoahava.com if you want to interact with the cookie. In other words:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;test1\u0026#39;});  This would work, because without 'cookieDomain' : 'auto', the cookie would be written on .test.simoahava.com. Now, since a _ga cookie already exists on .test.simoahava.com, it is used in all interactions with tracker named test1.\nIf you want to interact with the cookie written on .simoahava.com, then you need to add the cookieDomain parameter, and make sure it would write the cookie on the top-most possible domain:\nga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;test2\u0026#39;, \u0026#39;cookieDomain\u0026#39; : \u0026#39;auto\u0026#39;}); // OR ga(\u0026#39;create\u0026#39;, \u0026#39;UA-12345-1\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;test2\u0026#39;, \u0026#39;cookieDomain\u0026#39; : \u0026#39;.simoahava.com\u0026#39;});  Both would do the same thing: attempt to write the _ga cookie on .simoahava.com. However, since that cookie already exists, the tracker named test2 can now be used to interact with that particular cookie.\nPhew! So much talk about cookies it makes my stomach growl.\nImplications Now, let\u0026rsquo;s talk about what this all means. I\u0026rsquo;ll split this up into a little Q\u0026amp;A, which might help interpret the results.\nQ: Should I set 'cookieDomain' : 'auto' on in all my Tags and trackers?\nA: I would say that, by default, yes. Having the setting on in all Tags ensures that the same Client ID is used everywhere across your subdomains. Even if you have Tags collecting data to different UA-XXXXX-Y properties, it doesn\u0026rsquo;t matter that they share the Client ID, since it\u0026rsquo;s just a label each property uses to assign hits to the same user.\nQ: What would happen if only one of my Tags has 'cookieDomain' : 'auto', but the others don\u0026rsquo;t?\nA: You should still be fine, as long as that one Tag fires on every single page. Basically, when a Tag fires on the page, it first checks for a pre-existing _ga cookie. If one is found, it then checks the domain on which the cookie is written, and whether or not this matches the tracker settings. If the settings match, then the Tag simply uses this cookie. If the settings don\u0026rsquo;t match, a new _ga is written on the current domain, but the Client ID is still copied from the first cookie.\nThus, as long as one Tag on the page is fired with 'cookieDomain' : 'auto', the Client ID copying mechanism ensures that the same Client ID is accessible across your domains.\nQ: What happens if I don\u0026rsquo;t have the 'cookieDomain' : 'auto' setting anywhere?\nA: In the best case scenario, nothing. This would require that traffic is always from a higher-level-domain to its subdomain. This way the subdomain can copy the Client ID from the higher-level-domain cookie.\nHowever, if traffic can be the other way around, so starting from deeper in the domain structure and moving up (or parallel), you\u0026rsquo;re in trouble. You\u0026rsquo;ll end up with different Client IDs since the cookies are not shared across the domains.\nI hate doling out \u0026ldquo;best practices\u0026rdquo; since I don\u0026rsquo;t believe they exist, but in this case we\u0026rsquo;re talking about a technological reality. I strongly recommend that you always add the 'cookieDomain' : 'auto' field to all your Tags and trackers. If that\u0026rsquo;s a stretch, then make sure that at least one Tag which is guaranteed to fire on all pages has that setting. This way the Client ID will be copied and passed across the domains.\nNext time I\u0026rsquo;ll write something lighter, I promise!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-dynamically-loaded-youtube-videos-in-google-tag-manager/",
	"title": "Track Dynamically Loaded YouTube Videos In Google Tag Manager",
	"tags": ["dynamic content", "Google Tag Manager", "videos", "youtube"],
	"description": "How to track embedded YouTube videos using Google Tag Manager, when the videos are loaded dynamically after initial page load.",
	"content": " Tracking YouTube videos in Google Tag Manager is one of the more useful things you can do in terms of tracking. YouTube has a wonderful API that you can tap into and convert the detected events into dataLayer messages.\nThere are some really good solutions out there for tracking YouTube videos in GTM:\n The wonderful solution by Cardinal Path.\n An even more thorough treatment by LunaMetrics.\n  Both do a great job of tracking videos that have been loaded with the page. However, both have difficulties with tracking dynamically loaded videos. That means videos which are loaded lazily, or in pop-ups, or when some content link is clicked.\n  In this article, I\u0026rsquo;m going to show how you can track dynamically loaded videos using LunaMetrics\u0026rsquo; solution with slight modifications. LunaMetrics is my favorite group of geeks in North America, and they bribed me with their awesome book just before Christmas, which would already be reason enough to use their code. However, their solution is also all kinds of robust, and it really lends itself to tracking dynamic stuff as well.\nWhat you\u0026rsquo;ll need The modifications will be done to the JavaScript code in the Custom HTML Tag. In other words, you can\u0026rsquo;t use LunaMetrics\u0026rsquo; CDN for this. You will have to create a Custom HTML Tag, and copy-paste the code in the next chapter within.\nAs for the rest of the stuff, just follow LunaMetrics\u0026rsquo; guide. All this does is add a method you can trigger when videos have been loaded dynamically. Don\u0026rsquo;t worry, I\u0026rsquo;ll explain the method later on as well.\nThe modified Custom HTML Tag So, follow the LunaMetrics guide, avoiding the CDN, and when you come to the chapter titled Google Tag Manager Installation, read the following instead.\nCreate a new Custom HTML Tag, and give it some cool name like Utility - Video Tracking Bomb Overload Christmas Awesome.\nSorry for that.\nNext, add the following code.\n\u0026lt;script\u0026gt; // Respectfully copied and modified from // https://github.com/lunametrics/youtube-google-analytics // // Original implementation by LunaMetrics var ytTracker = (function( document, window, config ) { \u0026#39;use strict\u0026#39;; window.onYouTubeIframeAPIReady = (function() { var cached = window.onYouTubeIframeAPIReady; return function() { if( cached ) { cached.apply(this, arguments); } // This script won\u0026#39;t work on IE 6 or 7, so we bail at this point if we detect that UA  if( !navigator.userAgent.match( /MSIE [67]\\./gi ) ) { init(); } }; })(); var _config = config || {}; var forceSyntax = _config.forceSyntax || 0; var dataLayerName = _config.dataLayerName || \u0026#39;dataLayer\u0026#39;; // Default configuration for events  var eventsFired = { \u0026#39;Play\u0026#39; : true, \u0026#39;Pause\u0026#39; : true, \u0026#39;Watch to End\u0026#39;: true }; // Overwrites defaults with customizations, if any  var key; for( key in _config.events ) { if( _config.events.hasOwnProperty( key ) ) { eventsFired[ key ] = _config.events[ key ]; } } //*****//  // DO NOT EDIT ANYTHING BELOW THIS LINE EXCEPT CONFIG AT THE BOTTOM  //*****//  // Invoked by the YouTube API when it\u0026#39;s ready  function init() { var iframes = document.getElementsByTagName( \u0026#39;iframe\u0026#39; ); var embeds = document.getElementsByTagName( \u0026#39;embed\u0026#39; ); digestPotentialVideos( iframes ); digestPotentialVideos( embeds ); } var tag = document.createElement( \u0026#39;script\u0026#39; ); tag.src = \u0026#39;//www.youtube.com/iframe_api\u0026#39;; var firstScriptTag = document.getElementsByTagName( \u0026#39;script\u0026#39; )[0]; firstScriptTag.parentNode.insertBefore( tag, firstScriptTag ); // Take our videos and turn them into trackable videos with events  function digestPotentialVideos( potentialVideos ) { var i; for( i = 0; i \u0026lt; potentialVideos.length; i++ ) { var isYouTubeVideo = checkIfYouTubeVideo( potentialVideos[ i ] ); if( isYouTubeVideo ) { var normalizedYouTubeIframe = normalizeYouTubeIframe( potentialVideos[ i ] ); addYouTubeEvents( normalizedYouTubeIframe ); } } } // Determine if the element is a YouTube video or not  function checkIfYouTubeVideo( potentialYouTubeVideo ) { // Exclude already decorated videos  if (potentialYouTubeVideo.getAttribute(\u0026#39;data-gtm-yt\u0026#39;)) { return false; } var potentialYouTubeVideoSrc = potentialYouTubeVideo.src || \u0026#39;\u0026#39;; if( potentialYouTubeVideoSrc.indexOf( \u0026#39;youtube.com/embed/\u0026#39; ) \u0026gt; -1 || potentialYouTubeVideoSrc.indexOf( \u0026#39;youtube.com/v/\u0026#39; ) \u0026gt; -1 ) { return true; } return false; } // Turn embed objects into iframe objects and ensure they have the right parameters  function normalizeYouTubeIframe( youTubeVideo ) { var a = document.createElement( \u0026#39;a\u0026#39; ); a.href = youTubeVideo.src; a.hostname = \u0026#39;www.youtube.com\u0026#39;; a.protocol = document.location.protocol; var tmpPathname = a.pathname.charAt( 0 ) === \u0026#39;/\u0026#39; ? a.pathname : \u0026#39;/\u0026#39; + a.pathname; // IE10 shim  // For security reasons, YouTube wants an origin parameter set that matches our hostname  var origin = window.location.protocol + \u0026#39;%2F%2F\u0026#39; + window.location.hostname + ( window.location.port ? \u0026#39;:\u0026#39; + window.location.port : \u0026#39;\u0026#39; ); if( a.search.indexOf( \u0026#39;enablejsapi\u0026#39; ) === -1 ) { a.search = ( a.search.length \u0026gt; 0 ? a.search + \u0026#39;\u0026amp;\u0026#39; : \u0026#39;\u0026#39; ) + \u0026#39;enablejsapi=1\u0026#39;; } // Don\u0026#39;t set if testing locally  if( a.search.indexOf( \u0026#39;origin\u0026#39; ) === -1 \u0026amp;\u0026amp; window.location.hostname.indexOf( \u0026#39;localhost\u0026#39; ) === -1 ) { a.search = a.search + \u0026#39;\u0026amp;origin=\u0026#39; + origin; } if( youTubeVideo.type === \u0026#39;application/x-shockwave-flash\u0026#39; ) { var newIframe = document.createElement( \u0026#39;iframe\u0026#39; ); newIframe.height = youTubeVideo.height; newIframe.width = youTubeVideo.width; tmpPathname = tmpPathname.replace(\u0026#39;/v/\u0026#39;, \u0026#39;/embed/\u0026#39;); youTubeVideo.parentNode.parentNode.replaceChild( newIframe, youTubeVideo.parentNode ); youTubeVideo = newIframe; } a.pathname = tmpPathname; if(youTubeVideo.src !== a.href + a.hash) { youTubeVideo.src = a.href + a.hash; } youTubeVideo.setAttribute(\u0026#39;data-gtm-yt\u0026#39;, \u0026#39;true\u0026#39;); return youTubeVideo; } // Add event handlers for events emitted by the YouTube API  function addYouTubeEvents( youTubeIframe ) { youTubeIframe.pauseFlag = false; new YT.Player( youTubeIframe, { events: { onStateChange: function( evt ) { onStateChangeHandler( evt, youTubeIframe ); } } } ); } // Returns key/value pairs of percentages: number of seconds to achieve  function getMarks(duration) { var marks = {}; // For full support, we\u0026#39;re handling Watch to End with percentage viewed  if (_config.events[ \u0026#39;Watch to End\u0026#39; ] ) { marks[ \u0026#39;Watch to End\u0026#39; ] = duration * 99 / 100; } if( _config.percentageTracking ) { var points = []; var i; if( _config.percentageTracking.each ) { points = points.concat( _config.percentageTracking.each ); } if( _config.percentageTracking.every ) { var every = parseInt( _config.percentageTracking.every, 10 ); var num = 100 / every; for( i = 1; i \u0026lt; num; i++ ) { points.push(i * every); } } for(i = 0; i \u0026lt; points.length; i++) { var _point = points[i]; var _mark = _point + \u0026#39;%\u0026#39;; var _time = duration * _point / 100; marks[_mark] = Math.floor( _time ); } } return marks; } function checkCompletion(player, marks, videoId) { var duration = player.getDuration(); var currentTime = player.getCurrentTime(); var playbackRate = player.getPlaybackRate(); player[videoId] = player[videoId] || {}; var key; for( key in marks ) { if( marks[key] \u0026lt;= currentTime \u0026amp;\u0026amp; !player[videoId][key] ) { player[videoId][key] = true; fireAnalyticsEvent( videoId, key ); } } } // Event handler for events emitted from the YouTube API  function onStateChangeHandler( evt, youTubeIframe ) { var stateIndex = evt.data; var player = evt.target; var targetVideoUrl = player.getVideoUrl(); var targetVideoId = targetVideoUrl.match( /[?\u0026amp;]v=([^\u0026amp;#]*)/ )[ 1 ]; // Extract the ID  var playerState = player.getPlayerState(); var duration = player.getDuration(); var marks = getMarks(duration); var playerStatesIndex = { \u0026#39;1\u0026#39; : \u0026#39;Play\u0026#39;, \u0026#39;2\u0026#39; : \u0026#39;Pause\u0026#39; }; var state = playerStatesIndex[ stateIndex ]; youTubeIframe.playTracker = youTubeIframe.playTracker || {}; if( playerState === 1 \u0026amp;\u0026amp; !youTubeIframe.timer ) { clearInterval(youTubeIframe.timer); youTubeIframe.timer = setInterval(function() { // Check every second to see if we\u0026#39;ve hit any of our percentage viewed marks  checkCompletion(player, marks, youTubeIframe.videoId); }, 1000); } else { clearInterval(youTubeIframe.timer); youTubeIframe.timer = false; } // Playlist edge-case handler  if( stateIndex === 1 ) { youTubeIframe.playTracker[ targetVideoId ] = true; youTubeIframe.videoId = targetVideoId; youTubeIframe.pauseFlag = false; } if( !youTubeIframe.playTracker[ youTubeIframe.videoId ] ) { // This video hasn\u0026#39;t started yet, so this is spam  return false; } if( stateIndex === 2 ) { if( !youTubeIframe.pauseFlag ) { youTubeIframe.pauseFlag = true; } else { // We don\u0026#39;t want to fire consecutive pause events  return false; } } // If we\u0026#39;re meant to track this event, fire it  if( eventsFired[ state ] ) { fireAnalyticsEvent( youTubeIframe.videoId, state ); } } // Fire an event to Google Analytics or Google Tag Manager  function fireAnalyticsEvent( videoId, state ) { var videoUrl = \u0026#39;https://www.youtube.com/watch?v=\u0026#39; + videoId; var _ga = window.GoogleAnalyticsObject; if( typeof window[ dataLayerName ] !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; !_config.forceSyntax ) { window[ dataLayerName ].push( { \u0026#39;event\u0026#39; : \u0026#39;youTubeTrack\u0026#39;, \u0026#39;attributes\u0026#39;: { \u0026#39;videoUrl\u0026#39;: videoUrl, \u0026#39;videoAction\u0026#39;: state } } ); } else if( typeof window[ _ga ] === \u0026#39;function\u0026#39; \u0026amp;\u0026amp; typeof window[ _ga ].getAll === \u0026#39;function\u0026#39; \u0026amp;\u0026amp; _config.forceSyntax !== 2 ) { window[ _ga ]( \u0026#39;send\u0026#39;, \u0026#39;event\u0026#39;, \u0026#39;Videos\u0026#39;, state, videoUrl ); } else if( typeof window._gaq !== \u0026#39;undefined\u0026#39; \u0026amp;\u0026amp; forceSyntax !== 1 ) { window._gaq.push( [ \u0026#39;_trackEvent\u0026#39;, \u0026#39;Videos\u0026#39;, state, videoUrl ] ); } } return { init : init, digestPotentialVideos : digestPotentialVideos } })(document, window, { \u0026#39;events\u0026#39;: { \u0026#39;Play\u0026#39;: true, \u0026#39;Pause\u0026#39;: true, \u0026#39;Watch to End\u0026#39;: true }, \u0026#39;percentageTracking\u0026#39;: { \u0026#39;every\u0026#39;: 25, \u0026#39;each\u0026#39;: [ 10, 90 ] } }); /* * Configuration Details * * @property events object * Defines which events emitted by YouTube API * will be turned into Google Analytics or GTM events * * @property percentageTracking object * Object with configurations for percentage viewed events * * @property each array * Fires an event once each percentage ahs been reached * * @property every number * Fires an event for every n% viewed * * @property forceSyntax int 0, 1, or 2 * Forces script to use Classic (2) or Universal(1) * * @property dataLayerName string * Tells script to use custom dataLayer name instead of default */ \u0026lt;/script\u0026gt; Yes, that is a LOT of stuff. Bear with me, though.\nThe modifications to LunaMetrics\u0026rsquo; solution are few but significant.\nFirst of all, instead of using an anonymous function, we\u0026rsquo;re actually reserving a slot in the global namespace, and exposing the function in a variable named ytTracker.\nWe do this because we want to invoke certain methods in the setup after the initial execution. If we didn\u0026rsquo;t expose a public method for it, we\u0026rsquo;d need to run the whole thing again and again, each time a video is dynamically loaded, and that\u0026rsquo;s just a huge strain on performance.\nNext thing we\u0026rsquo;re doing is adding a single line into the normalizeYouTubeIframe() method:\nfunction normalizeYouTubeIframe( youTubeVideo ) { ... youTubeVideo.setAttribute(\u0026#39;data-gtm-yt\u0026#39;, \u0026#39;true\u0026#39;); // \u0026lt;--- NEW  return youTubeVideo; } \nThe youTubeVideo.setAttribute() command is used to add a data attribute to all iframes which have already been treated by the script. This is because we want to avoid running the initialization methods again and again for videos which have already been configured for tracking. In my testing, if a video was tracked multiple times it led to runtime conflicts.\nNow that the data attribute is there, we need to check for its existence. In the checkIfYouTubeVideo() method, we\u0026rsquo;ll add the check like this:\nfunction checkIfYouTubeVideo( potentialYouTubeVideo ) { if (potentialYouTubeVideo.getAttribute(\u0026#39;data-gtm-yt\u0026#39;)) { return false; } ... }  This check just looks for the data-gtm-yt attribute we added in the previous step, and if it\u0026rsquo;s found, the initialization is skipped for this particular video.\nThis way only videos which have not been treated yet will be processed.\nFinally, we need to expose two methods in the ytTracker interface. These will let us handle dynamically added videos. Lets do that in the very end of the function expression.\nvar ytTracker = (function(...) { ... return { init : init, digestPotentialVideos : digestPotentialVideos } })(...);  We return an object with two members: init and digestPotentialVideos. So, when we call ytTracker.init(), the script is basically run again, and all newly added, yet untreated YouTube iframe embeds will be processed and decorated with event trackers.\nIf you want it to be a bit more robust, you can use ytTracker.digestPotentialVideos(iframe) instead. You pass an iframe object as its parameter, and the script will only treat the one video. This is better since it won\u0026rsquo;t loop through all the iframes on the page, and instead just decorates the one you want.\nFinally, set the Custom HTML Tag to fire on a Page View / DOM Ready Trigger.\nThat\u0026rsquo;s the changes right there, ladies and gentlemen.\nHow to use it As said, there\u0026rsquo;s two new methods in town:\nytTracker.init(); // \u0026lt;-- Decorate all new videos on the page ytTracker.digestPotentialVideos(iframe); // \u0026lt;-- Only decorate the iframe that was passed as a parameter  Making the solution work will still most likely require developer help. If your developers have added some complex, dynamic content loaders, which add the videos after some awesome jQuery fade-in has finished, you\u0026rsquo;ll need to cooperate with them to add the ytTracker.init() or ytTracker.digestPotentialVideos() command in the right place.\nHere\u0026rsquo;s an example of what a modified content loader might look like:\nfunction processVideoClick(ytEmbedSrc) { var video = document.createElement(\u0026#39;iframe\u0026#39;); video.src = ytEmbedSrc; var content = document.querySelector(\u0026#39;#content\u0026#39;); content.appendChild(video); window.ytTracker.digestPotentialVideos(video); }  After the video is injected, you call ytTracker.digestPotentialVideos(). You could use the init() method without any parameters, but since you already have the iframe element at hand, it\u0026rsquo;s better to use the more direct method.\nSummary Since loading content dynamically is notoriously standard-free, it\u0026rsquo;s difficult to give a generic solution for managing dynamically loaded content in your analytics or tag management platform. However, LunaMetrics\u0026rsquo; original solution has a very nice set of tools to tackle dynamically loaded YouTube videos as well, without having to make drastic modifications to the code.\nLunaMetrics\u0026rsquo; solution is so flexible and useful. Poking some holes into its interface to let some light out just makes it even better, in my own, humble opinion.\nThe optimal way of working with it is to cooperate with your developers. I hope we\u0026rsquo;ve all matured past the notion of GTM being developer-independent. So, communicate with your developers, ask them to modify the JavaScript controlling the dynamic video injection, and request that they\u0026rsquo;ll add the simple ytTracker methods to the handlers they create.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtmtips-track-launch-campaigns-in-gtm-for-ios/",
	"title": "#GTMTips: Track Launch Campaigns In GTM For iOS",
	"tags": ["campaign tracking", "Google Tag Manager", "gtmtips", "ios", "swift"],
	"description": "How to track launch campaigns in Google Analytics, using Google Tag Manager for iOS (legacy SDK).",
	"content": " In Google Analytics for iOS, there are two types of campaign measurement. There\u0026rsquo;s install campaign measurement, which lets you track the channels which brought your visitors to the App Store, where they proceeded to download your app. There\u0026rsquo;s also launch campaign tracking, which lets you attribute app launches to specific campaigns.\nIn this tip post, we\u0026rsquo;ll tackle the latter. We\u0026rsquo;ll leverage a feature of the Google Analytics iOS SDK to build the parameters, and then push them to dataLayer so that they can be used in the Tag.\nWe\u0026rsquo;ll be using Swift as the language of choice. Check out my previous two posts on GTM for iOS if you need more information on how to make GTM work in your iOS / Swift app.\nTip 39: Launch campaign tracking in Google Tag Manager for iOS   To make it all work, you need two things.\n Code which parses the parameters from the URL and pushes them to dataLayer.\n Data Layer Variables to send the campaign parameters through your Tag.\n  1. Modifying the app code To parse the URL, we\u0026rsquo;ll leverage the setCampaignParametersFromUrl method in the GAIDictionaryBuilder class of the Google Analytics SDK. We won\u0026rsquo;t use it for anything else except for parsing the URL. So, in your AppDelegate.swift file, locate the overloaded constructor with the handleOpenURL method, or create it yourself:\nfunc application(application: UIApplication, handleOpenURL url: NSURL) -\u0026gt; Bool { ... } This is where the app parses any URL parameters used in the launch.\nSo, now we need to leverage the GA SDK\u0026rsquo;s built-in methods, and we need to push the parameters to dataLayer. The setup might look something like this:\nfunc application(application: UIApplication, handleOpenURL url: NSURL) -\u0026gt; Bool { let urlString = url.absoluteString let hitParams = GAIDictionaryBuilder.init() let dataLayer = TAGManager.instance().dataLayer hitParams.setCampaignParametersFromUrl(urlString) dataLayer.push([ \u0026#34;campaignMedium\u0026#34; : hitParams.get(kGAICampaignMedium) ?? \u0026#34;\u0026#34;, \u0026#34;campaignName\u0026#34; : hitParams.get(kGAICampaignName) ?? \u0026#34;\u0026#34;, \u0026#34;campaignSource\u0026#34; : hitParams.get(kGAICampaignSource) ?? \u0026#34;\u0026#34; ]) return true } Let\u0026rsquo;s just quickly walk through this. urlString is the variable where we\u0026rsquo;ll store the URL string itself (d\u0026rsquo;oh). hitParams is what we\u0026rsquo;ll use to parse the URL, and dataLayer is where we\u0026rsquo;ll push the information.\nThe setCampaignParametersFromUrl() method takes a URL string, and parses it for the regular UTM campaign parameters. It stores them in a bunch of constants the GA SDK leverages to pass information between the app and Google Analytics.\nSo, if your app is launched with something like:\nawesomeApp://?utm_source=newsletter\u0026utm;_medium=email\u0026utm;_campaign=December_2015\nThe values for source (newsletter), medium (email), and campaign (December_2015) would be stored in the constants kGAICampaignSource, kGAICampaignMedium, kGAICampaignName, respectively.\nThe dataLayer.push() pulls these from hitParams and stores them in the data structure. If a parameter is missing from the URL, then a blank string is stored for that particular parameter.\nNow we have the values in dataLayer. Next, we need our container to pick them up and send them with our Tag(s).\n2. Modifying the container To make it all work, you now need to create three Data Layer Variables (one for each parameter), and add them to your Tag.\nDLV - campaignSource\nVariable name: campaignSource\nDLV - campaignMedium\nVariable name: campaignMedium\nDLV - campaignName\nVariable name: campaignName\nNext, edit your Screen View Tag (or whichever Tag fires first on your app). Go to More Settings -\u0026gt; Fields to Set, and add the following three fields:\nField Name: \u0026amp;cs\nValue: {{DLV - campaignSource}}\nField Name: \u0026amp;cm\nValue: {{DLV - campaignMedium}}\nField Name: \u0026amp;cn\nValue: {{DLV - campaignName}}\nFinally, publish the container, download the binary, update your app, and go crazy with launch campaign tracking.\nSummary There\u0026rsquo;s one thing you need to pay heed to. We\u0026rsquo;re pushing the campaign parameters to dataLayer but we\u0026rsquo;re not sending an \u0026lsquo;event\u0026rsquo; key. The reason for this is that we want the app to send its regular Screen View, using these values only if they\u0026rsquo;re in the dataLayer when the Screen View is dispatched.\nYou probably see how this can be a problem. If your app sends a Screen View as soon as the initial view appears, it\u0026rsquo;s possible this dataLayer.push() happens after the Screen View hit is built, leading to a nasty race condition. The best way to ensure it works is to defer the initial hit to Google Analytics until the handleOpenURL method has completed.\nThe whole thing is slightly more complex than when using just the GA SDK, as many things seem to be with the Google Tag Manager SDK, but it\u0026rsquo;s still consistent with leveraging dataLayer for message passing, rather than communicating directly with the endpoint.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/url-source-in-the-url-variable/",
	"title": "#GTMTips: URL Source In The URL Variable",
	"tags": ["Google Tag Manager", "gtmtips", "Guide", "variables"],
	"description": "You can use the URL Source setting in your URL variables to make your Google Tag Manager URL variables even more flexible.",
	"content": " One of the less-known features of Google Tag Manager, a hidden gem if you will, is the URL Source setting in the URL Variable type. It lets you parse any URL String for its components.\nTip 38: Parse URL strings with the URL Source setting   The setting itself is easy to find. Just edit an existing URL Variable, or create a new one. Then, scroll down to the More Settings divider, expand it, and you\u0026rsquo;ll see the URL Source drop-down list.\nThis list will list all the Variables in your container, Built-In Variables included, and you can pick the one you want to parse. Note that the Variable you choose needs to return a properly formatted URL string for parsing to work. A properly formatted URL has at least the protocol (e.g. http:// or https://) and hostname (e.g. domain.com).\nWon\u0026rsquo;t work:\nsimoahava.com\nwww.simoahava.com\nwww.simoahava.com/some-page\nWill work:\nhttp://careers.simoahava.com\nhttps://makemoney.simoahava.com/about-us/\nThe URL Source setting establishes a URL String that is then parsed according to the Component Type setting you chose. In the image above, I\u0026rsquo;m using the Referrer Built-In Variable, which returns the referrer URL of the page in question, and I\u0026rsquo;m parsing it just for its path. In other words, this particular URL Variable will return the path of the previous page.\nIf the referrer is https://www.simoahava.com/about-simo-ahava/, the Variable will return /about-simo-ahava/.\nQuite a useful feature, and often overlooked.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/multiple-gtm-containers-on-the-page/",
	"title": "#GTMTips: Multiple GTM Containers On The Page",
	"tags": ["container", "Google Tag Manager", "gtmtips"],
	"description": "Tip on how to add multiple Google Tag Manager containers to a single page. For whatever reason.",
	"content": " For some reason, you might run into a situation where you need to add multiple Google Tag Manager containers on the same page. Usually this is because of poor governance or an inflexible organization. My recommendation is to fix things in your projects first, and only resort to multiple containers if you can\u0026rsquo;t seem to resolve your governance issues using your vocal cords (or your fists).\nOfficially, Google Tag Manager introduced support for adding multiple containers earlier in 2015. It\u0026rsquo;s still not a recommended process, however, and rightfully so. Personally, I hope that development efforts in GTM would be directed towards making a single container more manageable by different parties, rather than adding support for hacks like this.\nIn any case, this tip post is to remind you of how multiple containers can be implemented on a single page.\nTip 37: Multiple containers use the same dataLayer   As you can see, the implementation is simple. Just add your containers as you would normally, but remember to use the same name for dataLayer across the container snippets. This is an important thing to note, because the unofficial recommendation before this support surfaced was to rename the dataLayer objects across the different containers.\nGTM takes care of the rest. Triggers should not have any conflicts, and even though the gtm.js event is pushed into dataLayer multiple times (by each container snippet), your All Pages and Page View Triggers should still just fire once per container.\nOne place where potential conflicts can surface is with Data Layer Variables. When you push a key-value pair into dataLayer, it\u0026rsquo;s registered just once, but each container will have access to this value, even if you pushed it \u0026ldquo;for one container\u0026rdquo; only.\nThis means that with stuff like Enhanced Ecommerce tracking you might run into a situation where Tags in container B are inadvertently sending Ecommerce data, when you only intended Tags in container A to send them.\nThe best way to mitigate this is to send an \u0026lsquo;event\u0026rsquo; key with each Enhanced Ecommerce push, and then purge the key from the data layer after the Tag has fired. You can use hitCallback or eventCallback for that.\nAdding multiple containers is definitely not optimal, and there are many things to take into account, but it\u0026rsquo;s doable if you devote some time to the implementation. Naturally, I would suggest you devote this time to making the organization work with just one container, but sometimes inflexibility takes precedence.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtm-container-snippet-in-the-head/",
	"title": "#GTMTips: GTM Container Snippet In The HEAD",
	"tags": ["container snippet", "Google Tag Manager", "gtmtips"],
	"description": "Quick tip that you can actually add the GTM container snippet to the head of the document.",
	"content": " (UPDATE 28 Sep 2016: The official recommendation has finally caught up with the times. Now the correct placement for the JavaScript methods of the container snippet is, indeed, in \u0026lt;head\u0026gt;.)\nI want to address something I\u0026rsquo;ve been confused about from the very first day since I started using Google Tag Manager. Why on earth would an asynchronously loading JavaScript library be recommended to place in the beginning of \u0026lt;body\u0026gt;, when the logical place to start loading dependencies is as early as possible in the document load process? Well, the main reason for this is that the GTM library makes modifications to the document object model of the page in such a way that might cause conflicts when using Internet Explorer 7 or older.\nAnother reason is that the \u0026lt;iframe\u0026gt; within the \u0026lt;noscript\u0026gt; block is not valid HTML, which is a legitimate concern.\nThe third reason, which isn\u0026rsquo;t really a reason but rather an offshoot of the original Google Tag Manager recommendation, is that Google\u0026rsquo;s Search Console verification requires that the container snippet be embedded in the beginning of \u0026lt;body\u0026gt;.\nIn this post, I\u0026rsquo;ll tackle these three \u0026ldquo;issues\u0026rdquo; and wrap up with a consolation note that yes, it\u0026rsquo;s perfectly fine to add Google Tag Manager to the \u0026lt;head\u0026gt; of the document, and it might even be preferable to do so.\nTip 36: Add the GTM Container Snippet to \u0026lt;head\u0026gt;   Now, the possible conflicts arising with Internet Explorer 7 and older are easy to dismiss. Just forget those users! Punish them for using an antiquated version of the web browser. Honestly, Internet Explorer 7 is being used by 0.1% of Internet users, and that ratio is only going to go down. Do not weep for the lazy. Make them suffer in the hopes of inspiring them to upgrade or, preferably, change to some other brand of web browser.\nNow, one thing you will have to do is remove the \u0026lt;iframe\u0026gt; element from the container snippet, since that\u0026rsquo;s just not valid HTML. An \u0026lt;iframe\u0026gt; is embedded content, and in HTML5, embedded content is never allowed in the \u0026lt;head\u0026gt; of the document. However, you don\u0026rsquo;t need to remove it entirely. Just copy-paste the entire \u0026lt;noscript\u0026gt; in the beginning of \u0026lt;body\u0026gt; if you\u0026rsquo;re concerned about your non-JavaScript users.\n\u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;script\u0026gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-XXXXXX\u0026#39;);\u0026lt;/script\u0026gt; \u0026lt;!-- End Google Tag Manager --\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;noscript\u0026gt;\u0026lt;iframe src=\u0026#34;//www.googletagmanager.com/ns.html?id=GTM-XXXXXX\u0026#34; height=\u0026#34;0\u0026#34; width=\u0026#34;0\u0026#34; style=\u0026#34;display:none;visibility:hidden\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/noscript\u0026gt; Simple solution for dealing with the validation problem.\nFinally, the Search Console validation issue is a pain. There\u0026rsquo;s nothing you can do about that. If you choose to move the container snippet to the \u0026lt;head\u0026gt; of the document, you will need to use some other means of validating your site.\nWhy do it? Sometimes you don\u0026rsquo;t have an option. WordPress themes, for example, rarely have a hook for adding code to the beginning of \u0026lt;body\u0026gt;, and you\u0026rsquo;ll need to hack around that by modifying the child templates. In these cases, adding the library to the \u0026lt;head\u0026gt; can save a lot of time and effort.\nAlso, remember that Google Tag Manager is an asynchronously loading library. This means that it\u0026rsquo;s loading as the page renders, and it\u0026rsquo;s non-blocking. Thus, the earlier you start loading the library, the more chance your Tags will have to fire and complete before the user leaves the page or closes the browser. This might result in a slight increase in data collection accuracy and quality.\nAs soon as the Search Console validator relaxes a little, I see little reason why you shouldn\u0026rsquo;t always add the container snippet to the \u0026lt;head\u0026gt; of the page. In fact, if we ever get a synchronous version of the container (for running e.g. A/B tests), adding the snippet to the \u0026lt;head\u0026gt; becomes a necessity.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/firing-a-single-tag-multiple-times-in-gtm/",
	"title": "Firing A Single Tag Multiple Times In GTM",
	"tags": ["Google Tag Manager", "Guide", "triggers"],
	"description": "How to fire a single Google Tag Manager tag multiple times, with a variable changing value dynamically. This is useful if you want to use a single GA tag to track data to multiple properties.",
	"content": " There might be many reasons you\u0026rsquo;d want to fire a single Tag multiple times in Google Tag Manager. The most common one is when you want to deploy multiples of a single tracking point on the web. Perhaps you have a roll-up account you want to send the hits to, in addition to the site-specific tracking property.\nQuite a while ago, I gave a solution for this with a specific focus on Google Analytics Tags. It leveraged the hitCallback feature of the Universal Analytics library by increasing a global counter each time a Tag had fired. This solution had a number of drawbacks: being GA-specific, polluting the global namespace, and requiring a unique setup for every single Tag you wanted to fire.\nNot long after this, I actually started doing the whole thing in a different way. A much more durable, sensible, robust way, and in this article I want to open up the method. In fact, it\u0026rsquo;s not just me who wants to introduce this. This article is a collaboration with Marco Wekking from Adwise. He approached me with almost exactly the same solution asking for a review. Instead of reviewing, I asked if he would like to contribute to a collaboration of sorts on this post, and he gracefully accepted. So, much of this post is from Marco\u0026rsquo;s pen, with my typical bad humour and some JavaScript shenanigans intertwined in the rhetoric.\nHow it works   The skilfully grafted diagram above shows how the solution works. Every single event that passes through dataLayer is duplicated by suffixing it with .first and .second. This way, all the Tags you want to fire twice per event just need to be modified to use the original event name plus the two suffixes. You can even use this in a Lookup Table to fire the hits to different Google Analytics tracking properties, for example.\nIt\u0026rsquo;s a simple, elegant solution to a pressing problem which, if you ask me, should be handled natively by the platform. This is such a common use case for so many people - it would be immensely helpful if you could just denote multiple cycles to each Tag using the Tag template settings instead of having to resort to hacks like this.\nHow to do it The solution comprises three steps:\n Create a new Custom Event Trigger\n Create the Custom HTML Tag which manages the duplication\n Create new Triggers\n  We\u0026rsquo;ll wrap it up with an example of how to leverage this when firing to multiple Google Analytics properties! So stay tuned.\n1. Create the Custom Event Trigger To fire the Custom HTML Tag, we\u0026rsquo;ll need a Trigger which activates on every single event. Why? Because we want to duplicate every single event! There\u0026rsquo;s just one exception - we don\u0026rsquo;t want to fire the Trigger when the actual duplication events are pushed into dataLayer, or we might find ourselves in an infinite loop. Ontologically fascinating, but not cool when it comes to site performance.\nBefore you create the Trigger, make sure you have the Event Built-in Variable checked in the appropriate slot of the Variables page in your container.\n  This is required for the Trigger to work.\nNext, create a Trigger which matches all events except for the duplicated ones. In this example, we\u0026rsquo;re using the generic .first and .second as the suffixes, but nothing\u0026rsquo;s stopping you from using something more descriptive, for example .Country and .Rollup.\n  To reiterate: The exception is important! If you don\u0026rsquo;t add that Fire On condition, you will run into issues, as the Trigger would fire again and again with each duplication cycle. Yes, you could use the Tag Firing Options feature of the Tag templates, but it\u0026rsquo;s better to nip bad behavior in its bud.\n2. Create the Custom HTML Tag The Custom HTML Tag is the heart and soul of this solution. It\u0026rsquo;s very simple, but it does have some peculiarities that might surprise if you\u0026rsquo;re not familiar with how GTM works.\nActually, to ensure that one of these special features works as it should, you\u0026rsquo;ll need to activate yet another Built-In Variable: Container ID. This returns, surprise surprise, the public ID of the GTM container the Tag is firing in (GTM-XXXX).\n  Create a new Custom HTML Tag and add the following code within:\n\u0026lt;script\u0026gt; (function() { var event = {{Event}}; var gtm = google_tag_manager[{{Container ID}}]; window.dataLayer.push({ \u0026#39;event\u0026#39; : event + \u0026#39;.first\u0026#39; }); window.dataLayer.push({ \u0026#39;event\u0026#39; : event + \u0026#39;.second\u0026#39;, \u0026#39;eventCallback\u0026#39; : function() { gtm.onHtmlSuccess(); } }); })(); \u0026lt;/script\u0026gt; We\u0026rsquo;re wrapping the whole thing in an IIFE as we want to avoid polluting the global namespace. Next, we\u0026rsquo;re assigning a local variable event with whatever value is currently stored in the Built-in Event variable (i.e. the event that was pushed in the first place).\nFinally, we\u0026rsquo;re doing two consecutive dataLayer.push() commands, one for each iteration of the cycle. If you want to add more events there, be my guest. As far as we know, there is no limitation to the number of events you can push into dataLayer this way.\nThe latter push includes the special eventCallback key (read more about it here). The key holds a callback function which is invoked as soon as Tags which fire on this particular push have signalled their completion. Within this callback, we\u0026rsquo;re using the onHtmlSuccess() feature of GTM\u0026rsquo;s interface. This is something that was exposed for public use with the Tag sequencing feature. The only thing you need to know about it is that it\u0026rsquo;s our way of telling GTM that it can now proceed with whatever was going on before this loop of dataLayer.push() commands.\nIn other words, if you\u0026rsquo;re duplicating a Click / Just Links, and you\u0026rsquo;ve got \u0026ldquo;Wait for Tags\u0026rdquo; checked (meaning the Trigger will wait for all dependent Tags to fire before proceeding with the link default action), the process goes something like this:\n The link click Trigger fires this Custom HTML Tag.\n The Custom HTML Tag pushes the first duplicated event, and any Tags which use it start their execution.\n Immediately after, the Custom HTML Tag pushes the second duplicated event, and any Tags which use it start their execution.\n Once the last Tag firing on the second duplicated push signals its completion, the eventCallback callback is invoked, and the Custom HTML Tag tells the link click Trigger that everything is done, allowing it to proceed with the redirect.\n  Now, add the Trigger you created in the previous step to this Tag, and you\u0026rsquo;re ready to duplicate. You can preview this to see what happens in your dataLayer with each event.\n  As you can see, each event is duplicated. There\u0026rsquo;s the Pageview, followed by its duplicates: gtm.js.first and gtm.js.second. There\u0026rsquo;s DOM Ready, followed by its duplicates: gtm.dom.first and gtm.dom.second, and so on.\n(If you don\u0026rsquo;t understand what \u0026ldquo;Pageview\u0026rdquo; and \u0026ldquo;gtm.js\u0026rdquo; have to do with each other, the latter is the underlying event representation of the former. More information in my Trigger guide.)\n3. Create new Triggers The only housekeeping pain you\u0026rsquo;ll need with this solution is with the Triggers. Here\u0026rsquo;s how it should work:\n To duplicate a Trigger, you need one \u0026ldquo;base\u0026rdquo; Trigger of the event type firing without any delimiting conditions. This is the event that is duplicated.\n To fire your duplicate Tags, you\u0026rsquo;ll need to use Custom Event Triggers which use the original event name (e.g. gtm.linkClick) plus .first or .second, all wrapped in a simple regular expression.\n  In other words, we\u0026rsquo;re taking a step back to how GTM used to work before the auto-event triggers. We\u0026rsquo;re creating listeners using the generic event Triggers, and when these are duplicated, the Custom Event Triggers are used to delimit the Tags to fire only when specific conditions exist.\nNOTE! You don\u0026rsquo;t need to create a \u0026ldquo;base\u0026rdquo; Trigger for the Page View event type. This is because \u0026ldquo;Pageview\u0026rdquo;, \u0026ldquo;DOM Ready\u0026rdquo;, and \u0026ldquo;Window Loaded\u0026rdquo; are automatically pushed into dataLayer as the page and GTM load. In other words, they are automatically duplicated, and you just need to focus on creating the Custom Event Triggers.\nLook at the illustration below for clarity:\n  Let\u0026rsquo;s zoom in. If you have an \u0026ldquo;Outbound Links\u0026rdquo; Trigger, which fires when the Click URL is not your own hostname, the duplicated Trigger would look something like this:\n  Make note of the \u0026ldquo;Event name\u0026rdquo; field. That\u0026rsquo;s what it should look like for your Triggers. With custom event names it\u0026rsquo;s easy, as you\u0026rsquo;re the one pushing them into dataLayer in the first place. With the built-in Triggers it might be a bit more difficult, so here\u0026rsquo;s a cheat sheet for you:\n   Built-in Event Underlying event name     Page View / Page View (also All Pages) gtm.js   Page View / DOM Ready gtm.dom   Page View / Window Loaded gtm.load   Click / All Elements gtm.click   Click / Just Links gtm.linkClick   Form Submit gtm.formSubmit   History Change gtm.historyChange   JavaScript Error gtm.pageError   Timer gtm.timer    Make sure you\u0026rsquo;ve got the Fire On condition on the Custom Event Trigger, as you don\u0026rsquo;t need it on the generic event Trigger. If you miss it from the Custom Event Trigger, you\u0026rsquo;ll inadvertently fire the Tag whenever any such event is detected on the page. For example, if we\u0026rsquo;d left out the Click URL Hostname condition from the example above, the Outbound Links Tag would fire whenever the Link Click event is pushed into dataLayer.\nBONUS: Use variable Tracking ID Here\u0026rsquo;s a tip straight from Marco. To create a variable which sends a different Universal Analytics tracking ID depending on which cycle of the duplication loop is currently active, use the following Custom JavaScript Variable:\nfunction() { var event = {{Event}}; var regexFirst = /\\.first$/; var regexSecond = /\\.second$/; if (regexFirst.test(event)) { return \u0026#34;UA-XXXXXXXX-1\u0026#34;; } else if (regexSecond.test(event)) { return \u0026#34;UA-XXXXXXXX-2\u0026#34;; } // Do something in case neither matches  }  This returns the UA code \u0026ldquo;UA-XXXXXXXX-1\u0026rdquo; if the Tag is firing on the first loop of the duplication cycle, and \u0026ldquo;UA-XXXXXXXX-2\u0026rdquo; if on the second. You might want to setup some type of fallback or default return value in case neither matches.\nOverview and summary While the solution works for all kinds of tags and creates less redundancy in many setups, it has some drawbacks of its own.\nFirst, it inflates the number of dataLayer events significantly. A simple setup with just two events (Page View and Outbound Link Clicks) already triples the amount. Note that this doesn\u0026rsquo;t really have any impact on performance. dataLayer is just a message bus used by Google Tag Manager\u0026rsquo;s internal data model. Whenever GTM needs to access the \u0026ldquo;Data Layer\u0026rdquo;, it\u0026rsquo;s actually just performing a lookup in its own data model, so the size of dataLayer is inconsequential here.\nSecond, it requires a different and probably more difficult approach to triggers. All tags need to be linked to custom event triggers instead of the built-in Trigger types you might have become used to. If you were around during GTM\u0026rsquo;s previous version, you might be familiar with the setup, as it resembles how things were done with the old auto-event tracking setup. However, when you really chew it down, all you\u0026rsquo;re actually doing is creating one extra Trigger per event type, and moving from the built-in Trigger types to Custom Event Triggers.\nFinally, trigger conditions become more critical as they can cause infinite loops or Tags firing in wrong situations. While such accidents shouldn’t cause infinite regret (assuming you test before publish) it does remain another difficulty for you to deal with.\nOne thing you might be concerned about is whether or not all the Variables populated with the initial base Trigger are still available when the duplicate Custom Event Triggers fire. For example, you might need the Click URL Variable, and now you\u0026rsquo;re worried that it\u0026rsquo;s not available when the duplicate Triggers fire. Don\u0026rsquo;t worry! GTM persists Variable values until they\u0026rsquo;re overwritten or there\u0026rsquo;s a page unload/refresh. So, unless you\u0026rsquo;re manually overriding the Data Layer values populated by GTM\u0026rsquo;s auto-event Triggers, you should be fine.\nWell, we might have overstated the simplicity and elegance of the setup, but the idea of intercepting each event and duplicating it is far more approachable than the complex hitCallback setup used before.\nI want to thank Marco for putting the approach into writing, and most of the content in this article has come from his pen, edited to suit the devil-may-care style of this blog. Any errors, factual mistakes, or radicalist propaganda cleverly hidden in the whitespace is solely the fault of me, Simo, and I take full responsibility for all the uprisings that will inevitably follow.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/useful-gtm-for-ios-tips/",
	"title": "#GTMTips: Useful GTM For iOS Tips",
	"tags": ["Google Tag Manager", "gtmtips", "ios", "swift"],
	"description": "Useful tips for setting up Google Tag Manager for iOS using the legacy SDK.",
	"content": " A while ago I wrote a blog post about how to install Google Tag Manager for iOS using the Swift programming language (you can read the article here). I\u0026rsquo;ve been doing a lot of work with Swift lately, and I\u0026rsquo;m more and more convinced that GTM is actually a very powerful utility for running in your iOS app instead of the Google Analytics SDK.\nWhy? Because it abstracts a lot of the nitty-gritty you\u0026rsquo;d otherwise need to explicitly manage in your GA installation. Also, by using the TAGDataLayer interface, you\u0026rsquo;re abstracting stuff yourself, not forced to adopt any specific syntax or semantic structure in your tracking. Instead, you\u0026rsquo;ll be leveraging generic key-value pairs and an object structure, which you\u0026rsquo;re probably already familiar with if you\u0026rsquo;ve worked with GTM for the web.\nIn any case, here\u0026rsquo;s a bunch of tips I\u0026rsquo;ve discovered while working with the SDK. Some of them might be quite evident, but they\u0026rsquo;re useful nevertheless. Also, I\u0026rsquo;ve learned that nothing is 100% self-evident in the world of GTM.\nTip 35: Bunch of GTM4iOS tips!   The tips are:\n Dispatch the Tag Manager / GA queue when the application is entering background / terminating\n Log verbosely and set dispatch interval to 1 second only when debugging\n Purge dataLayer in between pushes\n Use the dryRun of the GAI.sharedInstance() to avoid sending data to GA\n Get the Google Analytics Client ID from the tracker instance\n Switch IDFA on in your Tags\n  1. Dispatch the Tag Manager / GA queue when the application is entering background / terminating One of the rather ugly default features of the Google Analytics and Google Tag Manager SDKs is that they have a 120 second batch interval. It makes a lot of sense when the app is running, as it preserves battery et cetera, but it\u0026rsquo;s nasty when the app is in the background. Basically, it forces the app to \u0026ldquo;wake up\u0026rdquo; after 120 seconds of down time, just for the queue to dispatch.\nIn AppDelegate, you have a bunch of useful functions, which you can use to run commands when the app is ready to do something. Also, the TAGManager implementation has the method dispatch(), which lets you send all the hits that are currently in the dispatch queue. So, by combining these two, you can empty the queue whenever the app is about to enter the background or terminate!\nfunc applicationDidEnterBackground(application: UIApplication) { tagManager.dispatch() } func applicationWillTerminate(application: UIApplication) { tagManager.dispatch() } 2. Log verbosely and set dispatch interval to 1 second only when debugging If you\u0026rsquo;ve set preprocessor macros (you should!), you can execute code only when in a certain environment, such as QA, staging, or production.\nGTM also provides verbose logging, and you can set the dispatch interval of the request queue (see the previous tip) manually. Now, combine all these in a bowl, stir well, and you\u0026rsquo;ll get some really powerful debugging tools.\n#if !ENV_PROD tagManager.logger.setLogLevel(kTAGLoggerLogLevelVerbose) tagManager.dispatchInterval = NSTimeInterval(1.0) #endif The first command sets the logging level to verbose, and the second one sets the dispatch interval to just one second. Both commands are only executed if the environment is not ENV_PROD, thus covering ENV_QA, ENV_TEST, ENV_DEBUG etc. These are, of course, just examples, and your setup probably uses some other names.\nYou can utilize the #if DEBUG further in the containerAvailable callback, which is invoked when a container is first opened. Now, if you\u0026rsquo;re debugging the GTM implementation, it\u0026rsquo;s possible you\u0026rsquo;re also updating the container in Google Tag Manager as well, and you might want to see changes immediately rather than having to wait the 12 hours for the container to go stale. So, modify the callback accordingly:\nfunc containerAvailable(container: TAGContainer) -\u0026gt; Void { dispatch_async(dispatch_get_main_queue(), { self.container = container; #if !ENV_PROD container.refresh() #endif }); } See that container.refresh() there? That fetches a container over the network every single time, as long as you\u0026rsquo;re not in an environment named ENV_PROD.\n3. Purge dataLayer in between pushes In my Analytics.swift module (see this article for more information), I call the following function just after dataLayer.push() where content or hit-scoped custom dimensions are passed. To keep things consistent, I\u0026rsquo;ve created a dataLayer syntax, where all content data is stored under the key contentData, and all eCommerce data is stored under the key ecommerce. I have other collections as well, such as metaData and userData, but these I want to persist, so the purge is not called after they are used.\nprivate static func purgeDataLayer() -\u0026gt; Void { dataLayer.push([ \u0026#34;contentData\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;ecommerce\u0026#34; : \u0026#34;\u0026#34; ]) } Yes, pushing blank strings is a clumsy way to purge the structure but it works. Basically, every time after content data and ecommerce data have been pushed into dataLayer and subsequently processed by GTM, I call purgeDataLayer() to ensure that this hit-scoped information does not persist.\n4. Use the dryRun of the GAI.sharedInstance() to avoid sending data to GA I\u0026rsquo;m actually not sure why you\u0026rsquo;d want to do this, since you can just send your debug hits to a secondary Google Analytics property. But if you do want to avoid sending any data to Google Analytics, and just look at the verbose logs to see if things are working, you can set this flag in the Google Analytics tracker instance.\nYes, I\u0026rsquo;m aware this isn\u0026rsquo;t GTM-specific, but it works with GTM-created trackers as well!\nGAI.sharedInstance().dryRun = true A simple tip, no doubt.\n5. Get the Google Analytics Client ID from the tracker instance Again, this is more Google Analytics than Google Tag Manager, but it works in the latter as well. All trackers created via the GA or GTM SDKs have the same Client ID, which persists until you clear all settings and content in the app.\nTo get the Client ID, run the following commands:\nlet tracker = GAI.sharedInstance().trackerWithTrackingId(\u0026#34;UA-12345-1\u0026#34;) let clientId = tracker.get(kGAIClientId) Now clientId has the GA Client ID, and you can do whatever you wish with it. In other words, you can actually use the string \u0026ldquo;UA-12345-1\u0026rdquo; if you wish, since it would have the same Client ID as the actual tracker (with the real Universal Analytics property ID).\n6. Switch IDFA on in your Tags This is a very simple tip, as there\u0026rsquo;s really almost no customization required. All you need to make sure is that the following Pod is loaded in your Podfile:\npod 'GoogleIDFASupport'\nThis loads the IDFA library, and you won\u0026rsquo;t need to do anything else in your Swift app. The only other thing you\u0026rsquo;ll need to do is switch on the Enable Advertising ID Features in your GTM Tags.\n  Now your app will be sending the \u0026idfa; parameter with your device\u0026rsquo;s IDFA identifier, and you can set on your demographics reports and your iTunes install campaign tracking and whatnot via GA.\nSummary That\u0026rsquo;s it for this group of tips! I have lots more to share around Google Tag Manager for iOS, but I can\u0026rsquo;t extinguish my entire tip collection in one single post.\nI hope you found these useful! Do you have other tricks up your sleeve?\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/referral-exclusion-on-receipt-page/",
	"title": "#GTMTips: Referral Exclusion On Receipt Page",
	"tags": ["ecommerce", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "Here&#39;s an easy way to block all those pesky payment portals from messing up your Google Analytics data. Set all referral hits to null on the receipt page of your site.",
	"content": " You might have noticed that the Referral Exclusion List in Google Analytics is difficult to maintain. You can\u0026rsquo;t copy a list from one property to another, the list is a wildcard match for domain names (so all subdomains are automatically excluded), and it\u0026rsquo;s just about the clunkiest user interface we\u0026rsquo;ve seen since ERP tools from the 1990s. A while ago, I wrote of a solution which lets you manage referral exclusions using Google Tag Manager, and it\u0026rsquo;s still a neat trick, as it\u0026rsquo;s way more flexible than said clunky UI.\nHowever, it\u0026rsquo;s still an a priori setup. You need to know what referrals are coming in. Also, if you have hundreds of referrals that you want to exclude, it\u0026rsquo;s still a headache. With Ecommerce payment gateway referrals, it\u0026rsquo;s very common to have a huge amount of domains you didn\u0026rsquo;t even know to exist polluting your session data.\nIn this tip, I\u0026rsquo;ll show you a simple and elegant way to make sure that nothing interferes with correct attribution on your Ecommerce receipt page.\nTip 34: Exclude all referrals on your receipt page   That\u0026rsquo;s right! We\u0026rsquo;re going to brutally exclude all referrals on the receipt page. No matter where you come from, you will not be counted as a referral, and thanks to Google Analytics\u0026rsquo; last non-direct source attribution, your pre-payment-gateway-session will stay intact.\n\u0026ldquo;Exclude all referrals? Regardless of where they come from?\u0026rdquo; I hear you whisper in fear. Speculations about me finally losing my mind along with my hair are flying to and fro like suicidal swans.\nI\u0026rsquo;m serious! Think of a scenario where a referral to your receipt page is significant. You\u0026rsquo;re not going to be sending campaign traffic to that page. You\u0026rsquo;re not going to want to see it in Google\u0026rsquo;s search index. Unless you\u0026rsquo;re the worst SEO manager in the world, you\u0026rsquo;re not going to want to build links to that page. So we don\u0026rsquo;t care about referrals to the receipt page. The hypothesis is that whenever someone lands on the receipt page, it\u0026rsquo;s always as part of your checkout funnel.\nI know, always is not something you should articulate outside of singing Bon Jovi at the local karaoke bar. But in this case it\u0026rsquo;s worth the risk. The only reason you might want to see referral data on the receipt page is to debug some issue with your checkout funnel. But, my friends, there are better tools than Google Analytics\u0026rsquo; session attribution to do that. If you\u0026rsquo;re really concerned, you can always send the referrer as a Custom Dimension.\nAnyway, to get things working, you need to do two things: create a Custom JavaScript Variable and modify the Tags which fire on the receipt page. Let\u0026rsquo;s start with the first one.\nCreate a new Custom JavaScript Variable, and name it {{JS - Null referrer on thank you page}} or whatever suits your fancy. Next, populate it with the following code:\nfunction() { return {{Page Path}}.indexOf(\u0026#39;/thank-you-page/\u0026#39;) \u0026gt; -1 ? null : document.referrer; }  I\u0026rsquo;m aware that this is different than the code in the image above. I\u0026rsquo;m dark, mysterious, and unpredictable that way! (Both work just fine).\nThe key thing is to change the string in the indexOf method to match the path (or part of path) of your receipt page. It\u0026rsquo;s case sensitive, so if you\u0026rsquo;re one of the 3 people who think that URLs that are something else than all lowercase are cool, make sure you include the case in the check.\nOnce you\u0026rsquo;ve created the Variable, head on over to your Universal Analytics Tags which fire on the receipt page. That\u0026rsquo;s right, you\u0026rsquo;ll need to edit all of them, because even a single Tag which gets through with incorrect referrer information will start a new session. In the Tag settings, browse down to Fields to Set, and add a new field with this setup:\nField Name: referrer\nValue: {{JS - Null referrer on thank you page}}\n  And now you\u0026rsquo;re all set! When you run this setup, whenever the user lands on /thank-you-page/, all hits to GA are sent without a referrer.\nThanks to Michael] for bringing up the point of editing all the Tags on the page, not just the Page View Tag.\nSimple, elegant, and quick.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/better-qa-with-google-tag-manager-environments/",
	"title": "Better QA With Google Tag Manager Environments",
	"tags": ["environments", "Google Tag Manager", "Guide"],
	"description": "Introducing Google Tag Manager&#39;s environments. This guide will walk you through the feature, and how you can use it to enhance quality assurance in your data organization.",
	"content": " Google Tag Manager, our favorite free tag management solution, has always struggled with its enterprise-worthiness. There are many features still lacking, most of which have to do with working in multi-user environments. Now, grab the last word of that sentence (see what I did there), and hug it tightly, for GTM just introduced a new, enterprise-friendly feature: Environments.\n  These Environments are actually browser cookies, which you use to link a Google Tag Manager container state with the browser of the user who needs to or wants to view that particular state. In other words, if you have a QA (quality assurance) process, as you should have, or if you do most of your testing on a staging server, as you should do, you can create an Environment in GTM, after which you can publish container versions (even the draft) into that particular Environment alone.\nThis is, actually, pretty significant compared to how GTM used to work. Before, you had to Share a Preview version, but that was always a container version. When the version changed, you had to retrieve a new authentication token. Now, GTM will distribute Environment tokens instead, meaning as long as the Environment is linked to Google Tag Manager and the authentication is not revoked, that particular token will have access to whatever versions are published into said Environment. Cool!\nThis makes GTM more manageable across multiple contexts. There are two ways to do this: by sharing a link, as before, or by adding a piece of code into the page templates of each Environment, in which case the link between GTM and the Environment works without you having to distribute authentication tokens via cumbersome links.\nOfficial support documents can be viewed here. Let\u0026rsquo;s get cracking!\nWhy this change? This development is necessary not only because it makes GTM function better across environments and teams, but also because the old Share Preview feature was not optimal. In this chapter, I\u0026rsquo;ll briefly walk you through how container version sharing used to work, so that you\u0026rsquo;ll understand why this development is necessary.\nMany thanks to Brian Kuhn, again, for his invaluable insight into the inner workings of Google Tag Manager.\n  Thus far, when you\u0026rsquo;ve clicked the Share Preview link either in the yellow preview bar (seen above), or via the Versions page, you get a URL which you can then distribute to whomever should be able to preview (or debug) this particular container version.\nThis URL, when executed in the browser, actually writes a secret authentication token into the user\u0026rsquo;s browser while on the googletagmanager.com domain. Now, when requesting the gtm.js library from googletagmanager.com on the website where the container is installed on, GTM will detect this authentication token in the cookies written on googletagmanager.com. Once it detects the authentication token, it will know to download the container version with which this particular token is associated. The following modern art masterpiece illustrates this relationship:\n  As you can see, the authentication token in the Share Preview link matches that of a specific cookie found on the googletagmanager.com domain.\nIn other words, since an authentication token links a specific version with the user\u0026rsquo;s browser, it means that that user is permanently forced to digest that particular container version in their browser.\nOK, well, I might be exaggerating a little. The cookie itself is a session cookie, meaning it will expire when you close the browser. However, the token is permanent. So if the user saves the link, they can revisit that version as much as you like, and there\u0026rsquo;s very little you can do about it (short of deleting the version).\nAlso, to get rid of Preview mode without having to shut down the browser is a bother as well. Basically, you need to browse again to the page you get when copy-pasting the Share Preview link, and then click the \u0026ldquo;Exit Preview\u0026rdquo; link you see. It\u0026rsquo;s easy to miss and easy to forget.\n  Not very streamlined.\nAnyway, this is how it\u0026rsquo;s worked thus far. The main problems with the current setup are:\n Authentication tokens are permanent, so there\u0026rsquo;s no way for you to revoke authentication. Also, cookies are session cookies, and it\u0026rsquo;s difficult to delete them (unless you remember to click the \u0026ldquo;Exit Preview\u0026rdquo; link on the Share Preview page). The permanence of the authentication token is especially problematic with the Container Draft, as once a user has the authentication token for the draft, they\u0026rsquo;ll be authenticated against ALL future drafts as well!\n Since the token is linked to a specific version, it makes the QA process cumbersome. Optimally, you\u0026rsquo;d want the cookie to be bound to the environment, not the version. Now QA needs a new authentication token whenever a new version of the container is ready for testing.\n Sharing the container preview link is a hassle, looks suspicious, and is sensitive to errors. Also, it does not scream \u0026ldquo;FLEXIBILITY\u0026rdquo;, which is what I do a lot when working with GTM (my co-workers find it amusing).\n  These are the problems the Google Tag Manager team wanted to tackle with Environments, and they sure did take a step in the right direction with the new feature.\nIntroducing Environments The main benefit of Environments is that you no longer share a version cookie, but rather an Environment cookie. In other words, if you want to link a user\u0026rsquo;s browser with an Environment created in GTM, you don\u0026rsquo;t have to send them a new token each time the version updates. Instead, you give them the authentication token to that particular Environment, after which you simply publish to that Environment, and the user on the other end with their QA browser will have access to whichever version is currently published to that Environment.\nAnother thing that has been made simpler is revoking access. You can now nullify an authentication token via GTM, helping you manage who has access to which Environments.\nTo get started, you will need to enable Environments in your Google Tag Manager container. If you don\u0026rsquo;t do that, nothing will change in your Google Tag Manager user interface. So, head on over to the Admin section of your container, and click the new Environments link.\n  This is where you\u0026rsquo;ll create your own, long-lived Environments. I stress long-lived, since you really only want to create an Environment which lasts more than the lifespan of a single version. I mean, you CAN use Environments to substitute the old \u0026ldquo;Share Preview\u0026rdquo; functionality, but they truly come to life when actually creating an Environment for a permanent process in your organization, and then using it methodically to test new versions of the container, without having to share cookies every single time.\nManage Environments In the list of Environments, you\u0026rsquo;ll see three default Environments. These can\u0026rsquo;t be deleted or published to manually. They are:\n Live - The currently live Container Version is automatically added to this Environment\n Latest - The newest created version (not the Draft)\n Now Editing - The current container draft\n    Now, these are all states that exist in GTM with or without creating custom Environments. When you edit a container, the version is maintained in the \u0026ldquo;Now Editing\u0026rdquo; Environment. When you save a draft as a container version, the version is maintained in the \u0026ldquo;Latest\u0026rdquo; Environment. And when you publish a version, it is published into the \u0026ldquo;Live\u0026rdquo; Environment.\nClick New to create your first, custom Environment. Give it a honest name and a good description. You can also choose to enable the Debug panel by default (if you don\u0026rsquo;t check this, then Environments will be Preview only by default, meaning users won\u0026rsquo;t see the debug panel).\nIf you want, you can set the hostname of the site where the Environment is. This way the Share Preview dialog will directly link the user to the website.\n  So, now you\u0026rsquo;ve created your first custom Environment, and you\u0026rsquo;ll see it in its own list in the Environments page.\n  As you can see, the Version ID field is empty, meaning you haven\u0026rsquo;t published a version into this Environment yet.\nLet\u0026rsquo;s take a look at the Actions menu.\n  NOTE! The default containers have the same menu, except they do not have the Delete or Publish to\u0026hellip; options available.\nThe options are:\n Edit Settings - lets you edit the settings you first set when creating the Environment\n Publish To\u0026hellip; - opens a publish dialog, where you can select which container version you want to publish to the selected Environment. After this, sharing a preview link to this Environment will allow users to preview the published container only.\n Share Preview - shares a preview link to the Environment, allowing users with access to this particular Environment preview and debug it with their browsers.\n Reset Link - removes authentication from the previously shared link AND from the new snippet (see below). This is very cool but also dangerous (see the next chapter).\n Get Snippet - gives you the updated GTM Container Snippet which replaces the original snippet. All pages with this Environment will automatically be in preview mode for the Environment.\n Delete - lets you delete the Environment.\n  Let\u0026rsquo;s move on to how the sharing works.\nSharing Environment access To share Environment access, you have two options.\nYou can distribute it as a link, as before, which binds the user\u0026rsquo;s browser to the Environment via an authentication token. This way, the user\u0026rsquo;s browser is linked to that particular Environment until the authentication token is revoked or the user manually deletes the token cookie using the Share Preview page.\n  An alternate, more robust way is to modify the container snippet on the website of the Environment (e.g. QA or staging site). The simple modification enables the authentication token to be accessed whenever that site is visited, meaning the site (read: the container snippet) is bound to the Environment instead of just the user\u0026rsquo;s browser. This method dispenses with the need to share the authentication link, and it allows the user to browse other Environments on the same domain (e.g. the live site) without interference.\nIn other words, the Environment will only be active on pages with the new container snippet. When you browse to a page or site (even under the same domain) that does not have the authentication token in the snippet, you will be privy to the live, published container as usual.\n  NOTE! When you reset the link to the Environment, it will also make the container snippet for that Environment change! In other words, only reset a link which is used in a container snippet if you are certain it\u0026rsquo;s necessary. Otherwise you\u0026rsquo;ll have hell to pay with your developers.\nOn that note, it\u0026rsquo;s probably best to avoid using the same Environment both with Share Preview links and distributing the authentication token via the container snippet. Make a note of what the Environment is used for in the Description field or, even better, in the Name field. That way you\u0026rsquo;ll know what you risk if you want to reset the link.\nThings you can do via the GTM UI Once you enable Environments, you can selectively publish to these Environments, you can use a new Built-In Variable to query which Environment the user is currently in, and you can view which version is currently live in which Environment.\nFirst, go to the Versions screen. As you can see, there\u0026rsquo;s a new column \u0026ldquo;Environments\u0026rdquo;. That column contains information about to which Environments a particular version has been published.\n  Next, if you click the Actions menu next to a version, you\u0026rsquo;ll find the Publish To\u0026hellip; link again. Here, you can publish the selected version to an Environment of your choice! So no need to go through the Environments page every single time you want to publish a version to an Environment.\n  Next, go to the Container overview and click the red Publish button. As you can see, you can now choose to which Environment you actually want to publish the container draft to! Live is selected by default, of course.\nNOTE! When you publish a container draft, it is first created into a version, and then automatically published to the Latest Environment in addition to whichever Environment you chose in the Publish dialog. Also, the version in the \u0026ldquo;Now Editing\u0026rdquo; Environment is updated to the NEW container draft. Phew!\nThe new Environment Name variable Yes, there\u0026rsquo;s a new Built-In Variable in town: Environment Name.\n  You might be surprised that this variable returns the name of the Environment the user\u0026rsquo;s browser is currently viewing (shocker!). My favorite use case for this is to create a Lookup Table Variable, which distributes hits to different Google Analytics properties depending on which Environment the user is in:\n  You can also use this Variable in a Trigger, creating a powerful Exception to avoid firing expensive Tags in certain Environments.\n  All in all, a very useful addition to your arsenal of variables.\nSummary Environments are really useful. They\u0026rsquo;re a huge leap in the right direction, again, turning Google Tag Manager into a more manageable mess, especially in multi-user projects.\nThe first thing you\u0026rsquo;ll want to do is establish some permanent Environments (e.g. QA and Staging), and update the web servers with the Environment container snippet. Then, make sure to write it down clearly that the link for these Environments should not be reset without good reason! If you reset the link, the container snippet needs to be rewritten.\nAfter that, you can start using other Environments for your own purposes as well. Perhaps you want to create an Environment only for a particular side project, where you need to allow preview and debug access to an agency or consultant. Or perhaps you want to start your own \u0026ldquo;branch\u0026rdquo; of versions, debugging and previewing them in your own, enclosed Environment, distributing links to anyone who might be able to help you in your work.\nThe fact that giving and revoking authentication is now completely in your administrator\u0026rsquo;s hands is also an excellent change. Now you don\u0026rsquo;t have to hunt down the person you shared the container draft link with, as you can just reset the link to the \u0026ldquo;Now Editing\u0026rdquo; Environment, revoking preview access from anyone who used to have it.\nOne thing that\u0026rsquo;s missing is the end user\u0026rsquo;s ability to revoke access by themselves. A simple \u0026ldquo;Close\u0026rdquo; link in the debug panel would be awesome. Now you have to revisit the \u0026ldquo;Share Preview\u0026rdquo; page to remove access. If the authentication is done via the container snippet, there\u0026rsquo;s no way to get rid of Preview mode while in that environment. It would be nice if you could temporarily (e.g. via a session cookie) revoke the authentication imposed by the container snippet while browsing the site.\nIt\u0026rsquo;s also a bit strange that you can see deleted versions in the Environment lists. For example, if you create a new version and then delete it, it still appears in the \u0026ldquo;Latest\u0026rdquo; Environment, and you can publish it to any Environment you want via the Actions dropdown.\nFinally, remember that tools don\u0026rsquo;t create processes, they facilitate them. If you don\u0026rsquo;t have a process the Environment is designed for, this new GTM feature will bring very little gratification. It will make some aspects of testing and previewing easier, but Google Tag Manager Environments truly shine when they reflect and facilitate existing processes.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/from-project-to-process/",
	"title": "From Project To Process",
	"tags": ["agile", "analytics", "data layer", "process", "tag management solutions"],
	"description": "How to introduce agility to your analytics projects. A successful analytics endeavor is always a process, never a single project.",
	"content": " This year I had the opportunity to present at eMetrics London and Berlin on a topic that is very close to my heart. I\u0026rsquo;m psychotically neurotic about data quality. I\u0026rsquo;ve written about it many times before, and it\u0026rsquo;s pretty much why I want to keep on blogging and writing about analytics and tag management customizations. At eMetrics, I stepped out of my comfort zone of development and implementation, and chose to talk about organization practices.\n  For the past number of years, I\u0026rsquo;ve had the fortune of working with some amazing clients and colleagues, helping entire organizations understand the concept of meaningful data and how data is always an investment. In this article, I want to pull some of these threads together, and explain how I approach data quality and the optimization thereof within an organization.\nDisclaimer As always, I do not want to preach, nor do I have any authority to tell others how to conduct their business. Quoting my good friend Craig Sullivan, experts and best practices are \u0026ldquo;rather rare and mystical beasts\u0026rdquo;.\nAll we can rely on are the experiences of people we trust.\nIf we find these experiences useful, and we can trust that the person who shared them knows what they\u0026rsquo;re talking about, we can see if these experiences could be adopted by whatever environment or context we are working in. This, I think, is lost to many who\u0026rsquo;ve succumbed to the ease of finding answers instead of methods. Too often, people ask for Please do this for me instead of Please show me how it works.\nThe way I approach learning new things is to find experiences with which I can relate, after which I dissect these experiences, trying to recreate them in a way that is most beneficial to me and my goals.\nIn this article, I will be sharing my experiences of working in and with various types of organizations. If some of these thoughts resonate with you, then I\u0026rsquo;m glad, and I look forward to hearing what you think about what I\u0026rsquo;ve written. If this sounds alien to you, then I\u0026rsquo;m equally glad, and I look forward to explaining myself further in the comments.\n1. Don\u0026rsquo;t screw up data collection Surprise, surprise, I\u0026rsquo;m all about data collection. I don\u0026rsquo;t hesitate to say that it\u0026rsquo;s the most crucial part of the web analytics process. But what about analysis, insights, visualization, segmenting? I hear you say. Yeah, those are really important as well, but if you screw up data collection, you screw up all the subsequent stages as well.\n  That image above, lovingly adopted from online-behavior.com (my favorite analytics blog), illustrates this nicely. I used my Photoshop skillz to copy-paste the cute little diamond bug on top of the \u0026ldquo;Collect Data\u0026rdquo; node. This represents a virus that has infected data collection. It means you\u0026rsquo;ve either failed or forgotten to measure something on the site. As you might guess, it means that this data is either not available or is corrupt.\nA typical example is in Ecommerce tracking. Ecommerce comprises such a huge number of variables that successful comparison across date ranges would require that these variables be encoded consistently across different points in time. How often does that happen? I\u0026rsquo;m willing to say rarely, and the likelihood decreases with time. However, still we see people comparing Revenue from last quarter (which included shipping and tax) with Revenue from a year ago (which did not include shipping and tax). The very fact that they have different aggregation methods means that they can\u0026rsquo;t be compared unless you know how these methods differ. Unfortunately, this information is often misplaced when teams and organizations change.\nIn other words, data collection is an investment. It requires labor, love, and a crystal ball. It\u0026rsquo;s one of the most difficult things to get right, and requires a lot of experience. But there\u0026rsquo;s nothing, nothing as frustrating as data that\u0026rsquo;s missing or incorrectly collected.\n2. Analytics as a PROJECT is the root of all evil Here we go: diving into the controversial end of the pool. Let me juice it up with another claim.\nData quality is destroyed by ineffectiveness and non-involvement.\nLet\u0026rsquo;s see if we agree on this. Are you, or have you been, affected by the following phenomena in your organization?\n Monthly reports, which lack relevance, are rife with generic suggestions that lack research in the context of your business, reiteration of previous month\u0026rsquo;s points, even if there are solid reasons why they weren\u0026rsquo;t addressed\n Ridiculously ugly and ineffective JavaScript hacks for measurement points, which should be tackled in the Data Layer\n Clueless managers who want you to fix metrics rather than the underlying reasons that output the data into those metrics (\u0026ldquo;Fix our Bounce Rate, please!\u0026rdquo;)\n Analytics features are deprioritized, and deployed extremely infrequently\n  These are all symptoms of data being treated as a project outcome! They smack of non-involvement. They are deliverables and off-shoots of mail-order projects, where an entire analytics process is treated as something that can be time-boxed, outsourced, and ignored.\nIn the agency world, these assignments were quite typical. It\u0026rsquo;s not because the agencies are lazy (well, sometimes it\u0026rsquo;s that too), but it\u0026rsquo;s because organizations have not matured enough to turn analytics into a business-driver, and treat it as a diagnostics tool instead.\nWhat I\u0026rsquo;ve learned is that the only way to make analytics truly work in an organization is to implement it as a process. As consultants, we can be \u0026ldquo;purchased\u0026rdquo; to help get things moving. This might mean an implementation project, or a consultancy project, but the key deliverable of these projects is a shift in the momentum of the organization that we are trying to help. If the organization chooses to externalize analytics to an \u0026ldquo;extra pair of hands\u0026rdquo;, which happens ever so often, they will lack the incentive to actually integrate an understanding and respect of data into their processes.\n3. Tag management solutions help us fight Conway\u0026rsquo;s law One of the reasons analytics is so difficult to integrate into organizations is because it\u0026rsquo;s cross-disciplinary. I wrote about this in a recent article in my company\u0026rsquo;s blog (10 Truths About Data):\nData is the lifeblood of the organization. It flows through all departments, across job titles, permeating the very fabric of the organization, reinforcing its foundations for growth. It cannot and should not be contained in one vector (a dedicated analyst) alone. Now, try to think of anything in a modern organization that works like that. It\u0026rsquo;s difficult, right? A typical organization is riddled with departments and silos, and there\u0026rsquo;s just so much friction in the seams.\nIn 1968, Melvin Conway said something pretty insightful, which was then coined into a law bearing his name. The law is approximated as (quoting Wikipedia):\norganizations which design systems ... are constrained to produce designs which are copies of the communication structures of these organizations In other words, if the departments within your organization (e.g. IT and marketing) are unable to communicate with each other, any systems they manage or want to create (e.g. the CMS and an analytics platform) will be unable to function together as well.\nThis is one of the reasons we resort to projects so eagerly. By requesting a project, we are allocating our department\u0026rsquo;s budget to said project, and we\u0026rsquo;ll receive something that\u0026rsquo;s optimized for our department, and our department alone. For example, the marketing department might want to implement Google Analytics on some new landing pages, and they request the help of an agency to write the implementation plan. The result is an implementation plan that only tackles the problems the marketing department outlined, instead of treating data collection as something owned by the entire organization.\nThe agency might also utter the most ridiculous words in the history of language:\n\u0026ldquo;We recommend you install Google Tag Manager, because then we won\u0026rsquo;t need IT anymore to implement analytics measurement.\u0026rdquo;\nI\u0026rsquo;m not a violent man, but when I hear or see that argument it makes my blood boil. I feel very strongly about this, and for a good reason. Nothing is as detrimental to an organization as an outside influence (e.g. agency) that communicates only with a single point of contact (e.g. marketing), but inadvertently gets mixed up in something that spans the entire organization (the IT infrastructure).\nFriends, compatriots, fellow analytics aficionados: data and analytics belong to the entire organization, not just a subset thereof. It\u0026rsquo;s unnerving, and quite honestly impossible, to try to implement something as significant as a bloody JavaScript injector (which a tag management solution often is) without involving the developers or IT!\nIn fact, I want to make the following bold claim:\nA tag management solution empowers DEVELOPERS more than others.\nWe implement a tag management solution because we want to harness a very developer-centric tool to facilitate communication within our organization. This necessarily involves multiple disciplines in the decision-making process. If you entrust a TMS solely in the hands of a department or individual that already has prejudices against working with developers, it will only inflame this relationship further.\nThe way I see it, an optimal implementation of a tag management solution is perfect for mitigating the effects of Conway\u0026rsquo;s law. Similarly, a cooperative IT or developer process is paramount in an optimal implementation of a tag management solution.\n4. Data Layer is the universal translator You see, a tag management solution is built on top of a Data Layer. Typically, we have a number of definitions for a Data Layer, but here are the three I most often fall back to:\n A set of business requirements, encoded as key-value pairs against each hit, visit, and visitor that your digital property might collect\n A uniformly encoded, global data structure that collects and distributes data on the digital property\n An internal data model in the tag management solution with which you communicate through the global data structure\n  OK, let\u0026rsquo;s try again. That was confusing.\nThe purpose of a Data Layer is to provide a **bilateral** layer on the digital asset, which **decouples**, **normalizes**, and **uniformly encodes** semantic information passed through and stored within.   Hmm, I\u0026rsquo;m not sure that made any sense either.\nLook, the Data Layer is a translator. It forces you and your buddies in IT to communicate using a common syntax. It\u0026rsquo;s a joint venture, where people and systems communicate across silos. You can keep on hating the gremlins in the IT lair if you want, but you\u0026rsquo;d better respect and love the Data Layer. If you don\u0026rsquo;t get this right, then you can just chuck the TMS out of the window, as it won\u0026rsquo;t be worth the migration.\nPerhaps unsurprisingly, I\u0026rsquo;ve written about the Data Layer before, and the more I work with organizations, the more I place my faith in its transformational power.\nWhen crafting an implementation or measurement plan, involve all the relevant departments and individuals in the process, and speak only Datalayerian. Instead of writing vague descriptions of what you might want to measure, write down key-value-pairs. Start and end with the Data Layer, in all parts of the implementation and data collection process. Let she or he who knows the constraints of this structure best lead the discussion. Translate all requirements you hear into variables and values, associated with their respective measurement points.\n5. Empower and facilitate the developers My past year at Reaktor has only strengthened something I already knew: agility is extremely helpful in the proper implementation of an analytics process.\nIt\u0026rsquo;s not easy in a world still dominated by the pitfalls of the waterfall, where projects comprised distinctive stages, each with entry and exit conditions.\nThe handovers between the discrete stages of the waterfall are where data is most often corrupted! When a deliverable is passed from one stage to another, it\u0026rsquo;s always a release rather than a continuum. Whoever passed the information is absolved of responsibility outside that of the deliverable, and whoever received the setup is forced to survive the possible conflicts, quality issues, and misgivings of the previous stages.\nThe void between the project milestones is where good data turns bad.\nInstead, what if we treat the process not as a collection of milestones but rather something that\u0026rsquo;s on-going and part of everything we do in our front-end or app development?\nThe first thing I want to implement in an analytics process is a proper consideration of measurement when developing features.\n  Since the agile process is, by nature, quite chaotic, we need something to facilitate quality assurance. Often, this comes in the shape of a Definition of Done. It\u0026rsquo;s a set of conditions that determine what is considered a success in the development process.\nIf we add analytics and measurement requirements into the Definition of Done, we are actually mitigating data quality issues even before they crop up. By making sure that developers consider measurement when developing or updating features, we are cultivating a perfect breeding ground for successful data collection.\nThis requires, of course, that the developers are aware of what measurement entails. I could refer you to read the previous chapters again, but I can just reiterate myself here:\nA tag management solution empowers DEVELOPERS more than others.\nWhenever I start working with a client, I educate the developers first. This might include:\n Helping them design modules and interfaces for communicating with the Data Layer\n Getting them up-to-speed in front-end development and the requirements that tag management solutions place on the document object model\n Inspire them to create a sandbox for tag management solution testing (this WASP playground is pretty much what I have in mind)\n Only hire to educate, not to delegate\n  Oh, that last point is so important. I respect the naïveté and hypocrisy (as I\u0026rsquo;m also a consultant) of the statement, but I truly believe in it.\nA good consultant should work in a manner that inevitably makes them redundant.\nTake that statement with a grain of salt. What I mean is that if you hire consultants for outsourcing tasks that should be handled within your organization, you not only create an unfavorable dependency, but you also lose the opportunity to improve your own processes.\nData collection and analytics are prime examples of this. I have most success when working in the client\u0026rsquo;s premises, being extremely transparent about everything I do, and working together with their key players so that they can eventually do everything I\u0026rsquo;ve done themselves. This builds trust and helps the consultant find new areas to improve and focus on, rather than things that are trivial to the consultant but super important to the client.\nSummary This text is a summary of what I\u0026rsquo;ve been talking about this past year in conferences. I\u0026rsquo;m crazy passionate about data quality, data collection, and facilitating growth in organizations.\nI believe in this stuff with every fibre of my being.\nI believe that successful projects morph into processes. They rejuvenate organizations, and build trust across silos that are engaged in ridiculous trench warfare, propagated by inflexibility and complicated hierarchies.\nI believe that an empowered developer is at the heart of a successful analytics project. However, the entire team works together to build bridges from business requirements, through the Data Layer, all the way to reports.\nI also believe that data is difficult. I\u0026rsquo;ll end this article with another one of my \u0026ldquo;10 Truths About Data\u0026ldquo;:\nData is difficult. It has to be. There are no short-cuts, no omniscient tools, no out-of-the-box solutions that give you perpetual satisfaction. The entire life cycle of a single data point, from collection to reports, requires knowledge and expertise to manage. Turning arbitrary numbers into actionable insights is not, and never will be, a walk in the park. Do you agree?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/iframe-cross-domain-tracking-in-google-tag-manager/",
	"title": "Iframe Cross-Domain Tracking In Google Tag Manager",
	"tags": ["google analytics", "Google Tag Manager", "Guide", "iframe"],
	"description": "How to track iframes with cross-domain parameters using Google Tag Manager and Google Analytics.",
	"content": "  NOTE! This solution has been upgraded, and the new approach can be found here.\n If you\u0026rsquo;re unfamiliar with the lingo, cross-domain tracking is a hack used by Google Analytics to circumvent the web browser\u0026rsquo;s same-origin policy. Essentially, the policy dictates that browser cookies can only be shared with a parent domain and all its sub-domains. In other words, domainA.com and domainB.com do not share cookies.\nSince Google Analytics calculates sessions and users by using a cookie, this is problematic. If the user navigates from domainA.com to domainB.com, they will, by default, browse domainB.com in a different session (often a different user as well) from that on domainA.com.\nThere are some great guides out there for implementing cross-domain tracking, and I want to highlight the LunaMetrics article as well as the Knewledge tutorial. Both have excellent coverage of this difficult topic, and Knewledge have devoted a lot of words for iframe tracking as well.\n  In this article, I want to go over iframe tracking once again, and update the method to GTM V2. We\u0026rsquo;ll be using the hitCallback method to decorate the iframe properly with cross-domain tracking parameters, to ensure that any tracking that takes place within is attributed to the original session (and user).\nQuick note on SUB-domain tracking Remember, cross-domain tracking applies only to separate parent domains. If you want to track traffic across sub-domains, you don\u0026rsquo;t need cross-domain tracking. Instead, you just need the cookieDomain field set in your Tags and you\u0026rsquo;re good to go. Luckily some visionary has already written a simple guide about this.\nCustom JavaScript Variable To make it all work, all you\u0026rsquo;ll need is a Custom JavaScript Variable. Well, and a simple tweak to your Page View Tag. And some testing. And good luck. But anyway, the Custom JavaScript Variable is what patches everything together.\nWe\u0026rsquo;ll use the Variable in the hitCallback field of the very first Tag that fires on your site (should be the Page View Tag). This callback function will reload any iframe of your choice with linker parameters, meaning the Tags in the iframe will run nicely as part of the ongoing session.\nLinker parameter is basically your browser\u0026rsquo;s unique client ID (with some other stuff), attached as a query parameter to the iframe src value. This is then picked up by the tracker in the iframe and used to recreate the _ga cookie in the iframe. That\u0026rsquo;s how Google Analytics\u0026rsquo; cross-domain hack works!\nSo, to get started, create a new Custom JavaScript Variable, and name it intelligently. I\u0026rsquo;ve used {{JS - hitCallback for X-Dom iframe}}, but you can use something less poetic if you wish. Here\u0026rsquo;s what it looks like:\nfunction() { return function() { try { var gobj = window[window.GoogleAnalyticsObject]; var iframe = document.querySelector(\u0026#39;#myIframe\u0026#39;); var tracker, linker; if (gobj) { tracker = gobj.getAll()[0]; linker = new window.gaplugins.Linker(tracker); iframe.src = linker.decorate(iframe.src); } } catch(e) {} } }  So, time for a line-by-line walkthrough.\nfunction() { ... }  On the first line, you\u0026rsquo;re declaring a basic GTM JavaScript function, which needs to be an anonymous function. Nothing special here, moving on.\nreturn function() { ... }  Next, you\u0026rsquo;re returning another function, as hitCallback requires a function as a parameter for it to work correctly. Also, by returning a function, we\u0026rsquo;re avoiding unsolicited side effects which would result if you just executed global DOM methods in the outer function. Since we\u0026rsquo;re operating in a closure, we\u0026rsquo;re restricting the execution of this function to only the single time it\u0026rsquo;s called, which is when the hitCallback is executed at the end of the Google Analytics payload dispatch process.\ntry { ... } catch(e) {}  We\u0026rsquo;re wrapping the code with a try...catch because that\u0026rsquo;s simply a good practice. You can add some debugging code into the catch(e) {} block if you wish, but I usually just let it sizzle down silently.\nvar gobj = window[window.GoogleAnalyticsObject]; var iframe = document.querySelector(\u0026#39;#myIframe\u0026#39;); var tracker, linker;  The following three lines setup some variables. First, we\u0026rsquo;re setting gobj to the global Google Analytics function name. This is again just a good practice, since there are cases where you want to change the function name from ga to something else. With this one-liner, we\u0026rsquo;re making sure we\u0026rsquo;re always referring to the correct object.\nThe next line is important. This is where you\u0026rsquo;ll retrieve the iframe element you want to modify. I\u0026rsquo;m using a simple CSS selector to find my iframe (an element with the ID myIframe), so remember to change it to reflect whatever you want to target. You can run this code on multiple iframes if you wish. You just need to loop through each iframe, and run the linker.decorate() method on each.\nWe\u0026rsquo;re also declaring tracker and linker as utility variables, which we\u0026rsquo;ll use in a bit.\nif (gobj) { tracker = gobj.getAll()[0]; linker = new window.gaplugins.Linker(tracker); iframe.src = linker.decorate(iframe.src); }  The final part of the code is where the magic happens. Checking for the existence of the global Google Analytics object is just another good practice you might want to employ.\nNext, we initialize tracker with the first Google Analytics tracker created on the page. As I mentioned before, this should optimally be the tracker created by your Page View Tag. We use the getAll() function call to retrieve all the trackers created on the page, and then pick the first one with [0].\nOn the following line we use the Google Analytics Linker plugin, initializing it with the retrieved tracker. This plugin is what we\u0026rsquo;ll use to decorate the iframe src with the correct cross-domain parameters. The plugin has a utility method decorate, which takes a URL string as its parameter.\nIn other words, you\u0026rsquo;re updating the iframe\u0026rsquo;s src value with a decorated URL, and this decoration actually adds the correct cross-domain parameters to the URL.\nOnce you\u0026rsquo;ve written all this code, remember to save the Variable.\nFinally, you need to add this new Variable into the hitCallback field of your Page View Tag.\nSo, open the Tag, browse to More Settings -\u0026gt; Fields to set, and add a new field:\n  There we go! We have now successfully set the stage for one of nature\u0026rsquo;s most spectacular ev\u0026hellip; Sorry, been watching too much Planet Earth.\nWhat will happen Here\u0026rsquo;s the process of what happens when you next browse the site:\n The Page View Tag fires, and after it has completed, its hitCallback field is executed\n Since this field had our custom function returned, the code within is run\n This code takes the tracker that was just created, and decorates the iframe(s) of your choice with cross-domain tracking parameters\n The iframe will reload (because its src value changed) with the cross-domain tracking parameters\n  What else you\u0026rsquo;ll need Now, any Tags firing in the iframe should have the allowLinker : true field set. You can find instructions for this in the LunaMetrics guide, for example. This simple little field will ensure that the Universal Analytics library looks for cross-domain tracking parameters in the URL, and uses them to set up the tracker in the iframe.\nIn other words, we\u0026rsquo;ve circumvented the crippling effect of same-origin policy on cookie sharing by, well, sharing a cookie value as a URL parameter. The wonderfully robust Universal Analytics library takes care of the rest.\nAlso, you will want to defer the Page View Tag from firing on the landing page of the iframe. Why? Because if you didn\u0026rsquo;t, the iframe might send a Page View when it\u0026rsquo;s first loaded, and then again when the iframe is reloaded with the hack. By preventing the iframe from firing on any page whose referrer is not the iframe URL and when the page is in an iframe, you\u0026rsquo;ll prevent double- or triple-counting your page views in the iframe. For subsequent page views you\u0026rsquo;d want to fire the Tag, because it reflects actual browsing behavior.\nAlso, if you look at the Knewledge tutorial, they have a nice solution for actually not loading the iframe in the first place, and only loading it when the hitCallback is executed (or if there\u0026rsquo;s some problem with loading the JavaScript).\nIt\u0026rsquo;s all up to you, of course. Double- or triple-counting isn\u0026rsquo;t always a problem.\nIf you have a situation where the iframe isn\u0026rsquo;t in the DOM in time, you might also need to add a setTimeout in the hitCallback to allow time for the DOM to complete. However, this is very rare in my experience.\nAnyway, working with iframes is quite difficult, as you can probably guess. Lots of things to pay attention to.\nThat was a perfect segue to the final chapter and a well-deserved rant.\nSummary This was a rather simple guide for setting up iframe tracking with cross-domain parameters. Let me be clear and on-the-record about something:\nIFRAMES SUCK!\nThey are horrible, Lovecraftian subterranean beings of horror that crawl from the nether pits of darkness after the tolling of the midnight bell. They are playground bullies; entitled little brats that wreak havoc on innocent markup. They are artefacts of human laziness, true examples of Conway\u0026rsquo;s Law in motion. They are, in essence, untrackable little shit-monsters that exist in the void between websites, accountable to none and hazardous to all.\nI can personally attribute some 45% of my hair loss to working with iframes, and they have ruined my day far too many times to call it coincidence.\nIf you are forced to work with iframes, cross-domain tracking might be the least of your worries.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/setup-google-tag-manager-ios-with-swift/",
	"title": "Setup Google Tag Manager iOS With Swift",
	"tags": ["apps", "google analytics", "Google Tag Manager", "Guide", "ios", "mobile", "swift"],
	"description": "Guide for setting up Google Tag Manager tracking in your iOS app using Swift and the legacy SDK.",
	"content": " I\u0026rsquo;ve been meaning to write about Google Tag Manager for mobile apps for such a long time. Finally, I have some great use cases to share, as well as some useful examples for implementing GTM for iOS. That\u0026rsquo;s right, this is an iOS guide, and, to be more specific, geared towards a successful Swift implementation.\n  If you didn\u0026rsquo;t know, Swift is a relatively new programming language, developed by Apple for iOS and OS X programming. It\u0026rsquo;s got some nice synergies with existing Objective-C implementations, which means you can either gradually migrate to Swift, or just start writing new apps with it instantly.\nIn this article, we\u0026rsquo;ll walk through a simple Swift implementation of Google Tag Manager and Google Analytics. I\u0026rsquo;ll very briefly review the GTM SDK in the Comments chapter, but this is a how-to article, not a why-should-I writeup. I\u0026rsquo;m going to be expanding on this theme of mobile GTM in future texts, so this will stand out as a starting point for understanding how the SDK plays together with your application.\nMany thanks to my colleague, Sampsa Kuronen, for exposing me to the dark arts of Xcode and Swift.\nGetting started This guide is written with the assumption that you\u0026rsquo;re using the latest version of Xcode as your IDE of choice. It\u0026rsquo;s not the best IDE (by far) out there, but it has been created with iOS and OS X programming in mind, meaning there are certain benefits from using it.\nAnother, quite obvious, assumption is that you have access to your project source. You will be adding new files, importing headers and modifying project source code. It\u0026rsquo;s a good idea to run everything you\u0026rsquo;re doing by your team, as you don\u0026rsquo;t want to merge unverified source code into your project.\nHere\u0026rsquo;s something you might not yet fully realize:\nGTM for mobile apps is not the same as GTM for the web!\nThe level of freedom you have when working with the latter simply does not exist in the mobile app world. We\u0026rsquo;re working with projects and applications, so you need to have a solid understanding of how to do software development in a proper and consistent manner, abiding to any design patterns you have found successful.\n1. Google Tag Manager setup To get things rolling, let\u0026rsquo;s setup Google Tag Manager first. In this tutorial, we\u0026rsquo;ll create a simple Screen View Tag to test the implementation with. In later chapters, we\u0026rsquo;ll go over the event payload as well, but it\u0026rsquo;s up to you to create the Tag for it.\nIn GTM, create a new Container under some Account. Choose iOS as the container type, and give it a descriptive name.\n  Next, you\u0026rsquo;ll be whisked to the Container Overview, and you\u0026rsquo;ll see a small popup saying your container is ready to use. You can close that.\nAs you can see, it looks pretty much like GTM for web.\nNext, go to Tags, and click New.\n  Wow, that\u0026rsquo;s way fewer Tags than in GTM for web. Let\u0026rsquo;s hope we\u0026rsquo;ll get more soon! Also, make note that there is no Custom HTML Tag. It makes perfect sense, since you\u0026rsquo;re not working with HTML, but I thought I should point it out nevertheless.\nWe\u0026rsquo;ll be creating a simple Google Analytics Tag , which sends an App View (also known as a Screen View) to Google Analytics when the first View of the app loads (don\u0026rsquo;t worry, it will all be clear soon). So, create the Google Analytics Tag, and add the Tracking ID.\nMake sure that App View is selected as the Track Type, and expand More Settings -\u0026gt; Fields to Set.\nClick + Add Field, and add screenName as the Field Name. In Value, click the \u0026ldquo;Variable\u0026rdquo; button and choose New Variable\u0026hellip;.\n  We need to create a Variable, which picks up the desired Screen Name from the Data Layer (Screen Name is to an app what Page is to a website). So, after marvelling the list of Variables that\u0026rsquo;s completely different from GTM for web, choose Data Layer Variable.\nGive it a descriptive name, e.g. DLV - screenName, and set the Variable Name field to screenName. Save the new Variable.\n  Next, in the Tag screen, click Continue and proceed to the Fire On step.\nIn this step, click Custom, as you want to create a new Trigger for the Tag. So, in the popup that appears, click New.\n  Give the Trigger a descriptive name, e.g. Event - screenView, and set the condition as in the screenshot below.\n  Save the Trigger, and then click \u0026ldquo;Create Tag\u0026rdquo; to, well, create the Tag.\nPhew, almost done here! We\u0026rsquo;ll go with just this one Tag, as this is a simple setup guide.\nNext, go to the Versions page of your GTM container, and click open the Actions menu for the only container version you\u0026rsquo;ll see (the initial draft). Click Publish and follow the prompts to publish your container.\n  There, GTM is almost ready, hungry to process the Data Layer commands you dispatch from your app.\nJust one more thing to do. You\u0026rsquo;ll need to download the container version binary, as GTM for apps is a bit different in how it processes containers. Basically, you can\u0026rsquo;t trust that the app will have access to a container downloaded over the network, so you\u0026rsquo;ll always want to provide a local container binary file for the app as well. Read more about this in chapter 5.1.\nSo, click open the Actions menu for the Live container version, and choose Download. Make sure you download it somewhere you can easily find it from.\n  That\u0026rsquo;s it! We\u0026rsquo;re done with the GTM setup. All that\u0026rsquo;s left is the minor task of upgrading your App to use the Google Tag Manager (and Google Analytics) SDK!\nCongratulate yourself with a power bar and some coffee.\nI\u0026rsquo;ll wait. Maybe get some coffee myself, and boogie silently to your profound success in setting up GTM!\n(2. Create a new Xcode workspace) I won\u0026rsquo;t linger here, as I\u0026rsquo;m actually assuming you already have an Xcode project and workspace to work with. If you need something to get started with, take a look at this tutorial by Ray Wenderlich. If you pay close attention to the screenshots in the article you\u0026rsquo;re reading right now, you might notice that I\u0026rsquo;m actually using Ray\u0026rsquo;s Tip Calculator as the basis for this article.\nIf you only have a project setup and no workspace, keep reading. When you add the required dependencies to your project using Cocoapods (see below), a workspace is automatically generated for you.\n3. Download the SDKs using Cocoapods In order for Google Tag Manager to work with your app, you will need to download the SDKs for both Google Tag Manager and Google Analytics. To do that we\u0026rsquo;ll use Cocoapods, which is an open-source dependency manager for your iOS and OS X projects. As you might have guessed, both Google Analytics and Google Tag Manager SDKs are also distributed as Pods.\n  After you\u0026rsquo;ve installed Cocoapods (if you need help, check e.g. this guide), you need to go to your workspace root directory (the one with your .xcodeproj and .xcworkspace files), and type:\npod init\nThis command initializes a simple Podfile for your project.\nOpen Podfile with your favorite editor.\nBetween the lines target 'YourProject' do and end, you need to add the Pod references you want to download and install for your project, so add the following construct into the file:\ntarget \u0026#39;YourProject\u0026#39; do pod \u0026#39;GoogleTagManager\u0026#39; pod \u0026#39;Google/Analytics\u0026#39; end Once you\u0026rsquo;ve done this, you can run the command pod install, which will automatically install and import all the files to your Xcode project. Neat, huh?\n  Now that you\u0026rsquo;ve installed the Pods, the next thing you need to do is import them into your project.\nIt\u0026rsquo;s not exactly straightforward, as Google Tag Manager source code is in Objective-C, which means you can\u0026rsquo;t just directly import it to your Swift project. Instead, you need to use something called a Bridging Header.\n4. Create and edit the Bridging Header file A bridging header is key to creating projects where the codebase includes code from multiple languages - Objective-C and Swift in this case. Basically, you use a bridging header file to expose Objective-C structures in your Swift files, so that you can, for example, work with the GTM SDK (which is Objective-C at the time of writing) without having to worry about clashes and conflicts that occur when working across languages.\nFirst of all, if you installed the Pods correctly, you should see them in your Project navigator.\n  Now, to create the bridging header file, go to File -\u0026gt; New -\u0026gt; File. Under iOS / Source, you\u0026rsquo;ll find Header File, so select that and click Next.\n  Give the file a name: yourProjectName-Bridging-Header.h, and save it in your project root. Remember to choose a target for the file, so that the header file is properly associated with your project.\n  You should see the file open in your editor. Add the following import statements to the file, and then save it:\n#import \u0026#34;TAGManager.h\u0026#34; #import \u0026#34;TAGContainer.h\u0026#34; #import \u0026#34;TAGContainerOpener.h\u0026#34; #import \u0026#34;TAGDataLayer.h\u0026#34; #import \u0026#34;TAGLogger.h\u0026#34; #import \u0026lt;Google/Analytics.h\u0026gt; These headers include all the necessary Google Tag Manager headers, as well as all the Google Analytics SDK headers.\nFinally, you need to include the bridging header file in your build settings.\nClick your project (the root level node) in your Project navigator. In the settings screen that opens, choose the tag labelled Build Settings, and scroll all the way down to Swift Compiler - Code Generation.\nEdit the field next to Objective-C Bridging Header, and type in the file name of the bridging header file you just created.\n  Now, build your project and make sure everything checks out right.\nNext up, setting up Google Tag Manager in the project!\n5. Load Google Tag Manager in the project My, how far we\u0026rsquo;ve come!\nIf you look at how the developer guide kicks off, you\u0026rsquo;ll notice the rather limited capabilities of Google Tag Manager for mobile. For now, at least. Basically, you can dispatch Google Analytics hits and run custom functions. Also, you can change configuration values.\nIn this tutorial, we\u0026rsquo;ll focus on the first use case, so we\u0026rsquo;ll setup a simple interface for tracking screen views and events to Google Analytics.\n5.1. Add container binary to project Before we do anything, however, we\u0026rsquo;ll need to add the container version binary to the project. This is rather important, as even though GTM can load a \u0026ldquo;fresh\u0026rdquo; container over the network, some of the interactions on the site might actually need to be tracked before the asynchronous operation of loading the container is complete. In this case, GTM can fall back to the local container binary, also referred to as the default container.\nNOTE! This also means that you should try to keep the binary in the project as up-to-date as possible, so that batches which use the binary would be as similar as possible to those that use the fresh container. So make it a habit that every time you publish a new container version, you download the version binary, and add it to the project (delete the old binary first).\nWe\u0026rsquo;ll cover all this very soon, don\u0026rsquo;t worry.\nIn Xcode, simply drag-and-drop the container binary file to your project. A window should open, where you need to make sure that you add the file to your target (so check the relevant box).\n  If you don\u0026rsquo;t have a Supporting Files group under your project, now\u0026rsquo;s a good time to create one. Right-click on the container binary, and choose New Group from Selection. Name the group Supporting Files. Your navigator should look like this:\n  If you already do have a Supporting Files group, just move the binary into that folder.\nNext up, source code and stuff.\n5.2. Modify AppDelegate The AppDelegate.swift file is where you control states of your app. For example, when the app loads, AppDelegate, well, delegates operations to different parts of your application. Similarly, when your phone rings and interrupts the application, you\u0026rsquo;d control this process through AppDelegate.\nSince Google Tag Manager is something you want to load as the application loads, you\u0026rsquo;ll need to make changes to AppDelegate.swift. So, proceed to open the file in your editor.\nWe want to modify the function which is called once the application is loaded. Aptly, there\u0026rsquo;s one that looks like this:\nfunc application(application: UIApplication, didFinishLaunchingWithOptions launchOptions: [NSObject: AnyObject]?) -\u0026gt; Bool { // Override point for customization after application launch. // ... return true } That\u0026rsquo;s the callback we\u0026rsquo;ll open the container in. Here, \u0026ldquo;open the container\u0026rdquo; means we\u0026rsquo;ll make it available for dispatching hits using the available interfaces. On top of that, having a container available is a prerequisite for interacting with the TAGDataLayer interface. This is a slight departure, again, for how things work with GTM for web, where you could create a dataLayer object before the container loading began.\nAdd the following lines into the function:\nlet tagManager = TAGManager.instance() TAGContainerOpener.openContainerWithId( \u0026#34;GTM-XXXXXX\u0026#34;, tagManager: tagManager, openType: kTAGOpenTypePreferFresh, timeout: nil, notifier: self) // if DEBUG tagManager.logger.setLogLevel(kTAGLoggerLogLevelVerbose) Line-by-line, here\u0026rsquo;s what happens. First, you initialize an immutable variable named tagManager as a singleton instance of the TAGManager class.\nNext, you use the TAGContainerOpener interface to signal that you want to fetch a container to work with. Remember to change the \u0026ldquo;GTM-XXXXXX\u0026rdquo; to whatever the container ID you\u0026rsquo;re using is.\nThis next bit is a bit more complicated.\nWhen you download the container binary into the Supporting Files of your project, it\u0026rsquo;s called a default container. This is what GTM uses until a saved container is found, or if this saved container is not fresh (\u0026gt; 12 hours old), a new, fresh one is loaded over the network. This is why it\u0026rsquo;s imperative that the saved binary is usable. The first screen view of the app might well be ready to dispatch before a non-default container has loaded, which means you want the default container to be as accurate as possible.\nWhen choosing the openType value, I suggest you use either kTAGOpenTypePreferNonDefault or kTAGOpenTypePreferFresh.\nkTAGOpenTypePreferNonDefault attempts to load a saved container (i.e. one that was previously loaded over the network), regardless of whether it\u0026rsquo;s stale or not. Stale means it\u0026rsquo;s over 12 hours old. This means that you\u0026rsquo;ll have a container to work with sooner. If the container is stale, Google Tag Manager starts an asynchronous request for a fresh container over the network.\nkTAGOpenTypePreferFresh only loads a saved container if it\u0026rsquo;s fresh. If it isn\u0026rsquo;t, it loads a new, fresh container over the network.\nBoth revert to the default container if a saved container couldn\u0026rsquo;t be loaded or if there was a network error.\nNext, you can enable logging. I\u0026rsquo;ve commented if DEBUG because it might be a good idea to verbosely log only if you\u0026rsquo;re debugging the app, since it produces a lot of console output, which is unnecessary overhead in the live app.\nYou might have noticed that I skipped over the notifier: self key-value pair in the TAGContainerOpener call. That\u0026rsquo;s because it requires a bit more attention.\nThe notifier parameter is basically a setting, where I instruct GTM to notify my app when a container becomes available. Once a container is available, our methods and functions can create an instance of the AppDelegate class to access the loaded container. You can use container to update your app\u0026rsquo;s configuration values through GTM, for example.\nBecause you\u0026rsquo;re invoking self as the parameter value, it means that the class you\u0026rsquo;re currently in (AppDelegate) needs to implement the TAGContainerNotifier protocol, as self is bound to an instance of the current class.\nScroll up to the beginning of AppDelegate, and change the class declaration to:\nclass AppDelegate: UIResponder, UIApplicationDelegate, TAGContainerOpenerNotifier { ... var container: TAGContainer? In other words, you add the TAGContainerOpenerNotifier to the declaration line, and in the beginning of the class (so not in a func), you create a new variable container, which refers to a TAGContainer optional.\nPhew! Almost there.\nIn the end of the class, after all the other func declarations, add a new one:\nfunc containerAvailable(container: TAGContainer) -\u0026gt; Void { dispatch_async(dispatch_get_main_queue(), { self.container = container; }); } And now things should start aligning in your mind.\ncontainerAvailable is the callback that TAGContainerOpener invokes once a container becomes available. The container is passed as a parameter to this function.\nNext, we initialize self.container with the retrieved container. This way your app can use the loaded container through an instance of the AppDelegate class.\nBy the way, here\u0026rsquo;s a nifty trick. If you want to always load a fresh container over the network, you can add the following line to the dispatch_async callback:\ncontainer.refresh() This forces a fresh container load over the network.\nHow you want to load the container is completely up to you. Some methods, such as container.refresh(), impose more network requests than others, so it\u0026rsquo;s always a compromise between freshness vs. availability vs. network load.\nMuch of the container load process is explained here, though I have to say it\u0026rsquo;s not very clearly documented at all (and it\u0026rsquo;s in Objective-C).\nNow, build the project and make sure no errors pop up. You can run the project, and you should already see some verbose logging:\n  You\u0026rsquo;re ready to push stuff to the Data Layer to fire your Tags. Awesome!\n6. Push stuff to Data Layer This is where Google Tag Manager for apps is very similar to GTM for web. By invoking the push method of the Data Layer instance, GTM will react to the dictionary you push and fire any relevant Tags.\nTo try it out, open a view controller file in your project. If it\u0026rsquo;s a default project setup, there should be one named ViewController.swift.\nNow, to send the screen view, it makes sense to only send it once the view has loaded. So, find the method with the following signature, or create one if it doesn\u0026rsquo;t exist:\noverride func viewWillAppear(animated: Bool) { super.viewWillAppear(animated) } Let\u0026rsquo;s create an instance of dataLayer and push the payload to it. So modify the function to look like this:\noverride func viewWillAppear(animated: Bool) { super.viewWillAppear(animated) let dataLayer = TAGManager.instance().dataLayer dataLayer.push([\u0026#34;event\u0026#34; : \u0026#34;screenView\u0026#34;, \u0026#34;screenName\u0026#34; : \u0026#34;Home\u0026#34;]) } First you create an immutable variable dataLayer, which is a reference pointing to the dataLayer interface of a TAGManager instance.\nNext, you do the dataLayer.push(), sending a dictionary with key-value pairs. As with GTM for web, the 'event' is what makes things tick, and the other variables can (and will) be utilized if that\u0026rsquo;s how you\u0026rsquo;ve set the Tags up.\nSince we already have a Tag which uses the 'screenName' variable, this code should work, sending a screen view with Home as the screen name.\nGo ahead, build the project and run your app. You should see something like this in the debugger:\n  As you can see, the \u0026cd; (for screen name) and \u0026t; parameters are right there, meaning the payload is OK. Then, there\u0026rsquo;s the GET request to the Google Analytics endpoint, signalling that the payload has been dispatched.\nAnd that\u0026rsquo;s it! You\u0026rsquo;ve got a functioning Google Tag Manager installation in your hands.\nBONUS: Simple interface for interacting with the Data Layer Since we want to be slightly more ambitious, we can actually create an interface (or module) for interacting with the Data Layer. This way you can create elegant code in your app, simplifying some of the complex interactions and mitigating the risk of human error (e.g. typos).\nCreate a new file called Analytics.swift. Add the following code within:\nimport Foundation class Analytics { private static let dataLayer = TAGManager.instance().dataLayer private struct DataLayerMessage { let event: String let ScreenName: String func getPayload() -\u0026gt; [String:AnyObject] { return [\u0026#34;event\u0026#34; : self.event, \u0026#34;screenName\u0026#34; : self.screenName] } } static func pushScreen(screenName: String) { let screenViewData = DataLayerMessage(event: \u0026#34;screenView\u0026#34;, screenName: screenName) dataLayer.push(screenViewData.getPayload()) } } Here, you create a new class called Analytics. Within, you define some variables, structs and methods that can be used by other parts of your app.\nYou can expand the DataLayerMessage struct and the pushScreen method to include more extensive payloads, such as event objects (with category, action, label, and value), custom definitions, content groups and so forth.\nTo send a screen view with this interface, all you need is the following command:\nAnalytics.pushScreen(\u0026#34;Some screen name\u0026#34;) The class will take care of the rest.\nIt might seem complex, but it actually reduces a lot of overhead, since everything is neatly encapsulated in this single Analytics module.\nIn later articles we\u0026rsquo;ll use a similar structure in all the GTM interactions, so that things will stay nice and functional.\nComments on Google Tag Manager for iOS It\u0026rsquo;s not perfect, I\u0026rsquo;ll give you that. You might wonder what the actual benefit is to just using the Google Analytics SDK, and you\u0026rsquo;re right to feel a bit confused.\nHowever, as with GTM for web, the main benefit is with the Data Layer. Using the Data Layer interface lets you collect arbitrary semantic information from the app, and push it into the message queue without having to consider platform-specific implications. Instead, you can trust that whatever app uses the Data Layer will be able to transform the data to the form required by whatever endpoint it communicates with.\nAnd that\u0026rsquo;s exactly why we spent some time to create a custom interface for interacting with Google Tag Manager. We want to decouple semantic information from actual app logic, only sending generic strings and dictionaries through the interface.\nThis way, when GTM for apps hopefully expands and becomes richer and larger, you\u0026rsquo;ll have the general infrastructure in place already, and implementing expansions and additions will happen organically and in a controlled, fluid manner, which leaves your app none the worse for wear.\nSummary This has been a rather extensive tutorial for something as \u0026ldquo;simple\u0026rdquo; as setting up Google Tag Manager in your mobile app. Well, I hope that bubble has burst. It\u0026rsquo;s not simple. It\u0026rsquo;s not meant to be. You\u0026rsquo;re messing with a software project for goodness sake. You don\u0026rsquo;t want to mess up your chances with App Store review, or the hundreds of thousands of eager users that cringe if even the smallest thing is amiss in your beautiful app.\nGTM for mobile is not perfect. Far from it. There\u0026rsquo;s still a lot to be done, and I hope the developers come up with some solid selling points for the platform, before people dismiss it entirely in favor of the pretty robust Google Analytics SDKs.\nTo me, one of the biggest issues is, funnily enough, the terminology used. GTM for mobile is so far removed from GTM for web that it\u0026rsquo;s weird they even share the same name. There are no \u0026ldquo;tags\u0026rdquo; in mobile development. It\u0026rsquo;s just variables, classes, structs, dictionaries, functions, objects, etc.\nIt\u0026rsquo;s not \u0026ldquo;tag management\u0026rdquo;, it\u0026rsquo;s app management, and as such it carries with it far greater risks than anything you could unleash on your website.\nAnd the risks are the main reason I want to stay far away from the value collection methods and the whole idea of updating configuration values of the app through GTM. A mobile app, being a software project, should be governed by the code base, and not some outside dependency.\nI don\u0026rsquo;t understand why you\u0026rsquo;d want to delegate app operations to a web-based control panel, when all it takes is a single failed network request and a slightly outdated default container to screw up the experience for the user. And I\u0026rsquo;m sure that app users are less forgiving than web visitors, especially if the app costs money.\nThings like automatic screen tracking or automatic exception handling are not things I particularly miss, as creating the Analytics.swift module pretty much gives you a one-liner to track all your screenviews with (and events, if you extend it a little). Thus, ultimately it\u0026rsquo;s the same effort as setting a self.screenName property or something.\nOther than the above, setting GTM for apps up is a breeze once you understand the logic. I love how I can use the Data Layer to decouple semantic information stored in the app from the app logic itself. I also love how I don\u0026rsquo;t have to write analytics-specific syntax, and I can just use a generic Data Layer syntax instead. Perfection!\nI\u0026rsquo;m looking forward to writing more about GTM for mobile soon. There are many ways you can improve the analytics tracking, and the SDK still has many tricks up its sleeve that you can use to facilitate your app tracking even further.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/measure-ad-content-blocker-impact-on-traffic/",
	"title": "Measure Ad And Content Blocker Impact",
	"tags": ["adblocker", "content blocker", "google analytics", "Google Tag Manager", "Guide"],
	"description": "How to measure ad and content blocker impact on your Google Analytics tracking using Google Tag Manager.",
	"content": " So, looks like iOS 9 has built-in support for integrating \u0026ldquo;content blocking\u0026rdquo; extensions on your iPhone. Now, blocking ads and other intrusive content is nothing new, nor do I want to get into a debate about whether it\u0026rsquo;s a good thing or not. But as a data geek I\u0026rsquo;m very interested in knowing just what share of my site tracking has some content blocker enabled. In this post, I\u0026rsquo;ll show two tricks (easy and advanced) to expose these content blockers. It\u0026rsquo;s always a good idea to keep tabs on the numbers, especially if you\u0026rsquo;re concerned about them blocking your analytics tools as well (as you should be!).\n  The two solutions I\u0026rsquo;m going to introduce differ in their accuracy. Both require that you upload a small file to your web server. After that, the accuracy depends on whether or not you\u0026rsquo;re interested in knowing how many of these content blockers end up blocking Google Tag Manager as well! As it turns out, there are some that do, and you might want to measure that traffic as well.\nNOTE! Just to dispel any confusion, the following solutions will not work if Google Analytics tracking is blocked by preventing the HTTP request from ever leaving the site. The hack using an XMLHttpRequest() will circumvent those blockers which simply prevent analytics.js from loading, but it will not help if the HTTP request to Google Analytics is blocked. To measure THAT share of traffic in GA, you\u0026rsquo;ll need to relay the hits via a local web server endpoint, and send the Measurement Protocol hit to Google Analytics from your web server, where ad and content blockers can\u0026rsquo;t reach it.\nCreate the JavaScript file and upload it First thing you need to do is create a simple JavaScript file called advertisement.js and upload it to the web server. This file has just one single line:\nwindow[\u0026#39;noBlocker\u0026#39;] = true;  This file functions as bait. It has the most blatant name you could think to give to an ad library, so most of the blockers should latch onto it with their greedy, publishers\u0026rsquo;-livelihood-decimating-tendrils.\nYou need to upload this file to some location on your web server where you can link to it from your page template (or from GTM). Because I\u0026rsquo;m using WordPress, I uploaded it to the directory /wp-content/.\nOnce you\u0026rsquo;ve done this, you can follow either the easy solution (coming up soon), or the more intricate one (coming up later in the article). But start by reading the generic GTM configuration you\u0026rsquo;ll need for either approach.\nGoogle Tag Manager configuration First, you\u0026rsquo;ll need a Custom JavaScript Variable, which we\u0026rsquo;ll call {{JS - noBlocker}}. This Variable has the following code within:\nfunction() { return window[\u0026#39;noBlocker\u0026#39;] ? undefined : \u0026#39;true\u0026#39;; }  This will return nothing if the advertisement.js file loaded and created the global variable, and \u0026lsquo;true\u0026rsquo; if the file was not loaded. In other words, if a content blocker blocked advertisement.js, this Variable will return \u0026lsquo;true\u0026rsquo;.\nNext, you\u0026rsquo;ll need to create a Custom Dimension in Google Analytics. I\u0026rsquo;ve chosen Session as the scope, as Hit-level might be too granular, and User-level might be too broad. But it\u0026rsquo;s up to you. When you create the Custom Dimension, make note of the Index number that GA assigns to it.\n  Next, edit your generic Page View Tag. You need to add a new Custom Dimension row to it, with the Index number derived from Google Analytics\u0026rsquo; settings, where you just created the new dimension. The value of this dimension needs to be the Custom JavaScript Variable you created earlier. So it would look like this:\n  Let\u0026rsquo;s look at what\u0026rsquo;s going on here. When this Tag fires, it tries to populate Custom Dimension with Index number 4 with whatever the variable {{JS - noBlocker}} returns. If the site did not load the file advertisement.js, this dimension gets the value \u0026lsquo;true\u0026rsquo;, which is what\u0026rsquo;s dispatched to Google Analytics. If the file did load, the variable returns undefined, and the dimension does not get sent.\nAnd that\u0026rsquo;s the generic setup! That\u0026rsquo;s how we\u0026rsquo;ll know if a content blocker is running on the site or not.\nNext, we\u0026rsquo;ll need to choose how to link the file to the site, and whether or not we want to account for blockers that actually block GTM as well.\nEasy: link the file via GTM This is the \u0026ldquo;easy\u0026rdquo; setup, as we\u0026rsquo;ll be only using Google Tag Manager to upload advertisement.js.\nStart by creating a new Custom HTML Tag, named SETUP - Link to advertisement.js. This has the following code within:\n\u0026lt;script\u0026gt; (function() { var d = document.createElement(\u0026#39;script\u0026#39;); d.src = \u0026#39;/wp-content/advertisement.js\u0026#39;; // Modify this!  document.head.appendChild(d); })(); \u0026lt;/script\u0026gt; This creates a new element in the DOM (a script element), adds a link to the file you\u0026rsquo;ve uploaded earlier, and then appends it to the head of the document. Remember to modify the line with d.src = ... to reflect the actual location where you\u0026rsquo;ve uploaded the file to!\nSave the Tag. Note! Do NOT add any Triggers to it. Just save it. Good.\nNext, open your Page View Tag (the one where you just added the Custom Dimension to), and open Advanced Settings -\u0026gt; Tag Sequencing.\nUnder Tag Sequencing, check the box for \u0026ldquo;Fire a tag before Page View Tag fires\u0026rdquo;, and choose the SETUP - Link to advertisement.js from the drop-down list.\n  Save the Page View Tag.\nHere\u0026rsquo;s what\u0026rsquo;s going to happen. When it\u0026rsquo;s time for the Page View Tag to fire, the Custom HTML Tag is first executed. This Tag links to and executes the advertisement.js file you\u0026rsquo;ve uploaded to your web server. Next, the Page View Tag fires, and the Custom JavaScript Variable either detects a content blocker (if one is activated) or doesn\u0026rsquo;t (if one isn\u0026rsquo;t activated), and sends the Custom Dimension accordingly.\nStill with me? That\u0026rsquo;s all you\u0026rsquo;ll need. After this, data will start flowing in with your Page View Tags, annotating sessions which have a content blocker with the value \u0026lsquo;true\u0026rsquo; in the new Custom Dimension field.\nAdvanced: Page Template magic This is more advanced, as it requires you to modify the page template, but it will also account for traffic which also blocks Google Tag Manager (the b*stards!). It\u0026rsquo;s not a large share by any count, but it\u0026rsquo;s still something you might want to be wary of.\nNOTE! This solution uses a XMLHttpRequest to dispatch the data to GA, and many blockers filter block these requests as well. So you might be left with no other option than to send the data to an endpoint you own and are certain is not blocked by these tools. That\u0026rsquo;s left up to you and your developers, of course.\nLet\u0026rsquo;s start with the technical stuff first.\nYou\u0026rsquo;ll need to add the following tag to the page template before the Google Tag Manager container snippet. The logical place for it is in the \u0026lt;head\u0026gt; of the document.\n\u0026lt;script src=\u0026#34;/wp-content/advertisement.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; Remember to change the value of the src attribute to reflect the actual location of the file.\nNext, add the following minified JavaScript code to the template as well. You can add it anywhere you want in the template, though adding it to the very end is logical as it\u0026rsquo;s just synchronous JavaScript.\n\u0026lt;script\u0026gt;!function(d,e){window.addEventListener(\u0026#39;load\u0026#39;,function(){if(!window.noBlocker\u0026amp;\u0026amp;!window.google_tag_manager){for(var t=new XMLHttpRequest,n=(new Date).getTime()+Math.floor(1e8*Math.random()),o=\u0026#39;ab_gc=\u0026#39;,a=document.cookie.split(\u0026#39;;\u0026#39;),i=0;i\u0026lt;a.length;i++){for(var c=a[i];\u0026#39; \u0026#39;==c.charAt(0);)c=c.substring(1);0==c.indexOf(o)\u0026amp;\u0026amp;(n=c.substring(o.length,c.length))}t.open(\u0026#39;POST\u0026#39;,\u0026#39;https://www.google-analytics.com/collect\u0026#39;);var r=\u0026#39;tid=\u0026#39;+e+\u0026#39;\u0026amp;cd\u0026#39;+d+\u0026#39;=true\u0026amp;t=pageview\u0026amp;dp=\u0026#39;+document.location.pathname+\u0026#39;\u0026amp;v=1\u0026amp;cid=\u0026#39;+n;t.send(r);var g=new Date;g.setTime(g.getTime()+63072e6);var d=\u0026#39;expires=\u0026#39;+g.toUTCString();document.cookie=\u0026#39;ab_gc=\u0026#39;+n+\u0026#39;; \u0026#39;+d}})}(\u0026#39;1\u0026#39;,\u0026#39;UA-1234567-1\u0026#39;);\u0026lt;/script\u0026gt; It looks nasty, I know! Read through the following bit carefully.\nThis script adds a window.onload listener, which fires after the entire window object has loaded. In other words, it waits for the page load and all scripts, images, and external assets to load as well.\nNext, it checks for the existence of the noBlocker global variable, which, if you remember, is created in the advertisement.js file. It also checks for the existence of the google_tag_manager object, which is created by Google Tag Manager.\nIf both of these are missing, it means that a content blocker has blocked both advertisement.js and GTM!. How rude!\nIf these are blocked, the script proceeds with the following:\n Create a new randomized clientId, using the current timestamp and a random number.\n If a cookie named ab_gc exists, use its value as the clientId instead.\n Fire a Measurement Protocol hit to Google Analytics, using the clientId established in either step (1) or (2), and send the hit as a Page View, using the current page as the location, and setting the value \u0026lsquo;true\u0026rsquo; to a custom dimension.\n Write/update the cookie ab_gc with the clientId.\n  One important thing to note here. See the very last parentheses in the script: ('1','UA-1234567-1')? You need to update those yourself.\nThe first value in the parentheses is the index number of the Custom Dimension you want to send details about the ad blocker to. You can, for example, just use the Custom Dimension you created earlier, or you can do what I\u0026rsquo;ve done.\nI created a new Google Analytics property to collect these hits, and the Custom Dimension is a hit-scoped dimension, used in an Include Only filter on the reporting view. In other words, this new property will only accept hits that have this Custom Dimension in them, meaning it will only collect data from users that block both advertisement.js and GTM (grrr!).\nSo that\u0026rsquo;s what the second value in the parentheses is. It\u0026rsquo;s the property ID where you want to dispatch the data to. Personally, I wouldn\u0026rsquo;t use my main property, as this data simply isn\u0026rsquo;t comparable. It\u0026rsquo;s programmatically created, and is very limited as to what information is sent. You can, of course, populate all the dimension fields with some clever JavaScript magic, but I\u0026rsquo;m not that interested in all those gimmicks.\nI\u0026rsquo;m just interested in knowing how many sessions are blocking both ads and GTM (stop it!).\nSummary What you do next is up to you. You can create a custom report with session shares for those with a ad blocker vs. those without. With this data, you can optimize your site, making sure no critical information is behind potentially blocked sources.\nThere are other solutions out there as well that you might want to check out.\nUploading the advertisement.js might not be the most robust solution out there, as it doesn\u0026rsquo;t require too much imagination from content blockers to disregard this file in the future. Some methods of blocker detection include creating elements in the DOM which resemble slots for advertisements. These will probably work nicely as well.\nWith this solution, you\u0026rsquo;ll get some useful information about content blocker shares on your site, and you can immediately act on this information.\nI really, really, wish Google Tag Manager wouldn\u0026rsquo;t be blocked, as it\u0026rsquo;s not an advertisement or content distribution platform by itself. It\u0026rsquo;s just a JavaScript injector that can be used for benevolent, cool stuff as well.\nDo note that one thing that\u0026rsquo;s missing is checking whether or not Google Analytics was blocked but Google Tag Manager wasn\u0026rsquo;t. That\u0026rsquo;s an interesting use case as well, and it\u0026rsquo;s simple enough to do with a check for window['GoogleAnalyticsObject'] upon page load. You can do this via GTM or in the page template as well - it just requires some customization.\nDo you have other tips for detecting ad and content blockers? What results are you seeing? On my blog, content blockers account for around 25 % of the sessions, and those who block GTM as well are very few (but they do exist).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/measure-serp-bounce-time-with-gtm/",
	"title": "Measure SERP Bounce Time With GTM",
	"tags": ["google analytics", "Google Tag Manager", "Guide", "SEO", "serp", "timings"],
	"description": "How to measure the dwell time of users who visit your site via SERP before bouncing back to the SERP page. Using Google Tag Manager, of course.",
	"content": " Here\u0026rsquo;s an interesting and hacky use case for you. It\u0026rsquo;s all about uncovering bounce metrics for visits which originate from organic Google search results. In particular, the metric we\u0026rsquo;re interested in is how long user dwelled on the landing page after arriving from organic Google search AND returned to the search engine results page (SERP) using the browser\u0026rsquo;s back button.\n  The inspiration for this post came from an audience question at the Best Internet Conference in Lithuania, which I recently attended as a speaker. They were concerned that Google is using Bounce Rate as a search ranking signal, and I was fairly strongly opinionated that it\u0026rsquo;s simply not possible, as all the \u0026ldquo;native\u0026rdquo; GA metrics are really easy to manipulate. However, Dr. Pete from Moz wrote about dwell time in 2012, and it makes a lot of sense. Google should be very interested how long the visitor stays out of the SERP when following a link. If users tend to immediately return to the SERP, it\u0026rsquo;s very likely the result was not relevant for them.\nSo, inspired by this question, I wanted to see if I can get some metrics from how long people dwell on these landing pages before returning to the SERP. I got my results, but it\u0026rsquo;s definitely not an easy problem to solve. As usual, we\u0026rsquo;re using a combination of Google Tag Manager and Google Analytics to perform the operation.\n(UPDATE 17 April 2016 I updated this article, as I had to make some modifications to the code. It\u0026rsquo;s slightly more robust now, and it lends itself better to e.g. Custom Metrics, if you prefer to use those instead of User Timings.)\nThe result is a list of User Timings, where each landing page can be scrutinized against the time users spent on there before clicking the browser\u0026rsquo;s back button.\nThe mystery of the history The difficulty is that when the user clicks the browser\u0026rsquo;s back button, we have no knowledge of where the user is taken to. That\u0026rsquo;s browser security for you. It would be highly questionable if the website had access to the history of the web browser. Makes sense, right?\nAnother difficulty is the actual browser back button. It\u0026rsquo;s not part of the browser object model, so we can\u0026rsquo;t actually measure clicks on it. Instead, we can infer a back button click from how people navigate with URL hashes! When a hash change is recorded, we can infer that it was due to browser back if we implement a little hack, where the hash is unique to organic Google search.\nYou see, by creating a new browser history entry for people landing from organic Google search, the back button click doesn\u0026rsquo;t take them to the SERP, but rather to the original landing page that existed before we redirected the user to the new history state. Using that as an indicator, we can extrapolate that the hash change occurred due to a browser back button click (or the backspace).\nThe process The process is as follows:\n If the user lands on the site through organic Google search, create a new browser history entry with the hash #gref\n Later, if a hash change is registered, and the user is still on the landing page, and the hash change is from #gref to a blank string, fire a Google Analytics timing event, after which programmatically invoke the \u0026ldquo;Back\u0026rdquo; event in the browser history\n  Looks simple (actually, doesn\u0026rsquo;t look simple at all), but it\u0026rsquo;s very hacky indeed. You see, we\u0026rsquo;re manipulating browser history by creating a new, fictional entry called #gref. Then, when the user clicks browser back, instead of taking them back to Google search, it actually takes them to the previous state, which is the URL without the #gref.\nTHAT\u0026rsquo;S how we know both that the user clicked browser back AND that they were trying to return to the SERP. All we have to do is send the Google Analytics timing hit, and then move the user manually to the previous entry in the history (i.e. the SERP).\nWhy is it hacky? Well, you\u0026rsquo;re manipulating browser history, for one. You\u0026rsquo;re creating a custom state, and you\u0026rsquo;re forcing the user to adopt that state if they land from organic search. Next, you\u0026rsquo;re intercepting a legitimate browser back event, and instead of letting the user directly leave the site, you\u0026rsquo;re forcing them to send the GA timing hit first, before manually whisking them back to the SERP.\nWhew! Lots of things that can go wrong. Luckily the JavaScript is solid and beautiful, but don\u0026rsquo;t forget to test thoroughly!\nWait, let me repeat that: test thoroughly. Also, if you\u0026rsquo;re running a single-page website, I can almost promise you that this won\u0026rsquo;t work out-of-the-box.\nThe Custom HTML Tag At the heart of this solution is a single Custom HTML Tag. It\u0026rsquo;s fired by two different events, to which we\u0026rsquo;ll return shortly.\nFirst of all, here\u0026rsquo;s the code:\n\u0026lt;script\u0026gt; (function() { var s = document.location.search; var h = document.location.hash; var e = {{Event}}; var n = {{New History Fragment}}; var o = {{Old History Fragment}}; // Only run if the History API is supported  if (window.history) { // Create a new history state if the user lands from Google\u0026#39;s SERP  if (e === \u0026#39;gtm.js\u0026#39; \u0026amp;\u0026amp; document.referrer.indexOf(\u0026#39;www.google.\u0026#39;) \u0026gt; -1 \u0026amp;\u0026amp; s.indexOf(\u0026#39;gclid\u0026#39;) === -1 \u0026amp;\u0026amp; s.indexOf(\u0026#39;utm_\u0026#39;) === -1 \u0026amp;\u0026amp; h !== \u0026#39;#gref\u0026#39;) { window.oldFragment = false; window.history.pushState(null,null,\u0026#39;#gref\u0026#39;); } else if (e === \u0026#39;gtm.js\u0026#39;) { window.oldFragment = true; } // When the user tries to return to the SERP using browser back, fire the  // Google Analytics timing event, and after it\u0026#39;s dispatched, manually  // navigate to the previous history entry, i.e. the SERP  if (e === \u0026#39;gtm.historyChange\u0026#39; \u0026amp;\u0026amp; n === \u0026#39;\u0026#39; \u0026amp;\u0026amp; o === \u0026#39;gref\u0026#39;) { var time = new Date().getTime() - {{DLV - gtm.start}}; if (!window.oldFragment) { dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;returnToSerp\u0026#39;, \u0026#39;timeToSerp\u0026#39; : time, \u0026#39;eventCallback\u0026#39; : function() { window.history.go(-1); } }); } else { window.history.go(-1); } } } })(); \u0026lt;/script\u0026gt;  Let\u0026rsquo;s quickly walk through this code. First of all, the whole block is encased in an immediately invoked function expression (IIFE) (function() {...})();, which protects the global namespace. Also, the whole solution only works if the user\u0026rsquo;s browser supports the History API: if (window.history) {...}.\nThe first important code block is this:\nif (e === \u0026#39;gtm.js\u0026#39; \u0026amp;\u0026amp; document.referrer.indexOf(\u0026#39;www.google.\u0026#39;) \u0026gt; -1 \u0026amp;\u0026amp; s.indexOf(\u0026#39;gclid\u0026#39;) === -1 \u0026amp;\u0026amp; s.indexOf(\u0026#39;utm_\u0026#39;) === -1 \u0026amp;\u0026amp; h !== \u0026#39;#gref\u0026#39;) { window.oldFragment = false; window.history.pushState(null,null,\u0026#39;#gref\u0026#39;); }  This code checks the following:\n Was the Tag fired due to the Page View Trigger (i.e. a page load)?\n Did the user land from a Google site (referrer contains www.google.)?\n If they did, make sure it\u0026rsquo;s not from an AdWords ad (check that the URL does not have ?gclid) or custom campaign.\n Make sure also that the URL does not already contain #gref, which would imply the user followed a link with that hash or that the user already had a history entry with #gref, meaning they\u0026rsquo;ve navigated somewhere else within or outside the site after landing on it in the first place from the SERP.\n  If these checks pass, then a new global variable oldFragment is initialized with the value false. This means simply that this is a brand new landing on the site through organic Google search, and we check against this when we push the payload to dataLayer. We only want to send the Timing hit for landing page bounces.\nFinally, a new browser history state is created, where the URL is appended with #gref to show that the user landed from organic Google search.\nThe next code block is:\nelse if (e === \u0026#39;gtm.js\u0026#39;) { window.oldFragment = true; }  Here, we check if the event is a page load again, but the URL already has #gref. In this case, we set the global variable to true, since obviously this entry is not a direct landing from the SERP but something else. This way, we\u0026rsquo;ll block the Timing hit from happening, as we only want to measure true landing page bounces.\nThe final code block is:\nif (e === \u0026#39;gtm.historyChange\u0026#39; \u0026amp;\u0026amp; n === \u0026#39;\u0026#39; \u0026amp;\u0026amp; o === \u0026#39;gref\u0026#39;) { var time = new Date().getTime() - {{DLV - gtm.start}}; if (!window.oldFragment) { dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;returnToSerp\u0026#39;, \u0026#39;timeToSerp\u0026#39; : time, \u0026#39;eventCallback\u0026#39; : function() { window.history.go(-1); } }); } else { window.history.go(-1); } }  Again, there\u0026rsquo;s a checklist of things:\n Is the event a browser history event?\n Is the old hash #gref and the new hash a blank string?\n  If all these checks pass, it means that the user tried to go back in browser history to the SERP. Due to our manually imposed history state, they\u0026rsquo;re actually taken to the #gref-less landing page.\nNext, we check the dwell time on the page, using the difference between the current time and the time when the GTM container snippet was first loaded. This is a reasonable description of dwell time, but you can use something else for start time if you wish.\nFinally, we check if oldFragment is false, meaning we\u0026rsquo;re still on the landing page. If it is, the payload is pushed into dataLayer. The \u0026lsquo;eventCallback\u0026rsquo; key has the actual return to SERP command, and it will only be executed after any Tags that use the returnToSerp event have fired.\nHacky-dy-hack-hack! I love it!\nAll the other stuff you\u0026rsquo;ll need Here\u0026rsquo;s a list of the assets you need to create for this to work. Feel free to improvise, if you wish!\n1. Built-in Variables First, make sure the following Built-in Variables are checked in your container\u0026rsquo;s Variables settings.\n  So that\u0026rsquo;s Page URL, Event, History Source, New / Old History Fragment.\n2. The Triggers for the Custom HTML Tag The Custom HTML Tag runs on two Triggers.\nThe first one is the default All Pages Trigger.\nThe second one is a History Change Trigger which looks like this:\n  This Trigger only launches when a browser history event is detected which is also a popstate, and the new history fragment is empty.\n3. The Variables Create the following Data Layer Variables:\n  This one stores the time when the GTM container snippet was executed.\n  This is where the time spent on the landing page is stored.\n4. The Trigger for the Timing Tag The Trigger you\u0026rsquo;ll attach to the Timing Tag (created next) looks like this:\n  This Trigger fires when the returnToSerp dataLayer event is pushed via the Custom HTML Tag. It also checks that the dwell time pushed into dataLayer is less than 30 minutes. This way a new session won\u0026rsquo;t be started with the event, if the visitor stays on the page for an exceptionally long time.\n5. The Timing Tag And here\u0026rsquo;s the Universal Analytics Timing Tag you\u0026rsquo;ll need:\n  We\u0026rsquo;re sending SERP Bounce as the Timing Category, the full Page URL as the Timing Variable, and the time spent on the landing page as the value. As mentioned above, this Tag is fired by the Trigger you created in step (4) above.\nViewing the results Once you implement this, you\u0026rsquo;ll find the results under Site Content \u0026gt; Site Speed \u0026gt; User Timings under the Timing Category labelled SERP Bounce.\n  To drill into the data, it\u0026rsquo;s useful to view the Timing Variable as the primary dimension, as that\u0026rsquo;s the one where the landing pages are. Try to find landing pages with an abnormally small average dwell time:\n  These pages have a very short dwell time compared to site average. Just make sure that the timing sample is large enough for you to draw conclusions from. Pages with an abnormally short dwell time from the SERP MIGHT indicate a poor experience or lack or relevant content.\nAlso, the Distribution view is useful if you want to drill down to individual page performance:\n  This report lets you view the timing buckets. As you can see, there are some anomalies here, though the sample is quite small.\nSummary I hope I\u0026rsquo;ve convinced you by now that this is a very hacky solution. Remember to test thoroughly. I can also promise that you will have problems if you try to implement this on a single-page application (e.g. AJAX site), which rely on the browser history API for navigation.\nNevertheless, it\u0026rsquo;s an interesting way of uncovering potential issues with your landing pages. It would be interesting to align this data with keyword data, but that\u0026rsquo;s up to you to solve, since that data is difficult to come by these days, and User Timings don\u0026rsquo;t align well with acquisition dimensions like Keyword.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/check-for-new-user/",
	"title": "#GTMTips: Check For New User",
	"tags": ["cookies", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "How to check if a user is &#34;New&#34; in terms of Universal Analytics tracking. This uses Google Tag Manager to collect and send the information to Google Analytics.",
	"content": " Every now and then we want to create a bridge between the stateful machines we send data to (e.g. Google Analytics), and the stateless environment where we collect the data itself (e.g. Google Tag Manager). This is not easy. There is no synergy between Google Analytics and Google Tag Manager which would let the latter understand anything about things like sessions or landing pages or Bounce Rates.\nOne thing we can reliably measure, however, is whether or not the visitor is a New User in Google Analytics. This is done by checking whether or not the Universal Analytics cookie _ga exists in the user\u0026rsquo;s browser when they enter the site. Naturally, this check needs to happen before the Universal Analytics Tag has time to create the cookie, which is the only difficult thing to solve here.\nTip 32: Check for a new Google Analytics user   The process is quite simple. When the user lands on the page, check if they have the _ga cookie in their browser. If not, then they\u0026rsquo;re a \u0026ldquo;New User\u0026rdquo; in Google Analytics. Once this check is made, you can do whatever you want with this information (with one caveat, see below).\nIn any case, the first thing you need is a 1st Party Cookie Variable, which checks for the existence of the _ga cookie:\n  This would return undefined if the cookie does not exist, so we can check against this in a Custom HTML Tag.\nThe only thing to solve here is when to fire the Custom HTML Tag. Basically, you have two options. Either upon an event that takes place before the first Universal Analytics Tag on the page fires, or upon the same event which fires the first Universal Analytics Tag.\nIf you make the Custom HTML Tag fire upon an event which happens after the Universal Analytics Tag is fired, it\u0026rsquo;s possible that a race condition emerges, and the UA Tag has time to create the cookie before the check is made.\nStill following?\nThe Custom HTML Tag could look like this:\n\u0026lt;script\u0026gt; if (!{{Cookie - _ga}}) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;newUser\u0026#39;, \u0026#39;ga_newUser\u0026#39; : \u0026#39;true\u0026#39; }); } \u0026lt;/script\u0026gt; This Tag would push a dataLayer object which has an event and an arbitrary key (ga_newUser in the example). You can use these to fire some Tag or run some functions that you only want to run for Google Analytics \u0026ldquo;New Users\u0026rdquo;.\nUPDATE As pointed out by both dusoft and Stephen Harris in the comments (thanks guys!), you can use tag sequencing to send user status information to the main Tag without having to build a clumsy event chain. You can follow the guide linked to in the previous sentence, and simply update GTM\u0026rsquo;s data model with google_tag_manager[{{Container ID}}].dataLayer.set('ga_newUser', 'true') in the Custom HTML tag.\nThis way the Custom HTML tag, being the setup tag of the sequence, updates the value of ga_newUser in GTM\u0026rsquo;s data model, and it is then available to the main tag to use in a Data Layer Variable.\nCaveats So, there are some caveats here. First, it\u0026rsquo;s most likely that your Universal Analytics Tag fires on the \u0026ldquo;All Pages\u0026rdquo; Trigger. That\u0026rsquo;s the most common setup. If you set the Custom HTML Tag to fire upon the All Pages Trigger as well, any information you push into dataLayer in the Custom HTML Tag will not be available to the Universal Analytics Tag. Google Tag Manager has a fixed Data Layer for the duration of an event, so any changes will not be available until the next Data Layer event.\nAlso, it\u0026rsquo;s possible that the user is a \u0026ldquo;New User\u0026rdquo; even if they have the _ga in the browser. The cookie lifetime is 2 years, so it\u0026rsquo;s entirely possible that the cookie exists due to an older installation or something. Also, the page can collect to a number of Universal Analytics trackers, each with different cookie configurations. The cookie name could be different, or the cookie domain could vary. In this case, just looking for _ga might not be robust enough to identify a New User. You\u0026rsquo;ll simply need to adapt to how your site\u0026rsquo;s Universal Analytics configuration is setup.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/enhanced-ecommerce-tips-and-learnings/",
	"title": "Enhanced Ecommerce Tips And Learnings",
	"tags": ["enhanced ecommerce", "google analytics", "Google Tag Manager", "Guide", "Tips"],
	"description": "Tips and learnings from a multitude of Enhanced Ecommerce implementations. Most of these tips relate to Google Tag Manager, but there are some Google Analytics tricks mixed in as well.",
	"content": " Enhanced Ecommerce is undoubtedly an excellent feature of Google Analytics. It provides us with a set of reports that truly extend the capabilities of funnel-based website analysis. As I\u0026rsquo;ve shown before, it\u0026rsquo;s also very useful for tracking other transactional events on your site, such as content engagement.\n  However, here\u0026rsquo;s the thing. It\u0026rsquo;s not very easy to implement. Even if you get everything right according to the documentation, there are still quite a number of pitfalls, and many of the learnings emerge only through experience. This is where I want to help out, so I composed this post with some of my key findings about Enhanced Ecommerce implementation and use.\nIt\u0026rsquo;s well worth learning this stuff, as a fully functional Enhanced Ecommerce implementation might well be the key to finally coming up with a useful report to plaster across your vanity dashboards.\n1. Implementation via Google Tag Manager As a self-proclaimed Google Tag Manager fanatic number 1, I do all my implementations with GTM. There are some quirks you need to consider, though, when implementing Enhanced Ecommerce through GTM. Here they are, in no particular order.\nThe fleeting ecommerce object If you use the Enable Enhanced Ecommerce / Use Data Layer option in your Tags, there\u0026rsquo;s one very important thing to understand.\nOnly the most recent ecommerce object is included in the hit!\nIn other words, if you do two consecutive dataLayer.push() commands with their own \u0026lsquo;ecommerce\u0026rsquo; objects, any Tag which fires after the latter push will only have access to the latter \u0026lsquo;ecommerce\u0026rsquo; object.\n  This is because the \u0026ldquo;Use Data Layer\u0026rdquo; option uses version 1 of the Data Layer, which doesn\u0026rsquo;t have fancy things like recursive merge of objects. In practice, this means that an \u0026lsquo;ecommerce\u0026rsquo; object will always overwrite the previous \u0026lsquo;ecommerce\u0026rsquo; object in the data layer, if the version 1 interface is used.\n  If you do want to recursively merge \u0026lsquo;ecommerce\u0026rsquo; objects, you will need to use the \u0026ldquo;Read data from variable\u0026rdquo; option which becomes available when you uncheck the \u0026ldquo;Use Data Layer\u0026rdquo; option. Read on\u0026hellip;\nCustom JavaScript Variable to the rescue I\u0026rsquo;ve written about this before, and these days I actually only use this option to send the payloads. When you use the Custom JavaScript option (see the developer guide for further information), you can create, parse, and delete parts of the \u0026lsquo;ecommerce\u0026rsquo; object until it\u0026rsquo;s to your liking. This is an incredibly powerful tool, letting you pull in data from multiple sources to compile the object, or allowing you to access the full \u0026lsquo;ecommerce\u0026rsquo; object stored in the data model, and not just the stunted version 1 object available if you use the \u0026ldquo;Use Data Layer\u0026rdquo; option in your Tags.\nfunction() { var ecom = {\u0026#39;ecommerce\u0026#39; : { \u0026#39;impressions\u0026#39; : pageData.productImpressions, \u0026#39;detail\u0026#39; : { \u0026#39;actionField\u0026#39; : {\u0026#39;list\u0026#39; : \u0026#39;Related Products\u0026#39;}, \u0026#39;products\u0026#39; : pageData.productDetailView } }; return ecom; }  The example above pulls together both product impressions and product detail view in a single object, sending the complete payload to Google Analytics with the Tag.\nTo access a recursively merged ecommerce object, you will need to create a new Data Layer Variable which accesses the \u0026lsquo;ecommerce\u0026rsquo; object pushed within. Instructions for this can be found in this article.\nYou can combine multiple data types in a single payload This is pretty vaguely covered in the developer guide, but combining data types in a single payload can be very useful if you want to keep the number of requests to Google Analytics down. So, if you want to send multiple \u0026lsquo;ecommerce\u0026rsquo; objects in one single payload, you can, but only if you send one of each object type (promoView, promoClick, impressions, action). An action is any Enhanced Ecommerce data type which has the products Array. In other words, these are the available action objects:\nclick, detail, add, remove, checkout, purchase, checkout_option, refund\nAlso, you can\u0026rsquo;t combine a promoClick with a promoView or an action object. These are, thus, the valid combinations:\n impressions with one of promoView, promoClick or action\n impressions with promoView and action\n promoView with one of impressions or action\n promoView with impressions and action\n promoClick with impressions\n action with one of impressions or promoView\n action with impressions and promoView\n  In any case, combining objects into a single payload can truly save a lot of time and make the whole thing more efficient, but don\u0026rsquo;t forget that Google Analytics has a character limit in the payload!\nThere is an 8KB limit in the payload The analytics.js library refuses to send a hit if the full payload size is larger than 8192 bytes. This does require quite a lot of data to be stuffed within, but it only takes some dozens of product impressions to clog up the channel.\nEivind Savio has written an excellent post about how to manage this overflow, so I suggest you head on over to take a look!\n2. Consistency is key Enhanced Ecommerce is comprised almost entirely of hit-level interactions. This means that every Enhanced Ecommerce payload sent to Google Analytics is unique, and does not persists its information across subsequent hits.\nThis, in turn, basically means that the products Array needs to be consistent throughout the funnel. For example, if you have a product which has the category \u0026rsquo;T-Shirts\u0026rsquo;, you will need to have this information in all the payloads the product is sent in if you want to query for it across the entire funnel. GTM or GA will not persist this information.\nYou\u0026rsquo;ll want to be very careful when designing and developing the Data Layer for your Enhanced Ecommerce payloads. The developers need to understand how important it is to have the product details be identical throughout the funnel process.\nThis has implications for queries as well. For example, let\u0026rsquo;s say you send the following two payloads to Google Analytics:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;A12345\u0026#39;, }] } }, \u0026#39;event\u0026#39; : \u0026#39;ecommerce\u0026#39; }); dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;A12345\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;My T-Shirt\u0026#39; }] } }, \u0026#39;event\u0026#39; : \u0026#39;ecommerce\u0026#39; });  In this case, querying for product SKU \u0026lsquo;A12345\u0026rsquo; will return a result when queried against product detail views and product adds to cart. However, product name \u0026lsquo;My T-Shirt\u0026rsquo; will only return a result when queried against product adds to cart. Since this product name was missing from the \u0026lsquo;detail\u0026rsquo; payload, you won\u0026rsquo;t be able to query for this information.\nMany times when working with an Enhanced Ecommerce implementation which uses client-side methods to populate some of the data (e.g. scraping from the page), this consistency requirement has become a serious issue. I\u0026rsquo;ve been forced to persist full product information throughout the funnel using solutions like HTML5 Storage and cookies.\nThis is not the recommended approach.\nThe best way is to render product details in dataLayer as the page loads, making sure your developers add them consistently in all steps of the funnel. Once the products are in dataLayer, you can use the Custom JavaScript Variable method to pull them out and parse them into a valid ecommerce object.\nNote that checkout is a bit exceptional in terms of consistency. It\u0026rsquo;s enough to send the \u0026lsquo;products\u0026rsquo; Array with just the first step. This is because Enhanced Ecommerce only has an aggregate productCheckouts metric, which increases by one when a product is sent with the first checkout step. The checkout option and the rest of the checkout steps need not, and thus perhaps should not include product information.\n3. Product-scoped custom dimensions and metrics Product-scoped custom dimensions and metrics are a wonderful way to extend the rather limited set of information you can send with each product.\nTo send a product-scoped dimension or metric in Google Tag Manager, you need to include the dimensionX and/or metricX key in the respective product in the payload you want to send the dimension/metric in. Again, as in the previous chapter, product-scoped dimensions and metrics do not persist, so you will need to include them consistently in the payloads.\nFor example, to send a dimension with details about the T-shirt size, and a metric with the tax-free value of the shirt, the dataLayer.push() would look like this:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;A12345\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;My T-Shirt\u0026#39;, \u0026#39;dimension3\u0026#39; : \u0026#39;Large\u0026#39;, \u0026#39;metric2\u0026#39; : 11.99 }] } }, \u0026#39;event\u0026#39; : \u0026#39;ecommerce\u0026#39; });  Naturally, a payload like this will only let you query for this information with product detail view queries, and for this particular product only. These dimensions do not persist across funnel payloads, nor do they cover multiple products. They\u0026rsquo;re per product, per hit.\nI\u0026rsquo;ve written about product-scoped custom dimensions and metrics before, so remember to check out this article as well.\n4. Product categories The \u0026lsquo;category\u0026rsquo; field has been available in \u0026ldquo;traditional\u0026rdquo; Ecommerce as well, but it\u0026rsquo;s been slightly revamped in Enhanced Ecommerce.\nFirst of all, the consistency requirement applies here as well. If you want to make full-funnel queries against a product category, you will need to send the category with every single product in all steps of the funnel you want to query against. The field does not persist.\nThe other thing about categories is that you can send five levels of categories, resulting in some sweet segmentation in your reports. These levels are sent by using the slash (/) between levels, where level 1 is the first item in the string, level 2 the second, etc. So, a full five-level product category string would look like this in a payload:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;A12345\u0026#39;, \u0026#39;category\u0026#39; : \u0026#39;Clothes/T-Shirts/Men/Sleeveless/Used\u0026#39; }] } } });  This way, you can query for individual category levels with the following Google Analytics dimensions:\nProduct Category Level 1: Clothes\nProduct Category Level 2: T-Shirts\nProduct Category Level 3: Men\nProduct Category Level 4: Sleeveless\nProduct Category Level 5: Used\nThese aren\u0026rsquo;t available in the default reports, but you can create custom reports easily, or use them as secondary dimensions.\n  If your category names contain the character \u0026lsquo;/\u0026rsquo;, you will need to write this in a different way, as there\u0026rsquo;s no way to encode the slash without it being interpreted as a category delimiter.\n5. Product list attribution Not everything about Enhanced Ecommerce is hit-level, though. Product lists and promotions have an attribution mechanism, where the last list or promotion that the user interacted with before a purchase within the same session is the one which gets full credit for the purchase. In other words, you don\u0026rsquo;t need to persist list information throughout the funnel. It\u0026rsquo;s enough to send it only where the list interaction takes place, and the attribution will take care of the rest.\nRemember to check the developer guide for a description of this attribution mechanism.\n6. Summary This short list of tips includes a number of things that are either vaguely described in the developer guides, or are difficult to grasp without concrete examples.\nIf there\u0026rsquo;s one thing that stands out, it\u0026rsquo;s the consistency requirement. It\u0026rsquo;s very important to keep product details consistent across the funnel. A single change in the product name, for example, can make reporting extremely difficult, as you\u0026rsquo;ll need to consolidate multiple product names under a single SKU in your reports.\nDid I miss some important tip / learning? Do you have something to add? Sound off in the comments!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/prevent-tag-from-firing-in-iframe/",
	"title": "#GTMTips: Prevent Tag From Firing In iFrame",
	"tags": ["google analytics", "Google Tag Manager", "gtmtips", "JavaScript"],
	"description": "Use Google Tag Manager to block a tag from firing in an iframe. This is useful if you want to avoid double-counting measurements to Google Analytics, for example.",
	"content": " Unfortunately, iFrames still exist. They are used to embed content from one page into another. Frames are horrible, nasty things, very often riddled with cross-domain problems, performance issues, responsive design obstructions and other crap from the nether pits of hell. Regardless, if you\u0026rsquo;re stuck with an iFrame which also collects data to your Google Analytics property, for example, you probably want to prevent at least the first Page View from firing, since otherwise you\u0026rsquo;ll be double-counting Page Views: once on the main page and once in the iFrame. In this tip, I\u0026rsquo;ll show you how to prevent a Tag from firing if it\u0026rsquo;s executed in a document that is in an iFrame.\nTip 31: Prevent Tag from firing in an iFrame   For easy copying, here\u0026rsquo;s the code:\nfunction() { try { return window.top !== window.self; } catch(e) { return false; } }  As you can see, it\u0026rsquo;s a simple solution. The Custom JavaScript Variable simply checks if the window object on the page is different than the window object on the outermost frame. This script thus returns true if there is a difference, meaning the page is not loaded in the outermost frame (and is thus in an iFrame), and false if there is no difference, meaning the page is the \u0026ldquo;main\u0026rdquo; document. The Trigger would thus look like this:\n  Add this Trigger as an Exception to a Tag which fires upon the Page View Event, and you will effectively block the iFrame from sending the Page View.\nIf you want to create a \u0026ldquo;global\u0026rdquo; Exception, which blocks all Tags from firing when in an iFrame, use the Custom Event Trigger:\n  Sometimes you only want to block the first Page View in the iFrame, but then allow the user to navigate from page to page in the frame, sending Page Views for subsequent pages. In that case, you need a bit more creativity, and you\u0026rsquo;ll need to check for the Referrer, blocking the Tag if the Referrer is the \u0026ldquo;main\u0026rdquo; document:\n  This solution should work cross-domain, since simply checking for the window object does not violate same-origin policy. There have been scattered reports about unreliability in some earlier versions of Internet Explorer (surprise, surprise), so it\u0026rsquo;s good to have a fallback if the script fails, which is why it sends the false upon an error.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-form-engagement-with-google-tag-manager/",
	"title": "Track Form Engagement With Google Tag Manager",
	"tags": ["form tracking", "google analytics", "Google Tag Manager", "Guide"],
	"description": "A guide to tracking forms with Google Tag Manager.",
	"content": " (Updated 13 August 2017)\nA little over a year ago, in April 2014, I wrote the post \u0026ldquo;Advanced Form Tracking In Google Tag Manager\u0026rdquo;, and it\u0026rsquo;s been at the top of my best seller list ever since. Turns out that many people are rightfully passionate about making the web forms on their websites as fluid and intuitive as possible, since a web form is often the only thing that stands between a prospect and their transformation into clienthood.\nI thought it was time to update the article to be Google Tag Manager V2 compliant. It\u0026rsquo;s not a major difference, but I have remodelled some of the JavaScript as well. Furthermore, I\u0026rsquo;ve pulled together some new ideas explored in other articles, so now it\u0026rsquo;s all conveniently packaged in this one big blog post.\nAt the heart of this article is still the methodology of picking up values from form fields. Perhaps you want to send some selection the user made to Google Analytics with the purpose of segmenting the data, or perhaps you want to identify values which most often block a conversion. Whatever the case, remember this: Google Analytics is very harsh towards PII (personally identifiable information) collection, and you need to be very vigilant in sanitizing any values you\u0026rsquo;re collecting. You don\u0026rsquo;t want to send anything to Google Analytics that can be used to identify the person who filled the form. The most typical value is an email address, which you should categorically avoid recording.\nWithout further ado, let\u0026rsquo;s get rolling. First, the basics\u0026hellip;\n1. Form tracking in Google Tag Manager In the new version (V2) of Google Tag Manager, form tracking is no longer isolated as its own \u0026ldquo;Form Listener\u0026rdquo; Tag type. Instead, auto-event tracking has shifted to handlers embedded in the Triggers you use to fire Tags.\nWhen you create a Form Trigger, it will activate on all pages where the Enable this trigger when\u0026hellip; setting is valid. Remember, you only see this setting if either \u0026ldquo;Wait For Tags\u0026rdquo; or \u0026ldquo;Check Validation\u0026rdquo; is checked in the Trigger settings.\n  If the Trigger is active on a page, it will actively listen for a form submission. The settings in the Trigger are:\n Wait For Tags - GTM will pause the form submission for as long as all the Tags that use the Trigger have fired or until the timeout (default 2000 milliseconds) expires.\n Check Validation - If this is checked, GTM will not fire the Trigger if the default action of the form (submit and redirect) is prevented. If left unchecked, the Trigger will go off whenever a submit event is registered, whether or not the default action is prevented.\n Enable this trigger when\u0026hellip; - As mentioned above, this condition is for establishing on which pages GTM should listen for form submissions. There\u0026rsquo;s really no performance penalty in having the listener active on all pages, but there are cases where Wait For Tags interferes with other JavaScript on the page, so you might want to only have the listener enabled on pages you\u0026rsquo;ve tested it on.\n Fire this trigger when\u0026hellip; - If you select \u0026ldquo;Some Forms\u0026rdquo; as the This trigger fires on setting, these conditions that govern when the Trigger makes any attached Tags go off. If you have just one form on the website, using \u0026ldquo;All Forms\u0026rdquo; here is justified. But if you want to specify you only want to fire the Tag when a form with id=\u0026quot;contactForm\u0026quot; should fire the Tag, you should add that as a condition here.\n    If you don\u0026rsquo;t see Variables like \u0026ldquo;Form ID\u0026rdquo; or \u0026ldquo;Form Classes\u0026rdquo; in the Variables drop-down menu, you will need to activate them, as they are Built-In Variables, introduced in Google Tag Manager V2.\nHowever, there might be many reasons why a properly created Form Trigger doesn\u0026rsquo;t work. So, read on\u0026hellip;\n2. Why the Form Trigger doesn\u0026rsquo;t always work For the Form Trigger to work, the form must dispatch a valid form submit event which also bubbles all the way to the document node. To de-gobbledegookify this statement, it means that:\n The form must dispatch a valid submit browser event\n This event must not be prevented from propagating to the document node\n  Those are the conditions. They seem simple enough, but you might be surprised how many forms out there violate either one.\nThe first means simply that GTM listens for a standard submit browser event, which is most often dispatched when an input or button element is clicked, where element type is submit.\n  The second means that the submit must be allowed to climb all the way up to the document node, where GTM\u0026rsquo;s listener is waiting for the event. You see, GTM uses something called event delegation to listen for form submissions. This is much more economical than adding a listener to all the forms on the page individually.\nThe first condition is most commonly violated when the submit event is either cancelled (see below) or never dispatched in the first place. Many forms send their data with custom-built requests (e.g. jQuery\u0026rsquo;s $.ajax or the XMLHttpRequest API), and these prevent the submit event from working, since it\u0026rsquo;s replaced with a custom dispatcher. Since the submit event is never dispatched, Google Tag Manager never records a form submission.\nThe second condition is violated when event propagation is stopped with return false; in a jQuery handler. Another common way to prevent propagation is to use stopPropagation() instead of preventDefault() on the event object.\nI\u0026rsquo;ve written about this phenomenon a number of times before:\n Why Don\u0026rsquo;t My GTM Listeners Work?\n #GTMTips: Fix Problems With GTM\u0026rsquo;s Listeners\n  The best way to fix the issue, however, is to open a line of communication with your developers, and tell them that GTM requires a standard submit browser event to propagate all the way to the document node to work.\nIf this can\u0026rsquo;t be done, the next best thing is to ask the developer to implement a custom dataLayer.push() into the callback function which is invoked upon a successful submission. The piece of code could be something like:\nfunction onFormSuccess(event) { window.dataLayer = window.dataLayer || []; window.dataLayer.push({ event: \u0026#39;formSubmissionSuccess\u0026#39;, formId: \u0026#39;contactForm\u0026#39; }); // Rest of the success callback code }  This would push formSubmissionSuccess into the dataLayer as the value of the event key. Then, you can create a Custom Event Trigger, which waits for an event named formSubmissionSuccess. Using this Trigger would then fire a Tag when the form is successfully submitted.\nThere are other workarounds which involve e.g. polling the page until a thank you message is identified, or perhaps using a custom-built DOM Listener. Unfortunately, all workarounds are far less robust than either fixing the form to respect GTM\u0026rsquo;s Form Trigger requirements or the custom dataLayer.push() method described above.\n3. Built-In Variables Google Tag Manager introduces a number of Built-In Variables you can use to simplify form tracking. Make sure all the \u0026ldquo;Form\u0026rdquo; Variables are checked before continuing.\n   Form Element - returns an HTML Object which contains the form element that was submitted. You can use this Variable to dig deep into the object properties of the form itself.\n Form Classes - returns a string of values in the class attribute of the form that was submitted.\n Form ID - returns a string with the value stored in the id attribute of the form that was submitted.\n Form Target - returns a string with the value stored in the target attribute of the form that was submitted.\n Form URL - returns a string with the value stored in the action attribute of the form that was submitted.\n Form Text - returns the entire text content of the form that was submitted (NOT very useful).\n  Many of the following solutions rely on these Built-In Variables.\n4. Note about scope All the Variables described below are Custom JavaScript Variables. They are all scoped, by default, to the form that was submitted with {{Form Element}}.querySelector.... If you want to access any form on the page, submitted or not, you need to use the following syntax:\nvar form = document.querySelector(\u0026#39;#someform\u0026#39;); var field = form.querySelector...  Keep this in mind when applying the following solutions to your own measurement plan.\n5. Capture field value This is a simple Custom JavaScript Variable which captures the value user has input into a form field. Do note that items like checkboxes, radio buttons, and drop-down lists work a little differently, which is why they are covered in their own chapters.\nName: {{Field value}}\nfunction() { var field = {{Form Element}}.querySelector(\u0026#39;#inputFieldId\u0026#39;); return field ? field.value : undefined; }  Description: This solution accesses the value attribute of the form field with ID inputFieldId, as long as its found within the form that was submitted. If no such field is found, then undefined is returned instead. Remember, do not collect personally identifiable information!\n6. Capture selected radio button value This solution is for capturing the value of the checked radio button. The default solution is for capturing just one radio button value, i.e. accessing just one group. See chapter 9 for an example of how to access multiple values from similar elements.\nName: {{Checked radio button}}\nfunction() { var radioName = \u0026#34;radioName\u0026#34;; var checked = {{Form Element}}.querySelector(\u0026#39;[name=\u0026#34;\u0026#39; + radioName + \u0026#39;\u0026#34;]:checked\u0026#39;); return checked ? checked.value : undefined; }  Description: Returns the value of the checked radio button in the group with the name radioName. This group must exist within the form that was submitted. If no checked button is found, undefined is returned.\n7. Capture selected checkbox value Returning the value of the selected checkbox within a group is done exactly the same way as how you\u0026rsquo;d capture a radio button value. Both use the checked property to identify if an element is checked.\nSo use the solution from the previous chapter to capture checkbox values as well. Just remember that it only returns the value of the first checkbox in a group that was selected. If the user can check multiple checkboxes (as is usually the case), you might want to check chapter 9 for tips on how to do this.\n8. Capture selected drop-down list item value To capture the selected item value in a drop-down list, checking for the value of the list itself will not work, as you\u0026rsquo;d intuitively expect. Instead, you need to access the option in the list that was selected, and then capture its value.\nName: {{Selected list item}}\nfunction() { var selectList = {{Form Element}}.querySelector(\u0026#39;#selectListId\u0026#39;); return selectList ? selectList.options[selectList.selectedIndex].value : undefined; }  Description: First, the script retrieves the drop-down list with ID selectListId. Next, it returns the value of the selected option in the list. If the list does not exist, the script returns undefined.\n9. Capture multiple values Sometimes you\u0026rsquo;ll want to capture multiple values of some specified group. A prime example is the checkbox, where you can have multiple checked boxes in a single group. Here are some ideas for how to capture these values.\nReturn concatenated string of checked item values\nfunction() { var groupName = \u0026#34;groupName\u0026#34;; var elems = {{Form Element}}.querySelectorAll(\u0026#39;[name=\u0026#34;\u0026#39; + groupName + \u0026#39;\u0026#34;]:checked\u0026#39;); var vals = []; var i, len; for (i = 0, len = elems.length; i \u0026lt; len; i++) { vals.push(elems[i].value); } return vals.length ? vals.join(\u0026#39; \u0026#39;) : undefined; }  Description: This returns a concatenated string of all the checked item values within the group with name groupName. An example would be e.g. \u0026ldquo;breakfast lunch\u0026rdquo;, where the user chooses which meals they always eat out of \u0026ldquo;breakfast\u0026rdquo;, \u0026ldquo;lunch\u0026rdquo;, and \u0026ldquo;dinner\u0026rdquo;.\nTo return just the plain Array, so that you can process it further in the Tag which calls this Variable, change the return statement to:\nreturn vals.length ? vals : undefined;  If you want to get the values in a multiple selection list, use the following script. It returns the results in a concatenated string again, but by following the tip in the previous paragraph you can return an Array instead.\nReturn selected values in a multiple selection list\nfunction() { var selectList = {{Form Element}}.querySelector(\u0026#39;#selectListId\u0026#39;); var options = selectList ? selectList.options : []; var vals = []; var i, len; for (i = 0, len = options.length; i \u0026lt; len; i++) { if (options[i].selected) { vals.push(options[i].value); } } return vals.length ? vals.join(\u0026#39; \u0026#39;) : undefined; }  Description: This returns a concatenated string of all the selected options in a multiple selection drop-down list, which has the ID selectListId and which is within the submitted form.\n10. Track form abandonment For ideas on how to track form abandonment, check out this article I wrote a short while ago:\nTrack Form Abandonment With Google Tag Manager\nLunametrics also has a sweet guide on how to achieve the same thing, albeit with a somewhat different approach.\nMy colleague at Reaktor, Lauri Piispanen, has also improved upon this solution, and you can check out his GitHub repo here.\n11. Track form field timings If you want to track how much time a user spends on your form, segmented by individual fields, check out the following article:\nForm Field Timing With Google Tag Manager\nIt utilizes User Timings in Google Analytics to collect data on how much time users spend in the fields of your form by average.\n12. One form element - multiple forms (ASP.NET) I decided not to dwell on this topic too much, since it\u0026rsquo;s so hacky and unreliable. The issue is that on e.g. ASP.NET sites, a single master form control wraps the entire page, and individual forms are just groups of elements under this one control.\nThe method I suggested in the previous guide is still somewhat valid, however. The way it works is that:\n Fire a Custom HTML Tag when the submit button of the form is clicked\n In this Custom HTML Tag, push the ID (or other relevant data) of the clicked element into the data layer\n Create a Form Submit Trigger which looks for this value in the data layer\n  This way the Form Submit Trigger should only fire when the form is submitted due to a click on the correct submit button.\nI\u0026rsquo;ve noticed this doesn\u0026rsquo;t always work due to race conditions or just the general fragility of the event chain. Nevertheless, it\u0026rsquo;s something you might want to try if you can\u0026rsquo;t get developers to assist you.\nIf you do have an established line of communications with your developers, the solution is to ask them to create / edit the success callback of each form to push a custom dataLayer object when a form is submitted. This object should contain information about which form was submitted, and you can then create a Custom Event Trigger based on this information. Go back to chapter 2 for an example of such a push.\n13. Summary This guide is a bit leaner than the first edition (at least it feels like so). That\u0026rsquo;s because the new Form Submit Trigger has made many things easier, and I\u0026rsquo;ve also rewritten the JavaScript to utilise methods like querySelector and properties like selectedIndex to get the desired result with far less hassle.\nOnce IE8 and older disappear entirely from the face of this earth (can\u0026rsquo;t wait!), we can use even simpler language, with e.g. CSS3 pseudo-classes like :checked.\nDo you think something relevant is missing from this guide? Let me know. I\u0026rsquo;m always happy to update this with new solutions. Don\u0026rsquo;t forget to read the previous version of the guide as well, and check the comments section, too! Lots of great questions and answers there.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/understanding-tag-sequencing-in-google-tag-manager/",
	"title": "Understanding Tag Sequencing In Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "tag sequencing"],
	"description": "Guide to tag sequencing in Google Tag Manager. You can use this feature to set dependencies in the firing order of related tags.",
	"content": " A recent update to Google Tag Manager introduced a feature which has been on the wishlist of many users for a long time. It\u0026rsquo;s called Tag sequencing, and its purpose is to facilitate the sequential firing of Tags. The idea is that you can specify a setup and a cleanup for each Tag in your container.\n  This article is intended to function as a quick tour of the feature. It\u0026rsquo;s not the simplest feature to understand, as Tag sequencing runs parallel but separate from the normal flow of your container. Don\u0026rsquo;t worry, I\u0026rsquo;ll get back to this soon.\n1.Sequence in a nutshell A sequence comprises three phases:\nThe setup, which is a Tag which must successfully complete before the main Tag fires.\nThe main tag, which is the Tag with the dependencies. It\u0026rsquo;s either dependent on the setup, or it establishes a dependency with the cleanup.\nThe cleanup, which is a Tag which fires after the main tag has completed successfully.\n  The sequence is created by editing the Advanced Settings of the main tag. You will see two new settings here:\n Fire a tag before\u0026hellip;\n Fire a tag after\u0026hellip;\n  The first setting is for choosing the setup for the main Tag. The latter is for the cleanup. If you choose a setup, it will need to complete before the main tag itself fires. If you choose a cleanup, the main tag will need to complete before the teardown is fired. For both, you can choose whether or not a failure in either the setup or the main tag will abort the sequence.\nOK. That was confusing. Allow me to visualize it with my superior PowerPoint skills.\n  In the sequence above, the Page View Tag (setup) must successfully complete before the Event Tag (main tag) fires. If the Page View Tag fails, the sequence is aborted. Similarly, the Event Tag must successfully complete before the final Event Tag (cleanup) fires. If the main Tag fails, the final Event Tag will not fire.\nYou can, of course, specify that the Tags fire even if some member in the sequence fails.\nThe key thing to understand about the sequence is that it\u0026rsquo;s isolated. Using Tag sequencing lets you specify a sequence of hits that fire when the main tag is triggered. This means that the setup and cleanup Tags will act completely oblivious to any Triggers you might have added to them.\nIndeed, no matter what Triggers you have or have not equipped on them, they are completely ignored if the Tag is used as a setup or cleanup. For this reason, it might be prudent to not use setup and cleanup Tags for anything except sequencing, but there is a way to make it work both ways (I\u0026rsquo;ll get back to this soon).\nI emphasize again that this is a difficult concept to grasp. I\u0026rsquo;m sure the UX / UI could be made more intuitive, but the reason it\u0026rsquo;s difficult is that it relies on callbacks, which are invisible in actual GTM usage (unless you start debugging on a really granular level).\n2. The callbacks We still have some theory to cover before delving deeper into the practical stuff.\nIn GTM, each Tag has a callback. With Tag templates, these callbacks depend on how the Tag works. For example, the Google Analytics Tag uses the hitCallback feature as its callback.\nSo, when you establish a setup, for example, the main tag will not fire until the onSuccess callback of setup is invoked. With the Google Analytics Tag template, the tag will be fired only after the hitCallback of the setup is executed successfully. Similarly, the cleanup will not be fired until the onSuccess callback of the main tag is called.\nPhew!\nThe other callback is onFailure. This is invoked in case the Tag does not successfully complete. In the settings for Tag sequencing, you can specify that the main tag must not fire if setup fails, or you can choose to ignore the failure. Similarly, you can specify that the cleanup must not fire if main tag fails, or you can, again, choose to ignore the failure.\nYou don\u0026rsquo;t have to worry about these callbacks when using Tag templates. GTM takes care of calling onSuccess and onFailure for you, and all you need to do is make sure that you\u0026rsquo;ve checked the correct boxes in the settings (I promise, we\u0026rsquo;re going to get to the settings very soon!).\n3. The Custom HTML Tag The exception is the Custom HTML Tag. Since you might want to tell Google Tag Manager not to proceed to the next tag until something has happened (e.g. an asynchronous operation has completed), a workaround is required. If you go to the Built-in Variables, you should see a new one: HTML ID:\n  This is used to invoke either the onSuccess or onFailure callback for the Custom HTML Tag.\nSo, if you want to use a Custom HTML Tag as either the setup or the main tag, and you want to establish a sequence with success and/or failure conditions, you will need the following:\n The HTML ID Built-In Variable\n The Container ID Built-In Variable\n The Custom HTML Tag itself\n  In the following code example, I\u0026rsquo;m running some custom JavaScript, and once it\u0026rsquo;s done, I\u0026rsquo;m letting the sequence know that onSuccess has been called.\n\u0026lt;script\u0026gt; (function() { var gtm = window.google_tag_manager[{{Container ID}}]; var el = document.getElementById(\u0026#39;content-head\u0026#39;); try { el.innerHTML = \u0026#39;We have taken over your website!\u0026#39;; gtm.onHtmlSuccess({{HTML ID}}); } catch(e) { gtm.onHtmlFailure({{HTML ID}}); } })(); \u0026lt;/script\u0026gt; In the first line of the script, you copy a reference to the GTM container interface into the gtm variable. This is a very specific interface into GTM\u0026rsquo;s mechanisms, so don\u0026rsquo;t worry about it too much. Suffice to say that this reference allows you to pass the onSuccess and onFailure callbacks, which is why it\u0026rsquo;s important here.\nNext, there\u0026rsquo;s a try...catch block, where a DOM method is executed. Once it\u0026rsquo;s completed, the onHtmlSuccess() method of the interface is invoked. The parameter to this method is the new HTML ID Built-In Variable. This way GTM will be able to communicate to the next member of the sequence that it was precisely this particular Custom HTML Tag that just completed.\nIf there\u0026rsquo;s an error, then the onHtmlFailure() method is invoked, and information is passed to the sequence that this Tag did not complete successfully.\nBy now it shouldn\u0026rsquo;t be too complicated anymore to understand what\u0026rsquo;s happening. Each Tag template has an onSuccess and onFailure callback, except for the Custom HTML Tag, where you can to provide them yourself.\n UPDATE 23 July 2018: Be sure to read my article on Custom HTML tags with tag sequencing for more details on how Custom HTML tags and tag sequencing work together.\n 4. How to create the sequence Finally! Some practical information!\nUnder the Advanced Settings of each Tag template, you will find three new options:\n Tag firing options - Lets you delimit the Tag to fire either just Once per event, Once per page, or just let it fire Unlimited times.\n Tag Sequencing -\u0026gt; SETUP - Lets you choose the Tag which must complete before the Tag whose settings you are currently editing. You can specify whether the setup must complete successfully, or if failures should still make this Tag fire.\n Tag Sequencing -\u0026gt; CLEANUP - Lets you choose the Tag which must fire after the current Tag has completed execution. Again, you can specify whether the current Tag must complete successfully, or if its failure should be ignored, and the cleanup should fire regardless.\n    That\u0026rsquo;s how you set up a Tag Sequence.\nNow, in the very beginning I mentioned that the sequence works in isolation. This means that the setup you establish for any particular Tag will run the sequence regardless of what other Triggers you might have attached to the setup or cleanup. This also means that a sequence is always bound to the event of the main tag. Thus, if the main tag fires upon the \u0026ldquo;All Pages\u0026rdquo; Trigger, for example, then the entire sequence will be completed during this event.\nBecause you can use a Tag both independently and as part of a sequence, the new Tag firing options are very useful, indeed. For example, if you have Tag A as the setup for some Tag, as well as firing on its own, individual Trigger, you can specify that Tag A must only fire Once per page to prevent multiple hits from being sent. This means simply that after it has fired once, either independently or as part of a sequence, it will not fire again while the user is on the page.\nYou can also specify Once per event, which means that the Tag will only fire once for any given data layer event. So, you might have Tag A firing on the \u0026ldquo;All Pages\u0026rdquo; Trigger, and you might also have it as the cleanup of some Tag which also fires on the \u0026ldquo;All Pages\u0026rdquo; Trigger. By using the Once per event setting, Tag A will only fire once during the \u0026ldquo;All Pages\u0026rdquo; event.\n5. Note about using dataLayer.push() in the sequence One of the main use cases for using tag sequencing would be to have the setup Tag push something into dataLayer for the main Tag to use.\nHold your horses!\nIf you know your Google Tag Manager, you\u0026rsquo;ll know that the Data Layer available to any Tag is fixed for the duration of the Data Layer Event! So any Tags which fire on the initial dataLayer.push() will only be able to access the values in this push. If some Tag tries to modify the values in the Data Layer, these values will not be registered until the next dataLayer.push() with an event.\n(UPDATE: Some time after this article was written, GTM\u0026rsquo;s behavior changed so that variables are resolved separately for every tag in a sequence. This means that you don\u0026rsquo;t need to use google_tag_manager[...].dataLayer.get() if you want to retrieve a variable that changed from one tag in the sequence to the next. Instead, you can just use regular Google Tag Manager Variables, as their values will update for each tag in the sequence!)\nThis hampers development a little, since it sounds like dataLayer can\u0026rsquo;t be used as a messaging medium within a sequence, as the entire sequence operates in the span of a single Data Layer Event (the one which fired the main Tag in the first place).\nThe developer guide actually has a note about this:\n  However, at the time of writing this, dataLayer.set() does not exist. I asked the developers, and this seems to be a mistake in the guide. Instead, you need to use the following command to set values in the Data Layer even during the tag sequence:\n// To set a value, use set() with the key as the first parameter, and value as the second google_tag_manager[{{Container ID}}].dataLayer.set(\u0026#39;someKey\u0026#39;, \u0026#39;someValue\u0026#39;);  Once you use this, any Tag that fires after this one (in the same sequence), will have its Data Layer Variable reference to someKey updated to return someValue.\nIf you want to retrieve this changed value in the same Tag it was changed in, you can\u0026rsquo;t use a Data Layer Variable, since it\u0026rsquo;s resolved before the Tag is executed (and the set() command is run). You\u0026rsquo;ll need to use this syntax instead:\n// To get a value, use get() with the key as the parameter google_tag_manager[{{Container ID}}].dataLayer.get(\u0026#39;someKey\u0026#39;);  Remember to enable the Container ID Built-in Variable!\nThese are fairly advanced use cases, but it\u0026rsquo;s very good to keep this in mind when working with Tag sequences that are scoped to a single Data Layer event.\n6. Why use tag sequencing? The asynchronous loading of JavaScript is taken for granted these days. It\u0026rsquo;s a nice way for browsers to ensure a decent browsing experience even with large, bulky linked assets.\nHowever, asynchronous JavaScript makes it difficult to establish order, as you can\u0026rsquo;t predict when some script or library finishes loading. Order is introduced with callbacks or promises, but these are difficult concepts to manoeuvre around, and the Google Tag Manager UI doesn\u0026rsquo;t necessarily let you take advantage of them, especially if using templates.\nSequencing lets you tap into callbacks that GTM establishes by default (the tag templates), or that you create manually (Custom HTML Tags). It lets you chain Tags together, which is particularly useful if you want to establish dependencies.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/two-ways-to-persist-data-via-google-tag-manager/",
	"title": "Two Ways To Persist Data Via Google Tag Manager",
	"tags": ["cookies", "Google Tag Manager", "Guide", "persistence", "storage"],
	"description": "Introducing browser cookies and HTML5 storage as options for data persistence when using Google Tag Manager.",
	"content": " The web is stateless. It\u0026rsquo;s basically blind to your past, and it does a poor job of predicting what you might do in the future. When you browse to a website, the browser requests the page from the web server, and then proceeds to render it for you. This is a detached, clinical process, and any personalized or stateful data transfer is left to the sophistication of your web server.\n  Statelessness has some implications to us concerned about web analytics and measuring our visitors. In Google Tag Manager, this is an ever-present elephant in the room. Indeed, many suffer over not being able to fire Tags for e.g. returning visitors, or after five page views, or if the original source of the Session was AdWords. GTM is (for now) blind to this type of thinking, as it\u0026rsquo;s simply a JavaScript machine operating in a stateless environment. Any notion of state needs to be injected manually into the machine.\nAnd how is this done? Cookies and the Web Storage API.\nBrowser cookies Cookies in the browser are the de facto way of persisting information in the web. They\u0026rsquo;ve been around for a long time (over 20 years!), and they\u0026rsquo;re supported by pretty much all browsers - legacy and modern. For a refresher on what cookies are and how they work, check out this Wikipedia article. The most relevant features of browser cookies are:\n 4KB size limitation (per cookie)\n Unencrypted in a single string, stored in document.cookie\n Sent to the server with every single HTTP request\n Can be set with an expiration date\n  The size limitation quickly becomes an issue with large payloads, and the fact that they are sent to the server unencrypted with each request can be a turn-off for those with security concerns.\nWeb Storage API The Web Storage API is a more recent innovation, and this is represented by lack of support from Internet Explorer 7 and older (who cares, though!). The API has two interfaces: localStorage and sessionStorage. The main difference is that the latter persists for the duration of the browser session (i.e. is flushed when the browser instance is shut down), and the former persists indefinitely.\n  Features of the Web Storage API are:\n Can only be read client-side in the browser. No data is sent to the server.\n Stores a maximum of 5MB per domain\n Stores data in a hash table, meaning you can make exact queries without having to parse the data\n  Basically, the Web Storage API is a logical evolution of persistence, taking the best of cookies and adding better data access and management features. The big drawback is the lack of server-side communication, so if you rely on cookies to pass information to the web server, migrating to the Web Storage API wouldn\u0026rsquo;t be logical unless you manually send the data to the server (e.g. via POST request).\nCookies and GTM Google Tag Manager, thankfully, already provides us an interface to query for cookie values: the 1st Party Cookie Variable. When you set the Variable to a cookie name, it will always return whatever value is stored in that particular cookie. This is a huge help, since you don\u0026rsquo;t need to go through the rather tedious process of parsing the entire cookie string for the name-value pair you\u0026rsquo;re looking for.\nSetting a cookie, however, still needs to be done manually. The easiest way to set a cookie is to add the following code in a Custom HTML Tag:\ndocument.cookie = \u0026#39;cookieName=cookieValue\u0026#39;;  This would set a cookie with the name cookieName and the value cookieValue. However, using this code alone would set the cookie to expire at the end of the browser session (i.e. when the browser is shut down), and the cookie would be set on the current path and the current domain only. The path and domain combination is especially important, as the cookie would only be accessible via the page it was set on.\nThis is why it\u0026rsquo;s customary to create a helper function, with which you can provide some important parameters. To create this type of helper in GTM\u0026rsquo;s context, I suggest using a Custom JavaScript Variable named {{JS - setCookie}}:\nfunction() { return function(name, value, ms, path, domain) { if (!name || !value) { return; } var d; var cpath = path ? \u0026#39;; path=\u0026#39; + path : \u0026#39;\u0026#39;; var cdomain = domain ? \u0026#39;; domain=\u0026#39; + domain : \u0026#39;\u0026#39;; var expires = \u0026#39;\u0026#39;; if (ms) { d = new Date(); d.setTime(d.getTime() + ms); expires = \u0026#39;; expires=\u0026#39; + d.toUTCString(); } document.cookie = name + \u0026#34;=\u0026#34; + value + expires + cpath + cdomain; } }  This handy little function actually returns another function, which takes a number of parameters:\n name: Required. The cookie name.\n value: Required. Value for the cookie.\n ms: Expiration time of the cookie in milliseconds. If not set, defaults to Session.\n path: Path of the cookie. If not set, defaults to the current path.\n domain: Domain of the cookie. If not set, defaults to the current domain.\n  To use this Variable in a script, you need to use the following syntax:\n{{JS - setCookie}}(\u0026#39;session\u0026#39;, \u0026#39;true\u0026#39;, 1800000, \u0026#39;/\u0026#39;, \u0026#39;simoahava.com\u0026#39;);  This would set a cookie with the name session and value true, which persists for 30 minutes, and is written on the root page of the root domain.\nIf you want to leave a parameter out, you\u0026rsquo;ll need to replace it with undefined, if you still want to send one of the latter parameters. For example:\n{{JS - setCookie}}(\u0026#39;session\u0026#39;, \u0026#39;true\u0026#39;, undefined, undefined, \u0026#39;simoahava.com\u0026#39;);  Would set a cookie with name session, value true, which would be a Session cookie, written on the current page of the root domain.\nPhew! That\u0026rsquo;s a mouthful of code. But it does its job nicely. Combine this with the excellent 1st Party Cookie Variable, and you\u0026rsquo;ve managed to create a nice and handy cookie setter/getter.\nWeb Storage API and GTM You could create a fancy set of Custom JavaScript Variables for localStorage and sessionStorage as well, but why bother? They\u0026rsquo;re dead simple to interact with.\nTo set a key-value pair in storage, you can use the following syntax:\nif (window[\u0026#39;Storage\u0026#39;]) { // localStorage persists indefinitely  localStorage.setItem(\u0026#39;session\u0026#39;, \u0026#39;true\u0026#39;); // sessionStorage persists until the browser is closed  sessionStorage.setItem(\u0026#39;session\u0026#39;, \u0026#39;true\u0026#39;); } else { // Fallback for when the browser doesn\u0026#39;t support Web Storage API  {{JS - setCookie}}(\u0026#39;session\u0026#39;, \u0026#39;true\u0026#39;); }  First of all, you need to check if the browser supports the Web Storage API. That\u0026rsquo;s just a simple if...else block. See what I did with the fallback? That\u0026rsquo;s right! I used the {{JS - setCookie}} method we just created! What a beautiful segue.\nWeb Storage only accepts strings as values, so you need to make sure whatever you\u0026rsquo;re storing can be safely converted into a String. Don\u0026rsquo;t worry, the Storage API does the casting for you, if you fail to explicitly save a String type.\nUnfortunately, as of yet GTM does not have a handy Variable you can use to fetch items from storage (I hope this changes soon!). But to retrieve a value is just as simple as setting one:\nif (window[\u0026#39;Storage\u0026#39;]) { var localSession = localStorage.getItem(\u0026#39;session\u0026#39;); var sessionSession = sessionStorage.getItem(\u0026#39;session\u0026#39;); }  That\u0026rsquo;s right, it\u0026rsquo;s the getItem() method of the API that lets you access stored keys. It returns null if the item isn\u0026rsquo;t found.\nAnd that\u0026rsquo;s how you roll with the Web Storage API. You get by with a LOT less code, and the value lookup is way more intuitive than with cookies, though GTM does take a lot of the burden away from you with its awesome 1st Party Cookie Variable.\nSummary For many interactions, persisting data in the browser is very important. However, not all persistence should be left for the client, since servers do a far better and more robust job of storing user- and usage-based data. That\u0026rsquo;s why Google Analytics shifted from client-side calculations (ga.js and older) to server-side algorithms (Universal Analytics). And that\u0026rsquo;s why if you really have pressing and business-critical needs to persist information, you might want to talk to your developers about storing this in a proper data store or database, exposing the information in the dataLayer when and where relevant.\nBut for the simple, session-scoped persistence, the two methods outlined in this guide should be quite useful. I strongly recommend using the Web Storage API, but unfortunately you might need to introduce a fallback with browser cookies, since there are still many fools out there using outdated browsers.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/product-scoped-custom-dimensions-and-metrics/",
	"title": "#GTMTips: Product-Scoped Custom Dimensions And Metrics",
	"tags": ["enhanced ecommerce", "Google Tag Manager", "gtmtips"],
	"description": "How to use product-scoped custom dimensions and metrics in your Enhanced Ecommerce tracking. This guide is focused especially on Google Tag Manager.",
	"content": " With the advent of Enhanced Ecommerce for Universal Analytics, a new scope was introduced for Custom Dimensions and Metrics. Product scope can be used to send information about each product that is sent through Enhanced Ecommerce, but it\u0026rsquo;s not exactly the most logical or intuitive thing to wrap your head around.\nIn this #GTMTips post, we\u0026rsquo;ll take a look at how to implement Product-Scoped Custom definitions via Google Tag Manager, and I\u0026rsquo;ll quickly explain how they work in relation to queries and reports you might want to build on top of them.\nTip 29: Add product-scoped Custom Dimensions and Metrics to Enhanced Ecommerce   Here\u0026rsquo;s the key piece of information about the product scope: it\u0026rsquo;s bound to the Enhanced Ecommerce event and product it\u0026rsquo;s sent with. So, if you send the dimension or metric with a product in the Add to cart payload, it will only exist in that event. It won\u0026rsquo;t persist through the entire Enhanced Ecommerce funnel!\nThis is crucial information, as it reminds us that Enhanced Ecommerce is very clinical by nature. Barring some exceptions (e.g. product list click attribution), a well-oiled Enhanced Ecommerce funnel requires consistency. It\u0026rsquo;s critical to maintain a uniform product object throughout the funnel, adding relevant dimensions when they become available, as product variant (e.g. size) might be something you select only after the detail view, when you add the product to cart.\nProduct-scoped custom dimensions and metrics give you more dimensions and metrics to play with, but they are bound by the same consistency requirement as the regular dimensions and metrics. So keep this in mind when implementing them. In the picture above, dimension12 is used to maintain product size, which is \u0026ldquo;N/A\u0026rdquo; until the Add To Cart step. So any queries for \u0026ldquo;Show product abc123 with size Large\u0026rdquo; would only return hits for Add To Cart, Checkout and Purchase - not Impressions or Detail.\nExample uses for these custom dimensions and metrics would be:\n In stock vs. out of stock (dimension)\n Stock status (metric)\n Profit margin (dimension if percentage, metric if value)\n VAT-less price (metric)\n Host product or bundle add-on (dimension)\n  To implement product-scoped custom definitions, you basically add the dimension or metric key directly into the relevant products Array object in dataLayer:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;eecDetail\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;abc123\u0026#39;, \u0026#39;dimension3\u0026#39; : \u0026#39;In Stock\u0026#39;, \u0026#39;metric5\u0026#39; : \u0026#39;11.99\u0026#39; },{ \u0026#39;id\u0026#39; : \u0026#39;abc234\u0026#39;, \u0026#39;dimension3\u0026#39; : \u0026#39;Out of Stock\u0026#39;, \u0026#39;metric5\u0026#39; : \u0026#39;13.00\u0026#39; }] } } });  After this, any Enhanced Ecommerce / Data Layer -enabled Tag which fires on Custom Event eecDetail will also send these custom dimension and metric values to GA along with their respective products.\nTo be more generic with dataLayer, a simple way of incorporating Google Analytics -specific dimensions (such as these product-scoped definitions) is to utilize the Custom JavaScript Variable method for Enhanced Ecommerce implementation.\nIf you want to see a nice example of how to use a product-scoped custom metric, check out my post on measuring cart value with Google Tag Manager.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/block-your-tags-with-trigger-exceptions/",
	"title": "#GTMTips: Block Your Tags With Trigger Exceptions",
	"tags": ["exceptions", "Google Tag Manager", "gtmtips", "Guide", "triggers"],
	"description": "Use trigger exceptions to block Google Tag Manager tags from firing under certain conditions and circumstances.",
	"content": " To prevent a Tag from firing in Google Tag Manager, you can:\n Delete the Tag\n Remove all Triggers from the Tag\n Add an Exception Trigger to the Tag\n  The third option is usually the best if the blocking is just temporary. Exceptions are what used to be called blocking rules in the first version of GTM. To add them is easy enough. In the Fire On step of Tag creation, you can click Create Exceptions, and choose the Trigger that will block this Tag from firing.\n  However, creating an Exception can lead to confusion, as you have to pick a Trigger type for the exception! But you just wanted to block a Tag from firing; what\u0026rsquo;s with this Trigger type nonsense?!\nTip 29: Event of an Exception must match Event of the Tag   Every single Tag needs an Event to fire. An Event, in the GTM world, is a special event key that is pushed into dataLayer, either automatically by Google Tag Manager, or manually by the website developer:\nwindow.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;triggerSomeTag\u0026#39;, \u0026#39;money\u0026#39; : \u0026#39;lots\u0026#39; });  When an event key is pushed into dataLayer, GTM goes through all Triggers attached to Tags, and looks for Triggers which respond to this Event.\nIf such a Trigger is found, and if any other Trigger conditions pass, then the Tag can happily fire.\nIf you want to block a Tag from firing, you will essentially need to create an Exception for every single Event you want to prevent the Tag from firing on - individually. So let\u0026rsquo;s say you have a Tag which fires on Page View, Click, and Form, and you want to block it from firing on Page View and Click, but you still want it to respond to a Form submission. The Trigger you\u0026rsquo;d need to create as an Exception looks like this:\n  Now, when you add this Trigger as an Exception to a Tag, the following will happen:\n Upon Page View (i.e. when the container snippet loads), GTM finds the Event name gtm.js (Page View Event) in the Exception Trigger and prevents the Tag from firing.\n Upon a Click Event, GTM finds the Event name gtm.click in the Exception Trigger and prevents the Tag from firing.\n Upon a Form Submit Event, GTM does not find the Event name gtm.formSubmit in the Exception Trigger, and the Tag fires\n  So as you can see, an Exception always wins against the corresponding Trigger. The Custom Event Trigger type combined with RegEx matching is a very powerful way of blocking multiple Events at once.\nIf you want to create a comprehensive, universal, block-all Trigger Exception, all you need to do is set the Event name field to .* in the Exception Trigger. This means that whenever any Event is registered by GTM, the Exception will block every single one of these, as they are all covered by the wildcard pattern in the regular expression.\nKey takeaway here is this: the Exception Event must match the Trigger Event. For example, if you want to block a Click Trigger, you need to have a Click Trigger blocking it. Indeed, an easy way to block a single Trigger is to add the very same Trigger as the Exception!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/form-field-timing-with-google-tag-manager/",
	"title": "Form Field Timing With Google Tag Manager",
	"tags": ["form", "Google Tag Manager", "Guide", "user timings"],
	"description": "Measure the time users dwell in individual form fields using Google Tag Manager to send the data to Google Analytics.",
	"content": " The inimitable Craig Sullivan gave me an idea for a continuation to my latest post on form abandonment tracking. In this short tutorial, I\u0026rsquo;ll show you how to track the time users spend on your form fields. We\u0026rsquo;re going to use the User Timings hit type, and we\u0026rsquo;ll send the data for just one form. With small modifications, you can expand the script to cover multiple forms on a page.\n  This simple solution tracks the time the user spends on each form field by measuring the distance between the focus event and the blur or change event. The first one occurs when a form field is entered, and the latter depends on if a value changed (change) or no change was registered (blur).\nThe timing object that is sent to GA looks like this:\nTiming Category - Comment Form Field Timing\nTiming Variable - Form field name attribute value\nTiming Label - \u0026lsquo;blur\u0026rsquo; or \u0026lsquo;change\u0026rsquo; depending on how the field was exited\nTiming Value - Time spent in the field in milliseconds\nNote! Timings are counted against the 500 hits / session limit in Google Analytics. That\u0026rsquo;s why you have to be careful when implementing this. I suggest you only implement it on one form and for a short time, and then see if users\u0026rsquo; sessions are getting miscalculated thanks to them surpassing the 500 hit limit. There are some additional limitations per property as well, but they only count towards the timing hits and not all hits in the session.\nThe Custom HTML Tag The Custom HTML Tag looks like this:\n\u0026lt;script\u0026gt; (function() { var form = document.querySelector(\u0026#39;#commentform\u0026#39;); var fields = {}; var enterField = function(name) { fields[name] = new Date().getTime(); } var leaveField = function(e) { var timeSpent; var fieldName = e.target.name; var leaveType = e.type; if (fields.hasOwnProperty(fieldName)) { timeSpent = new Date().getTime() - fields[fieldName]; if (timeSpent \u0026gt; 0 \u0026amp;\u0026amp; timeSpent \u0026lt; 1800000) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;fieldTiming\u0026#39;, \u0026#39;timingCategory\u0026#39; : \u0026#39;Comment Form Field Timing\u0026#39;, \u0026#39;timingVariable\u0026#39; : fieldName, \u0026#39;timingLabel\u0026#39; : leaveType, \u0026#39;timingValue\u0026#39; : timeSpent }); } delete fields[fieldName]; } } if (form) { form.addEventListener(\u0026#39;focus\u0026#39;, function(e) { enterField(e.target.name); }, true); form.addEventListener(\u0026#39;blur\u0026#39;, function(e) { leaveField(e); }, true); form.addEventListener(\u0026#39;change\u0026#39;, function(e) { leaveField(e); }, true); } })(); \u0026lt;/script\u0026gt; To fire this Tag, I suggest you create a Page View Trigger which only fires this Tag on pages where your form exists.\nNext, change the very first variable var form = document.querySelector('#commentform'); to select the form you want to track. On my site this happens to be a form with ID #commentform.\nWhenever a focus event is detected, a hash table is updated with the form field name and the time when the field was entered.\nThen, when the field is exited, and either a blur or change is recorded, the time spent in the field is calculated, and then the field name is deleted from the hash table. If you don\u0026rsquo;t delete the field, a change event would send the timing twice, because when the user edits the value of a field and leaves it, a change is dispatched first, and then a blur.\nAnyway, feel free to change the value of the \u0026lsquo;timingCategory\u0026rsquo; variable in the dataLayer.push(). I use \u0026lsquo;Comment Form Field Timing\u0026rsquo;, as that\u0026rsquo;s what I\u0026rsquo;m doing here.\nFinally, if the form selector you use in the very first variable declaration of the script works, the three listeners are attached to the form with their respective callbacks.\nThis is the script itself. We\u0026rsquo;ll wrap up the setup in the next chapter.\nTiming Tag, Trigger, and Data Layer Variables To make the setup work, we need a Timing Tag, a Custom Event Trigger and four Data Layer Variables.\nData Layer Variables Create the Data Layer Variables first. You need four Variables with the following settings:\nName: {{DLV - timingCategory}}\nData Layer Variable Name: timingCategory\nName: {{DLV - timingVariable}}\nData Layer Variable Name: timingVariable\nName: {{DLV - timingLabel}}\nData Layer Variable Name: timingLabel\nName: {{DLV - timingValue}}\nData Layer Variable Name: timingValue\nCustom Event Trigger The Trigger is a Custom Event Trigger with the following settings:\nName: Event - fieldTiming\nFire On / Event name: fieldTiming\nTiming Tag Finally, you need to create the Timing Tag. Create a new Tag of type Google Analytics, and set the following settings:\nName: UA - Timing - Form Field Timing\nTracking ID: UA-XXXXXX-Y (substitute with your property ID)\nTrack Type: Timing\nVar: {{DLV - timingVariable}}\nCategory: {{DLV - timingCategory}}\nValue: {{DLV - timingValue}}\nLabel: {{DLV - timingLabel}}\nAttach the Trigger you created in the previous section to this Tag.\nAnd now you\u0026rsquo;re set to go! Each interaction with the fields in your form should now send the Timing hit. You can find the results in Google Analytics, by going to Behavior -\u0026gt; Site Speed -\u0026gt; User Timings.\nSummary Like I mentioned, this is a very simple solution. It just measures the time spent on each form field, and reports this as a User Timing hit to Google Analytics. You might want to tweak it a little to be more robust, and you have to be mindful of the 500 hits / session limitation that GA imposes on sessions.\nYou can do some cool stuff with the data, such as building a histogram where it\u0026rsquo;s easier to visualize the problematic fields. It would be also interesting to see if long time spent on a field correlates with form abandonment.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-form-abandonment-with-google-tag-manager/",
	"title": "Track Form Abandonment With Google Tag Manager",
	"tags": ["custom html", "form", "Google Tag Manager", "Guide"],
	"description": "Track how, where, and when users are abandoning your forms. Use Google Tag Manager to send the data to Google Analytics.",
	"content": " Form abandonment isn\u0026rsquo;t always easy to define. Most often, it refers to when someone starts to fill in an HTML form, but leaves the page without submitting it. As a definition, this works nicely. However, with multi-page forms it naturally refers only to the last page of the form. Also, especially with government institutions, forms can be saved to be submitted later. Here, again, form abandonment must be reconsidered.\n  In this article, I\u0026rsquo;ll go over four different ways to track form abandonment in Google Analytics, using Google Tag Manager to setup the tracking. The definition I\u0026rsquo;ll use is the first one: abandonment occurs when someone enters a form page, but leaves it without submitting the form. Do note that GA might not be the right tool to actually track issues with your form. There are dedicated resources for that, such as ClickTale or Hotjar. But if you want to measure form engagement as part of a more coherent visitor journey, then it might make sense to track this engagement (or lack thereof) in Google Analytics.\nThe different methods I\u0026rsquo;ll go over, in order of difficulty (as perceived by myself):\n Advanced Segment in Google Analytics\n Event sent if form interacted with\n Event sent with the last field interacted with\n Event sent with full interaction history\n  Well, the first one can be done without Google Tag Manager at all. But the others require some setting up.\nThe technology, if you will, is based on the beautiful combination of beforeUnload, a browser event that is dispatched when the user leaves or closes the web page, and the transport field in Universal Analytics. With these in place, GA will receive an event that contains information about form interaction when the user leaves the form page. You can then use an Advanced Segment to only view interaction data for sessions where the form was not submitted.\nI\u0026rsquo;ll even show you a simple way of sending the event only if the user didn\u0026rsquo;t submit the form.\nNote that this guide is created around a very simple, basic form, which has been created according to Best Practices; capital B, capital P. If you have some Ajax-postback-dynamic-validation-jQuery-horror-ultra-modern-form, this might not work for you, and you\u0026rsquo;ll have to put your JavaScript skills to the test as you apply these lessons to the abomination you\u0026rsquo;re cursed to work with.\nDon\u0026rsquo;t say I didn\u0026rsquo;t warn you!\n(UPDATE. My colleague, Lauri Piispanen, wrote a very, very nice upgrade to the Custom HTML Tag, and it\u0026rsquo;s freely downloadable from his GitHub repo. It automatically tracks multiple forms on the page!)\nAdvanced Segment in Google Analytics In Google Analytics, the simplest way to track form abandonment is to create an Advanced Segment, which includes Sessions where the form page was visited, but the session itself did not include a conversion for the form submission:\n  This is OK. It\u0026rsquo;s not polished, as it doesn\u0026rsquo;t really tell us anything about why the form was abandoned. Also, a simple page view of the form page is simply not a good way to extrapolate intent. But for all intents and purposes, this exposes possible flaws in a crucial funnel on your website.\nAs you create the Events in the chapters that follow, you can substitute the Page rule in the segment condition with an Event rule that matches the Event you\u0026rsquo;ve created.\nThe base Custom HTML Tag This Custom HTML Tag is what we\u0026rsquo;ll use to setup the beforeUnload listener as well as the interaction handlers created incrementally in the following chapters.\nSo, beforeUnload is a browser event that is dispatched when the page is unloaded from the browser. Most typical ways for a page to unload is if the user is redirected to some other page (via a link or form submission, for example), or if the user decides to close the browser. Naturally, if the user\u0026rsquo;s computer crashes, no controlled beforeUnload event is dispatched.\nWe want to use this browser event to invoke a dataLayer.push() when the user leaves the page. This push() will include a custom event key as well as values for the fields in the Event Tag we\u0026rsquo;ll create in the next chapter.\nCreate a Custom HTML Tag, give it some illustrious name, and set it to fire only on pages with forms. Here\u0026rsquo;s the code we\u0026rsquo;ll work on. Just copy-paste it into the Tag.\n\u0026lt;script\u0026gt; (function() { var eventAction; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;formAbandonment\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Abandonment\u0026#39;, \u0026#39;eventAction\u0026#39; : eventAction }); }); // Add actual logic here...  })(); \u0026lt;/script\u0026gt; That\u0026rsquo;s pretty simple, right? All you do is attach a listener to the page, which waits for the beforeunload event. When that takes place, a dataLayer.push() is invoked, which is then used to fire a Google Analytics Event Tag with all your abandonment issues within. The whole thing is wrapped in an immediately-invoked function expression to protect the global namespace from being polluted with your variables.\nThe Event Tag Before we go on, let\u0026rsquo;s create the Event Tag itself. And before we do that, you\u0026rsquo;ll need to create a Custom Event Trigger and two Data Layer Variables.\nThe Custom Event Trigger looks like this:\n  And the two Data Layer Variables look like this:\n    Next, onto the Event Tag itself. It\u0026rsquo;s your basic affair, with a simple Event Category and Event Action. I\u0026rsquo;ve set the Non-Interaction field to True, since this isn\u0026rsquo;t really a user interaction but more like metadata about the page view, but you can do as you wish.\nRemember to add your new Custom Event Trigger you just created to this Tag.\nThe Tag itself looks like this:\n  You\u0026rsquo;ll need one more thing that\u0026rsquo;s not visible in the screenshot. Go to More Settings -\u0026gt; Fields to Set, and add the following:\nField Name: transport\nValue: beacon\nThis will utilize a beautiful feature of the Universal Analytics library, where any HTTP request that is initiated as the page is unloaded will be allowed to complete before the page or browser is run down. It doesn\u0026rsquo;t have stellar browser support, which means that horrible browsers such as Internet Explorer might simply exit the page before the request to GA completes. But we can live with that.\nNow that we\u0026rsquo;ve taken care of the foundations, we can get to the juicy stuff. Are you ready? I didn\u0026rsquo;t hear you? ARE YOU READY?\nSorry for that.\nTrack simple interaction \u0026ldquo;Simple interaction\u0026rdquo; here translates to: the user changed the value of any form field. That\u0026rsquo;s all we care about. It doesn\u0026rsquo;t matter which field, and it doesn\u0026rsquo;t matter how many form fields. We want to draw a line between two types of people: those who didn\u0026rsquo;t interact with the form at all, and those who did.\nTo make this work, you\u0026rsquo;ll need to add another custom listener into the Custom HTML Tag. Here\u0026rsquo;s what we\u0026rsquo;ll go with in the Custom HTML Tag you\u0026rsquo;ve already created:\n\u0026lt;script\u0026gt; (function() { var eventAction; var formSelector = \u0026#39;form\u0026#39;; // Modify this CSS selector to match your form. Default is first form on the page.  window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { if (eventAction) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;formAbandonment\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Abandonment\u0026#39;, \u0026#39;eventAction\u0026#39; : eventAction }); } }); document.querySelector(formSelector).addEventListener(\u0026#39;change\u0026#39;, function() { eventAction = \u0026#39;True\u0026#39;; }); })(); \u0026lt;/script\u0026gt; In the beginning, you define a formSelector. This is a basic CSS selector that you use to target a single form, e.g. \u0026lsquo;#formId\u0026rsquo; or \u0026lsquo;.formClass\u0026rsquo;. If you choose a selector that can have potentially multiple hits on the page, this script will only listen to the first instance.\nIn the end, we add a change listener to this particular form. If a change event is registered in any of the form fields, i.e. the form field value changes, then the eventAction variable is given a value \u0026lsquo;true\u0026rsquo;.\nFinally, the dataLayer.push() that sends the payload to dataLayer which triggers the Event Tag is set to execute only if the eventAction variable is set. Thus, you\u0026rsquo;ll only report on potential form abandonments if the user has interacted with the form.\nThe Event Tag will have Event Category Form Abandonment and Event Action True.\nTo get the most out of this solution, you\u0026rsquo;d create an Advanced Segment in Google Analytics, where you\n Include only sessions where form goal completions is 0\n AND where Event Category equals Form Abandonment\n  You need the \u0026ldquo;goal completions is 0\u0026rdquo; because this Event will be dispatched when a form is submitted as well. In order to only send the Event when the user has interacted with the form but did not submit it, jump to chapter 7.\nLike I said, this is a very simple, rudimentary way of analyzing traffic that interacted but did not submit.\nTrack last field interacted with Let\u0026rsquo;s improve the previous solution a little. Instead of just blindly looking at who interacted and who didn\u0026rsquo;t, let\u0026rsquo;s send the last field the user interacted with to GA. Maybe this will give us some clue about what made the user abandon the form.\nSo, modify the Custom HTML Tag to look like this:\n\u0026lt;script\u0026gt; (function() { var eventAction; var formSelector = \u0026#39;form\u0026#39;; // Modify this CSS selector to match your form. Default is first form on the page.  var attribute = \u0026#39;name\u0026#39;; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { if (eventAction) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;formAbandonment\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Abandonment\u0026#39;, \u0026#39;eventAction\u0026#39; : eventAction }); } }); document.querySelector(formSelector).addEventListener(\u0026#39;change\u0026#39;, function(e) { eventAction = e[\u0026#39;target\u0026#39;].getAttribute(attribute); }); })(); \u0026lt;/script\u0026gt; We\u0026rsquo;ve added a new variable, attribute. In this, you specify the attribute name that you want to collect to describe which form field was the last one that was interacted with. I would recommend against choosing value or anything that the user can add content to. This is to protect your GA account from inadvertently collecting personally identifiable information such as e-mail addresses and such.\nThe other additions are the e parameter in the callback function of the \u0026lsquo;change\u0026rsquo; listener, and the attribute value of the e['target'] object as the value that eventAction retrieves. The target parameter of the event object contains the HTML element that was the target of the event action, which in this case would be the form field whose value changed.\nI would recommend you use the name attribute, since it\u0026rsquo;s usually the most descriptive one (especially with well-formed forms).\nSo, an input field like \u0026lt;input name=\u0026quot;email\u0026quot; type=\u0026quot;text\u0026quot;\u0026gt; would send \u0026lsquo;email\u0026rsquo; as the Event Action of the Event Tag.\nNow, again, this would send an Event every time someone leaves the form page, so you\u0026rsquo;ll get some false positives as well. Remember to apply the Advanced Segment, where you look for sessions with this event (using the Event Category filter in the segment settings), and sessions without any form submissions (using a goal completion filter or something similar).\nGet full interaction history Here we\u0026rsquo;ll extend the Event Action value that is sent to Google Analytics to include a complete \u0026ldquo;history\u0026rdquo; of fields that were interacted with this. This is done as a trail that might look like this:\nfirstName \u0026gt; lastName \u0026gt; address \u0026gt; creditCardNumber \u0026gt; expirationDate \u0026gt; creditCardNumber\nAs you can see, it will record multiple interactions as well. The history example above would indicate that the Credit Card Number field was the one that caused the user to disdainfully abandon your form.\nTo make this work, here\u0026rsquo;s the revamped version of the Custom HTML Tag:\n\u0026lt;script\u0026gt; (function() { var formSelector = \u0026#39;form\u0026#39;; // Modify this CSS selector to match your form. Default is first form on the page.  var attribute = \u0026#39;name\u0026#39;; var history = []; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { if (history.length) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;formAbandonment\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Abandonment\u0026#39;, \u0026#39;eventAction\u0026#39; : history.join(\u0026#39; \u0026gt; \u0026#39;) }); } }); document.querySelector(formSelector).addEventListener(\u0026#39;change\u0026#39;, function(e) { history.push(e[\u0026#39;target\u0026#39;].getAttribute(attribute)); }); })(); \u0026lt;/script\u0026gt; Let\u0026rsquo;s see. We\u0026rsquo;ve removed the variable eventAction, and opted for a new Array named history. Instead of checking for whether the eventAction variable has a value, we now check if the history Array has any contents. If it does, we join() the history Array as a string delimited with whitespace-\u0026gt;-whitespace. So, an Array that looks like ['firstName', 'lastName', 'phone'] becomes 'firstName \u0026gt; lastName \u0026gt; phone'.\nFinally, in the change listener we use the history.push() method to insert the specified attribute value of the changed form field into the history Array.\nThus, each time the user changes a value of a form field, the specified attribute (\u0026lsquo;name\u0026rsquo; is again recommended) value will be pushed into the history Array, and this is how we get our neatly formatted interaction history to GA as the Event Action value of the hit.\nThis is, as you might have guessed, a very simple way of mapping form abandonment. Nevertheless, it does give you some idea about which fields are interacted with and how much. In fact, you can easily convert this from a form abandonment survey into an engagement analysis. Using some simple data analysis, you can map the most common paths in your form.\nOnly send event when a form isn\u0026rsquo;t submitted The major caveat with all the previous examples, apart from the browser support, is that the event is sent every time the page is unloaded and a field has changed, so for successful form submissions as well. This means you\u0026rsquo;ll need to create an Advanced Segment in GA to make the most of your form abandonment analysis.\nHowever, you can tweak the Custom HTML Tag slightly to only send the form abandonment event when the page unloads for some other reason than a form submission. To do this, the revised Custom HTML Tag should look like this:\n\u0026lt;script\u0026gt; (function() { var eventAction, i; var checkSubmit = function() { i = window.dataLayer.length - 1; while (i \u0026gt; -1) { if (window.dataLayer[i][\u0026#39;event\u0026#39;] === \u0026#39;gtm.formSubmit\u0026#39;) { return true; } i--; } }; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { if (!checkSubmit()) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;formAbandonment\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Abandonment\u0026#39;, \u0026#39;eventAction\u0026#39; : eventAction }); } }); // Add actual logic here...  })(); \u0026lt;/script\u0026gt; The first change is that you define a new counter variable i. Next, there\u0026rsquo;s a new mini-function in town called checkSubmit(). This loops through dataLayer, starting from the end, and returns the Boolean value true if an \u0026lsquo;event\u0026rsquo; key with the value \u0026lsquo;gtm.formSubmit\u0026rsquo; is found. This would indicate that the unload was due to a form submission.\nFinally, the window.dataLayer.push() is wrapped in an if block, which is executed only if the checkSubmit() function does not return a truthy value. This is because we want to send the Event only if a form submission didn\u0026rsquo;t cause the page unload.\nYou might be wondering why not just check against the value of the {{Event}} key. Well, GTM has some internal logic running which prevents the value of a Data Layer Variable from being modified during the lifetime of a Tag. Thus, {{Event}} will always return gtm.js or whatever event name you\u0026rsquo;re using to fire the Custom HTML Tag in the first place.\nIf you already have the if block there to check for either eventAction or history.length, you can simply add the checkSubmit() check with Boolean logic:\nif (eventAction \u0026amp;\u0026amp; !checkSubmit()) { ... } if (history.length \u0026amp;\u0026amp; !checkSubmit()) { ... }  This solution might not work on single-page apps or web pages which have forms that do not redirect. In these cases, you\u0026rsquo;ll need to make additional checks to see if the form that was submitted was the one you\u0026rsquo;re actually tracking. It\u0026rsquo;s relatively simple, but I won\u0026rsquo;t explain it here as it\u0026rsquo;s an edge case.\nWith JavaScript and GTM, it\u0026rsquo;s always a little bit of give-and-take, so you\u0026rsquo;ll need to modify these solutions to fit whatever frameworks and setups you have running on your site. With a generic, Best Practices -infused HTML form, though, these setups should work beautifully.\nSummary Tracking form abandonment is an interesting way to see what types of interactions (or lack thereof) result in your forms not being submitted. Fixing this funnel can be key to opening up your website to exponential goal conversions.\nHowever, abandonment is very difficult to define, and you need to ask the correct business questions first before you can start looking for a solution. The four different methods outlined here serve a very simple hypothesis that correlates the fields of a form with the user\u0026rsquo;s tendency to leave the form unfinished. This correlation might not work on many forms.\nLike I mention in the guide, it would be very simple to convert this from a form abandonment analysis to a form interaction analysis, where you inspect the \u0026ldquo;history\u0026rdquo; of the filled fields to see if users are bouncing around the form and not following the chronology or layout that you have established.\nIf none of this resonates with you, at least you\u0026rsquo;ll have some cool new tricks up your sleeve with the transport : beacon field as well as the beforeunload browser event!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/access-array-members-in-the-data-layer/",
	"title": "#GTMTips: Access Array Members In The Data Layer",
	"tags": ["Google Tag Manager", "gtmtips"],
	"description": "How to access individual array indices or members in Google Tag Manager Data Layer variable model.",
	"content": " In JavaScript, if you want to access an Array member, you use square bracket notation to retrieve the value stored at a specific index. Indices are numbered in order, with the first index always being at location zero (0). This means that to get the first value stored in Array simo, you\u0026rsquo;d use something like:\nvar firstValue = simo[0];  In Google Tag Manager, you can push Arrays into the Data Layer. However, the Data Layer Variable type, which you use to retrieve values stored in the Data Layer, does not support the aforementioned square bracket notation in its fields. Instead, you need to use a special, proprietary format to access Array members.\nTip 28: Use dot notation to access Array members in the Data Layer   As usual, this is a simple tip. Just substitute the square brackets you\u0026rsquo;d use in vanilla JavaScript with dots. So classic JavaScript Array[0].name becomes Array.0.name in Google Tag Manager.\nDo note that this also means that you can\u0026rsquo;t use square bracket notation to access object literal properties either. You need to use dot notation all the way through.\nA practical example is in Ecommerce tracking. To get the SKU of the first product in an ecommerce.purchase object (Enhanced Ecommerce), you\u0026rsquo;d use this in a Data Layer Variable:\necommerce.purchase.products.0.id\nThat retrieves the value stored in the id key of the first product in the products Array of the Enhanced Ecommerce purchase object.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/implement-referral-exclusions-via-gtm/",
	"title": "#GTMTips: Implement Referral Exclusions Via GTM",
	"tags": ["google analytics", "Google Tag Manager", "gtmtips"],
	"description": "Manage and update your referral exclusion list using Google Tag Manager. This is much more flexible than using the Google Analytics user interface.",
	"content": " Maintaining the list of Referral Exclusions in Google Analytics admin is a pain. Especially if you have a webstore, the number of referral sources you need to exclude to avoid sessions being split can grow really fast. Also, it\u0026rsquo;s not like the list is has the most intuitive UI. Instead of a handy text area where you could just copy-paste stuff, you\u0026rsquo;re left with a horrible line-by-line list, and there\u0026rsquo;s no way of copying lists across properties or anything useful like that.\nSo, in this tip, I\u0026rsquo;ll show you how you can modify the data at its source (the website), so that it becomes easier to manage the list of referrals you want to exclude.\nTip 27: Exclude referrals with a Custom JavaScript Variable   First, let\u0026rsquo;s get one thing straight. The referral exclude list excludes referral traffic, it doesn\u0026rsquo;t block it. \u0026lsquo;Exclude\u0026rsquo; here means that traffic that comes in from a referral you\u0026rsquo;ve excluded gets converted into the Direct / (none) source/medium bucket. If you know your Google Analytics, you know that GA attributes all hits to the last non-direct acquisition source. In plain English this means that all hits that have no referral information get attributed to whatever non-direct source you previously had active. If you don\u0026rsquo;t have a previous campaign, or if the Campaign Timeout setting has expired, then it gets attributed to Direct / (none).\nThat means also that Referral Exclusion Lists should not be used to fight referral spam. So many people have recommended this method, and all these people are thus guilty of giving horrible, horrible advice.\nNow that we\u0026rsquo;ve got that cleared, let\u0026rsquo;s get on with the solution. For this to work, you need to create a new Custom JavaScript Variable. Give it a descriptive name such as {{JS - Exclude Referrals}}. Copy-paste the following code within:\nfunction() { var referrals = [ \u0026#39;referrer1.com\u0026#39;, \u0026#39;referrer2.com\u0026#39;, \u0026#39;referrer3.com\u0026#39;, \u0026#39;referrer4.com\u0026#39; ]; var hname = new RegExp(\u0026#39;https?://([^/:]+)\u0026#39;).exec({{Referrer}}); if (hname) { for (var i = referrals.length; i--;) { if (new RegExp(referrals[i] + \u0026#39;$\u0026#39;).test(hname[1])) { return null; } } } return {{Referrer}}; }  The only thing you need to edit is the referrals Array. Each referral source you want to exclude is on its own row, enclosed in single quotes, and all lines end with a comma except the last one. That\u0026rsquo;s the syntax.\nThe list gets turned into a regular expression, against which the referrer of the page (i.e. the URL of the page that brought the visitor to the current page) is tested. The regular expression is open on the left, and closed on the right, meaning that an entry such as simoahava.co will match the following:\n simoahava.co\n www.simoahava.co\n super.genious.simoahava.co\n  But not the following:\n simoahava.com\n www.simoahava.co.uk\n www.google.fi\n  I hope you get the drift. If you\u0026rsquo;re handy with regular expressions, feel free to modify the strings in the referrals Array. For example, to only exclude simoahava.com but not, for example store.simoahava.com, you\u0026rsquo;d create the entry like:\nvar referrals = [ \u0026#39;^simoahava.com\u0026#39; ];  The $ which closes the expression at the end is added automatically to each line later in the script.\nSo, the script tests each entry you\u0026rsquo;ve added into the referrals Array against the hostname of the current referrer, and if there is a match, null is returned. This means that any GA Tag that uses this Variable will not send the Document Referrer key with the payload, which is what GA uses to establish referral traffic.\nTo add this to your Google Analytics Tag, browse to More Settings -\u0026gt; Fields to Set, and add the following details:\nField Name: referrer\nValue: {{JS - Exclude Referrals}}\n  Like so.\nNote! Try this at your own risk. Remember to test the solution carefully before going ahead with a full-scale implementation. Referrer information is crucial in Google Analytics, as it can make or break your traffic attribution reports.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/folders-and-syntax-highlighting-in-google-tag-manager/",
	"title": "Folders And Syntax Highlighting In Google Tag Manager",
	"tags": ["folders", "Google Tag Manager", "release", "syntax highlight"],
	"description": "Introducing the new Folders feature in Google Tag Manager, and also showing how syntax highlighting works in the code editor.",
	"content": " What a nice way to wake up to a new day, when brand-spanking new features have been released for Google Tag Manager.\nThe two features I want to introduce here are Folders in the UI, and code syntax highlighting in Custom HTML Tags and Custom JavaScript Variables.\nFolders   Folders is one of those features that has been requested for over and over again since day one. The UI clutter in GTM is a serious problem, especially when dealing with dozens and dozens of items in a single view. With folders, you can logically categorize individual items, so it should dramatically reduce clutter. That is, once the feature is more refined.\n  To create a new folder, browse to the new navigation item Folders in the left-hand panel, after which you\u0026rsquo;ll be treated to a new view. In this view, it is possible to create a New Folder, and select multiple items to Move into this folder.\nHere\u0026rsquo;s the thing. For now, this is just a nice UI feature. In essence, it\u0026rsquo;s a new sortable column, nothing more. It\u0026rsquo;s a huge step in the right direction, but it requires a lot more refinement:\n Ability to have one item in multiple folders\n Restrict user access to only certain folders, preferably on all user levels, but at least so that they can only View the contents\n Selective publish only folder X, or leave folder Y out of publish workflow\n Only show items from folder X in the view (Tags / Triggers / Variables)\n Include folders in the quick search on top of the left-hand panel\n  Only after refinements like these can we truly celebrate. Just kidding, we can do a little GTM jiggle right now.\nCode syntax highlighting This got me way more excited. I and many others have been using the excellent Code Editor for GTM, created by the awesome people at fifty-five.\nNo matter how great that extension is, it\u0026rsquo;s weird that GTM didn\u0026rsquo;t have syntax highlighting enabled natively. Well, now it does!\n  It looks great, and has features you\u0026rsquo;d expect from a syntax highlighter, such as automatic indentation. It does lack some stuff, like highlighting both brackets around a code block when the cursor passes over one of them, but I\u0026rsquo;m sure these are refinements that can be added to the tool later.\nBoth of these features are very welcome to Google Tag Manager, so good job devs, again! Now let\u0026rsquo;s make them even better, right?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/measure-cart-value-in-enhanced-ecommerce/",
	"title": "Measure Cart Value In Enhanced Ecommerce",
	"tags": ["enhanced ecommerce", "google analytics", "Google Tag Manager"],
	"description": "How to collect and measure shopping cart value in your Google Analytics Enhanced Ecommerce funnel. Use Google Tag Manager to setup the measurement.",
	"content": " One of the glaring omissions in the Enhanced Ecommerce reports of Universal Analytics is the ability to calculate cart value for products. Cart value, here, is the value that has been added to the cart.\nThis value can be used to query for products that have the highest discrepancy between cart value and generated revenue. These are missed opportunities of the highest caliber.\nWith some Custom Metrics magic, we can, however, get cart value into our reports, and we can find our most and least \u0026ldquo;effective\u0026rdquo; products with just a glance:\n  As you can see, my most revenue-generating product, The Ahava Machine 2.0, also has the most value left in the shopping cart. This is more interesting to me than comparing the buy-to-detail and cart-to-detail ratios, as now I actually have a currency attached to the gap between purchases and cart interactions.\nIt\u0026rsquo;s very easy to setup. We will, of course, be using Google Tag Manager, here, but with a little tinkering you should be able to set it up with the on-page tracking code as well, if you are archaic enough to still use that. I\u0026rsquo;m assuming here that you already have Enhanced Ecommerce setup through Google Tag Manager, and you have a valid ecommerce.add (and ecommerce.remove) object in dataLayer or returned with a Custom JavaScript Variable.\nTo get things rolling, you need to create the Custom Metric itself. A product-scoped Custom Metric will be scoped to a single product in a single Enhanced Ecommerce interaction. So, if you send a product-scoped Custom Metric with a product object in the ecommerce.add.products Array, the metric can only be queried against that particular product. The metric itself will only apply to the Add To Cart interaction, but you can of course combine valid metrics for the same product as I have done in the screenshot above.\nCreate the Custom Metric In the Property settings in your Google Analytics Admin, open Custom Definitions \u0026gt; Custom Metrics, and click + New Custom Metric.\n  In the screen that opens, give the Custom Metric a name (I chose Cart Value), select Product as the scope and Currency (Decimal) as the type.\n  Remember to make sure the Metric has Active checked, and then click Save.\nYou should be back in the Custom Metrics screen. Make note of the Index the Custom Metric receives. You\u0026rsquo;ll need this in a short while.\n  Next we\u0026rsquo;ll head on over to Google Tag Manager, where we\u0026rsquo;ll modify the ecommerce.add object to include the new Custom Metric with the value that was added to cart.\nSend the Custom Metric with the product object Let\u0026rsquo;s assume that your ecommerce.add object looks like this in dataLayer:\ndataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;addToCart\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;42\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;The Ahava Machine 2.0\u0026#39;, \u0026#39;brand\u0026#39; : \u0026#39;AHAVA\u0026#39;, \u0026#39;price\u0026#39; : \u0026#39;3999.90\u0026#39;, \u0026#39;quantity\u0026#39; : \u0026#39;2\u0026#39;, \u0026#39;variant\u0026#39; : \u0026#39;Awesome|Kick-ass\u0026#39; }] } } });  So it\u0026rsquo;s a fairly basic affair. With an object like this, you\u0026rsquo;ll be able to track adds-to-cart no problem through Enhanced Ecommerce.\nBut if we want to have the product-scoped Custom Metric there, we\u0026rsquo;ll need to add metricX into the product object in the products Array like this:\n... \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;42\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;The Ahava Machine 2.0\u0026#39;, \u0026#39;brand\u0026#39; : \u0026#39;Ahava\u0026#39;, \u0026#39;price\u0026#39; : \u0026#39;3999.90\u0026#39;, \u0026#39;quantity\u0026#39; : \u0026#39;2\u0026#39;, \u0026#39;variant\u0026#39; : \u0026#39;Awesome|Kick-ass\u0026#39;, \u0026#39;metric1\u0026#39; : \u0026#39;7999.80\u0026#39; }] ...  That would solve it. You\u0026rsquo;d push the total value of the cart addition for that particular product into the Custom Metric at index 1 (which we got from previous chapter), after which you\u0026rsquo;ll accumulate cart value for that particular product.\nOn top of that, you\u0026rsquo;d need to push a negative value for cart removals, right? So the ecommerce.remove object for when you want to remove one of the Ahava Machines (why would you, seriously?) looks like this:\ndataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;removeFromCart\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;remove\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;42\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;The Ahava Machine 2.0\u0026#39;, \u0026#39;price\u0026#39; : \u0026#39;3999.90\u0026#39;, \u0026#39;quantity\u0026#39; : \u0026#39;1\u0026#39;, \u0026#39;metric1\u0026#39; : \u0026#39;-3999.90\u0026#39; }] } } });  That way you\u0026rsquo;ll have the correct balance in your Cart Value metric at all times.\nBut this sucks! It sucks because metric1 is purely for Google Analytics. It\u0026rsquo;s not generic! dataLayer should be as generic as possible.\nSo let\u0026rsquo;s do what I did in my previous article about modifying the ecommerce object using a Custom JavaScript Variable. We\u0026rsquo;ll add the Custom Metric dynamically using a Custom JavaScript Variable.\nHow cool is that? I know, very cool.\nModify the \u0026lsquo;ecommerce\u0026rsquo; object in the Data Layer First, you\u0026rsquo;ll need to create a Data Layer Variable for the ecommerce object, just as I did in the article linked to a paragraph or two ago. It looks like this:\n  This will return the most recent ecommerce object stored in the Data Layer. Since we\u0026rsquo;re working with the Add To Cart or Remove From Cart events, it will return the ecommerce.add or ecommerce.remove object, respectively. This makes sense, right?\nNext, we\u0026rsquo;ll need a Custom JavaScript Variable, which adds the Custom Metric into the payload, and returns the modified ecommerce object to your Tag. You can name it whatever you want, e.g. {{JS - Modified EEC Cart Object}}. The Custom JavaScript would look like this:\nfunction() { try { var index = \u0026#39;1\u0026#39;; // Change to reflect the Custom Metric Index  var ecom = {{DLV - ecommerce}}; var i, len, prefix, obj; if (\u0026#39;add\u0026#39; in ecom) { prefix = \u0026#39;\u0026#39;; obj = \u0026#39;add\u0026#39;; } else if (\u0026#39;remove\u0026#39; in ecom) { prefix = \u0026#39;-\u0026#39;; obj = \u0026#39;remove\u0026#39;; } if (typeof prefix != \u0026#39;undefined\u0026#39;) { for (i = 0, len = ecom[obj][\u0026#39;products\u0026#39;].length; i \u0026lt; len; i += 1) { ecom[obj][\u0026#39;products\u0026#39;][i][\u0026#39;metric\u0026#39; + index] = prefix + (ecom[obj][\u0026#39;products\u0026#39;][i][\u0026#39;price\u0026#39;] * ecom[obj][\u0026#39;products\u0026#39;][i][\u0026#39;quantity\u0026#39;]); } } return {\u0026#39;ecommerce\u0026#39; : ecom}; } catch(e) { return {\u0026#39;ecommerce\u0026#39; : {{DLV - ecommerce}}}; } }  This piece of JavaScript takes the existing ecommerce.add or ecommerce.remove object, and cycles through all the products stored within. For each product, it calculates the product\u0026rsquo;s price multiplied by its quantity. This gives the total value for that product in the cart interaction. This value is then stored in the metricX, and X is defined in the beginning using the index variable. The value is positive if it was an Add To Cart action, and negative if it was a Remove From Cart action.\nThe Variable finally returns the modified ecommerce object, which is then used by your Tag as instructed in this article. If you can\u0026rsquo;t bother to read through the linked article, you will need to change your Tags\u0026rsquo; Enhanced Ecommerce settings to not use the Data Layer, but rather retrieve the data from the Custom JavaScript Variable you just created.\n  Summary The core of this article is really simple. Let\u0026rsquo;s use a Custom Metric to fix a flaw in Enhanced Ecommerce reports of Universal Analytics. The flaw is that Cart Value isn\u0026rsquo;t automatically calculated, as it would be very simple to do so with the existing dimensions and metrics.\nCart Value lets us see how much value is left into the shopping cart when people are browsing on your site. When someone adds a product to the cart, the value added is automatically saved into the Custom Metric for that particular product in the Add To Cart action. When products are removed from the cart, their value is deducted from the Custom Metric.\nUsing the product-scoped Custom Metric lets you then query the Custom Metric with the Product SKU or Name, for example, and you can combine total Product Revenue in the custom report as well, as in the screenshot at the very beginning of this article.\nThe Custom JavaScript Variable method lets you add a lot of platform-specific flexibility to your Enhanced Ecommerce measurement. Let\u0026rsquo;s just hope this is one of those articles that becomes obsolete soon, as Google Analytics hopefully introduces Cart Value as a default metric in the Enhanced Ecommerce reports!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/enhanced-ecommerce-with-a-custom-javascript-variable/",
	"title": "Enhanced Ecommerce With A Custom JavaScript Variable",
	"tags": ["enhanced ecommerce", "Google Tag Manager", "Guide", "universal analytics"],
	"description": "Measure Enhanced Ecommerce with a Custom JavaScript variable in Google Tag Manager, rather than directly via the dataLayer. This improves the flexibility of the setup.",
	"content": " Enhanced Ecommerce is a very nice improvement to the pretty lame, transaction-based Ecommerce tracking in Universal Analytics. Instead of staring blindly at what happens on a receipt page, Enhanced Ecommerce expands your entire webstore into one large funnel labelled \u0026ldquo;Shopping Behavior\u0026rdquo;, and you\u0026rsquo;re able to zoom in on the Checkout funnel as well. Also, the addition of product-scoped tracking is incredibly useful, and it\u0026rsquo;s enabled us to think of any asset (our content, for example) on our site as something we could track through the Enhanced Ecommerce reports.\n  Tracking Enhanced Ecommerce through Google Tag Manager is pretty straight-forward. It boils down to a properly formatted Data Layer, which GTM will then use to send the hits to Google Analytics.\nNow, the thing with the Data Layer is that you want to try to make it as platform-agnostic as possible. I mean, it doesn\u0026rsquo;t make sense to encode objects in the Data Layer for one platform\u0026rsquo;s needs alone, as a complex object syntax will make it quite difficult to reuse the same information for platforms which might have a completely different syntax.\nEnhanced Ecommerce requires a very specific syntax in the Data Layer object. In addition to this, there are some very ill-designed, Google Analytics -specific, customizations you will need to implement if you want to utilize the Data Layer for Enhanced Ecommerce. An example of these customizations would be adding product-scoped Custom Dimensions and/or Metrics to the payload.\nProduct-scoped Custom Definitions the GTM way Here\u0026rsquo;s an example. Let\u0026rsquo;s send a product-scoped Custom Dimension with our \u0026ldquo;Add To Cart\u0026rdquo; action. The Custom Dimension will tell whether the product is a promotion or a regular item. The code you\u0026rsquo;d need in your Data Layer would look like this:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;addToCart\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;12345\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;ACME Flame Thrower\u0026#39;, \u0026#39;dimension2\u0026#39; : \u0026#39;Promotion\u0026#39; }] } } });  This hit would prepare the Data Layer for an \u0026ldquo;Add To Cart\u0026rdquo; action, where the value \u0026lsquo;Promotion\u0026rsquo; is sent to GA to Custom Dimension index 2.\nNow, this would be fine in a perfect world, where you have an incredibly agile cooperation model with your own developers and with the developers of third-party platforms you have on your site. If the Custom Dimension should change, you can just quickly ask them to push an update to the Data Layer, where dimension2 is replaced with the new index number.\nHowever, this is rarely the reality. Also, all other parts of the Data Layer object above can be easily reused in other platforms, and the key names (e.g. \u0026lsquo;id\u0026rsquo;, \u0026lsquo;name\u0026rsquo;) are self-explanatory, but \u0026lsquo;dimension2\u0026rsquo; just won\u0026rsquo;t ring a bell with platforms that do not think in terms of dimensions. So we\u0026rsquo;ve taken an agnostic Data Layer and turned it very proprietary, respecting the needs of one single platform (Google Analytics) alone.\nUse a Custom JavaScript Variable instead Turns out that you can use a Custom JavaScript Variable to push Enhanced Ecommerce payloads to Google Analytics as well:\n  We can thus use a Custom JavaScript Variable to do all the platform-specific customizations, and we can leave our Data Layer as generic as possible.\nSo, let\u0026rsquo;s assume we still have the Data Layer in its normal state, but without the \u0026lsquo;dimension2\u0026rsquo; key in it:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;addToCart\u0026#39;, \u0026#39;ecommerce\u0026#39; : { \u0026#39;add\u0026#39; : { \u0026#39;products\u0026#39; : [{ \u0026#39;id\u0026#39; : \u0026#39;12345\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;ACME Flame Thrower\u0026#39; }] } } });  We want to fire the GA Tag, which sends the Add To Cart action to Google Analytics, when this payload is pushed into Data Layer, but we want to also add the Custom Dimension to the payload without having to modify the dataLayer.push() method.\nTo make this happen, you will first need to create a new Data Layer Variable, which returns the \u0026lsquo;ecommerce\u0026rsquo; payload:\n  This Variable returns the value of the \u0026lsquo;ecommerce\u0026rsquo; key in the data model. Note, I\u0026rsquo;m using Version 1 of the Data Layer, because that\u0026rsquo;s what GTM uses for Enhanced Ecommerce. It protects your Enhanced Ecommerce objects from something called a recursive merge, which would result in each \u0026lsquo;ecommerce\u0026rsquo; payload persisting all the previous objects, e.g. \u0026lsquo;promotions\u0026rsquo; and \u0026lsquo;impressions\u0026rsquo; in each hit, resulting in a lot of extra, invalid information being sent to Google Analytics.\nOnce you have that Variable in place, you will need the actual Custom JavaScript Variable, which I\u0026rsquo;ve named {{EEC - AddToCart With Dimension}}.\nfunction() { var dIndx = \u0026#39;2\u0026#39;; // This is the Custom Dimension Index  var ecomAddProducts = {{DLV - ecommerce}}[\u0026#39;add\u0026#39;][\u0026#39;products\u0026#39;]; ecomAddProducts[0][\u0026#39;dimension\u0026#39; + dIndx] = ecomAddProducts[0][\u0026#39;id\u0026#39;] === \u0026#39;12345\u0026#39; ? \u0026#39;Promotion\u0026#39; : \u0026#39;Regular\u0026#39;; return {\u0026#39;ecommerce\u0026#39; : {\u0026#39;add\u0026#39; : {\u0026#39;products\u0026#39; : ecomAddProducts}}}; }  On the first line, you define the Custom Dimension index. Next, you create a little placeholder variable for the \u0026lsquo;products\u0026rsquo; key in the {'ecommerce' : {'add' : {}} } object.\nIn the third line, you basically check if the first (only) product in the \u0026lsquo;products\u0026rsquo; Array has ID \u0026lsquo;12345\u0026rsquo;. If it does, you add the Custom Dimension key \u0026lsquo;dimension2\u0026rsquo; into the product object with the value \u0026lsquo;Promotion\u0026rsquo;. If the ID is something else, the dimension value is set to \u0026lsquo;Regular\u0026rsquo;.\nYou can be very creative here, fetching valid IDs from a Lookup Table, for example. The key thing is to return a complete \u0026lsquo;ecommerce\u0026rsquo; object in the Custom JavaScript Variable. That\u0026rsquo;s how GTM works. If you don\u0026rsquo;t return a syntactically valid \u0026lsquo;ecommerce\u0026rsquo; object, Enhanced Ecommerce will not work.\nJust to clarify: a valid \u0026lsquo;ecommerce\u0026rsquo; object means that the payload needs to be crafted according to how you would create the Data Layer object. A good place to find more information is in the developer guide for the Enhanced Ecommerce Data Layer.\nThings to keep in mind To make the Custom JavaScript Variable method work with GTM, you will need to remember the following, easy steps:\n Use a Custom JavaScript Variable which returns a valid {'ecommerce' : {}} object\n Uncheck Use data layer in your GA Tag settings\n Select the variable you created in (1) in the drop-down menu labelled Read data from variable\n  That\u0026rsquo;s all you need to change. Your Tag should still fire on the Custom Event Trigger for Event Name: addToCart. This time, however, instead of using the Data Layer \u0026lsquo;ecommerce\u0026rsquo; object, it uses the \u0026lsquo;ecommerce\u0026rsquo; object returned by your Custom JavaScript Variable.\nUse cases The best way to use the Custom JavaScript Variable has already been mentioned a few times in this article. Use the Custom JS Variable to turn a generic Data Layer object into a Google Analytics -specific payload. This means that you can ask your developers to implement a very generic Ecommerce payload with the \u0026ldquo;Add To Cart\u0026rdquo; action. This makes it easier for other platforms to tap into the data, as you don\u0026rsquo;t need to know how Google Analytics works to be able to understand how the object is built.\nAnother good use case is for product-specific Custom Dimensions and Metrics, which I\u0026rsquo;ve showed an example of in this article. It doesn\u0026rsquo;t really make sense to add those to the Data Layer, as dimension and metrics can change, and adding keys that are only used by one platform is a bit counter-intuitive.\nI\u0026rsquo;ve found myself using the Custom JavaScript Variable method in almost all the implementations I work with, even if the Data Layer \u0026lsquo;ecommerce\u0026rsquo; object is well-formed to begin with. I like the idea that I can flexibly change the payload on a whim, without having to update the Data Layer.\nNaturally, if the changes are fundamental, such as product names changing or IDs receiving a new format, you will want to update the on-page Data Layer instead of encoding these changes in your Custom JavaScript Variable. But the Custom JavaScript Variable is perfect for implementing platform-specific payload syntax in your Ecommerce tracking.\nHave you got some other use cases for the Custom JavaScript Variable method? Please, do share!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/cross-domain-tracking-across-subdomains/",
	"title": "Cross-domain Tracking Across Subdomains",
	"tags": [],
	"description": "Quick tip how cross-domain tracking to Google Analytics works across subdomains.",
	"content": " Wait. What? Why write an article about something that should work by default in Universal Analytics? I mean, here\u0026rsquo;s a screenshot from the guide I just linked to in the previous sentence:\n  There it is. Clear as day: \u0026ldquo;Tracking users across subdomains does not require any additional configuration.\u0026rdquo; Also, some of the recent, excellent guides to cross-domain tracking, written by E-Nor and Lunametrics enforce the same: you just need a default Universal Analytics Tag in Google Tag Manager.\nWell, unfortunately, that\u0026rsquo;s not true. You do need a configuration setting, but it\u0026rsquo;s thankfully very simple.\nTL;DR: In the Fields to Set of your Universal Analytics (Page View) Tag, add the following setting:\n  But since you\u0026rsquo;re awesome, you didn\u0026rsquo;t come here for the dirty truth, you want to know why this is necessary. So read on!\nHow Universal Analytics writes cookies To track the same user and session across any two pages, these pages require the following:\n A tracker object that tracks to the same Google Analytics Property ID (UA-XXXXXX-Y)\n A _ga cookie that has the same Client ID\n    Client ID is what is used to stitch the hits in the session together, and also to stitch sessions the same user has had into a common level of aggregation (the GA concept of a user).\nNow, if you don\u0026rsquo;t have any customizations in your Universal Analytics Tag, here\u0026rsquo;s the logic with which cookies are written:\n If the hostname of the page (http://this is the hostname/home/) starts with www., the \u0026ldquo;www\u0026rdquo; is stripped, and the cookie is written on what remains. So, in the case of www.simoahava.com, the cookie is written on .simoahava.com.\n On all other hostnames, the cookie is written on the hostname itself, prefixed with a period. So, test.simoahava.com would retrieve a _ga cookie written on .test.simoahava.com\n  If prefixed with a period, like the _ga cookie is, the cookie can be used on all hostnames that contain this string. So the .simoahava.com cookie can be used by test.simoahava.com, www.simoahava.com, simoahava.com, and immortal.genius.simoahava.com, for example.\nThe .test.simoahava.com cookie, on the other hand, can be used by www.test.simoahava.com, but not by www.simoahava.com, as the latter does not contain the string \u0026ldquo;test.simoahava.com\u0026rdquo;.\nCan you see where I\u0026rsquo;m going with this?\nIf traffic is from www.simoahava.com to test.simoahava.com, the _ga cookie is shared, and all is well. Right?\nHowever, if the visitor first visits test.simoahava.com, and then moves to www.simoahava.com, these two domains will have different _ga cookies, and thus different Client IDs, and thus the user will be a different user with a new session!\nSo clearly, in many, many cases, this will lead to problems. We need to somehow ensure that the _ga cookie is always written on .simoahava.com, so that it can be used by all subdomains, regardless of if they have \u0026ldquo;www.\u0026rdquo; or something else as a prefix.\ncookieDomain : auto The answer is in the cookieDomain setting. When you set cookieDomain to auto, the following will happen with a (fictional) domain like www.simoahava.co.uk:\n GA tries to write the cookie on .co.uk, which is the first possible root domain candidate. This fails because the browser is not authorized to write a cookie on a top-level domain like that.\n Next, GA tries to write the cookie on .simoahava.co.uk, which is the next possible root domain candidate. This works because that\u0026rsquo;s a valid domain to write the cookie on.\n  So there\u0026rsquo;s a recursive algorithm, which tries to write the cookie, starting from the most generic domain-level (the top-level domain), and stopping once it succeeds. What should be left is the root domain, and thus the cookie will be available to all subdomains.\nYay!\nThe new and improved recommendation Here\u0026rsquo;s the improved recommendation for cross-domain tracking across subdomains:\nAlways default to having cookieDomain : auto in your tracker settings. In GTM, I\u0026rsquo;ve shown an example in the beginning of the post.\nIn the Universal Analytics tracking code, the snippet would look like this:\n\u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;//www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-40669554-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; This is, actually, what the Google Analytics Tracking Code, if copy-pasted from the Property settings, offers by default, so all is well if you use this.\nPersonally, I think the setting should always default to \u0026ldquo;auto\u0026rdquo; unless explicitly changed to some other value.\nHere\u0026rsquo;s a thread in Google+ which inspired me to write this post.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/remember-to-flush-unused-data-layer-variables/",
	"title": "#GTMTips: Remember To Flush Unused Data Layer Variables",
	"tags": ["data layer", "Google Tag Manager", "gtmtips"],
	"description": "Remember to set unused variables in generic dataLayer pushes to undefined when they are not used. This way the values will not &#34;leak&#34; from hit to hit.",
	"content": " Here\u0026rsquo;s a tip that\u0026rsquo;s especially important to anyone working with a single-page application. Google Tag Manager persists items in its data model until you either manually delete the variable and/or its value from the data model, or until the user browses away from the page. There\u0026rsquo;s nothing as annoying as the example in the image below, where a value that was set for an earlier Tag is resent with a new Tag, even though the purpose was to leave it out.\nTip 26: Flush unused Data Layer Variables   Let\u0026rsquo;s extend the example in the image above. Say you have a Google Analytics Event Tag, which fires on the makeMoney Custom Event Trigger, and has the following Tag settings:\nEvent Category: Make Money\nEvent Action: {{DLV - userId}}\nEvent Label: {{DLV - criminalStatus}}\nEvent Value: {{DLV - howMuch}}\nAs you can see, the naming convention I use for the Variables is pretty self-explanatory. It\u0026rsquo;s just the variable name in the Data Layer prefixed by \u0026ldquo;DLV - \u0026ldquo;.\nSo, this Tag fires when the first payload is pushed. It gets the following values:\nEvent Category: Make Money\nEvent Action: abcb-1234\nEvent Label: true\nEvent Value: 10000\nThis Event signifies that a user with ID \u0026ldquo;abcb-1234\u0026rdquo; has scored 10000 dollars in a nefarious scheme, and this event is thus labelled as a criminal act. I will send this information to the proper authorities, after first taking my cut.\nNext, the same person, on the same page, decides to make amends and scores a far more appropriate amount of cash in this cyber-scam:\nEvent Category: Make Money\nEvent Action: ddff-2211\nEvent Label: true\nEvent Value: 2000\nBut what\u0026rsquo;s that? Criminal status is still true?! But you left it out of the dataLayer.push(), why would it still be there? Shouldn\u0026rsquo;t it be empty? Is there no way for this vigilante to escape the searchlights of the police helicopter patrolling the abandoned brick factory?\nYou see, because there was no reload, the value of the criminalStatus variable in GTM\u0026rsquo;s data model remains true until overwritten, or until a page (re)load is executed.\nThis is why the following bit is important. Whenever you push a payload to dataLayer that makes a Tag Trigger, make sure you\u0026rsquo;ve accounted for any other Data Layer Variables the Tag might use. In the example we\u0026rsquo;ve used until now, if you want to make sure that criminalStatus is flushed for the second push, you would use the following syntax in the push:\ndataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;makeMoney\u0026#39;, \u0026#39;howMuch\u0026#39; : \u0026#39;2000\u0026#39;, \u0026#39;userId\u0026#39; : \u0026#39;ddff-2211\u0026#39;, \u0026#39;criminalStatus\u0026#39; : undefined });  This stores the value undefined for the variable criminalStatus, effectively making it so that the variable does not resolve, dropping the parameter from the Google Analytics hit entirely.\nSo remember to flush those unused variables!\nOne other thing. You might be concerned that when using Enhanced Ecommerce, this means that your impressions (which you send with the Page View Tag, right?) will be sent with every single other Enhanced Ecommerce hit on the page as well. Worry not! Enhanced Ecommerce is special. It leverages an older version of GTM\u0026rsquo;s data model, where objects are not merged together. With Enhanced Ecommerce, only the most recent hit is ever processed by your Tags.\nThat\u0026rsquo;s it. Go enjoy the summer!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/remove-email-addresses-from-url-parameters/",
	"title": "#GTMTips: Remove Email Addresses From URL Parameters",
	"tags": ["Google Tag Manager", "gtmtips", "pii", "query string"],
	"description": "How to purge email addresses from URL parameters when sending hits to Google Analytics. Use Google Tag Manager to fix this PII issue.",
	"content": " PII (Personally Identifiable Information) is something we need to actively combat against when using Google Analytics, as the platform explicitly forbids sending PII to Google Analytics properties in any size, form, or shape.\nOne of the most common ways of accidentally passing PII to a property is via query parameters. Many email platforms out there, for example, see no problem in including the user\u0026rsquo;s email address in the query string, especially when the user follows a link in a newsletter. This is, however, a definite no-no in Google Analytics. Thus, I wanted to create a blanket solution for proactively weeding out potential PII in your Google Analytics Tags deployed via Google Tag Manager.\nTip 25: Remove email addresses from URL parameters   For this solution to work, you\u0026rsquo;ll need to create a new user-defined variable in GTM, which returns the URL Query string. In this example, the variable is called {{URL Query}}, and it looks like this:\n  After this, you need to create the Custom JavaScript Variable itself. Let\u0026rsquo;s name it {{Return URL Query without email}}, and it looks like this:\nfunction() { var q = {{URL Query}}.length ? \u0026#39;\u0026amp;\u0026#39; + {{URL Query}} : \u0026#39;\u0026#39;; // q = decodeURIComponent(q);  var newQ = q.length ? \u0026#39;?\u0026#39; + q.replace(/\u0026amp;[^\u0026amp;@]+@[^\u0026amp;]+/g, \u0026#39;\u0026#39;).substring(1) : \u0026#39;\u0026#39;; return newQ.length \u0026lt;= 1 ? \u0026#39;\u0026#39; : newQ; }  Thanks to Phil Pearce and David Vallejo for pointing out some errors in the original script. Also thanks to Steven J in the comments of this post for suggesting to check if the new query string just has one character (\u0026lsquo;?\u0026rsquo;).\nUncomment the commented line if your URL Query strings tend to have HTML encoded characters (e.g. %3D for \u0026lsquo;=\u0026rsquo;, and %26 for \u0026lsquo;\u0026amp;\u0026lsquo;).\nThe JavaScript function above is a very simple regular expression search-and-replace, which looks for an email address in the URL query string. If it finds one (or more), it simply removes the offending key-value pair(s) from the query string, and returns the stripped result.\nTo implement this in your Tags, you\u0026rsquo;ll need to add the following to every single Google Analytics Tag in Fields to Set.\nField name: page\nValue: {{Page Path}}{{Return URL Query without email}}\nIt\u0026rsquo;s not perfect, it\u0026rsquo;s a bit cumbersome as you need to implement it in all Tags, but especially with large websites that invite a lot of traffic, it might save you from data loss due to Terms of Service infringement.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-soundcloud-integration/",
	"title": "Google Tag Manager: SoundCloud Integration",
	"tags": ["custom", "google analytics", "Google Tag Manager", "Guide", "soundcloud"],
	"description": "Track interactions with your embedded SoundCloud widget using Google Tag Manager. You can send the data to Google Analytics, for example.",
	"content": " According to their website, SoundCloud is \u0026ldquo;the world’s leading social sound platform where anyone can create sounds and share them everywhere\u0026rdquo;. For artists, it\u0026rsquo;s a channel for distributing previews of their tracks, and for people like me it\u0026rsquo;s a nice way to do some API tinkering. To each their own, I guess!\n  I saw a number of requests in the Google+ Google Tag Manager community about a SoundCloud integration, so I decided to look into it to see if I could just build one.\nSoundCloud has something called the Widget API, which listens for window.postMessage calls from within the embedded SoundCloud iframes. The benefit of this versus, for example, the YouTube API is that you don\u0026rsquo;t need to do anything to the iframe itself to make this work. All you need to do is load the Widget API, and then indicate which iframe(s) you want to listen to for interactions.\nThe setup For this to work, you will need the following:\n Custom HTML Tag which loads the Widget API, adds the listeners, and does the dataLayer.push() calls\n Custom Event Trigger which fires your Tag when a SoundCloud event is registered\n Data Layer Variables for Event Category, Event Action, and Event Label\n Event Tag which fires when the Trigger is activated, and sends the event hit to Google Analytics\n  The most complex component is the Custom HTML Tag, so let\u0026rsquo;s start there.\nThe Custom HTML Tag Here\u0026rsquo;s the full Tag code. Copy-paste it into a new Custom HTML Tag:\n\u0026lt;!-- Load the SoundCloud API synchronously --\u0026gt; \u0026lt;script src=\u0026#34;https://w.soundcloud.com/player/api.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;!-- Initiate the API integration --\u0026gt; \u0026lt;script\u0026gt; (function() { try { // initWidget is called when a SoundCloud iframe is found on the page  var initWidget = function(w) { var currentSound, act, pos, q1, q2, q3, go, lab; var cat = \u0026#39;SoundCloud\u0026#39;; var widget = SC.Widget(w); // Events.READY is dispatched when the widget has been loaded  widget.bind(SC.Widget.Events.READY, function() { // Get the title of the currently playing sound  widget.getCurrentSound(function(cs) { lab = cs[\u0026#39;title\u0026#39;]; }); // Fire a dataLayer event when Events.PLAY is dispatched  widget.bind(SC.Widget.Events.PLAY, function() { act = \u0026#39;Play\u0026#39;; sendDl(cat, act, lab); }); // Fire a dataLayer event when Events.PAUSE is dispatched  // The only exception is when the sound ends, and the auto-pause is not reported  widget.bind(SC.Widget.Events.PAUSE, function(obj) { pos = Math.round(obj[\u0026#39;relativePosition\u0026#39;] * 100); if (pos !== 100) { act = \u0026#39;Pause\u0026#39;; sendDl(cat, act, lab); } }); // As the play progresses, send events at 25%, 50% and 75%  widget.bind(SC.Widget.Events.PLAY_PROGRESS, function(obj) { go = false; pos = Math.round(obj[\u0026#39;relativePosition\u0026#39;] * 100); if (pos === 25 \u0026amp;\u0026amp; !q1) { act = \u0026#39;25%\u0026#39;; q1 = true; go = true; } if (pos === 50 \u0026amp;\u0026amp; !q2) { act = \u0026#39;50%\u0026#39;; q2 = true; go = true; } if (pos === 75 \u0026amp;\u0026amp; !q3) { act = \u0026#39;75%\u0026#39;; q3 = true; go = true; } if (go) { sendDl(cat, act, lab); } }); // When the sound finishes, send an event at 100%  widget.bind(SC.Widget.Events.FINISH, function() { act = \u0026#39;100%\u0026#39;; q1 = q2 = q3 = false; sendDl(cat, act, lab); }); }); }; // Generic method for pushing the dataLayer event  // Use a Custom Event Trigger with \u0026#34;scEvent\u0026#34; as the event name  // Remember to create Data Layer Variables for eventCategory, eventAction, and eventLabel  var sendDl = function(cat, act, lab) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;scEvent\u0026#39;, \u0026#39;eventCategory\u0026#39; : cat, \u0026#39;eventAction\u0026#39; : act, \u0026#39;eventLabel\u0026#39; : lab }); }; // For each SoundCloud iFrame, initiate the API integration  var i,len; var iframes = document.querySelectorAll(\u0026#39;iframe[src*=\u0026#34;api.soundcloud.com\u0026#34;]\u0026#39;); for (i = 0, len = iframes.length; i \u0026lt; len; i += 1) { initWidget(iframes[i]); } } catch(e) { console.log(\u0026#39;Error with SoundCloud API: \u0026#39; + e.message); } })(); \u0026lt;/script\u0026gt; Make sure this Custom HTML Tag fires upon a Page View Trigger, where the Trigger Type is DOM Ready. If it doesn\u0026rsquo;t work, try changing the Trigger Type to Window Loaded. It\u0026rsquo;s possible a race condition emerges, where the Custom HTML Tag is fired before your SoundCloud widgets are loaded, and shifting the Trigger to fire on Window Loaded should remedy that.\nLet\u0026rsquo;s chop it up into pieces so we\u0026rsquo;ll understand what\u0026rsquo;s happening. This time, we\u0026rsquo;ll start from the end!\n// For each SoundCloud iFrame, initiate the API integration var i,len; var iframes = document.querySelectorAll(\u0026#39;iframe[src*=\u0026#34;api.soundcloud.com\u0026#34;]\u0026#39;); for (i = 0, len = iframes.length; i \u0026lt; len; i += 1) { initWidget(iframes[i]); } \nThe code above goes through all the iframes on the page. If it encounters an iframe that loads an embedded SoundCloud Widget, it calls the initWidget method, using the iframe object as a parameter. This is as simple as it gets. The cool thing is that each iframe gets its own bindings, so you can run the script with multiple SoundCloud widgets on the page!\nvar initWidget = function(w) { var currentSound, act, pos, q1, q2, q3, go, lab; var cat = \u0026#39;SoundCloud\u0026#39;; var widget = SC.Widget(w); // Events.READY is dispatched when the widget has been loaded  widget.bind(SC.Widget.Events.READY, function() { // Get the title of the currently playing sound  widget.getCurrentSound(function(cs) { lab = cs[\u0026#39;title\u0026#39;]; });  The initWidget function is called for all the SoundCloud iframes on the page. First, it declares some utility variables. Next, it uses the Widget API SC.Widget constructor to create a new widget object the API uses for the bindings.\nOn the following lines, the SC.Widget.Events.READY event is bound to the widget object. This event is fired when the embedded SoundCloud object has loaded and is ready to be interacted with. All the listeners are put into this function callback, as we don\u0026rsquo;t want to start listening for events before the embedded file has loaded, right?\nThe first thing we do is get the title of the sound, and for that we need to use the asynchronous getCurrentSound function, whose callback returns the sound object. Then, we access this object\u0026rsquo;s title key and store it in a variable. Now we have all the static variables defined, and we can create our four listeners.\n// Fire a dataLayer event when Events.PLAY is dispatched widget.bind(SC.Widget.Events.PLAY, function() { act = \u0026#39;Play\u0026#39;; sendDl(cat, act, lab); });  The first listener is bound to the SC.Widget.Events.PLAY event, which, surprisingly, is dispatched when a \u0026ldquo;Play\u0026rdquo; event is recorded in the widget. Once that happens, we set the act variable to \u0026ldquo;Play\u0026rdquo;, and invoke the sendDl (see below) method, which does the dataLayer.push(). Parameters are the cat (\u0026ldquo;SoundCloud\u0026rdquo;), act (\u0026ldquo;Play\u0026rdquo;), and lab (Sound title) variables.\n// Fire a dataLayer event when Events.PAUSE is dispatched // The only exception is when the sound ends, and the auto-pause is not reported widget.bind(SC.Widget.Events.PAUSE, function(obj) { pos = Math.round(obj[\u0026#39;relativePosition\u0026#39;] * 100); if (pos !== 100) { act = \u0026#39;Pause\u0026#39;; sendDl(cat, act, lab); } });  The next event we\u0026rsquo;ll bind is SC.Widget.Events.PAUSE, which is dispatched when a \u0026ldquo;Pause\u0026rdquo; event is recorded in the widget. It\u0026rsquo;s practically the same as the \u0026ldquo;Play\u0026rdquo; event, but we need to add one extra check there. SoundCloud auto-pauses the sound when it\u0026rsquo;s completed, so GA would receive a number of \u0026ldquo;Pause\u0026rdquo; events that were not initiated by the user. That\u0026rsquo;s why we have the check on the first line of the callback, where we basically see if the \u0026ldquo;Pause\u0026rdquo; event occurred when the position of the sound is at 100%. This would indicate that it\u0026rsquo;s an auto-pause, and we won\u0026rsquo;t invoke sendDl in that case.\n// As the play progresses, send events at 25%, 50% and 75% widget.bind(SC.Widget.Events.PLAY_PROGRESS, function(obj) { go = false; pos = Math.round(obj[\u0026#39;relativePosition\u0026#39;] * 100); if (pos === 25 \u0026amp;\u0026amp; !q1) { act = \u0026#39;25%\u0026#39;; q1 = true; go = true; } if (pos === 50 \u0026amp;\u0026amp; !q2) { act = \u0026#39;50%\u0026#39;; q2 = true; go = true; } if (pos === 75 \u0026amp;\u0026amp; !q3) { act = \u0026#39;75%\u0026#39;; q3 = true; go = true; } if (go) { sendDl(cat, act, lab); } });  The next binding is for the SC.Widget.Events.PLAY_PROGRESS. This event is dispatched every few milliseconds, and the object it returns has the relative position of the sound at the time of the event. This relative position is actually a percentage of how far the user has listened to the track. So, because I\u0026rsquo;ve chosen to send an event at 25%, 50%, 75% and 100%, I need to check if the relative position is at these milestones. I also use a couple of booleans, q1 q2 q3 go, which prevent the same milestone from being sent multiple times. The go variable ensures that the GA Event is only fired when the milestones are reached, and not for every single iteration of the PLAY_PROGRESS event.\n// When the sound finishes, send an event at 100% widget.bind(SC.Widget.Events.FINISH, function() { act = \u0026#39;100%\u0026#39;; q1 = q2 = q3 = false; sendDl(cat, act, lab); });  Finally, when the sound finishes, we send the 100% event, and we also reset the utility variables. If we don\u0026rsquo;t reset them, repeated listenings would not be recorded.\n// Generic method for pushing the dataLayer event // Use a Custom Event Trigger with \u0026#34;scEvent\u0026#34; as the event name // Remember to create Data Layer Variables for eventCategory, eventAction, and eventLabel var sendDl = function(cat, act, lab) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;scEvent\u0026#39;, \u0026#39;eventCategory\u0026#39; : cat, \u0026#39;eventAction\u0026#39; : act, \u0026#39;eventLabel\u0026#39; : lab }); };  And here\u0026rsquo;s the sendDl method. It just takes the parameters, and pushes them into a dataLayer object.\nThe Trigger To activate GTM Tags when a SoundCloud event is registered, create a new Custom Event Trigger that looks like this:\n  It\u0026rsquo;s a simple one. This Trigger will fire your Tags when the sendDl method we built above is invoked.\nThe Data Layer Variables Next, make sure you have three Data Layer Variables. One for eventCategory, one for eventAction, and one for eventLabel. They\u0026rsquo;d look something like this:\n  These are pretty generic, so you might find them useful elsewhere as well.\nThe Event Tag Finally, you need an Event Tag to carry this information to Google Analytics. Set it up as you would any other Event Tag, and make sure it fires with the Trigger you created before (Event - scEvent). Then, add the three Variables you created to their respective fields:\n  And that\u0026rsquo;s it! Now your site should be ready to collect hits from SoundCloud widgets.\nSummary and caveats First, some caveats.\nEvery now and then I noticed an annoying race condition, where the widget had loaded before the GTM Custom HTML Tag had time to complete. This means that the SC.Widget.Events.READY was dispatched too early for the listener to catch it. This race condition could be fixed by having a timeout of a second or something, which then does the bindings anyway. I didn\u0026rsquo;t write it into this solution, but it should be pretty trivial to implement once you understand how the Widget API works.\nSome other things I noticed were quota errors from the API. There\u0026rsquo;s nothing you can do about these, though I believe you can subscribe to some Premium account where these errors don\u0026rsquo;t crop up. As far as I could tell, however, they had no impact on this tracking solution, and the events were sent nevertheless.\n  Anyway, this is a pretty simple solution for tracking SoundCloud widgets on your site. I\u0026rsquo;ve tried to mirror the excellent YouTube tracking guide by Cardinal Path.\nThe Widget API has a number of other interfaces you can tap into if you want to make the solution even better. Let me know if you encountered any problems, or if you have ideas how to improve this solution!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/take-the-google-tag-manager-fundamentals-course/",
	"title": "#GTMTips: Take The Google Tag Manager Fundamentals Course",
	"tags": ["Google Tag Manager", "gtmtips", "Guide"],
	"description": "Take the Google Tag Manager Fundamentals online course.",
	"content": " Are you (even marginally) interested in one of the most powerful tag management systems out there? Do you want to refresh your memory on how JavaScript works in the web? Do you want to get the most out of Google Tag Manager as the go-to system for all marketing and measurement tagging on your websites?\nTake the Google Tag Manager Fundamentals Course at the Analytics Academy, then! And take it even if you have no idea what the tool is.\nTip 24: The GTM Fundamentals course at the Analytics Academy   Google\u0026rsquo;s really amped up their support as of late, with the new and improved Tag Manager Help, the refurbished Developer Guide, and the Solutions Guide for integrating Google Analytics with Google Tag Manager.\nNow they\u0026rsquo;ve come up with an entire course around Google Tag Manager, and it\u0026rsquo;s sure to be a great one! Just sign up quick, as this first course will start on June 23, 2015. As usual, there will be a community of learners to interact with, and a flashy certificate for all who duly take and pass the course. Find the course here:\nhttps://analyticsacademy.withgoogle.com/course05/preview\nIt\u0026rsquo;s so great to see the big G really amping up their outreach, and to see more and more users take up this wonderful tool. Enjoy the course!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/add-google-tag-manager-to-your-blogger-blog/",
	"title": "#GTMTips: Add Google Tag Manager To Your Blogger Blog",
	"tags": ["blogger", "container snippet", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "How to add Google Tag Manager to your Blogger blog and avoid the encoding error you normally get.",
	"content": " This is a very simple tip, but judging by the number of queries on the Product Forums, it should prove helpful.\nBlogger is a free blogging service by Google. Like WordPress, they allow you to run hosted blogs on the blogger.com domain, and they also allow you to modify the HTML source. This, of course, means that you can add the Google Tag Manager code to the HTML template, if you wish (and why wouldn\u0026rsquo;t you!).\nThere\u0026rsquo;s just a small catch.\nTip 23: Add GTM Container Snippet to the Blogger blog template   To edit the HTML template of your Blogger blog, click the Template menu item in the main navigation of your blog settings, and then choose Edit HTML in the screen that is displayed.\n  Next, copy-paste the GTM container snippet into its rightful place just after \u0026lt;body\u0026gt;.\nNow, here\u0026rsquo;s the important thing. In the container snippet, find the following string: dl=l!='dataLayer'?'\u0026amp;l='+l:'';, and change the ampersand (\u0026amp;) to its HTML encoded counterpart (\u0026amp;), so that the string looks like this: dl=l!='dataLayer'?'\u0026amp;amp;l='+l:'';.\nThis needs to be done, as the template format used in Blogger has a strict encoding schema, and unescaped or non-encoded special characters such as ampersand will cause errors in the template if not fixed.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/how-to-get-google-tag-manager-help/",
	"title": "#GTMtips: How To Get Google Tag Manager Help",
	"tags": ["Google Tag Manager", "gtmtips", "support"],
	"description": "A number of ways you can get help with your Google Tag Manager issues.",
	"content": " Google Tag Manager has a learning curve. We\u0026rsquo;ve all gone through it. The developer guide as well as the new and improved help center are very useful, but they do not answer all the questions a thorough implementation project might face. There are many ways to find answers to your questions, and I thought I\u0026rsquo;d go through some of my favorite options here.\nTip 22: Get GTM Assistance   To help you in getting help with GTM, there are two things we\u0026rsquo;ll need to go over: where to look for help, and how to ask for assistance.\nWhere to find help Here are some of the best resources for learning about GTM, and for getting assistance.\nGoogle+ Google Tag Manager community is the best place to ask your questions. It has dozens of members who are active daily, and they almost compete to be the first to answer your question. Google+ is definitely the best place to get help. You might even run into some of the GTM developers in the community as well!\nThe Official Google Tag Manager Forum is a good place to get help as well, though I find it more suitable for GTM beginners. Response activity isn\u0026rsquo;t as great as on Google+, but you might get a more thorough reply. The problem is that there\u0026rsquo;s very little editing or moderation. Since the forums aren\u0026rsquo;t always that active, wrong answers might persist for a far longer time, doing a lot of damage before anyone notices. Some GTM developers are actively responding to questions here as well.\nStack Overflow is always a good place to ask any questions, as the community has strict rules that maintain quality of both questions and responses.\nGoogle Analytics Certified Partners can help you in many ways, but in this case we\u0026rsquo;re not talking about free tips and assistance anymore, but actually hiring a consultant to help you with your issues.\nOn top of these four places, Google search is your friend, my friend. Please, please, please use Google to see if someone has tackled your problem already. At the very least, you\u0026rsquo;ll find blogs such as this one or the awesome Lunametrics blog, where you\u0026rsquo;ll find many articles and blog comments that should inspire you to find the help you need.\nI know I sound like a broken record, but take a look at the Google+ community. It\u0026rsquo;s the most awesome place to get GTM help from, as well as start up some inspiring discussions around best practices or advanced implementations, for example.\nHow to ask for help I hope I don\u0026rsquo;t sound smug or pretentious, but please read the following very, very carefully. I spend a lot of time answering questions, and if everyone asked their questions with the following steps in mind, I\u0026rsquo;d save countless hours of back-and-forth, trying to debug the issue with very little to work on.\n1) Always provide repro steps\nAlways, always, always describe your problem so that the person who\u0026rsquo;s helping you can follow exactly how you encountered the issue. And if it\u0026rsquo;s not a problem you\u0026rsquo;re looking for help with, but rather some conceptual question or something, always provide a clear and well-written description of the issue. Try to step into the reader\u0026rsquo;s shoes. Would you understand what the issue is if you read your own question?\n2) (Almost) always provide a test URL\nA URL where you have a live version of the GTM container with the issue will save hours from those who help you. Honestly, it\u0026rsquo;s the single best way to debug your issue. But it does require that the container is live. If you can\u0026rsquo;t publish it due to the problem, naturally it can\u0026rsquo;t be debugged on the live site. Also, if it\u0026rsquo;s a website in development, and behind a VPN or something, it\u0026rsquo;s understandable you won\u0026rsquo;t be able to share access. One excuse which I just do not understand is \u0026ldquo;it\u0026rsquo;s my client\u0026rsquo;s website, and I can\u0026rsquo;t share the URL because of privacy issues\u0026rdquo;. If it\u0026rsquo;s a public website, that\u0026rsquo;s the worst excuse ever, and you\u0026rsquo;ll have a hard time trying to get people to help you if you can\u0026rsquo;t meet them halfway.\n3) Screencast, screenshots, Preview/View/Edit access\nThese would be awesome to have when debugging. A screencast is great, but it might be difficult to figure out just what things you\u0026rsquo;ll need to include in the cast. Screenshots are a must, but nothing beats access to the container. Preview access lets you share Preview mode of the container with anyone, which is a great thing, but View or Edit access to the container is definitely the best and fastest way to get your issue sorted.\nSummary If you\u0026rsquo;ve got the dough, either contact a Google Analytics Certified Partner, or give a shout on Google+ for freelance help.\nOther than that, you\u0026rsquo;re dependent on the goodwill of others, so do your best in facilitating their debugging work to your best ability. Keep in mind that people who volunteer do so on their own time, so the more information you can give the better. Nothing\u0026rsquo;s worse than having to repeatedly ask for more information.\nNaturally, one of the most difficult things in asking for assistance is knowing what\u0026rsquo;s relevant information. But if you can share the URL, add some screenshots, and describe any errors / issues you\u0026rsquo;ve witnessed, you\u0026rsquo;re off to a great start.\nHappy hunting! It gets easier, I promise.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/data-is-difficult/",
	"title": "Data is difficult",
	"tags": ["data collection", "google analytics", "Google Tag Manager"],
	"description": "Analytics is difficult. Data is difficult. Digital marketing is difficult. They&#39;re all supposed to be difficult.",
	"content": " Data is difficult. Growing a business is difficult. Measuring success is difficult. And you know what? They should be difficult. Otherwise we\u0026rsquo;d all be equally stupid, whereas now those of us ambitious enough to exert themselves are winning the race.\n  And it\u0026rsquo;s not just working with data that\u0026rsquo;s difficult. The whole Web is a mess! Search engine optimization consultants, for example, are trigger-happy in doling out advice about server-side redirects without stopping to consider the implications of what they\u0026rsquo;re recommending.\nBut it still seems to me that those working in web analytics give up first. The passive, phlegmatic, lazy approach to implementing a data collection platform and to the subsequent analysis can be seen in many, many organizations out there.\nIt\u0026rsquo;s because data is difficult.\nNever mind the analysis. We all know how much experience, expertise, and industry knowledge it requires to derive value-adding insight from a data set. But implementing a platform so that data quality is constantly re-evaluated and tweaked is an intimidating task for many.\nThis seems to stem from the fundamental misunderstanding that data collection is plug-and-play. No, implementing Google Analytics is not very difficult, as it\u0026rsquo;s simply a copy-paste operation out-of-the-box. With Google Tag Manager it can be even easier. But this is just the start. When first installed, all Google Analytics is good for is tracking Pageviews and little else. All the things that really fascinate us, like call-to-action interactions, eCommerce transactions, and content engagement, require additional work to implement.\nYes, data requires work. Data quality isn\u0026rsquo;t acquired, it\u0026rsquo;s earned. Tools like Google Tag Manager and Google Analytics shouldn\u0026rsquo;t be designed to make data and analysis thereof easier. No, their function is to make data more manageable, so that maximum data quality can be achieved with minimum effort. This way, any data organization can pursue the famous 90\u0026frasl;10 rule, where 90% of resources (time/money/effort) should be focused on people and only 10% on tools.\n\u0026ldquo;Easy data\u0026rdquo; is one of the misconceptions making waves through the industry and saturating the digital space with practitioners who just refuse to give a damn. I\u0026rsquo;ve spent a lot of time talking and thinking about these misconceptions, and I\u0026rsquo;ve managed to group them under three observations, formulated here into rules.\nRule of Data Passivity The rule of data passivity can be best summed up as a rebuttal of the classic \u0026ldquo;Data Beats Opinion\u0026rdquo; quote, attributed to Jim Lecinski from Google.\nWith the Rule of Data Passivity, I maintain that data itself does nothing. It beats nothing. It tells nothing. It shows nothing. Data is not an active agent: it\u0026rsquo;s a passive medium.\nPure opinion can, and will, \u0026ldquo;beat\u0026rdquo; data, if data is of bad quality or if the interpretations are flawed. Naturally, success based on instinct alone is difficult to find, but so is success founded upon polluted data. Indeed, the most consistent, data-driven triumphs are derived at the convergence of informed decision-making and optimized data collection.\n  Data passivity also leads to dashboard blindness. When looking at a dashboard, we expect to derive insight at a glance. As if the pie charts, the tables, and the scatter plots were telling us how our business is doing and what we should do next. But they don\u0026rsquo;t!\nThe \u0026ldquo;green for good, red for bad\u0026rdquo; labels and interpretations in the dashboard have to be calculated by someone. And they need to align perfectly for each business and each objective. If we expect that a universal platform like Google Analytics will be able to tell us everything we need to know at a glance with no customization required, we\u0026rsquo;re sorely mistaken.\nIt\u0026rsquo;s because data is passive that smart analysts should, and hopefully will, be always in demand. They are the ones who take the metrics in the reports and churn them into meaningful visualizations in the dashboards. They are the ones that make sure real-time data flow is as informative as possible. But this, again, requires work. Data is difficult, remember?\nData is easy to hide behind, both in triumph and in failure. For this reason, it\u0026rsquo;s of paramount importance to ensure the quality of data at data collection, and to hire analysts who can interpret the data in a way that\u0026rsquo;s most beneficial for the business.\nPlug-and-play analytics might work for a while, if you\u0026rsquo;re lucky. But if you want to actually use data to make a difference in your business, customization is no longer optional.\nRule of Data Subjectivity The rule of data subjectivity is important to consider when talking about data quality. I have often said, in one form or another, that:\nData quality is directly proportional to how well the data collection mechanism is understood. Take Google Analytics, for example. For many, Bounce Rate represents a key metric in evaluating content engagement. But this is because of some weird marketing ploy or super-conspiracy, where Bounce Rate has been turned into a true data demon, an undeniably evil metric with the power to destroy like no other. Consider the following, however, before condemning Bounce Rate:\n A Bounce is not a session with just a single Pageview. It\u0026rsquo;s a session with a single interaction.\n Google Analytics does not know how much time a session lasts if the session is a Bounce.\n A high Bounce Rate on a page with your phone number and address can be a good thing.\n  All these three things question the \u0026ldquo;evilness\u0026rdquo; of Bounce Rate. If you don\u0026rsquo;t measure call-to-action engagement on a page, you should not read anything into the Bounce Rate of sessions that only visited this page. Why? Because if you did measure the call-to-action, you would see a lower Bounce Rate, since an event hit from interacting with the call-to-action would negate the bounce.\nSimilarly, even if you don\u0026rsquo;t have anything else except the Pageview to measure on the page, you do not know by default how much time the visitor actually spends on the page during a bounced session. This is because Google Analytics calculates Time On Page as the distance in time between two Pageview hits. Session Duration, instead, is calculated as the distance in time between any two interactions. Both are unavailable for bounced sessions. The visitor might spend 18 hours on the page, drinking in every bit of information, for all you know.\nAlso, if the phone number or the address of your store is literally all someone might want to know, it makes sense that your contact page has a high Bounce Rate. That means it\u0026rsquo;s been optimized to appear in search results, and after landing on the page, the visitor finds what they were looking for immediately. In fact, it would be a negative user experience to force the visitor to browse other pages (and thus record a lower Bounce Rate).\nThese are just some examples of how the quality of Bounce Rate as a metric is directly proportional to how well its collection and processing mechanism is understood. And web analytics platforms are teeming with similar examples.\nAnother way to consider the rule of data subjectivity is to consider how data quality can shift from bad to good, depending on the vantage point and the question asked.\nA data set with nothing but Pageviews is bad data for tracking visitor engagement, since it\u0026rsquo;s missing key things like content interaction, but it is good data for measuring the relative read counts of your articles.\nLinkedIn endorsements are bad data when figuring out if someone is truly skilled at something, but they are good data when trying to identify what the general perception of someone\u0026rsquo;s abilities is.\nTwitter retweets are bad data for identifying meaningful content, but good data for measuring the viral effect of a powerful headline.\nRule of Data Scarcity The rule of data scarcity is almost philosophical in nature. Web analytics measurement is limited by technology. There are only so many things that we can track with JavaScript and HTTP requests, and there is only so much processing power that server-side algorithms can exhaust when inferring meaning out of the incoming hit stream. This is why it\u0026rsquo;s a good practice to start pulling this web analytics data out of the system at some point, so that it can be combined with other data sources.\nHowever, no matter how much you collect and combine, you will never have all the data. The rule of data scarcity thus dictates that data will always be incomplete, and an arbitrary line has to be drawn somewhere in the data collection mechanism.\nWhen can you say you have \u0026ldquo;enough data\u0026rdquo;?\nFor example, if you want to measure content engagement with Google Analytics, it\u0026rsquo;s commonplace to measure scroll tracking. This way you\u0026rsquo;ll know how many people scroll down your articles, and you can use this as a rudimentary indicator of read-through rates.\nBut what is the increment of scrolling that constitutes an event? 1%? 5%? 25%? Should you also measure the time spent on the article? What about if someone just scrolls furiously fast to the bottom of the content, perhaps looking for comments? Should you also measure mouse movement? Perhaps someone is scrolling, but actually they\u0026rsquo;re just looking for sidebar content or your contact details?\nThe questions you can ask are infinite, because the data that you can collect is (almost) infinite. You will need to draw a line somewhere, and this requires deliberation. It\u0026rsquo;s important that you ask questions, check if the data responds to these questions (positively or negatively), and then adjust the questions and reformulate your hypotheses.\nMeaningful data Ultimately, data collection boils down to a simple thing: gathering meaningful data. What meaningful means is something that must be negotiated uniquely for each business case, each project, each product, each organization, and each platform.\nA data organization, i.e. an organization that is serious about using data to power their work, is never just a data collection or a data processing or a data reporting body. No, turning metrics into meaningful actions that drive your business requires that all aspects of this process should be observed almost religiously.\nThe reason I\u0026rsquo;m highlighting data collection is because there seems to be a disconnect between how data is collected, how it is accessed, and how it is reported on. The three rules I write about above are not just about data collection, as they are very much aligned with processing and reporting as well.\nHowever, if you screw up data collection, you screw up all subsequent stages. You need to get it right from the get-go, otherwise you\u0026rsquo;ll berate yourself for the decisions you made or neglected to make along the way.\nIn the end, all I\u0026rsquo;m saying is that data is difficult. There are no such things as \u0026ldquo;power users\u0026rdquo; of a platform like Google Analytics. There are just \u0026ldquo;users\u0026rdquo; and then people who have given up or have never bothered to try.\nTools and platforms should not try to make analysis easier by dumbing things down. No, they should facilitate data collection and processing, so that 90% of resources could actually be spent on doing the analysis.\nExperience, education, and a data-driven mindset are the ingredients to successful analytics. Going beyond the default feature set of a platform; integrating, combining, and visualizing data; and tweaking the data collection mechanism to better reflect your business objectives are things you will need to pick up along the way as well.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/spam-filter-insertion-tool/",
	"title": "Spam Filter Insertion Tool",
	"tags": ["api", "google analytics", "JavaScript"],
	"description": "Introducing the spam filter insertion tool web app to help you get rid of referral spam.",
	"content": " Last weekend, I wrote a very simple web app that automatically creates a number of referral spam filters to tackle the problem that seems to have everybody all riled up.\n  For a nice recap of the situation, take a look at this post by Jeff Sauer, or this article by Mike Sullivan.\nThis isn\u0026rsquo;t an opinion piece, even though I\u0026rsquo;ve got a great number of opinions about this issue. If you want to read some discussion surrounding this, take a look at this Google+ thread.\n(UPDATE: I have taken down the demo tool. You can still download the source code below if you wish, but there are more robust ways to block GA spam than creating an individual filter for each referral.)\nThe tool is called the \u0026ldquo;Spam Filter Insertion Tool\u0026rdquo;, or SFIT for short (I dare you to start using that in your everyday lingo). You can find a live demo at this address:\nhttps://www.simoahava.com/spamfilter/\nDownload the source code The real meat of the solution is in the GitHub repo.\nYou can download the source code, install the application on your own web server, and use it for your own purposes.\nThe application has access to the following features of the Google Analytics Management API:\n READ the list of accounts, properties, and profiles you have access to\n INSERT or UPDATE profile filters on the account level\n INSERT profile filter links, which attach the newly-created or updated filters to the selected profiles\n  To get it up and running, you will need to register a new project in the Google Developers Console, create a new Client ID for a web application, as well as a public API key. Remember to activate the Google Analytics API as well!\nHow it works When you click Initialize, the tool requests your authentication to do all sorts of horrible things to your GA account. Do not worry! This tool mainly only INSERTs and READs. The only exception is if you already have these spam filters installed on your GA account, but they are outdated, in which case the tool will automatically update them to their newest versions!\nOnce you\u0026rsquo;ve authenticated your account, you will be served a drop-down menu from which you can choose any GA account you have EDIT access to. Why EDIT access? Because that\u0026rsquo;s the required access level for new filter creation. You read that right! To create filters, you need EDIT access on the account level.\n  Anyhow, choose an account and the tool should shortly load with a multiple selection menu, where you can pick the profiles to which you want to link the filters.\nOnce you click the Create and apply filters, the tool does just that. First, it creates the filters on the account level, after which it links each filter to the profiles you selected.\nThe list of filters is the one maintained in this Lone Goat resource. Whenever they update the list, I update these filters. Which brings me to the\u0026hellip;\nCaveats These filters only help with referral spam. They will not help you with polluted Measurement Protocol hits, or with spam that doesn\u0026rsquo;t come in as referral traffic, or with spam that comes in as referral traffic but isn\u0026rsquo;t in the filters yet. There are many methods to combat this issue, and you might want to check the couple of links I had in the very beginning for ideas.\nAnyway, feel free to use the tool and let me know if there are issues.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/universal-analytics-plugins-explained/",
	"title": "Universal Analytics Plugins Explained",
	"tags": ["JavaScript", "plugins", "universal analytics"],
	"description": "Guide to how plugins work in Google Analytics.",
	"content": " There are many tools and methods to make Google Analytics more manageable. Google Tag Manager is probably the best known of these, and you can find many, many articles about GTM on these pages as well.\nHowever, today I want to tell you about one of the features of Universal Analytics that hasn\u0026rsquo;t, as far as I know, received too much attention. It\u0026rsquo;s funny, because at the same time almost everyone uses the feature in the shape of eCommerce, enhanced link attribution, and cross-domain tracking. I\u0026rsquo;m talking, of course, about Universal Analytics plugins.\n  Plugins are JavaScript objects, which you can load and execute using the Universal Analytics global object interface. This is accessed, by default, using the ga() function.\nPlugins allow you to do a number of useful things:\n Decouple tracker object access from JavaScript embedded in the page HTML, allowing you to crete, execute, and maintain often used ga() commands in library files instead of directly in the page\n Quickly access the tracker object of choice, without having to prefix every command with the tracker name, or to loop through all the existing trackers to find the correct one\n Execute the plugin commands synchronously, which means you can be 100 % sure that anything the plugin does will be available to commands that come after it in the command queue\n  All the benefits listed above facilitate a plug-and-play integration between a platform and Google Analytics. If you\u0026rsquo;re the developer of the platform, you can create a plugin that does most of the legwork, such as assigning a new Custom Dimension with its respective value, and the user only has to load the plugin to reap the benefits.\nHow plugins work Before getting into a technical description of plugins themselves, there\u0026rsquo;s something we need to clear up about the Universal Analytics tracker object first. Here\u0026rsquo;s a typical tracking code on a typical website:\n\u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;//www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; If you want to understand what the code above does statement by statement, this and this are good places to start.\nWhat\u0026rsquo;s important, however, is that the analytics.js library is loaded asynchronously. The loading starts when the immediately invoked function expression (IIFE) is executed, but the browser\u0026rsquo;s JavaScript engine moves right to the two ga() commands before the analytics.js library has loaded. This means that the two ga() calls are not actually interacting with analytics.js, but instead they are pushing commands into a command queue, which is processed first-in first-out as soon as the library has loaded.\n  This, in turn, has a significant implication on what you can do with the code. Consider the following example:\n\u0026lt;script\u0026gt; ...the IIFE here... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;, { \u0026#39;dimension1\u0026#39; : ga.getAll()[0].get(\u0026#39;clientId\u0026#39;) }); \u0026lt;/script\u0026gt; If you know your tracker methods, you\u0026rsquo;ll see that this attempts to send the clientId of the tracker object as a Custom Dimension with the page view hit.\nThis code will, however, result in the error: ga.getAll is not a function. The reason for this error is due to the library not having loaded yet when the JavaScript engine processes the command in the ga() call. It\u0026rsquo;s the analytics.js library that sets up the interface for the global object, not the tracking code.\nThere are two ways to overcome this. You can pass a callback function as an argument to the ga() call, and any code within that function will not be executed until the library has loaded. The second method would be to use a plugin.\nWhen you call the ga('require', 'pluginName') method, this request is added to the command queue. When the analytics.js library has finally loaded, the command queue will be processed in order. Once the processing reaches this \u0026lsquo;require\u0026rsquo; command, the queue will halt until a \u0026lsquo;provide\u0026rsquo; call with the same plugin name is found in or added to the queue. This means that the following code would work nicely:\n\u0026lt;script\u0026gt; ...the IIFE here... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-1\u0026#39;, \u0026#39;auto\u0026#39;); // Load the getClientId plugin, which gets the // clientId and sets it as dimension1 on following hits ga(\u0026#39;require\u0026#39;, \u0026#39;getClientId\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; Even though the tracker interface is not available when the \u0026lsquo;require\u0026rsquo; command is added to the queue, the interface will be available once the queue is being processed.\nHow to create a plugin Let\u0026rsquo;s create the getClientId plugin from the previous chapter. The plugin code itself consists of two required components:\n A constructor that is executed when the plugin is loaded\n A \u0026lsquo;provide\u0026rsquo; command that links the constructor with the plugin name\n  To create the plugin getClientId, you would need something like the following code loaded on the page:\nvar GetClientId = function(tracker) { tracker.set(\u0026#39;dimension1\u0026#39;, tracker.get(\u0026#39;clientId\u0026#39;)); }; var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;] || \u0026#39;ga\u0026#39;]; if (ga) { ga(\u0026#39;provide\u0026#39;, \u0026#39;getClientId\u0026#39;, GetClientId); }  The first lines are for the constructor. It\u0026rsquo;s just a JavaScript function, but it turns into an object constructor with the ga('require', 'getClientId') call, which creates a new object instance of GetClientId.\nIf object-oriented JavaScript confuses you, take a look at the excellent JavaScript track at codecademy.\nAnyway, the tracker object used in the call to the constructor is automatically passed as an argument to the function. This means that you can run commands on the tracker object, and you don\u0026rsquo;t have to worry about interacting with the right tracker or sending the hits to the right Google Analytics property.\nThe next lines first make sure that the ga() command exists. The ga() function is created in the Universal Analytics tracking snippet, so if your plugin code is executed before the browser parses the tracking snippet, it might not work.\nFinally, the ga('provide', 'pluginName', Constructor) command is run so that the plugin can be found with its respective \u0026lsquo;require\u0026rsquo; call.\nTo briefly recap, here is how plugins are loaded and linked to trackers:\n The Universal Analytics tracking snippet creates the ga() function and the command queue\n All function calls to ga() are added to this command queue\n If you have a plugin, both its \u0026lsquo;require\u0026rsquo; and \u0026lsquo;provide\u0026rsquo; calls will be added to the queue as well\n Once the analytics.js library has loaded, the commands in the queue are processed in order\n If a \u0026lsquo;require\u0026rsquo; command is encountered, the queue processing halts indefinitely, until a \u0026lsquo;provide\u0026rsquo; call with the same plugin name is run\n The entire plugin constructor function is executed before queue processing continues\n  Below is an example of the loading order in action. The plugin \u0026lsquo;require\u0026rsquo; call is between the \u0026lsquo;create\u0026rsquo; and \u0026lsquo;send\u0026rsquo; calls, and the library itself is loaded after the Universal Analytics tracking code snippet. This is to secure that the ga() function is created before the plugin.\n\u0026lt;script\u0026gt; ...the function expression here... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;require\u0026#39;, \u0026#39;getClientId\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://www.simoahava.com/scripts/getClientId.js\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; Note that the \u0026lsquo;require\u0026rsquo; command waits for the respective \u0026lsquo;provide\u0026rsquo; command indefinitely. This means that if you misspell the plugin name, or if you only have the \u0026lsquo;require\u0026rsquo; command there for some reason, the queue processing will not proceed. So try to avoid breaking your analytics implementation, please!\nExample: SimoPlugin library Here\u0026rsquo;s an example of a plugin I might be tempted to use over and over again. In it, I have two special features:\n A generic event pusher, which I can use with all my trackers to send events to their respective properties\n A hit duplicator, which duplicates the hit to the Universal Analytics collection endpoint, and sends it as an HTTP request to any custom endpoint of my choice\n  I\u0026rsquo;m storing the plugin in a file called simoPlugin.js, which I then load asynchronously after my tracking code:\n\u0026lt;script\u0026gt; ...the IIFE here... ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-1\u0026#39;, \u0026#39;auto\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;UA-1234567-2\u0026#39;, \u0026#39;auto\u0026#39;, {\u0026#39;name\u0026#39; : \u0026#39;rollup\u0026#39;}); ga(\u0026#39;require\u0026#39;, \u0026#39;simoPlugin\u0026#39;); ga(\u0026#39;rollup.require\u0026#39;, \u0026#39;simoPlugin\u0026#39;); ga(\u0026#39;send\u0026#39;, \u0026#39;pageview\u0026#39;); ga(\u0026#39;rollup.send\u0026#39;, \u0026#39;pageview\u0026#39;); \u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://www.simoahava.com/scripts/simoPlugin.js\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; As you can see, I have my normal tracker and a tracker with the name rollup, and I\u0026rsquo;m loading the plugin for both trackers using the typical multiple tracker syntax.\nThe way the hit duplicator works is that whenever a \u0026lsquo;send\u0026rsquo; command is used, e.g. ga('send', 'pageview'), the exact payload to the Universal Analytics endpoint is copied and sent to a (fictional) endpoint of mine at http://process.simoahava.com/collect:\n  By duplicating hits like this, you can create your own data collection mechanism. You can even use a cloud endpoint, which will give you a lot more processing power and scale. You might even use this to overcome the schema conspiracy I\u0026rsquo;ve been ranting about before.\nThe generic event pusher works by sending a custom event object to a plugin method called trackEvent:\nga(\u0026#39;simoPlugin:trackEvent\u0026#39;, { \u0026#39;cat\u0026#39; : \u0026#39;Link Click\u0026#39;, \u0026#39;act\u0026#39; : \u0026#39;Outbound\u0026#39;, \u0026#39;lab\u0026#39; : \u0026#39;http://www.google.com\u0026#39;, \u0026#39;di\u0026#39; : 4, \u0026#39;dv\u0026#39; : document.location.pathname });  As you can see, an object literal is passed as the second argument of the ga() call. This argument, in turn, is passed to the trackEvent method in the plugin code. The method takes the arguments, makes sure no undefined fields are sent, and pushes an event hit to the property associated with the tracker that was used to call the plugin method. If I wanted to send the call to my rollup tracker, I would have used the syntax ga('rollup.simoPlugin:trackEvent').\nsimoPlugin code The code stored in the simoPlugin.js library looks like this:\n(function() { // Assign the ga variable to the Google Analytics global function  var ga = window[window[\u0026#39;GoogleAnalyticsObject\u0026#39;] || \u0026#39;ga\u0026#39;]; // Helper function for registering the Plugin  var providePlugin = function(pluginName, pluginConstructor) { if (ga) { ga(\u0026#39;provide\u0026#39;, pluginName, pluginConstructor); } }; // Constructor for simoPlugin  // Copies payload to custom host  var SimoPlugin = function(tracker) { this.tracker = tracker; // Copy the original hit dispatch function  var originalSendHitTask = this.tracker.get(\u0026#39;sendHitTask\u0026#39;); // Modify the existing hit dispatcher to send a local copy of the hit  this.tracker.set(\u0026#39;sendHitTask\u0026#39;, function(model) { originalSendHitTask(model); // Send the original hit as usual  var xhr = new XMLHttpRequest(); xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;http://process.simoahava.com/collect\u0026#39;, true); xhr.send(model.get(\u0026#39;hitPayload\u0026#39;)); }); }; // Set up a generic event dispatcher  SimoPlugin.prototype.trackEvent = function(evt) { var c = evt[\u0026#39;cat\u0026#39;]; var a = evt[\u0026#39;act\u0026#39;]; var l = evt[\u0026#39;lab\u0026#39;] || undefined; var v = evt[\u0026#39;val\u0026#39;] || undefined; var x = {}; x[\u0026#39;nonInteraction\u0026#39;] = evt[\u0026#39;ni\u0026#39;] || false; if (evt[\u0026#39;di\u0026#39;]) { x[\u0026#39;dimension\u0026#39; + evt[\u0026#39;di\u0026#39;]] = evt[\u0026#39;dv\u0026#39;] || undefined; } this.tracker.send(\u0026#39;event\u0026#39;, c, a, l, v, x); }; providePlugin(\u0026#39;simoPlugin\u0026#39;, SimoPlugin); })();  First things first: the whole thing is wrapped in an immediately invoked function expression. This is a good habit in general, since it will scope all variables within to function scope, and thus you\u0026rsquo;ll avoid polluting the global namespace. Here\u0026rsquo;s good overview of why IIFEs rock: I Love My IIFE - Greg Frank.\nThe next few lines are for making the plugin loader more generic. Since it\u0026rsquo;s possible to change the global function name in the analytics.js tracking code, we\u0026rsquo;ll need to make sure the plugin loader works even if the function name is no longer ga.\nThe providePlugin is a generic helper function which is largely redundant, but it will provide useful if you\u0026rsquo;re loading multiple plugins in the same library.\nThe constructor We create the constructor function in these lines:\nvar SimoPlugin = function(tracker) { this.tracker = tracker; // Copy the original hit dispatch function  var originalSendHitTask = this.tracker.get(\u0026#39;sendHitTask\u0026#39;); // Modify the existing hit dispatcher to send a local copy of the hit  this.tracker.set(\u0026#39;sendHitTask\u0026#39;, function(model) { originalSendHitTask(model); // Send the original hit as usual  var xhr = new XMLHttpRequest(); xhr.open(\u0026#39;POST\u0026#39;, \u0026#39;http://process.simoahava.com/collect\u0026#39;, true); xhr.send(model.get(\u0026#39;hitPayload\u0026#39;)); }); };  As you can see, the first argument to the function will be the tracker object used to load the plugin. This means that we can manipulate and use this tracker object interface without having to worry about accidentally sending hits to wrong GA properties!\nI use this.tracker = tracker; to store a reference to the tracker object into each instance of the plugin created with this constructor. This is why commands like ga('simoPlugin:trackEvent') and ga('rollup.simoPlugin:trackEvent') access a different tracker object. They both have their own, unique bindings of this, and thus they both have their own, unique tracker object references.\nThe next line accesses the sendHitTask property of the tracker object. Whenever a \u0026lsquo;send\u0026rsquo; command is used with the Universal Analytics global function, a series of tasks are executed. sendHitTask is one of these, and it is used to send the hit payload to the Universal Analytics collection endpoint.\nThe last call in the block is for updating the sendHitTask task in the tracker. This update uses the original sendHitTask (now stored in a variable called originalSendHitTask), and sends the payload to the Universal Analytics collection endpoint as before. The next three lines create a new HTTP request to the endpoint of your choice. The payload of this request is the exactly same payload that is sent to Universal Analytics.\nBy using this code, you will be able to create a perfect copy of the hit sent to Universal Analytics, and you can send this copy anywhere you want, such as a local hit processor, or a custom endpoint in a cloud server, for example.\nBecause this code is in the constructor, it is automatically applied to all \u0026lsquo;send\u0026rsquo; commands that take place on the page after the plugin has been loaded.\nThe event pusher The event pusher is defined as a method of the SimoPlugin object prototype. The reason we\u0026rsquo;re applying it to the prototype is because we want it to be available to all instances created with the SimoPlugin constructor. If we\u0026rsquo;d leave the prototype object out of the declaration, the trackEvent method would be added to an object literal called SimoPlugin, and not the object prototype. This means that the instances created from this prototype would not be able to use that method.\nAgain, if this is confusing, be sure to read up on object-oriented JavaScript. It\u0026rsquo;s interesting stuff, and it really shows what a complex and powerful programming language JavaScript is!\nThe event pusher code looked like this:\nSimoPlugin.prototype.trackEvent = function(evt) { var c = evt[\u0026#39;cat\u0026#39;]; var a = evt[\u0026#39;act\u0026#39;]; var l = evt[\u0026#39;lab\u0026#39;] || undefined; var v = evt[\u0026#39;val\u0026#39;] || undefined; var x = {}; x[\u0026#39;nonInteraction\u0026#39;] = evt[\u0026#39;ni\u0026#39;] || false; if (evt[\u0026#39;di\u0026#39;]) { x[\u0026#39;dimension\u0026#39; + evt[\u0026#39;di\u0026#39;]] = evt[\u0026#39;dv\u0026#39;] || undefined; } this.tracker.send(\u0026#39;event\u0026#39;, c, a, l, v, x); };  This code takes an object as an argument. This object is sent with the ga() command when the method is invoked:\nga(\u0026#39;simoPlugin:trackEvent\u0026#39;, { \u0026#39;cat\u0026#39; : \u0026#39;category\u0026#39;, \u0026#39;act\u0026#39; : \u0026#39;action\u0026#39;, \u0026#39;lab\u0026#39; : \u0026#39;label\u0026#39;, \u0026#39;val\u0026#39; : 1, \u0026#39;ni\u0026#39; : false, \u0026#39;di\u0026#39; : 1, \u0026#39;dv\u0026#39; : \u0026#39;dimensionValue\u0026#39; });  There are fields for Category, Action, Label, and Value, and I also let you determine whether the hit is non-interaction or not. Finally, you can also add one dimension with the index number and value exposed in the parameters.\nBecause Category and Action are required fields for events, the code will fail if these are not in the object. All the other fields can be left out, which is why I have them resolve to undefined if they don\u0026rsquo;t exist in the event object. The exception is the nonInteraction field, which defaults to false.\nUsing this generic event pusher, it\u0026rsquo;s pretty trivial to send simple AND complex events to Universal Analytics.\nThe final line, this.tracker.send(), sends the event using the tracker object\u0026rsquo;s send() method. As you can see, we\u0026rsquo;re using this.tracker, which accesses the interface of the tracker object used to call the method. The beauty of object-oriented JavaScript, right here ladies and gentlemen! If we didn\u0026rsquo;t use the power of object instances like this, we\u0026rsquo;d need to loop through all the trackers on the page to find the one we want to use. Way too complex!\nPlatform integrations Well, if the event pusher didn\u0026rsquo;t persuade you with its potential, and if you\u0026rsquo;re left unimpressed by the hit duplicator, another great idea for plugins is to integrate a SaaS platform and Google Analytics together.\nFor example, let\u0026rsquo;s say you have a platform through which you can create a new Custom Dimension in a Universal Analytics property, and then you can populate it with some value. This would happen programmatically, and the platform would use the Google Analytics Management API to create the Custom Dimension.\nOnce the dimension is created, you\u0026rsquo;d dynamically generate the JavaScript plugin library to include these programmatically created Custom Dimensions. Then you use the plugin commands to send hits to the trackers, using the correct Custom Dimensions.\n  This makes the integration between the platform and the website very plug-and-play, and you don\u0026rsquo;t need to ask the users to look up the correct dimension number, add it to the inline code, and risk some silly misunderstanding ruining the integration.\nIt\u0026rsquo;s such an elegant way of associating a website with your platform with just two lines of code at best (one for loading the library, and one for the ga('require', 'pluginName') call).\nSummary Plugins are an excellent way of associating often made calls with their respective tracker objects.\nAlso, they allow you to decouple all of the Universal Analytics commands from inline code. This allows you to write complex handlers for these commands without polluting the page template.\nPlugins are, however, quite an advanced use case for data collection. They require a very good understanding of JavaScript and of how the Universal Analytics library works.\nEspecially if you\u0026rsquo;re working with platform integrations and want to minimize the amount of work that users willing to implement the plugin need to do, I strongly recommend talking to your developers about creating a custom plugin for the integration.\nUnfortunately, plugins are not supported by the Google Tag Manager Universal Analytics tag template yet, so you might have to use a Custom HTML Tag to load plugins with GTM. See this article for inspiration.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/use-the-all-pages-trigger-correctly/",
	"title": "#GTMtips: Use The All Pages Trigger Correctly",
	"tags": ["Google Tag Manager", "gtmtips", "triggers"],
	"description": "How to use the All Pages trigger in Google Tag Manager.",
	"content": " Here\u0026rsquo;s a very quick tip this time, but one that\u0026rsquo;s caused a lot of headache for many Google Tag Manager users.\nTip 21: Use the All Pages Trigger correctly   Let\u0026rsquo;s face it, All Pages isn\u0026rsquo;t really an intuitive Trigger name. Many seem to interpret it as: enable the Tag to fire on all pages, but use the other Trigger (e.g. Link Click) to actually fire it.\nAs it turns out, the All Pages Trigger will fire the Tag on all pages. And it does so instantly, as soon as the GTM library has loaded. This means that a Tag such as the one in the screenshot above will fire twice:\nFirst when the gtm.js event is triggered in dataLayer upon the loading of the container snippet.\nAgain when the second, Event Trigger is activated upon a Link Click.\nYou might have guessed by now that only the second Trigger is relevant here. If the Event Tag is using Variables like Click URL or Click ID in its fields, these fields will most likely return undefined or (not set) in Google Analytics when the All Pages Trigger fires. This is because at the time of the All Pages event (gtm.js), no click has yet been registered, and these Variables will resolve to\u0026hellip;nothing.\nSo, my friends, use the All Pages Trigger as it\u0026rsquo;s supposed to be used: to fire a Tag on every single page with GTM installed on it, at a very early stage in the page load sequence. Examples of Tags that might use the All Pages Trigger would be the Google Analytics Page View Tag, some very open-ended remarketing Tag, Custom HTML Tags which setup a JavaScript framework for the rest of the Tags to use, and so on.\nFor more information about Triggers, be sure to read my Trigger guide as well!\n"
},
{
	"uri": "https://www.simoahava.com/personal/100th-post-big-changes/",
	"title": "100th Post: Big Changes",
	"tags": ["netbooster", "personal", "reaktor"],
	"description": "My 100th blog post.",
	"content": " A year ago, I wrote a Year In Review post for one of the craziest 365 days of my life, both personally (got married), and professionally (started at NetBooster, and toured the world talking about Google Analytics and Google Tag Manager). Now it\u0026rsquo;s time for another recap, and the chance to announce a big change in the Simoverse.\n  No, I will not be joining Google (made you think so!).\nGoodbye NetBooster I will be leaving NetBooster, where I have been the Head of Analytics for the Nordic countries over the past months. I held a number of positions before, e.g. SEO Manager, Production Director, and Web Analytics Supergeek (I made up the last title), but I was always gravitating towards data and analytics, so the last appointment was a very satisfying one.\nLeaving is going to bittersweet, as the future looks very interesting and challenging (more on that below), but at the same time I consider NetBooster to be my alma mater, and it\u0026rsquo;s not easy for me to say goodbye to the company that really made me feel like I\u0026rsquo;ve found my place in the world.\nNetBooster is an amazing company, with a very clear vision of where they want to be. They have a lot of crazily talented individuals and experts doing their best to push towards this vision. For a listed company, I always thought that the pace at NetBooster was extraordinary without sacrificing strategy or quality of work.\nI also got to work with some of the most intelligent people I know: Kristoffer Ewald, Mark Edmondson, Christian Pluzek, Thomas Hubert, Daniel Carlbom, Krister Collin, Antti Raami, just to name a few. Their professionalism alone made it an amazing adventure for me, and I felt dwarfed by their incredible work ethic.\nI know things are in good hands, as Fanny Le Béguec, a veteran in the analytics circuit, has taken over the responsibilities for driving Nordic analytics strategy. I couldn\u0026rsquo;t be happier that she\u0026rsquo;s in the ropes, and I\u0026rsquo;m sure she\u0026rsquo;ll make everyone forget who I ever was in no time.\nAs for where I\u0026rsquo;m going?\nHello Reaktor I\u0026rsquo;m going to be joining probably the coolest company in Finland. Reaktor is a full-service technology house, and they employ some of the best developers, designers, and innovators in Finland.\nI will be joining them as a Senior Data Advocate, bringing with me my own expertise on web analytics implementation, data collection, and data integration. I am also looking forward to setting up a proper digital analytics culture in Finland, since Reaktor has a very strong track record of community building.\nFor me, this is an amazing opportunity to accumulate new skills in data science, big data, and front-end development.\nI will continue my Google nerdom, and I hope to \u0026ldquo;Googlify\u0026rdquo; Reaktor as well, even though they have a non-commitment to any single platform, which I very much respect.\nI will also continue the outreach I\u0026rsquo;ve been doing thus far, keeping up with my blogging, being very active as a Google Developer Expert, and keeping close ties to Google Analytics and Google Tag Manager development. I\u0026rsquo;ll continue touring the conference circuit as well, just under a different banner this time.\nAll in all, a very exciting change for me. Hopefully, it will be a big change for the digital analytics community in Finland as well, if and when we start paving the way for no-strings-attached knowledge transfer that\u0026rsquo;s already blooming elsewhere in Europe.\nBlog stats Well, my traffic has continued to grow:\n  There was a dip around Christmas and the winter holidays, and in February-March I foolishly added a broken Event which I let inflate my sessions for way too long (4-5 weeks). Regardless, I\u0026rsquo;m still amazed how a niche blog can get so much attention, and I\u0026rsquo;m forever grateful to anyone interested enough to read these articles.\nMy top 10 articles over the past 365 days, measured by Unique Page Views (in parentheses) are:\n Macro Guide For Google Tag Manager - 11 Feb 2014 (45594)\n Advanced Form Tracking In Google Tag Manager - 7 Apr 2014 (36961)\n Macro Magic For Google Tag Manager - 21 Mar 2014 (21881)\n Some Awesome Google Tag Manager Resources - 26 Feb 2014 (16230)\n Auto-Event Tracking In Google Tag Manager - 2 Oct 2013 (15216)\n eCommerce Tips For Google Tag Manager - 6 Oct 2014 (14133)\n Google Tag Manager: Track Social Interactions - 7 Nov 2013 (11781)\n Google Tag Manager: Playing By The Rules - 3 Mar 2014 (11184)\n Universal Analytics: Weather As A Custom Dimension - 19 Sep 2013 (10316)\n Why Don’t My GTM Listeners Work? - 14 Feb 2014 (9541)\n  Lots of older articles in that list, but I\u0026rsquo;ve written a lot of nice stuff in 2015 as well, so let\u0026rsquo;s hope the top 10 looks different in a year or so.\nOverall, I\u0026rsquo;ve written 138606 words over the 100 articles.\nSince starting the blog, I\u0026rsquo;ve had the pleasure of receiving visits from 151901 users, across 335925 sessions, spanning 572925 pageviews. Amazing stuff!\n  I\u0026rsquo;ve received a crazy 1665 comments altogether on my posts, which completely astounds me. The community is just so strong and active!\nI\u0026rsquo;ve written a couple of tools, and I\u0026rsquo;ve started a #GTMtips post series, which already has 20 (hopefully) useful tips for anyone interested in using GTM. Please use the hashtag in social media if you have cool stuff you want to share with others!\nOnwards and upwards The next 365 days will surely be amazing as well, as I\u0026rsquo;m just starting to find my groove. I have the most amazing wife with me, and we bought a lovely house in Finland last summer.\n  Thank you for taking the time to read this, and if you ever see me speaking in a conference or hanging out in an event, come say hi. Always happy to make new friends!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/access-the-tracker-object-in-your-page-view-tag/",
	"title": "Access The Tracker Object In Your Page View Tag",
	"tags": ["custom html", "Google Tag Manager", "tracker object", "universal analytics"],
	"description": "How to access the Google Analytics tracker object before the analytics.js library has properly loaded. This tip is relevant for Google Tag Manager.",
	"content": " If you read my previous post on fetching the Client ID from the Universal Analytics tracker object with Google Tag Manager, you might have agreed with me that it sucks you can\u0026rsquo;t access the tracker object interface in real time using Google Tag Manager. This is because all of the set commands you add to a Universal Analytics tag template take place before the analytics.js is loaded and the tracker object is properly created.\nThe other issue with the tag template is that there\u0026rsquo;s no set way to access the tracker object anyway. I mean, you can use the set command, sure, but you can\u0026rsquo;t really use get or, for that matter, make use of any other interface methods you\u0026rsquo;d want to such as plugins (more on them in this post).\n  So, in this post I want to show a method you can use to actually mine the tracker object for whatever information you want, and at the same time ensure that the data is usable by the time your all-important Page View Tag fires. This is a notable improvement to the method I talked about in the previous post, which was to basically use a Window Loaded Trigger to fire a non-interactive Event Tag with the Client ID.\nThis article was inspired and intellectually fuelled by the amazing Carmen Mardiros (follow her: @carmenmardiros).\nThe method You\u0026rsquo;ll have to use Custom HTML for this. I know, I know! It\u0026rsquo;s a huge step backwards from the awesome, templated world you\u0026rsquo;re used to. Using a Custom HTML Tag is necessary precisely for the reasons I listed in the beginning. Until the Tag Template supports adding arbitrary JavaScript code between the create and send commands in the template, you\u0026rsquo;ll have to use a workaround.\nThe upside is that all you need the Custom HTML code for is to setup the tracker object, and then push an initialization event in to dataLayer, which will subsequently fire your actual Page View Tag. So, you\u0026rsquo;ll end up with one extra Tag and a very slight delay to your Page View Tag, but the delay is so minimal it doesn\u0026rsquo;t really make a difference.\nHere\u0026rsquo;s what will take place:\n Tracker object for your UA-code is created\n The Client ID is extracted from the tracker object as soon as it\u0026rsquo;s available\n When the Client ID has been extracted, it\u0026rsquo;s pushed into dataLayer together with the initialization event\n This event fires your Page View Tag, and you can use a normal Data Layer Variable to retrieve the Client ID\n  The Custom HTML Tag So, start by creating a new Custom HTML Tag, and make sure it fires on the earliest possible Trigger - usually the All Pages Trigger.\nAs for the code within, you\u0026rsquo;ll get that from your Google Analytics Admin, under Property Settings -\u0026gt; Tracking Info -\u0026gt; Tracking Code.\n  Copy-paste that into your Custom HTML Tag. Now, proceed to remove the line which says ga('send', 'pageview');. We\u0026rsquo;re removing this because we still want to use the actual tag template for sending the pageview hit.\nNow, if there are any modifications you need to do, such as adding additional trackers, you can set them up here. This guide has been written with a fairly basic setup in mind.\nNOTE! Any modifications to the tracker, such as allowLinker : true, custom cookie settings, and so forth need to be setup on this Custom HTML tracker, so that the Client ID you will be fetching from this custom tracker matches the one used by your main Page View Tag.\nThe next part is important. The analytics.js library is loaded asynchronously, which means that you don\u0026rsquo;t actually know when the tracker object has been created and its get method can be invoked. So, the library lets you pass a callback function to the ga object, which will be executed once the library has loaded and the tracker has been created. As I mention in the beginning: this feature is not available in the default tag template, which is why we need this workaround.\nTo add the callback, you add the following rows of code after the ga('create', ...); expression:\nga(function(tracker) { ...any methods which need the tracker object });  Any code within the callback function will be executed only once the library has been loaded, the tracker has been created, and the tracker object responds to interface methods. In this callback function, we\u0026rsquo;ll first fetch the Client ID, and then push it into dataLayer together with an initialization event:\nga(function(tracker) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;trackerReady\u0026#39;, \u0026#39;cid\u0026#39; : tracker.get(\u0026#39;clientId\u0026#39;) }); });  As you can see, I\u0026rsquo;m invoking the get command of the tracker object, and asking to retrieve the Client ID from the tracker. This wouldn\u0026rsquo;t be possible without the ga(function(tracker) {}) call.\nMy personal, finished example for the Custom HTML Tag looks like this. Remember, any customizations you need for the tracker object need to go here as well, so be sure to read up on how to set up advanced configurations for your Universal Analytics tracking code.\n\u0026lt;script\u0026gt; (function(i,s,o,g,r,a,m){i[\u0026#39;GoogleAnalyticsObject\u0026#39;]=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,\u0026#39;script\u0026#39;,\u0026#39;//www.google-analytics.com/analytics.js\u0026#39;,\u0026#39;ga\u0026#39;); ga(\u0026#39;create\u0026#39;, \u0026#39;{{GA Tracking Code}}\u0026#39;, \u0026#39;auto\u0026#39;, {\u0026#39;allowLinker\u0026#39; : \u0026#39;true\u0026#39;}); ga(\u0026#39;require\u0026#39;, \u0026#39;simoPlugin\u0026#39;); // Any plugins you want to load would go here  ga(function(tracker) { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;trackerReady\u0026#39;, \u0026#39;cid\u0026#39; : tracker.get(\u0026#39;clientId\u0026#39;) }); }); \u0026lt;/script\u0026gt; Just a few comments on the customizations:\n {{GA Tracking Code}} is a Lookup Table Variable which returns the property ID depending on a few conditions.\n ga('require', 'simoPlugin'); is where you would load any plugins you want to use with your Tags. This is missing from the tag templates, and I really hope we\u0026rsquo;ll get the chance to load plugins soon.\n  That\u0026rsquo;s it for the Custom HTML Tag. The rest is very simple stuff.\nData Layer Variable and Custom Event Trigger The two other things you\u0026rsquo;ll need are a Data Layer Variable for the Client ID, and a Custom Event Trigger for the trackerReady event.\n  Nothing complicated about this. The Trigger is really simple as well:\n  Once you have these two setup, all you need to do is modify your existing Page View Tag to accommodate these changes.\nMy Tag, for example, now has the Client ID as a Custom Dimension, and it\u0026rsquo;s set to fire with the Event - trackerReady Trigger we just created.\n  Summary This is one of those articles that I hope becomes obsolete soon. The current Universal Analytics tag templates do not let you run arbitrary JavaScript (e.g. load plugins) or access the tracker object after it has been created, but before the \u0026lsquo;pageview\u0026rsquo; hit is sent.\nThat\u0026rsquo;s why you need this workaround. On the other hand, this isn\u0026rsquo;t exactly a very complex thing to do, as you\u0026rsquo;re only creating one additional Tag to set up the tracker and channel all the subsequent tags to not fire until the tracker object callback function has been executed.\nTime will tell when the Universal Analytics tag template supports these features. Personally, I hope soon. Google Tag Manager is already the de facto implementation mechanism for Universal Analytics, but if it doesn\u0026rsquo;t support advanced configuration of the tracker object, larger organizations especially might be deterred from migrating until such features are supported out-of-the-box.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/improve-data-collection-with-four-custom-dimensions/",
	"title": "Improve Data Collection With Four Custom Dimensions",
	"tags": ["client id", "custom dimensions", "Google Tag Manager", "Guide", "user id"],
	"description": "Add four crucial custom dimensions to all your Google Analytics hits with Google Tag Manager. The dimensions include hit timestamp, session ID, client ID and user ID.",
	"content": " Since writing my rant about the schema conspiracy of web analytics platforms, I\u0026rsquo;ve been giving the whole idea of hit-level data collection a lot of thought. Sessionization is very heavily implemented in Google Analytics, which is understandable, but the regular Google Analytics API just doesn\u0026rsquo;t give you the kind of information you\u0026rsquo;d need, if you wanted to stitch hits together differently in your own backend. In fact, there are four distinct levels of aggregation that are not exposed via the API, even though I think they should:\n Hit timestamp - You can\u0026rsquo;t query for the exact timestamp of a Google Analytics hit via the API. You can\u0026rsquo;t get it in your custom reports, either. However, this might be very meaningful information, especially if you want to verify data integrity across systems.\n Session ID - Hits are grouped together into sessions. However, using the API alone, you will not be able to easily identify if two distinct hits belong to the same session.\n Client ID - Sessions are bunched under a Client ID. Every instance of the _ga cookie gets a unique Client ID, which is how the Google Analytics backend knows that the same \u0026ldquo;User\u0026rdquo; has visited the site multiple times. This Client ID is not exposed in any dimension you can query via the API.\n User ID - The User ID feature in Universal Analytics groups together hits, sessions, and Client IDs. It is the highest possible level of abstraction and aggregation available in Google Analytics. However, the data rows do not expose if a hit/session belongs to a specific User ID.\n  So, the purpose of this post is to give you the tools to annotate your incoming hit-stream data with all the information listed above. For data integration, this is almost a necessity, especially if you have a complex mesh of systems across which you want to join arbitrary data.\nIn the following chapters, we\u0026rsquo;ll build four Custom Dimensions and four data collection methods that will let you include this information in your data set. We will, of course, be using Google Tag Manager to make things more manageable.\n1. The Method I\u0026rsquo;ve created a Custom Dimension for each of the four use cases. Two of the dimensions are session-scoped, and two are hit-scoped. The dimensions are:\n Client ID - session-scoped Custom Dimension that collects the Client ID set by Google Analytics\n Session ID - session-scoped Custom Dimension that collects a randomized Session ID\n Hit Timestamp - hit-scoped Custom Dimension that collects the actual timestamp of each hit in local time, with the timezone offset included\n User ID - hit-scoped Custom Dimension that collects the User ID that gets set when someone logs into your website\n    Why a hit-scoped Custom Dimension for User ID, you ask? Well, the whole privacy discussion around user tracking is complicated, and I would rather be poked repeatedly in the eye with a dead ferret than be drawn into it. By tracking User ID with a hit-scoped Custom Dimension, you\u0026rsquo;ll only collect the data from logged-in users. As soon as they log out, or if they re-enter the website having logged out, User ID will not be sent with the hits. If the Custom Dimension were session-scoped, or even user-scoped, you would be collecting User ID for potentially logged-out visitors as well, and that might be in the grey area privacy-wise.\nThe end result of combining all this information will be something like this:\n  In this (fictional) data export, you can see 7 unique hits, made by two different client IDs (e.g. different browsers or devices), which span across three distinct sessions, but are all made by the same, logged-in user. With layered information like this, you can build intelligent models using GA data alone, but the possibilities it offers for data integration are remarkable as well.\nThe most difficult one of these solutions to implement, by far, is Client ID collection, so we\u0026rsquo;ll start with that.\n2. Client ID (UPDATE 5 April 2018: I recommend using this customTask method instead for sending the Client ID in a Custom Dimension. The tracker object method outlined below is more complicated and far more unreliable. With customTask, you can send the Client ID with any tag you want, with 100% accuracy each time.)\nThe difficulty with Client ID is that the ga interface you use to retrieve the Client ID doesn\u0026rsquo;t perform well in real time, especially for Tags firing very early in the page load sequence (e.g. your Page View Tag).\nYou could get the Client ID from browser cookies, but if it\u0026rsquo;s a first-time visitor to your site, chances are that the cookie hasn\u0026rsquo;t been set by the time the Page View Tag fires, and you\u0026rsquo;ll miss this information. Also, if there are multiple trackers on the page, how do you know which _ga cookie to access? You don\u0026rsquo;t.\nSo, I\u0026rsquo;ve opted for a different approach. I\u0026rsquo;m sending the Client ID using a non-interaction Event Tag, which fires when the page has loaded. This almost certainly guarantees that the ga interface is up and running, and I can use it to pull the Client ID for the correct tracker. The correct tracker is identified by querying the property ID (UA-XXXXXX-X) associated with the tracker object.\nThis particular data collection method will require the following ingredients:\n Session-scoped Custom Dimension, to collect the data in Google Analytics\n Custom JavaScript Variable, which gets the correct Client ID\n Window Loaded Trigger, which fires when the window has loaded if the Custom JavaScript Variable returns a valid value\n Event Tag, which sends a non-interaction event to Google Analytics when the Window Loaded Trigger fires\n  2.1. Session-scoped Custom Dimension This one is easy. Browse to the Google Analytics Admin of the web property you want to track to, select Custom Definitions -\u0026gt; Custom Dimensions, and create a new Custom Dimension that looks like the one below.\n  The important thing is to choose Session as the scope, and to make note of the index assigned to it.\nNote that if you wish, you could just as well scope this to User instead. The Client ID, by definition, is the same for the user throughout, so it might make sense to scope it accordingly. User-scoped dimensions are a bit questionable in terms of privacy, but in this case I don\u0026rsquo;t see any issue, as you\u0026rsquo;re just exposing a dimension that exists anyway. Thanks to Michael Hayes for pointing this out in the comments!\n2.2. Custom JavaScript Variable The Custom JavaScript Variable is named {{Get Client ID for current Tracker}}, and it needs the following code:\nfunction() { try { var trackers = ga.getAll(); var i, len; for (i = 0, len = trackers.length; i \u0026lt; len; i += 1) { if (trackers[i].get(\u0026#39;trackingId\u0026#39;) === {{GA Tracking Code}}) { return trackers[i].get(\u0026#39;clientId\u0026#39;); } } } catch(e) {} return \u0026#39;false\u0026#39;; }  The function contents are wrapped in a try...catch block, so any errors and problems with loading the ga interface are gobbled up. If you want, you can add your own error debugging code into the catch block. The key thing is to make sure the Event Tag doesn\u0026rsquo;t fire if there\u0026rsquo;s a problem with retrieving the Client ID. This means that you might miss some hits, but since we\u0026rsquo;re sending the information to a session-scoped Custom Dimension, you only need one successful hit sent during the session.\nThe code is designed so that it cycles through all the GA trackers on the page. Once it encounters a tracker object which tracks to the property ID returned by the {{GA Tracking Code}} variable, it returns the Client ID associated with this object.\nThis means that you will need to have a variable called {{GA Tracking Code}}, which returns a valid property ID (UA-XXXXXX-X). On my website, for example, it\u0026rsquo;s a Lookup Table Variable, which returns my main property ID for everyone else, but for me it returns a different property ID. This is because I use this secondary property for debugging implementations.\n2.3. Window Loaded Trigger The Window Loaded Trigger is pretty simple. It\u0026rsquo;s your basic Page View Trigger, where you set the Trigger Type to Window Loaded. However, you will need an additional condition in it.\n  The condition Get Client ID for current Tracker does not equal false ensures that the Trigger only fires if the Custom JavaScript Variable you just created returns a valid value.\n2.4. Event Tag The Event Tag is very basic, except for two customizations. First, you need set its Non-Interaction value to true. This prevents the Event from being calculated into interaction metrics like Session Duration and Bounce Rate.\nAlso, you\u0026rsquo;ll need to add a Custom Dimension to the Tag, via More Settings -\u0026gt; Custom Dimensions. Add the index number of the dimension you created in step 1 to the Index field, and add the Variable reference you created in step 2 to the Value field.\n  You can see how the fields should look from the image above.\n2.5. End result If you did everything correctly, you should see your sessions populating with a new Custom Dimension that you can add to your reports, and pull out of GA via the API or via the reporting interface, if you wish.\n  The dimension contains the Client ID of the visitor. You can then use this in your backend, for example, when you want to stitch hits sent from the same _ga cookie together in meaningful ways.\n3. Session ID For Session ID, we\u0026rsquo;re using a randomized string that is sent with each Pageview hit to Google Analytics. The string changes with each Pageview, but this doesn\u0026rsquo;t matter. Because you\u0026rsquo;re sending it to a session-scoped Custom Dimension, only the last value you send will be applied to the hits in the session.\nThe required components are:\n Session-scoped Custom Dimension, to collect the data in Google Analytics\n Custom JavaScript Variable, which returns a valid Session ID string\n Small modification to your Page View Tag, so that the Session ID is sent to Google Analytics\n  3.1. Session-scoped Custom Dimension This is pretty much the same step you went through in the previous exercise.\n  Just remember to make note of the index number, again.\n3.2. Custom JavaScript Variable The Custom JavaScript Variable is aptly named {{Random Session ID}}, and it has the following code:\nfunction() { return new Date().getTime() + \u0026#39;.\u0026#39; + Math.random().toString(36).substring(5); }  This script creates a pretty unique, randomized session ID. It does it by taking the hit timestamp in Unix time, adding a period, and following with a random string of alphanumeric characters. Because of the timestamp (accurate up to milliseconds), it\u0026rsquo;s very improbable that two similar session IDs are ever created.\nAn example of a session ID would be: 1427856715104.jdubr7umobt9.\n3.3. Modified Page View Tag In your Page View Tag, add a new Custom Dimension under More Settings -\u0026gt; Custom Dimensions. Set the index number you got from step 1, and set the value to the Variable reference {{Random Session ID}} you just created.\nBy using only the Page View Tag, you\u0026rsquo;ll be sending the Session ID with each page load. Only the last Session ID you send will remain, however, and all the hits in the session will automatically be annotated with this ID, thanks to the session-scoped Custom Dimension. If this is confusing, remember to read up on Custom Dimensions!\n3.4. End result By virtue of the Custom Dimension, you now have an identifier with which you can stitch together arbitrary, discrete hits in Google Analytics.\n  Together with the hit timestamp, you can start building realistic visit paths, if that suits your fancy.\n4. Hit timestamp Hit timestamp is something you should send with every single hit you send to Google Analytics. This means that you\u0026rsquo;ll need to modify all your Google Analytics Tags, which might seem like a chore.\nAccuracy is, of course, completely up to you, and you can opt to only send the timestamp with Pageviews and Transactions, instead.\nWhat you\u0026rsquo;ll need:\n Hit-scoped Custom Dimension, to collect the timestamp in Google Analytics\n Custom JavaScript Variable, which returns a valid timestamp string\n Modification to all your tags, to which you want the timestamp to be attached\n  4.1. Hit-scoped Custom Dimension There\u0026rsquo;s nothing spectacular about this one. Create a new Custom Dimension in GA Admin, and set its scope to Hit.\n  Remember to make note of the index.\n4.2. Custom JavaScript Variable The Custom JavaScript Variable needs to return the timestamp in String format. Now, there are many ways you could do this, for example:\n Get timestamp in Unix time (milliseconds since Jan 1, 1970), adjusted for client timezone\n Get timestamp in Unix time, converted to UTC\n Get timestamp as an ISO string, adjusted for client timezone\n Get timestamp as an ISO string, converted to UTC\n Get custom string, adjusted for local time or converted to UTC\n Something completely different\n  In my setup, I wanted the timestamp to be customized for my own tastes. That means that I\u0026rsquo;m parsing it to resemble an ISO timestamp, but I\u0026rsquo;m using client local time including the timezone offset, so I can see just which timezone the user is in. So, for example, if a visitor comes from Finland, which is GMT+3 (stupid daylight savings time), the hit timestamp might look like this:\n2015-04-03T18:55:27.466+03:00\nThis translates to April 3rd, 2015, at 6:55PM Helsinki time.\nSo, to get something like this, some JavaScript is required. Create a new Custom JavaScript Variable, and name it {{Hit Timestamp Local Time With Offset}}. Add the following code within:\nfunction() { // Get local time as ISO string with offset at the end  var now = new Date(); var tzo = -now.getTimezoneOffset(); var dif = tzo \u0026gt;= 0 ? \u0026#39;+\u0026#39; : \u0026#39;-\u0026#39;; var pad = function(num) { var norm = Math.abs(Math.floor(num)); return (norm \u0026lt; 10 ? \u0026#39;0\u0026#39; : \u0026#39;\u0026#39;) + norm; }; return now.getFullYear() + \u0026#39;-\u0026#39; + pad(now.getMonth()+1) + \u0026#39;-\u0026#39; + pad(now.getDate()) + \u0026#39;T\u0026#39; + pad(now.getHours()) + \u0026#39;:\u0026#39; + pad(now.getMinutes()) + \u0026#39;:\u0026#39; + pad(now.getSeconds()) + \u0026#39;.\u0026#39; + pad(now.getMilliseconds()) + dif + pad(tzo / 60)  + \u0026#39;:\u0026#39; + pad(tzo % 60); }  This code has been gratefully copy-pasted form this StackOverflow discussion.\nThis script works across all browsers, and returns a parsed string timestamp, with the timezone offset appended to the string.\n4.3. Modified Tags I send this timestamp with every single Tag that\u0026rsquo;s firing on my site, but if you feel like this is overkill, you can choose to only send it with business-critical hits you\u0026rsquo;ll use with other backend data, for example.\nThe only thing you need to do is add the Custom Dimension to any Tag you want to send it with. The setting looks like this:\n  Remember to set the Index accordingly. Go back to Google Analytics Admin, and look for the Custom Dimension you created in Step 1 to get the correct index number.\n4.4. End result What you\u0026rsquo;ll get is something like this:\n  It\u0026rsquo;s all your transactions, coupled with the accurate hit timestamp in local time when the transaction was recorded. The timezone offset helps you compare data with your backend, if it uses server time or some fixed timezone in its own data collection.\n5. User ID For User ID, you\u0026rsquo;ll need to have it already implemented in some way or another. In this example, we\u0026rsquo;ll pull the ID from dataLayer, but you might be using a 1st Party Cookie instead, which means you\u0026rsquo;ll need to modify the code accordingly.\nRemember that tracking Users across sessions and devices is a tricky business both technologically and ethically. I\u0026rsquo;ll leave things like consent, opt-out, anonymisation, and privacy to linger in the nether regions of your mind, so remember to ensure that what you\u0026rsquo;re doing is considered OK by at least one other person in the right state of mind.\nWe\u0026rsquo;re using a hit-scoped Custom Dimension again, but you can choose what level of accuracy and stitching to implement. I\u0026rsquo;ve reasoned for hit-level accuracy in the beginning of this article (wow, that was a LONG time ago), and I think the reasoning is well-founded. Also, depending on what you want to do with the data in the backend, you might choose to send the User ID with all hits or with just some hits.\nTo expose User ID as a Custom Dimension in your hits, you\u0026rsquo;ll need:\n Hit-scoped Custom Dimension, to collect the User ID in Google Analytics\n Data Layer Variable, which picks up the User ID from dataLayer\n Modified Tags, to which you want the User ID to be attached\n  5.1. Hit-scoped Custom Dimension The Custom Dimension is simple, of course. Just go to Google Analytics Admin, browse to Custom Definitions under the web property you want to set this up with, and create a new Custom Dimension of Hit scope:\n  As before, make note of the Index.\n5.2. Data Layer Variable How you actually retrieve the User ID depends on how you expose it in your website. A very good method is to populate it in dataLayer by a server-side process, which renders it together with the rest of the page. This way the User ID will be cemented in the page template, and you can use it with your critical tags that fire early on in the page load sequence.\nI use dataLayer to implement User ID, so all I need to create is a Data Layer Variable that picks up the User ID from the data model, and returns the value stored within. On my site, the variable is named {{DLV - userId}}, and it looks like this:\n  As you can see, I\u0026rsquo;m not setting a default value in the Variable. This means that if userId is not set in dataLayer, this Variable will resolve to undefined, and the Custom Dimension will be dropped from any Tag that uses it. This is a wonderful feature of the analytics.js library, and it really helps in keeping your Tag setup nice and lean.\n5.3. Modified Tags Next, add the Variable you just created into all the Tags you want to associate with logged in users. I send it with every single hit, because I want a comprehensive analysis of what my visitors do on the site.\n  Remember to set the Index correctly according to what you setup earlier in Google Analytics Admin.\n5.4. End result What you\u0026rsquo;ll get is an extra annotation on all your hits from logged in users:\n  Now, let\u0026rsquo;s not kid ourselves. If you\u0026rsquo;re sending User ID with just a handful of hits, and you\u0026rsquo;re also collecting Client ID, you can extrapolate User ID in your backend to all the hits done by the Client IDs associated with the User ID dimension. Like I wrote in the beginning of this article, the ethical, legal, and privacy-related considerations are yours to make alone.\n6. Summary This article explores something I feel passionate about: meaningful data collection. Google Analytics uses a lot of information that isn\u0026rsquo;t exposed in the reporting interface or the APIs, even though this information is central to how the platform aggregates the hits coming in from digital properties.\nBeing able to access this type of granular data shouldn\u0026rsquo;t be reserved for BigQuery users alone, so the solutions in this post help you add an extra level of accuracy to the stream of data flowing to the tracking platform. You can then pull this data out, combine it with other backend data, and build powerful models that will allow you to optimize your digital properties better than before.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/migration-to-v2-using-the-migration-assistant/",
	"title": "#GTMtips: Migration To V2 Using The Migration Assistant",
	"tags": ["Google Tag Manager", "gtmtips", "migration"],
	"description": "How to migrate your V1 Google Tag Manager container to the new version using the migration assistant.",
	"content": " On March 30th, right on (the latest) schedule, the Migration Assistant tool was published for Google Tag Manager V2. This tool lets you opt-in to account migration for your legacy Google Tag Manager Accounts. Migration means simply that the accounts will be converted to V2 accounts, and you will have access to all the new features the upgrade provides.\nIn this #GTMtips post, we\u0026rsquo;ll go over the migration steps (it\u0026rsquo;s pretty simple), and I\u0026rsquo;ll leave you with a couple of tips on how to get started with the new features.\nTip 20: Launch the Migration Assistant   Browse to http://tagmanager.google.com/. That\u0026rsquo;s the URL for GTM V2. When you enter the site, the Migration Assistant should pop-up immediately. You can choose to launch the assistant there and then, or you can cancel and do this later.\n  If you do choose to cancel, you can launch the Migration Assistant by scrolling down to where the \u0026ldquo;Legacy Accounts\u0026rdquo; are listed on the V2 start page. In the title bar for the \u0026ldquo;Legacy Accounts\u0026rdquo; is a button that will also launch the migration tool.\n  When you do choose to launch the Migration Assistant, all your legacy accounts will be listed. You can select one or many from this list. After selecting the accounts, clicking Migrate will start the migration process.\n  The migration process is designed to be completely transparent. You will not need to edit the container snippet on the page template, nor will you need to republish the container version.\n  It will take some hours for the migration(s) to complete, so be patient.\nOnce the migration is done, you can start using the V2 features in your container. Here are two things you might want to get acquainted with.\n1. Trigger-based Auto-Event Tracking If you had setup auto-event tracking in your legacy container, you\u0026rsquo;ll have used the Event Listener Tag templates. However, in V2, auto-event tracking is now Trigger-based, and does not require a separate tag setup anymore.\nTake a look at my guide for auto-event tracking in GTM V2. What you\u0026rsquo;ll need to do is take the conditions from your old \u0026ldquo;Firing rules\u0026rdquo; (now converted to custom Triggers), and use them in the dedicated auto-event Trigger types: e.g. Click, Link Click, and Form Submit.\nFor example, if you had a Firing Rule that looked like:\n{{event}} equals gtm.formSubmit\n{{element id}} equals contactForm\nIn V2, you would create a Form Submit Trigger, and in its \u0026ldquo;Fire When\u0026rdquo; settings, you would add the condition:\nForm ID equals contactForm\nThis does require that you activate the built-in Form ID variable as well (see below).\nAnyway, follow the guide, and you\u0026rsquo;ll have a better idea of what you need to.\n2. Built-in variables In V2, the most common variables you\u0026rsquo;ll need are available as built-in variables. You can read more about them in my Variable Guide for GTM V2. I suggest you use these, as they will keep the container size down, and activating them is as simple as checking a box in the Variables screen.\nWhen you migrate from V1, you\u0026rsquo;ll have a bunch of pre-defined legacy variables such as {{url}}, {{url path}}, {{element url}}, etc. These all have equivalent built-in variables, so one of the things you might want to do is activate the respective built-in variables, and then modify your Tags and Variables to use these instead.\nHere\u0026rsquo;s a pretty sweet way to replace your user-defined variables with their respective Built-in Variables, courtesy of Brian Kuhn:\n Make sure the Built-in Variable has been deactivated\n Rename the user-named variable (e.g. {{url}}) to its respective Built-in Variable (e.g. Page URL)\n Reactivate the Built-in Variable, and choose Overwrite in the pop-up that\u0026rsquo;s displayed\n  This will update all your Tags, Variables, and Triggers to use the Built-in Variable instead.\n  Do note that this isn\u0026rsquo;t required, but it\u0026rsquo;s a good idea to migrate completely to V2, so that you can leverage the new features as much as possible.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/debugging-tag-execution-properly/",
	"title": "#GTMtips: Debugging Tag Execution Properly",
	"tags": ["debug", "Google Tag Manager", "gtmtips"],
	"description": "Tips and guide for debugging tag execution properly in Google Tag Manager.",
	"content": " One of the unfortunate misunderstandings regarding the wonderful Google Tag Manager Preview mode is what it actually means when GTM reports \u0026ldquo;Tags Fired On This Event\u0026rdquo;. For many, this seems to indicate that whatever code the Tag was meant to execute also completed successfully. However, this is not the case.\nTip 19: Debugging Tag execution vs. actual requests   Let\u0026rsquo;s get the distinction straight right away:\nGoogle Tag Manager debug panel tells you when a Trigger has been invoked by certain conditions, and the Tag which uses this Trigger has its JavaScript injected into the Document Object Model.\nThis does not mean that the expected result of the Tag code (e.g. fire a pixel, load an iframe, perform arbitrary JavaScript) has completed successfully.\nThis is a very clear distinction, and it basically means that looking at the debug panel alone, you cannot debug whether or not the execution of your Tags is performing expectedly.\nFor example, if you have some Google Analytics blocker running in the browser, GTM\u0026rsquo;s debug panel will tell you that the Tag has \u0026ldquo;fired\u0026rdquo;, but the browser will prevent the Tag code from completing its request to Google Analytics servers.\nHow to debug the whole process The best way to ensure that Tags are firing correctly is to pay attention to two things: network requests and the JavaScript console.\nThe former will tell you if requests are successfully completing, and the latter will tell you if the JavaScript has errors in it (or other, unexpected behavior).\nNetwork requests can be debugged with your browser\u0026rsquo;s Developer Tools:\n Chrome / Mac: Open the Developer Tools with Cmd + Opt + I and navigate to \u0026ldquo;Network\u0026rdquo;\n Chrome / Windows: Open the Developer Tools with F12 and navigate to \u0026ldquo;Network\u0026rdquo;\n Firefox / Mac: Cmd + Opt + Q\n Firefox / Windows: Ctrl + Shift + Q\n  What you\u0026rsquo;ll see is the list of requests your browser has made during the lifespan of the page. You can locate a specific type of request using the filter feature (Chrome). For example, to see hits to the Universal Analytics endpoint, I would filter for requests with the word \u0026ldquo;collect\u0026rdquo;. That\u0026rsquo;s because collect is the URI where all Universal Analytics hits are dispatched to.\nNext, I\u0026rsquo;ll focus on the Status column. Typical errors are e.g. 404 (not found) and 500 (internal server error). A successful request would have the response code 200.\n  If you want an even clearer view to what\u0026rsquo;s happening on the site, complete with an analysis of dataLayer state, take a look at my favorite debugging tool, WASP.\nTo debug JavaScript errors, open the same Developer Tools, but navigate to Console instead. You should see a verbose output of all JavaScript errors that the current page has dispatched, and you might see some errors in your GTM tags as well.\n  Do note that debugging JavaScript errors can be pretty difficult especially if you use frameworks like jQuery. You will have to plough through the call stack trace (if there is one), and even then the results might be inconclusive. That\u0026rsquo;s why it\u0026rsquo;s a good thing to cooperate with a developer who understands the existing scripting conditions of your website, and who can provide input on which errors are related to which scripts.\nSo, remember:\nDebug Panel tells you when a Trigger causes a Tag to be injected on your site.\nBut:\nNetwork debugger and JavaScript console tell you if the Tag code executed with expected results.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/send-weather-data-to-google-analytics-in-gtm-v2/",
	"title": "Send Weather Data To Google Analytics In GTM V2",
	"tags": ["api", "Google Tag Manager", "Guide", "JavaScript", "v2", "weather"],
	"description": "How to collect and send weather data from users who visit your website. You can send this information to Google Analytics using Google Tag Manager.",
	"content": " In 2013, I wrote a guide for Universal Analytics and Google Tag Manager on how to poll for weather conditions, and send this information to Google Analytics as a custom dimension of the session. The guide was intended as a technical introduction to Google Tag Manager, and I think it succeeded in that.\nHowever, GTM has changed a lot over the last 1.5 years, and I\u0026rsquo;ve made some improvements to the method along the way. So I wanted to update the guide for the new version of Google Tag Manager (V2), and introduce some changes to the code that make it more flexible and efficient.\n(UPDATE 21 August 2017) - I updated this article to work with the Weather Unlocked API (thanks to Kévin Coppens for the tip), due to openWeatherMap upgrading their SSL plan to a pretty expensive level. Do note that Weather Unlocked requires the use of an API key, and passing the API key client-side is risky, and opens up your API plan to abuse. For those who want to take this weather analysis seriously, I really recommend moving to a 100% server-side solution, where the weather data is polled before the page itself is rendered, and the data is written in the dataLayer of the page.\nSince this is a whopper of a post, I\u0026rsquo;ve got a table of contents right here:\n1. What it does The idea behind the solution is to poll a weather service, so that all sessions in Google Analytics would be annotated with information on what the weather conditions were at the time of the session. The underlying question we\u0026rsquo;re trying to answer is: \u0026ldquo;Does weather play a part in how people interact with your website or your brand?\u0026rdquo;. This might be a very relevant question for businesses very dependent on weather conditions, such as those with golf courses and ski slopes.\nThe technical method is split into three parts:\n Geolocation - we need to get an approximation of the geographic area the visitor is browsing from.\n Weather API - we will use this geolocation data to query for the weather conditions in the visitor\u0026rsquo;s region.\n Data Layer - finally, we will store all the information we get in the dataLayer object to be available for our Tags.\n  It\u0026rsquo;s not the simplest of processes, and there are many ways you can optimize it (I\u0026rsquo;ll expound these in the relevant chapters). Also, one of the main reasons for writing this guide in the first place is to show a prototype for any generic API call you might want to make. So it\u0026rsquo;s not just weather, but share price, traffic details, basketball results, and so on. If there\u0026rsquo;s an API for it, you can use this method to enrich your visitors\u0026rsquo; sessions with new Custom Dimensions and Metrics.\nThe solution itself follows the following flow, visualized with my mad PowerPoint skills:\n  It\u0026rsquo;s a fairly straightforward process, with only two junctions: session cookie state and success / failure of the API call itself.\n2. Core requirements Regardless of how you wind up doing the solution, you will require some core components. These are:\n geoPlugin API key and Weather Unlocked API credentials\n Custom HTML Tag to poll the API and store the information in dataLayer\n Trigger to fire an Event Tag when the data is in dataLayer Data Layer Variables to pull the information from the dataLayer into the Event Tag\n 1st Party Cookie Variable to maintain session state\n Session-scoped Custom Dimensions set up in Google Analytics to receive the API data from the Tag\n Universal Analytics Event Tag to send the data to Google Analytics\n  We\u0026rsquo;ll create the Custom HTML Tag later, since it requires a bit more work and deliberation than the other core requirements.\n2.1. Trigger The Trigger is simple. It\u0026rsquo;s just a Custom Event Trigger that fires when an \u0026lsquo;event\u0026rsquo; key with value \u0026lsquo;weatherDone\u0026rsquo; is pushed into dataLayer. Give it a descriptive name, such as Event - weatherDone.\n  Make sure the Trigger looks like the one in the screenshot above.\n2.2. Data Layer Variables In this solution, we\u0026rsquo;ll use two Data Layer Variables. One to hold a simplified description of the weather conditions (e.g. \u0026ldquo;Cloudy\u0026rdquo;, \u0026ldquo;Rain\u0026rdquo;, \u0026ldquo;Storm\u0026rdquo;), and one to store the temperature, also simplified (e.g. \u0026ldquo;5°C - 15°C\u0026rdquo;).\nSo, create two Data Layer Variables, one for Variable Name weather, and one for Variable Name temperature.\n  The Variable above is named DLV - weather.\n  Give the second Variable a name such as DLV - temperature. This is the naming convention I use (DLV stands for Data Layer Variable, of course), but you can name them as you wish.\n2.3. 1st Party Cookie Variable We\u0026rsquo;ll be artificially maintaining session state using a custom cookie, written by the script and refreshed each time the page loads. The reason we want to maintain state like this is because we only want to send weather data once per session.\nThe API call to the weather service is not light-weight. We want to avoid making calls like this as much as we can, because that way the page load process won\u0026rsquo;t be hindered by slowly loading asynchronous API calls like this. So, when the visitor first lands on the site, a cookie is created that mimics GA\u0026rsquo;s session logic by having a 30-minute expiration. Naturally, this isn\u0026rsquo;t the entire session logic (we\u0026rsquo;re missing stuff like referral exclusions, cross-domain tracking, etc.), but it\u0026rsquo;s close enough to save us from making unnecessary calls.\nThe cookie script is in the actual API script introduced later in this article, but the Variable you\u0026rsquo;ll need to create should look like this:\n  2.4. Session-scoped Custom Dimensions Because we have two measurements we want to send as extra data, we\u0026rsquo;ll need two Custom Dimensions to store them. Now, you might wonder: \u0026ldquo;Why not use Custom Metrics for temperature? It\u0026rsquo;s numeric, after all?\u0026rdquo;. That\u0026rsquo;s a good question, and the reason is that you can\u0026rsquo;t calculate on Custom Metrics yet. So all temperature data that you would be sending would end up as cumulative across your reports. It doesn\u0026rsquo;t make sense to ask \u0026ldquo;What was the sum of all temperatures for converting visits from Helsinki?\u0026rdquo;, but it makes a lot of sense to ask \u0026ldquo;What was the average of all temperatures for converting visits from Helsinki?\u0026rdquo;. The latter, unfortunately, is not yet available through Google Analytics.\nAnyway, create two session-scoped Custom Dimensions, and name them so that you\u0026rsquo;ll find them when going through your dimension lists. I\u0026rsquo;ve used simply \u0026ldquo;Weather\u0026rdquo; and \u0026ldquo;Temperature\u0026rdquo;.\n  It\u0026rsquo;s important to make note of the dimension index number for both new dimensions. We\u0026rsquo;ll need this information for our Event Tag.\n2.5. Universal Analytics Event Tag The Event Tag has two \u0026ldquo;customizations\u0026rdquo;, if you will. First of all, we\u0026rsquo;re sending this hit as a non-interaction event. This means that it will not affect the bounce rate of the session. The reasoning for this is that weather data isn\u0026rsquo;t something that results from a visitor action. It\u0026rsquo;s just meta information about the session, so it\u0026rsquo;s not interactive.\nUse the Trigger you created in step 2.1. to fire this Event Tag.\nWhy not use a Page View Tag, then? Another great question. Well, the API calls we\u0026rsquo;ll be making in the Custom HTML Tag take time to complete, since they\u0026rsquo;re executed asynchronously. This means that we won\u0026rsquo;t be able to pinpoint the moment in the page load sequence when the data is actually sent, but we will know it will be deferred for as long as the API call takes. If the call takes up a long time to complete, it will delay our Page View Tag from firing. This, I think, is a definite no-no. Page Views are a crucial part of session-based hit collection, and missing them simply is not an option.\nThere\u0026rsquo;s no down-side to using a non-interaction event.\nAnyway, the Tag I\u0026rsquo;ve used here has the following event parameters:\nEvent Category - Weather\nEvent Action - {{DLV - weather}}\nEvent Label - {{DLV - temperature}}\nNon-Interaction - True\n  Next, scroll down to More Settings, and expand Custom Dimensions. Here, you will need to add two new rows of Custom Dimensions to accommodate the two dimensions that are hungrily waiting for data to pass through the GA interface.\nAt this point, you will need to remember or look up the dimension index numbers from Google Analytics Admin. In my example, they\u0026rsquo;re simply 1 (for Temperature) and 2 (for Weather), but remember to adjust if necessary.\n  Add the respective Data Layer Variables to the value fields, as in the image above.\nThat\u0026rsquo;s it for the core requirements.\nThe next bit gets quite complicated.\n3. Building the script If you remember from the beginning, this technical solution falls into three parts: geolocation, weather query, and storing the information in dataLayer.\nTo get started, you will need a Custom HTML Tag that uses the All Pages Trigger. Give it a descriptive name. I\u0026rsquo;ve used Utility - HTML - Weather Query, but, again, you are free to go with your own naming convention.\nThis code has been rewritten to work with HTTPS-protected sites. If your site isn\u0026rsquo;t using HTTPS, much of this will be overkill and needlessly expensive, but I do recommend you upgrade your site security as soon as possible.\nThe code within, in all its JavaScript glory, is this:\n\u0026lt;script src=\u0026#34;https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; (function() { var fetchWeatherData = function(longitude, latitude) { // You need to sign up to Weather Unlocked for an account. Once you do,  // you will find your APP ID and APP KEY in your account dashboard.  var wuAppId = \u0026#39;paste_your_weather_unlocked_app_id_here\u0026#39;; var wuAppKey = \u0026#39;paste_your_weather_unlocked_app_key_here\u0026#39;; jQuery.getJSON(\u0026#39;https://api.weatherunlocked.com/api/current/\u0026#39; + latitude + \u0026#39;,\u0026#39; + longitude + \u0026#39;?app_id=\u0026#39; + wuAppId + \u0026#39;\u0026amp;app_key=\u0026#39; + wuAppKey) .done(function(data) { window.dataLayer.push({ event: \u0026#39;weatherDone\u0026#39;, weather: data.wx_desc, temperature: data.temp_c }); }).fail(function(jq, status, msg) { console.log(\u0026#39;Weather request failed: \u0026#39; + status + \u0026#39; - \u0026#39; + msg); }); }; var geoLocateUser = function() { // This is your API key for GeoPlugin, which you can purchase at  // http://www.geoplugin.com/premium#ssl_access_per_year  var geoPluginAPIKey = \u0026#39;paste_your_api_key_here\u0026#39;; jQuery.getJSON(\u0026#39;https://ssl.geoplugin.net/json.gp?k=\u0026#39; + geoPluginAPIKey + \u0026#39;\u0026amp;jsoncallback=?\u0026#39;) .done(function(data) { fetchWeatherData(data.geoplugin_longitude, data.geoplugin_latitude); }).fail(function(jq, status, msg) { console.log(\u0026#39;Geolocation failed: \u0026#39; + status + \u0026#39; - \u0026#39; + msg); }); }; if (typeof {{Session alive}} === \u0026#39;undefined\u0026#39;) { geoLocateUser(); } // Reset \u0026#34;session\u0026#34; cookie with a 30-minute expiration  var d = new Date(); d.setTime(d.getTime()+1800000); var expires = \u0026#34;expires=\u0026#34;+d.toGMTString(); document.cookie = \u0026#34;session=1; \u0026#34;+expires+\u0026#34;; path=/\u0026#34;; })(); \u0026lt;/script\u0026gt; Oh my, that\u0026rsquo;s a lot of code. In the next chapters I\u0026rsquo;ll walk you through just what the heck is going on here.\nIt\u0026rsquo;s important to notice that I\u0026rsquo;m loading jQuery at the very top of the script. Also, I\u0026rsquo;ve wrapped the whole script itself in an immediately invoked function expression to scope all variables to the function and thus avoid polluting the global namespace.\nIf you\u0026rsquo;re already loading jQuery on the site, you shouldn\u0026rsquo;t load it again in this Tag, but then you will need to ensure the Custom HTML Tag fires only after jQuery has completely loaded. If you load jQuery asynchronously, it leaves you little choice but to fire the Custom HTML Tag upon the Window Loaded Trigger, since that\u0026rsquo;s the only moment you can be sure that jQuery has been loaded.\nFor error logging, I simply invoke the .fail() callback of the JSON requests to the two APIs (geoPlugin and Weather Unlocked). In case of an error, the message is simply written to the console, but you can also invoke a dataLayer.push() to log the error elsewhere, such as Google Analytics.\n3.1. Geolocation There are many ways to do geolocation, but for usability\u0026rsquo;s sake I use an API call for this as well. If you\u0026rsquo;re serious about this solution, you might want to install a geolocation service on your own web server, so that you\u0026rsquo;ll avoid needing to make any extra API calls in the client.\nGeolocation hinges on one thing: the visitor\u0026rsquo;s IP address. There are many ways to get this data, as it is public information, exposed in the HTTP headers of the visitor\u0026rsquo;s requests. You might have guessed at this point that the accuracy of the solution is thus dependent on what type of proxies or VPNs the visitor might be using. This is something we will not be able to work around, and thus you will need to take the geolocation data, as any other data in the public web, with a grain of salt.\nWhat we\u0026rsquo;ll need back from the geolocation service are the latitude and longitude of the visitor. IP-based geolocation is usually accurate down to the city the visitor is from, but in many cases it might be a much broader spectrum, such as an entire state or even country. Nevertheless, we\u0026rsquo;ll take what we can get.\nThe method in the script uses an all-in-one API for both getting the IP address and retrieving the longitude and latitude of the visit. The service is called geoPlugin, and the SSL plan is fairly inexpensive.\nvar geoLocateUser = function() { // This is your API key for GeoPlugin, which you can purchase at  // http://www.geoplugin.com/premium#ssl_access_per_year  var geoPluginAPIKey = \u0026#39;paste_your_api_key_here\u0026#39;; jQuery.getJSON(\u0026#39;https://ssl.geoplugin.net/json.gp?k=\u0026#39; + geoPluginAPIKey + \u0026#39;\u0026amp;jsoncallback=?\u0026#39;) .done(function(data) { fetchWeatherData(data.geoplugin_longitude, data.geoplugin_latitude); }).fail(function(jq, status, msg) { console.log(\u0026#39;Geolocation failed: \u0026#39; + status + \u0026#39; - \u0026#39; + msg); }); };  In this method, you first need to write your API key into the geoPluginAPIKey variable. You\u0026rsquo;ll get this API key by subscribing to a very cheap plan at geoPlugin. Next, we use the JSONP endpoint of the geoPlugin API to fetch the geolocation data for the user. It\u0026rsquo;s all wrapped in jQuery\u0026rsquo;s extremely useful getJSON() method.\nThe asynchronous request is supplemented with the done() callback, which is invoked if everything goes well. In this callback, we pass the longitude and latitude information to the next function in the chain: fetchWeatherData().\nIn case of an error, the error information is output into the browser console.\n3.2. Building the API call So now we\u0026rsquo;ve got geolocation down. The next thing we need to do is use this information to poll for weather data.\nI use the Weather Unlocked service for this. It has a pretty generous free plan, and it supports both SSL and non-SSL requests. (UPDATE: Looks like Weather Unlocked Developer API for SSL requests requires a small subscription fee now.)\nOnce you\u0026rsquo;ve signed up to the service, you will find your APP ID and APP KEY in the dashboard.\n  The fetchWeatherData() method itself looks like this:\nvar fetchWeatherData = function(longitude, latitude) { // You need to sign up to Weather Unlocked for a free account. Once you do,  // you will find your APP ID and APP KEY in your account dashboard.  var wuAppId = \u0026#39;paste_your_weather_unlocked_app_id_here\u0026#39;; var wuAppKey = \u0026#39;paste_your_weather_unlocked_app_key_here\u0026#39;; jQuery.getJSON(\u0026#39;https://api.weatherunlocked.com/api/current/\u0026#39; + latitude + \u0026#39;,\u0026#39; + longitude + \u0026#39;?app_id=\u0026#39; + wuAppId + \u0026#39;\u0026amp;app_key=\u0026#39; + wuAppKey) .done(function(data) { window.dataLayer.push({ event: \u0026#39;weatherDone\u0026#39;, weather: data.wx_desc, temperature: data.temp_c }); }).fail(function(jq, status, msg) { console.log(\u0026#39;Weather request failed: \u0026#39; + status + \u0026#39; - \u0026#39; + msg); }); };  It\u0026rsquo;s fairly similar to the geolocation method. We use the latitude and longitude information to query the Weather Unlocked API. You\u0026rsquo;ll need your APP ID and APP KEY handy for this!\nUpon a successful request, the response is parsed for the description of the current weather (data.wx_desc) as well as the current temperature (data.temp_c). These are added to the dataLayer object under their respective keys.\nNote that all Ajax calls are made using jQuery. Now, the benefits and pitfalls of being dependent on an external, bloated framework like jQuery can be debated, but jQuery handles Ajax requests beautifully. It\u0026rsquo;s perfect for what we\u0026rsquo;re trying to achieve here, so I don\u0026rsquo;t mind using the framework.\nAnd that\u0026rsquo;s about it! The solution is fairly simple, relying on fairly simple, chained asynchronous requests. If one fails, then the rest doesn\u0026rsquo;t get executed, so you might want to add some error handling if you want to know what your success rate is. But since we\u0026rsquo;re using session-scoped Custom Dimensions, you can already get a success rate by looking at how many sessions have weather data out of all sessions.\nJust one thing remaining.\n3.3. Maintaining state with a cookie The final bit of the puzzle is to fire the tag just once per session. We do this by only starting the whole process if a custom 1st party cookie has not been set. The {{Session alive}} Variable returns undefined if the cookie is not set, so we can check against this before executing the first step (the geolocation).\nif (typeof {{Session alive}} === \u0026#39;undefined\u0026#39;) { ...the geolocation call... } // Reset \u0026#34;session\u0026#34; cookie with a 30-minute expiration  var d = new Date(); d.setTime(d.getTime()+1800000); var expires = \u0026#34;expires=\u0026#34;+d.toGMTString(); document.cookie = \u0026#34;session=1; \u0026#34;+expires+\u0026#34;; path=/\u0026#34;;  At the end of the script, regardless of whether the cookie was set or not, we create / update the cookie with a new 30-minute expiration.\nAnd that\u0026rsquo;s it. Easy, right?\nRemember to test it carefully in Preview mode. Check the JavaScript console for any errors, test that the cookie logic works, and monitor Real-Time reports in Google Analytics to verify that data is flowing in.\n4. Summary So this is the weather script for Google Tag Manager V2. Feel free to swap the Weather Unlocked API with any other API endpoint you might want to query. You will need to study the API, modify the parameters, and parse the data differently, but the logic is the same.\nIt would be cool to know if weather analysis has brought you any insights. A great idea for modifying the script would be to not just track today\u0026rsquo;s weather, but the weather next weekend or over a holiday. Does a warm Easter contribute to fewer bookings in the ski slopes, and does a rainy weekend ahead make green fee sales plummet at the local golf course?\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/track-url-fragments-as-pageviews/",
	"title": "#GTMtips: Track URL Fragments As Pageviews",
	"tags": ["Google Tag Manager", "gtmtips", "history change trigger", "history listener"],
	"description": "How to track dynamic changes to the page URL, especially URL fragments, as individual page views in Google Analytics. The guide is for Google Tag Manager.",
	"content": " (Updated 15 July 2015: Added a huge simplification. Jump straight to the update at the end.)\nURL fragments are strings of characters that follow a hash mark (#) in the URL. Typically, they are used for anchor links, where following a link keeps you on the same page but jumps the browser to some anchored position. They\u0026rsquo;re also the tool of choice for single-page apps, where content is served dynamically without page reloads.\nIn Google Analytics, fragment changes are not tracked by default, and the URL paths that are passed to GA with your Pageview hits are stripped of these fragments. With Google Tag Manager, this can be remedied with a History Change Trigger and some Variable magic.\nTip 18: Track URL fragments as Pageviews   When the URL fragment of the page changes, it doesn\u0026rsquo;t cause a reload. This is problematic for your Analytics tracking, as you probably have the All Pages Trigger firing your Page View Tag, and this Trigger only fires once per page load.\nHowever, when the URL fragment of a page changes, what happens behind the scenes is interesting: a browser history event is dispatched, and this can be hooked onto. Google Tag Manager provides the perfect way to do it with the History Change Trigger. It activates when it captures an event dispatched by a the URL fragment change.\nSo, to track fragment changes, all we need is the History Trigger and some Variables, so that we can get a nice, lean, flexible setup running.\n1. The Variables First, head on over to the Variables section of Google Tag Manager, and make sure you\u0026rsquo;ve checked the New History Fragment and History Source Built-In Variables.\n  New History Fragment stores the new URL fragment when it changes, and History Source will let us specify that we don\u0026rsquo;t the tag to fire on all browser history events; just the one that signals a fragment change.\nNext, you\u0026rsquo;ll need a Custom JavaScript Variable that will produce a new, well-formed URI that we can then send to Google Analytics as the page path of the URL fragment. So, create a new Custom JS Variable, name it {{get path with fragment}}, and add the following code within:\nfunction() { return {{Event}} === \u0026#39;gtm.historyChange\u0026#39; \u0026amp;\u0026amp; {{New History Fragment}} ? {{Page Path}} + \u0026#39;#\u0026#39; + {{New History Fragment}} : undefined; }  This simple, one-liner JavaScript function checks first if the Event that invoked this Variable was a history change. If it was and the URL fragment isn\u0026rsquo;t empty, the next thing it does is return the current page path (e.g. /home/) and concatenates the new URL fragment to the string, separating the two with the \u0026lsquo;#\u0026rsquo; symbol (e.g. /home/#contact-us). If the Event was not a history change, the Variable returns the undefined value to ensure that the default path is sent with the Pageview.\nThe reason we\u0026rsquo;re sending the Page Path with the \u0026lsquo;#\u0026rsquo; symbol in place is because we want to enable the direct link \u0026ldquo;Visit this page\u0026rdquo; functionality in Google Analytics reports. Thanks to Stéphane Hamel and Phil Pearce for this tip.\n  2. The Trigger Create a new Trigger, and name it Event - History Fragment Change.\nChoose History Change as the Event, and set the following condition in the Fire On section of the Trigger:\nHistory Source equals popstate\n  We\u0026rsquo;re using popstate as a condition, because we don\u0026rsquo;t want this Trigger to go off on other instances where the History Change Trigger can fire. If you don\u0026rsquo;t have an AJAX or a single-page site, you wouldn\u0026rsquo;t have to worry about this, but this is a nice way of delimiting a rather generic Trigger to only fire in relevant situations.\n3. The Tag Finally, take your regular Page View Tag, and add the Trigger from (3) to it. This means that the Page View Tag will now have multiple Triggers. Most likely, you\u0026rsquo;ve used the All Pages Trigger, so now the Tag will fire both when All Pages matches and when a browser history event is detected.\nNext, scroll down to More Settings -\u0026gt; Fields To Set. Add a new field, name it page, and set its value to {{get path with fragment}}.\n  Save the Tag and start testing.\nHow it works When the page loads, the All Pages Trigger fires your Page View Tag. At this point, GTM will look at the page field and find the {{get path with fragment}} Variable there. It proceeds to execute the JavaScript within. However, the one-liner JavaScript only works if the value of the {{Event}} Variable is gtm.historyChange, which is not the case when the All Pages Trigger fires ({{Event}} is gtm.js in that case). So, the Variable returns undefined, which ensures that the regular Document Path is sent with the Tag instead.\nWhen someone clicks on a link which only has an anchor in the href, such as \u0026lt;a href=\u0026quot;#contact-us\u0026quot;\u0026gt;Contact Us\u0026lt;/a\u0026gt;, the browser dispatches the history change event, and it\u0026rsquo;s picked up by the History Change Trigger you created. This causes the Page View Tag to fire again.\nThis time, as GTM executes the JavaScript code again, the value of {{Event}} resolves to gtm.historyChange, and the Variable returns a string where the URL path of the page, e.g. /home/, is concatenated with the fragment text #contact-us, resulting in /home/#contact-us.\nThings to keep in mind If your site is an AJAX or single-page site, there might be other cases where popstate is dispatched. If this is the situation, you will need to add an additional check into the Custom JavaScript Variable, which compares the Built-In Variables for New History Fragment and Old History Fragment. If they are the same, then it means that the fragment didn\u0026rsquo;t change and popstate was dispatched for some other reason. In this case, the Variable needs to return undefined as well.\nYou might want to edit the Custom JavaScript Variable to check for the URL fragment when the page is loaded as well, so that direct visits to a URL fragment will be recorded accordingly in Google Analytics. This would require something like the following:\nfunction() { return ({{Event}} === \u0026#39;gtm.js\u0026#39; || {{Event}} === \u0026#39;gtm.historyChange\u0026#39;) \u0026amp;\u0026amp; {{New History Fragment}} ? {{Page Path}} + \u0026#39;#\u0026#39; + {{New History Fragment}} : undefined; }  Let me know if you have other issues with this solution. For most use cases, this should work just fine.\nUPDATE The solution above has some problems. First, it doesn\u0026rsquo;t include a possible query string in the returned path. Also, if the page is loaded, i.e. there\u0026rsquo;s no history change, the hash isn\u0026rsquo;t included in the returned path.\nSo, a huge simplification is called for. The {{get path with fragment}} should actually look like this:\nfunction() { return window.location.pathname + window.location.search + window.location.hash; }  Then you can just have your Page View Tag fire on both a Page View Trigger as well as the History Change Trigger. This Variable, once added to the page field, will return the path, the query string (if there is one) and the URL hash (if there is one).\nSometimes I think of way too complicated solutions for simple problems :-)\n"
},
{
	"uri": "https://www.simoahava.com/analytics/the-schema-conspiracy/",
	"title": "The Schema Conspiracy",
	"tags": ["google analytics", "metrics", "schema", "sessions"],
	"description": "There are some problems with Google Analytics&#39; sessionization schema. I outline them in this article.",
	"content": " A schema is something that data processing platforms such as Google Analytics apply to the raw hit data coming in from the data source (usually a website). The most visible aspect of Google Analytics\u0026rsquo; schema is how it groups, or stitches, the arbitrary, hit-level data coming in from the website into discrete sessions, and these are actually grouped under yet another aggregate bucket: users.\nBut you already know this. You\u0026rsquo;re looking at metrics like Sessions, Bounce Rate, Conversion Rate, and you\u0026rsquo;re using them or variations of them as KPIs in your dashboards and whatnot. Right?\nTake a look at the group of metrics below:\n  These are some of the go-to metrics people use to assign meaning to the data stream coming in from the website. The thing about these metrics is that they are very heavily sessionized. They are entirely dependent on an arbitrary schema, which many fail to understand or to even question. Change the definition of a session even a little, and every single one of these metrics will have a different value.\nAnd herein lies the problem I now dub the Schema Conspiracy. I know, I know, it\u0026rsquo;s a tad dramatic. But the implications are dramatic as well.\nWhen you use Google Analytics, or any schema-applying data processing platform, you are subscribing to the schema imposed by the platform. You don\u0026rsquo;t have a say in it. In GA, you can make minor changes to the definition of a session, using tools like Session timeout and Referral Exclusion List, but the fact remains that the schema for sessions in Google Analytics remains universal, generic, and completely arbitrary; three qualities that should not exist when using data to optimize for business growth.\n  In Google Analytics, a session can be defined roughly as an uninterrupted browsing experience, which expires after 30 minutes of inactivity. So you enter a website, do stuff there, and 30 minutes after the last interaction the session expires. Naturally, it\u0026rsquo;s more complex than this, but as a rough description this should suffice.\nFurther reading: How a session is defined in Analytics\nNow ask yourself this: how does this mirror anything that happens in the real world? Not really, right? Shouldn\u0026rsquo;t the concept of a session be grounded in something less ephemeral than a completely arbitrary sequence of hits on the website, combined with a strange, inexplicable 30 minute timeout?\nYou might not see the relevance of any of this, and you might be completely satisfied with Google Analytics\u0026rsquo; concept of a session, and you are, of course, entitled to this.\nBut consider Conversion Rate, for example. Conversion Rate is the ratio of sessions with a conversion to all sessions. Sessions, sessions, sessions. If you\u0026rsquo;re using Conversion Rate as a KPI, you must realize you\u0026rsquo;re optimizing against a completely fictitious metric.\nThink of it like this. You might need 14 sessions to convert when buying a new boat. You might need only 6 sessions to convert when buying a new computer. But in the end you\u0026rsquo;re still just one user that converted, regardless of the number of sessions it took to do so. The key here is that you had a singular intent: to buy a boat or a new computer. This intent spanned a number of sessions, highlighting the disconnect between sessions and behavior even more.\n  I think this is very problematic indeed. Companies optimize against a metric that is very superficial and ephemeral, and completely unrelated to the intent of the visitor. You shouldn\u0026rsquo;t be interested in the number of sessions that converted, you should be interested in increasing the number of customers you have, by understanding intent and nurturing it into a purchase.\nNow, I\u0026rsquo;m cynical enough to see the justification for this arbitrary sessionization: granularity of attribution. That\u0026rsquo;s why a change in campaign source initiates a new session, even if the session hasn\u0026rsquo;t expired yet. Your advertising channels need the attribution for successful conversions, which is why this sessionization logic has been honed to give a nice, big, fat number for your acquisition metrics.\nDon\u0026rsquo;t get me wrong, I think it\u0026rsquo;s valuable to see all the channels that turned a non-converted user into a new customer. But the reality is that sessions don\u0026rsquo;t convert, users do. Attribution, too, should be balanced between the touch-points that led me to fulfil some intent I had. Following an ad starts a new session on the website, but my intent might be the same as before. The ad might have made the intent more targeted, more specific, but I\u0026rsquo;m still very much a single user on the path to conversion.\nOvercoming the problem at hand You\u0026rsquo;re pretty much out of luck if you want to apply your own schema to your Google Analytics data. Even though Google Analytics Premium boasts hit-level data through BigQuery, it\u0026rsquo;s still sessionized. The data tables stitch the hit-level data into sessions before you can access the data. This, I think, sucks big time.\n(UPDATE: Check Carmen Mardiros\u0026rsquo; comment and Pedro Avila\u0026rsquo;s comment in the comments of this article for workarounds to getting hit-level data through the API and BigQuery.)\nI get why the UI shows a sessionized data set, as applying your own, complex sessionization schema would require an astounding amount of processing power. But why not provide raw data through the API?\nSo, there\u0026rsquo;s nothing you can do with GA\u0026rsquo;s schema. That\u0026rsquo;s just how it is. You can\u0026rsquo;t even see proper user-level data, either, since that\u0026rsquo;s sessionized as well. Consider the following Custom Segment:\n  It looks like it should show data for all users that have converted at some point in the past, right? Right. And wrong.\nThe segment above shows me a cohort of users who have converted during the selected timeframe. But that\u0026rsquo;s not what I should be interested in. I should be able to segment between converted and not-converted visitors, regardless of the timeframe!\nNo, a user-scoped Custom Dimension won\u0026rsquo;t help either, as if I\u0026rsquo;m looking at a timeframe before the user converted, it will show me the user as a non-converter.\nThings like this drive me crazy. If I had access to raw, hit-level data, and if I could build my own stitching schema on top of that, I would be able to bend the processing and reporting aspects of GA to my will, improving the quality of data for my business alone. That\u0026rsquo;s what my dashboards should be showing! That\u0026rsquo;s what should be driving my business!\nFinal thoughts So what is a perfect schema? There\u0026rsquo;s no such thing. Just as each business is different, each schema should be different as well.\nOptimally, the schema should be a living thing, constantly in flux, because your visitors are living things, constantly in flux. An intelligent schema would mirror this, perhaps even learning autonomously along the way.\nOptimally, the schema wouldn\u0026rsquo;t be satisfied with just your website data. Your visitors are multi-dimensional, so the schema should be multi-dimensional as well.\nOptimally, the schema would let you optimize against metrics that are relevant for your business, and for your business alone. Your visitors are your business, so the schema should be optimized against visitors as well.\nFinally, the schema used by Google Analytics is perfectly fine. Just don\u0026rsquo;t interpret it as something it\u0026rsquo;s not. Google Analytics\u0026rsquo; sessionization does not reflect the real world, the Conversion Rate metric should not be an indicator of the state of your business, and completely sessionized metrics like Bounce Rate, Session Duration, etc. should never be used as KPIs alone.\nUsing a single, sessionized, flawed metric as a KPI is like only telling the punchline of a joke.\nFurther reading: Avinash Kaushik - Excellent Analytics Tip #26: Every Critical Metric Should Have A BFF!\nThere are tools out there that bridge the gap between Business Intelligence and web analytics. They let you build the interpretations for your raw data in any way you choose. It does require effort, however. A custom schema requires that you understand your audience behavior on a completely new level.\nFurther reading: Snowplow Analytics\nDo you agree with me? Or do you think I\u0026rsquo;m making mountains out of molehills? I\u0026rsquo;m not advocating for an upheaval of how these tools work, but I am campaigning very strongly for critical thinking.\nSo, the next time you use Google Analytics\u0026rsquo; Conversion Rate metric for anything, just pause for a second and think about what this metric means for your business. Try to come up with a sentence like: \u0026ldquo;The uplift we\u0026rsquo;re seeing in Conversion Rate means our business is\u0026hellip;\u0026rdquo; and then finish with what the change in Conversion Rate means for your business.\nYou might find it\u0026rsquo;s quite difficult.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/add-the-event-key-to-datalayer-pushes/",
	"title": "#GTMtips: Add The &#34;event&#34; Key To dataLayer Pushes",
	"tags": ["events", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "Quick Google Tag Manager tip for adding the event key to all dataLayer push commands.",
	"content": " In Google Tag Manager, every single Tag requires a Trigger to fire. Every single Trigger requires an Event condition to activate. Sometimes, these Event conditions are obfuscated under template semantics, but you can also create a Custom Event Trigger, where you specify the value of the \u0026lsquo;event\u0026rsquo; key in dataLayer that fires your tag. You can read more about the relationship between GTM events and Tags in these two posts:\n #GTMtips: Rules In A Nutshell\n Trigger Guide For Google Tag Manager\n  The key takeaway is that only an \u0026lsquo;event\u0026rsquo; key push into dataLayer has the power to fire a Tag. So, the tip of this post is to (always) include the \u0026lsquo;event\u0026rsquo; key when you use the push() method of dataLayer.\nTip 17: Add the \u0026lsquo;event\u0026rsquo; key to your dataLayer pushes   Now, the reason I suggested to always have the key in each dataLayer.push() is because there\u0026rsquo;s no way to fire your Tags if there\u0026rsquo;s no \u0026lsquo;event\u0026rsquo; key present. In Enhanced Ecommerce, for example, this is critical. Each push() into the dataLayer with an Enhanced Ecommerce payload exists only until the next Enhanced Ecommerce payload push(). If you don\u0026rsquo;t have a Tag firing with an Enhanced Ecommerce push, you will not be able to access this particular state of dataLayer later, if you\u0026rsquo;ve already managed to push another \u0026lsquo;ecommerce\u0026rsquo; object. To put it into perspective, take a look at the following code:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;impressions\u0026#39; : [{ \u0026#39;name\u0026#39; : \u0026#39;product1\u0026#39;, \u0026#39;id\u0026#39; : \u0026#39;12345\u0026#39; }] } }); // Some code dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;impressions\u0026#39; : [{ \u0026#39;product2\u0026#39;, \u0026#39;id\u0026#39; : \u0026#39;23456\u0026#39; }] }, \u0026#39;event\u0026#39; : \u0026#39;impressionsPushed\u0026#39; });  So you might think that having a Tag fire when Event equals impressionsPushed would send both impression objects (product1 and product2) to GA, but you\u0026rsquo;re wrong. Only the second push is processed. That\u0026rsquo;s why it\u0026rsquo;s important to have an \u0026lsquo;event\u0026rsquo; key in the first push as well. Or, it would be even better to combine these into a single push, but there might always be technical reasons why this isn\u0026rsquo;t possible.\nSo that\u0026rsquo;s key takeaway 1:\nAn \u0026lsquo;event\u0026rsquo; key in a push ensures that you can access the state of dataLayer at the time of the push in your tags.\nThe second thing I want to show you might be surprising to some. You can actually add the \u0026lsquo;event\u0026rsquo; key to pre-container-snippet pushes as well! This means that you can have Tags fire before the Pageview event, i.e. gtm.js.\nThis is because GTM processes the past states of dataLayer as well, which have been defined before the container snippet started to process the data structure.\nIf you take a look at the #GTMtips picture for this post, you can see an example of this. I have a dataLayer.push() before the container snippet, and it also includes the \u0026lsquo;event\u0026rsquo; key with value loggedIn.\nAs you can see in the debug panel, this Event is processed before the Pageview event in the message bus, meaning that the execution of any Tags that have Event equals loggedIn as their Trigger would start before Tags that fire on the All Pages Trigger, for example.\nSo, key takeaway 2: Pre-container-snippet \u0026lsquo;event\u0026rsquo; pushes can fire Tags before the Pageview Event.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/matches-css-selector-operator-in-gtm-triggers/",
	"title": "&#34;Matches CSS Selector&#34; Operator In GTM Triggers",
	"tags": ["auto-event tracking", "Google Tag Manager", "Guide", "triggers"],
	"description": "How the Matches CSS Selector operator works in Google Tag Manager triggers.",
	"content": " Be honest, can you think of anything that\u0026rsquo;s more unfair than this:\n  A new Google Tag Manager feature, published at 02:07 AM my time, and with an easter egg hunt involved?! Of course it was the infuriating Charles Farina who found the new feature and claimed the prize. Curses! (Just kidding Charles, you\u0026rsquo;re still awesome.)\n  Anyway, there\u0026rsquo;s a new GTM feature in town, and oh boy, this time it\u0026rsquo;s a big\u0026rsquo;un! Without further ado, allow me to introduce a new Trigger operator - the matches CSS selector:\n  It\u0026rsquo;s modus operandi is quite simple. You create a Trigger condition, where an HTML element is checked against a CSS selector. If the CSS selector applies to the HTML element, the condition passes.\nCSS selectors and GTM CSS selectors are patterns that you check for in any given HTML element. Traditionally, CSS selectors have been used to modify styles of the given elements. Nowadays, we can actually use them to target HTML elements for other purposes as well, especially since frameworks such as jQuery, which target elements using CSS selectors, have become ubiquitous. There are also the vanilla JavaScript querySelector(), querySelectorAll() and matches() DOM methods that allow you to pick elements based on CSS selectors.\nFor a nice list of currently supported CSS3 selectors, check out the W3Schools guide: CSS Selector Reference.\nHere are some CSS selectors you might find very useful. These are all auto-event tracking related, because the possibilities of auto-event tracking just opened up in a completely new way with the introduction of this new Trigger operator.\n  Instead of targeting Click ID or Form Class, you must now always provide an HTML element to the Trigger condition. So, you\u0026rsquo;ll need to use Click Element or Form Element (they\u0026rsquo;re the same thing) to pattern-match against your auto-event target element.\n   Selector Description     .thisclass Matches if element has class “thisclass”   .thisclass.thatclass Matches if element has class “thisclass” and class “thatclass”   #thisid Matches if element has ID “thisid”   #main .navlink Matches if element has class “navlink” and is a descendant of an element with the ID “main”   div#main \u0026gt; .navlink Matches if element has class “navlink” and is the direct child of a DIV element with the ID “main”   :checked Matches if element is checked (radio button or checkbox)   [data-title*=\u0026ldquo;chairman mao\u0026rdquo;] Matches if element has attribute “data-title” with the string “chairman mao” somewhere in its value   a[href$=\u0026ldquo;.pdf\u0026rdquo;] Matches if element is a link (A) with a HREF attribute that ends with “.pdf”   .contactmail:only-child Matches if element has class “contactmail” and is the only child of its parent    As you can see, you can do pretty creative stuff with it. The most significant asset is, by far, the chance to see ancestral relationships. You can now check if the element that was clicked or submitted is the child or direct descendant of any given element. What an ingenious way to fire tags only on clicks under the main navigation, for example!\nRemember that you can add multiple selectors just as with CSS by using a comma between the selectors:\nClick Element - matches CSS selector - video,video *\nThis condition would match clicks on a HTML5 \u0026lt;video\u0026gt; element or any of its descendants.\nYou\u0026rsquo;re limited by CSS3, mainly. You can\u0026rsquo;t do descendant checks, so you can\u0026rsquo;t have a CSS selector which only matches an element if it has a specific element as its child. You\u0026rsquo;ll still need JavaScript for this, unfortunately.\nLuckily, CSS4 is already pretty far in its draft stages. It brings a slew of amazing new features, which will only make this CSS selector Trigger even more powerful.\nTechnical details Just to wrap this post up, here\u0026rsquo;s a technical description of the new operator (thanks Brian Kuhn!). There\u0026rsquo;s nothing revolutionary about it, proving how GTM still leverages well-founded practices rather than inventing the wheel again each time.\nThe operator uses the matches() method with variations depending on which browser you\u0026rsquo;re using. The matches() method lets you check if a given element matches against a CSS selector:\nelement.matches(\u0026#39;.thisclass\u0026#39;);  The code above would evaluate to true if the given element has the class \u0026ldquo;thisclass\u0026rdquo;.\nmatches() isn\u0026rsquo;t supported by all browsers, and e.g. Internet Explorer only supports it at version 9.0. For antiquated browsers, GTM falls back to checking each node that matches a given selector, and it returns true if the given element is among these nodes.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/leverage-usebeacon-beforeunload-google-analytics/",
	"title": "Leverage useBeacon And beforeunload In Google Analytics",
	"tags": ["fields to set", "Google Tag Manager", "Guide", "JavaScript"],
	"description": "Leverage useBeacon and beforeunload to fire Google Tag Manager events to Google Analytics just as the user is about to leave the page or close the browser.",
	"content": " This nifty little solution will let you calculate the time spent on pages that are not tracked in Google Analytics by default. These include both bounced landing pages and exit pages. Bounced pages and exit pages lack the necessary subsequent pageview, which Google Analytics uses to calculate time-based metrics.\nBefore you go on, read this excellent article by Yehoshua Coren:\nREAL Time On Page in Google Analytics\nYehoshua gives a very nice use case for the technical solution I\u0026rsquo;m about to explore. He also leverages the Page Visibility API to get an even more accurate overview of visitors who actually digest content, and how much of that time that content is visible on their screens. Fundamental stuff, read it!\nSo what we\u0026rsquo;re actually doing here is this:\n On each page, use the default gtm.start Data Layer Variable to calculate the time when the document has started loading\n When the user decides to leave the page, either by closing the browser or navigating to another page, first calculate the time when the beforeunload event is dispatched. Then, use the sendBeacon() API to send a User Timing hit to Google Analytics without having to worry about the unload process cutting the request short.\n  Hopefully, you\u0026rsquo;ll end up with data like this:\n  Here you can see the User Timings recorded for pageviews of bounced sessions.\nHere\u0026rsquo;s another report:\n  In this report, you can view Exit Pages with the time spent on each page as a secondary dimension.\nNaturally, this data would be far more useful when extracted out of the GA interface into a spreadsheet, where you can actually make calculations with the Custom Dimension values, for example. Hopefully, at some point, we\u0026rsquo;ll have the possibility to calculate our own Custom Metrics, at which point it will make more sense to send this information as a metric instead. Also, read Yehoshua\u0026rsquo;s article I linked to in the beginning of the post. He uses Custom Metrics, which makes actually a lot more sense if you want to extract the data.\nNevertheless, until such a time that we can calculate on metrics, this is a useful method for obtaining a more accurate time on page across your sessions (so also for bounces and exit pages).\nTo get it working, you\u0026rsquo;ll need the following components:\n New Custom Dimension, session-scoped, to capture this information in GA\n Data Layer Variable to capture the value for gtm.start\n Data Layer Variable to store the time on page\n Custom HTML Tag, which sets the beforeunload listener and does the dataLayer.push() when the page unload begins.\n Timing Tag which uses the quite new useBeacon field available in Universal Analytics. This field is basically a helper for setting up the sendBeacon() request.\n  1. Custom Dimension Let\u0026rsquo;s start with the Custom Dimension. We\u0026rsquo;re using a session-scoped Custom Dimension for one simple reason: it will always have the last value sent during the session. This means that since we\u0026rsquo;re sending the custom time on page on every single pageview, the session-scoped Custom Dimension should always have the exit page time for the session! Once we have this in place, we can add the custom dimension as a secondary dimension in the Exit Page report, giving us the dwell time for exit pages only.\nNote that the session-scoped Custom Dimension fails if the user is inactive long enough for the session to expire (30 minutes by default). So it might actually be a good idea to modify the timing script to only allow values up to 1800000 milliseconds (30 minutes).\n  Make note of the index the new Custom Dimension gets. This is important when you\u0026rsquo;re setting up the Event Tag.\n2. Data Layer Variable for gtm.start The next step is to create the Data Layer Variable for gtm.start. You might wonder what this \u0026ldquo;gtm.start\u0026rdquo; is, but it\u0026rsquo;s actually a property in the very first dataLayer object pushed into the Array by GTM, when the container snippet starts loading:\n  The value for this variable is a timestamp in milliseconds of Epoch time. You don\u0026rsquo;t have to worry about what this means, since all we\u0026rsquo;re going to use this for is to calculate the difference between page unload time and gtm.start to get an approximation of how long the user spent on the page. The Data Layer Variable would look like this:\n  3. Data Layer Variable for timeonpage You\u0026rsquo;ll also need to create a Data Layer Variable for timeonpage, which is where we\u0026rsquo;ll store the time on page, pushed in the beforeunload callback. So create another Data Layer Variable that looks like this:\n  4. Custom HTML Tag The next step is our custom beforeunload listener. Create a new Custom HTML Tag, and set it to fire with the All Pages Trigger. Add the following code within:\n\u0026lt;script\u0026gt; window.addEventListener(\u0026#39;beforeunload\u0026#39;, function() { window.dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;unloadEvent\u0026#39;, \u0026#39;timeonpage\u0026#39; : new Date().getTime() - {{DLV - gtm.start}} }); }); \u0026lt;/script\u0026gt; This attaches the beforeunload listener to the global window object. When the unload process begins, i.e. when the user chooses to leave the page, the callback is invoked, and a dataLayer.push() is executed, with a custom \u0026lsquo;event\u0026rsquo; value and also a value for the \u0026lsquo;timeonpage\u0026rsquo; Variable we just created.\nThe time on page is calculated by getting the timestamp for the beforeunload event, and subtracting the gtm.start timestamp from it. The result is the time in milliseconds between these two events. If you want to have a safeguard for session expiration, cap this time at 1800000 milliseconds, which is 30 minutes.\nNow all we need is the Timing Tag, which sends the timeonpage value both as a Timing value and as a Custom Dimension value.\n5. User Timing Tag User Timing is a hit type that you can use to send your own timing events to Google Analytics. A common use case is to measure the load time of linked assets, such as huge, bloated JavaScript libraries (I\u0026rsquo;m looking at you, non-minified jQuery!).\nBut you can use User Timings for anything on the site that can be measured in milliseconds. So it works perfectly with page load time as well.\nBefore you create the Tag, you\u0026rsquo;ll need the Trigger that makes the Tag fire. The Trigger is simply a Custom Event Trigger, that fires with event name unloadEvent:\n  Next, create a new Google Analytics / Universal Analytics Tag, attach the Trigger you just created to it, and set the Tag fields to look something like this:\n  If you were to save this now and publish your container, the solution would be very unreliable. This is because the beforeunload event signals the browser to start the unload process, and the unload process is brutal. Any threads that are running once the browser reaches the unload stage are cut off, and all requests are cancelled. This is because the browser doesn\u0026rsquo;t want to let anything impede the user\u0026rsquo;s desire to leave the page.\nPerfectly understandable.\nIt is for this reason that we\u0026rsquo;ll leverage yet another little-known API: navigator.sendBeacon(). This API turns any request made in its scope into an asynchronous, uninterruptible call to whatever endpoint you choose. So, even if the browser window closes or you navigate from the site, the request is allowed to complete before the browser instance is unloaded from memory.\nGoogle Analytics were quick to react to this API, and they published their own shorthand for it: the useBeacon field. Read David Vallejo\u0026rsquo;s nice review about this new feature to get acquainted.\n!!! UPDATE !!! The useBeacon has been deprecated. Use the transport field name instead, and set its value to beacon. Read about the field here.\nAnyway, useBeacon turns the call into a POST request (instead of the usual GET), and passes it asynchronously to the GA endpoint using navigator.sendBeacon().\nTo add this feature to the User Timing Tag, add useBeacon as a Field To Set, and set its value to true.\nAlso, add the {{DLV - timeonpage}} as a Custom Dimension, using the index number you got from Step 1.\nSo now the More Settings of your User Timing Tag should look like this:\n  Save the Tag, Preview \u0026amp; Debug the Tag, and Publish when you\u0026rsquo;re ready.\nThen read the caveats below. Or actually, it would be good if you read these before you publish.\nCaveats There is actually only one major caveat here. navigator.sendBeacon() has horrible browser support. Like, dismal. Basically, Internet Explorer and Safari do not support it all. This is a big setback, as IE is one of the most popular desktop browsers, and Safari is among the most popular mobile browsers.\nThe thing is, you don\u0026rsquo;t really have to write any fallback functions for browsers that don\u0026rsquo;t support the API. The Universal Analytics library detects if navigator.sendBeacon() is supported, and if it isn\u0026rsquo;t, the hit is sent normally.\nDepending on your site, there\u0026rsquo;s still a good chance that the hit gets sent. This depends on how long it takes for the browser to unload your site.\nIf you want to play it safer, you could write your own click handler that intercepts external links, fires the Timing Tag, and only then lets the link redirect proceed. This would cover exits from your site to other sites nicely, but it wouldn\u0026rsquo;t help with the most interesting use case of people closing browser windows and tabs.\nThis is a problem we\u0026rsquo;ll just have to live with. However, as an eternal optimist, I see this as a solution that can only get better with time. Once navigator.sendBeacon() gets better support and once we get calculated Custom Metrics, this solution will be so awesome.\nRight now it\u0026rsquo;s more of a prototype, but as Yehoshua shows you, it can already have very interesting analytics applications.\nWell, I\u0026rsquo;d be remiss if I didn\u0026rsquo;t mention one other, small caveat. Triggering code on beforeunload invalidates the back-forward cache (BFCache) in Firefox. This means that the page state of the page is no longer cached, and if you\u0026rsquo;re trusting e.g. form field values to this cache, you\u0026rsquo;ll need to make adjustments.\nSummary In this quite simple solution we\u0026rsquo;re leveraging some pretty cool APIs again. The point is partly to give you a tool to get better data out of Google Analytics, but at the same time we\u0026rsquo;re doing what I love best: using JavaScript and Google Tag Manager to get data from unexpected places.\nAs I say in the previous chapter, this solution will only get better with time.\nHopefully, once navigator.sendBeacon() get better browser support, it will become the default request mechanism for all Google Analytics hits. It just makes so much sense. Also, it means that you won\u0026rsquo;t need to protect your tags with setTimeout() calls or the Wait For Tags method in Google Tag Manager.\nBut from the look of things, this is still a long way off.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/setting-google-analytics-fields-in-gtm/",
	"title": "#GTMtips: Setting Google Analytics Fields In GTM",
	"tags": ["Google Tag Manager", "gtmtips", "universal analytics"],
	"description": "How to set Google Analytics tracker fields using Google Tag Manager.",
	"content": " Due to a recent change in the UI (see entry for February 12, 2015 in the release notes), the large and ever-expanding group of fields you could set for your Universal Analytics tags has been mostly removed. Instead, the often obscure Fields to Set selection has been promoted to the top of More Settings, and you control most of the Universal Analytics fields through this selector.\nIn this #GTMtips, we\u0026rsquo;ll take a quick look at what\u0026rsquo;s changed, how it\u0026rsquo;s changed, and how to work with this new, slimmed-down tag template.\nTip 16: How To Set Google Analytics Fields In GTM   First, some justification for this bold move. The Universal Analytics JavaScript library, analytics.js, has a lot of fields you can set. If just a few of these fields are represented with their dedicated drop-downs in the Tag settings, it would mean that your container would be artificially bloated. We\u0026rsquo;re working with JavaScript, remember. Less is more.\nDemoting all settings to Fields to Set is a democratic move, giving you, the user, full rights to choose which fields to include in the Tag, and more importantly, the right to exclude all the fields you do not need to use.\nThe major change is thus that all relevant Universal Analytics fields should from now on be set through Fields to Set. The fields can be found in the drop-down menu for Field Name. You can add any field name you want (naturally, only valid field names actually work), you can get the field name from a Variable, or you can use the helpful auto-complete to find the correct field.\n  How do you know what fields to add, you ask? Well, browse over to Analytics.js Field Reference for the full list. Remember, be wise in your selection. There\u0026rsquo;s no point in adding the field for eventCategory in a Page View Tag.\nI respect the fact that for many this might mean a downgrade of the user experience. After all, you\u0026rsquo;re left with a less obvious interface. However, I\u0026rsquo;m courageous enough to argue that you only use a handful of fields anyway, and if you know your Universal Analytics, you\u0026rsquo;ll already know what their field names are. Also, checking the Field Reference is not such a huge effort.\nAn improvement would be that the drop-down list would also enable you to quickly check what the field you selected actually is (e.g. the \u0026ldquo;proper name\u0026rdquo;). This would save you the trouble of going to the Field Reference.\n"
},
{
	"uri": "https://www.simoahava.com/seo/dynamically-added-meta-data-indexed-google-crawlers/",
	"title": "Dynamically Added Meta Data Indexed By Google Crawlers",
	"tags": ["Google Tag Manager", "meta description", "SEO", "serp"],
	"description": "You can add meta HTML tags to your website using Google Tag Manager, and Google&#39;s search crawlers will crawl and index them.",
	"content": " Quick history. On May 23, 2014, the following announcement was made on the Google Webmaster Central Blog:\nIn order to solve this problem, we decided to try to understand pages by executing JavaScript. It's hard to do that at the scale of the current web, but we decided that it's worth it. We have been gradually improving how we do this for some time. In the past few months, our indexing system has been rendering a substantial number of web pages more like an average user's browser with JavaScript turned on. Read the full announcement here.\nAnyway, since I see the world through GTM-tinted shades, I instantly figured that this should extend to not only the presentational layer, but to semantic information as well. At the time, I was thinking in terms of the Search Engine Results Page (SERP) and the Meta Description, which prompted me to ask the following in Google+ from Gary Illyes, who made the announcement:\n  As you can see, I didn\u0026rsquo;t get a direct answer, so I decided to run some tests. I created some test pages, and used Google Tag Manager to inject a Meta Description with a simple Custom HTML Tag (that fired on the test page only):\n\u0026lt;script\u0026gt; var m = document.createElement(\u0026#39;meta\u0026#39;); m.name = \u0026#39;description\u0026#39;; m.content = \u0026#39;This tutorial has some helpful information for you, if you want to track how many hits come from browsers where JavaScript has been disabled.\u0026#39;; document.head.appendChild(m); \u0026lt;/script\u0026gt; This simple tag creates a new \u0026lt;meta name=\u0026quot;description\u0026quot; content=\u0026quot;This tutorial...\u0026quot;\u0026gt; tag and adds it as the last child of the head HTML element.\nSo I published the test pages, had Google crawl them and ended up with\u0026hellip;failure. For some reason, it didn\u0026rsquo;t work and I left it be, evangelizing to people to keep on adding the Meta Data directly in the page template.\nThen, at SuperWeek Hungary this January, I had the pleasure of meeting Gary Illyes in person, and I relayed to him my test results. To add some additional context, I had just tested successfully and written about injecting structured data JSON-LD through GTM. Anyway, Gary was adamant that the crawlers should understand injected meta tags, so I ran another series of tests.\nAgain, failure. But being your typical Finn, I refused to give up. So I ran three more tests.\nTest 1: Pure Test Page The first test I did was for a new page using my blog template, which had basically no content. Its title was \u0026ldquo;Test page\u0026rdquo; and the Meta Description was injected. After creating the page and setting up the tag in GTM, I published the page and asked Google to crawl the page via Webmaster Tools.\nHowever, the SERP refused to show the injected Meta Description. After asking about it, I was told that sometimes the crawlers index a page before rendering the JavaScript, and that I should make a dramatic change to the page to force Google to recrawl it.\nI added a lot of text and some images, but nothing changed so I abandoned the test as a failure.\nTest 2: Real Content The next test I ran was against real content. I had just written a blog post, and I decided to publish it with an injected Meta Description. This time, I was sure that the crawlers would render the Meta Description, as this was a real page with valuable content, and the Meta Description reflected this content very well.\nThis test was\u0026hellip;a failure. This time, I was told that sometimes Google\u0026rsquo;s crawlers decide not to render the JavaScript version. The justification was that pages with heavy JavaScript would create an enormous load for Google\u0026rsquo;s crawlers to work with, which is why they might not render the JavaScript at all in favour of sparing resources.\nInteresting reasoning. This means that the crawlers are not just going to take all the JavaScript you feed them with, but rather they still have an internal decision-making mechanism to determine whether or not to render the dynamic content.\nTest 3: Real-like Content, Little JavaScript I created a dummy page with real content and an actual call-to-action:\n  As you can see, I\u0026rsquo;ve pulled all my CRO chops in creating this page. Do NOT comment on how it looks, it\u0026rsquo;s just a test!\nAnyway, on this page I injected the Meta Description again, asked Google to crawl it and the test was\u0026hellip;A SUCCESS:\n  The Meta Description in the SERP result above has been injected with Google Tag Manager. So it IS true:\nGoogle\u0026rsquo;s crawlers index dynamically injected meta data as well.\nSorry if this was a no-brainer to you - but I had so many unsuccessful tests behind me that I wanted to be sure.\nImplications First of all, as you can probably see from my tests, this isn\u0026rsquo;t a 100 % sure method. So don\u0026rsquo;t delegate the creation and deployment of Meta tags to Google Tag Manager or any other dynamic, client-side solution. The best way is still to add Meta tags to the page template.\nHowever, this does open up a world of possibilities for single-page apps, for example. Instead of using a complicated setup of hashbangs and server-side responses, it just might be possible to serve Meta tags purely with JavaScript in the future. Right now I don\u0026rsquo;t think it\u0026rsquo;s robust enough to trust your entire app logic with, but in the future, who knows.\nThe incredibly interesting and reassuring thing here is that Google\u0026rsquo;s crawlers are really taking dynamic web pages seriously. This is a huge step in building an actual representation of the web, instead of just crawling source code that might have very little to do with what visitors to your website actually experience and find relevant.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-non-javascript-visits-google-analytics/",
	"title": "Track Non-JavaScript Visits In Google Analytics",
	"tags": ["Google Tag Manager", "JavaScript", "Google Analytics"],
	"description": "How to collect data from users who do not have JavaScript enabled in their browser. You can use Google Tag Manager to collect this information to Google Analytics.",
	"content": " One of the big mysteries in browser-based data collection platforms like Google Analytics is what happens when the visitor is not being tracked. This is most obvious in cases where the user explicitly opts out of tracking, when the user does not have JavaScript active in their browser, in bounced sessions, and on exit pages.\nOpt-outing means that the user explicitly prohibits a website from tracking them. In some cases, it\u0026rsquo;s possible that opt-out is the default, and the user must explicitly opt-in to allow GA to record their visits. In this article, I will of course not give you ideas how to circumvent this, as you must respect the user\u0026rsquo;s wishes.\nBrowsing with JavaScript disabled is surprisingly common, even though it makes a large part of the web unusable. If you disable JavaScript in your browser, the browser will no longer be able to run script blocks or arbitrary JavaScript functions. DOM methods still work, for example, but you won\u0026rsquo;t be able to use persistent storage such as cookies in your GTM container.\n  Bounced sessions and exit pages are problematic, since certain metrics such as Time on Page can only be calculated with two pageviews. This means that bounced sessions, which have a maximum of one pageview, will not be able to tell you how much time a visitor spent on your site. Similarly, an exit page does not have a subsequent pageview, which means that time on page is lost for these as well.\nI\u0026rsquo;ve got two use cases I want to explore. Because I want to keep things short(er than usual), I\u0026rsquo;ve split this into two articles. The first one, this, concerns sending pageview hits from browsers with JavaScript disabled.\nThe second article (read it here) covers using User Timings to capture time on page for bounced sessions and exit pages.\nI\u0026rsquo;m implementing both use cases using Google Tag Manager. As usual, these articles aren\u0026rsquo;t just about tackling specific GA use cases. They\u0026rsquo;re also about introducing cool JavaScript APIs and lesser-known Google Analytics features to the non-developer public.\nCollect pageviews from non-JS browsers To collect pageviews from browsers where JavaScript has been disabled, we\u0026rsquo;ll need to leverage a number of advanced features of both Google Tag Manager and Google Analytics. The steps we\u0026rsquo;re going to take are these:\n Add a dataLayer key-value pair into the iframe of the noscript element in the GTM container snippet.\n Use a Custom Image Tag to fire a Measurement Protocol pixel when this dataLayer key-value pair is detected.\n Filter these MP hits into their own Google Analytics profile.\n  (NOTE: The point of this solution is to show how the iframe can be used to leverage the Data Layer Variable in GTM. There\u0026rsquo;s actually a much more elegant way to check if the user doesn\u0026rsquo;t have JavaScript enabled in their browsers. Check Duncan\u0026rsquo;s comment below for the solution!)\nThis means that when a browser that\u0026rsquo;s disabled JavaScript enters the site, the noscript tag is executed, and the dataLayer key-value pair causes the Custom Image Tag to fire. This tag is a pageview hit to the Universal Analytics endpoint using Measurement Protocol. This way you can collect data from visitors who have JavaScript disabled!\n1. Edit the container snippet So, the first thing you need to do is edit the container snippet. When a browser without JavaScript tries to render the container snippet, it will not execute any of the code within the script element. Instead, it finds the noscript block, and renders the contained HTML code.\nGoogle Tag Manager loads an iframe, which is tailored to your container. By passing key-value pairs as query parameters to this iframe, you add data into the internal data model of Google Tag Manager, and it can be used by the Data Layer Variable even on browsers without JavaScript enabled.\nSo, in this use case, I want to send a key-value pair to Google Tag Manager, which I can then use as a Trigger condition to fire a Tag only for browsers which render the iframe. As you can see below, I\u0026rsquo;m sending nojscript=true to GTM. This is the non-JavaScript equivalent of dataLayer.push({'nojscript' : 'true'});\n  2. Data Layer Variable for nojscript Next, we\u0026rsquo;ll need a Data Layer Variable that accesses this key-value pair, and a Custom Event Trigger which fires the tag when nojscript=true is found in the data model.\n  This Data Layer Variable will retrieve the value of the key nojscript from the data model if such a key exists.\n3. Custom Event Trigger The Trigger which fires the Tag when nojscript=true looks like this:\n  As you can see, the Event for the Trigger is still gtm.js. This is the equivalent of the \u0026ldquo;All Pages\u0026rdquo; Trigger. However, you need to specify a new condition, which demands that the Data Layer Variable for nojscript resolve to true.\nSo, quick recap. Now we\u0026rsquo;ve modified the container snippet to push nojscript=true into Google Tag Manager\u0026rsquo;s data model when the user\u0026rsquo;s browser does not have JavaScript enabled. Then, we have a Data Layer Variable which picks up this information from the data model. Finally, we have a Trigger which fires any Tag it is attached to, when the value of nojscript is true.\n4. Custom Image Tag Now, we need the Tag itself. Create a new Custom Image Tag:\n  Use the Trigger you just created as the only Trigger for this Tag.\nCustom Image Tags are still supported even if the visitor\u0026rsquo;s browser does not use JavaScript. This is because the special iframe document that is loaded in the noscript can still render normal HTML tags, which an img very much is.\nThe URL of the img tag is a Measurement Protocol pixel call. If you know your Universal Analytics, you\u0026rsquo;ll know that every single hit from your web properties uses the Measurement Protocol, since it\u0026rsquo;s basically just a pixel that is loaded from the URL https://www.google-analytics.com/collect. All the fields and settings for each hit are provided as parameters to this call. So, this is what the Measurement Protocol hit for the Custom Image Tag would look like:\nhttps://www.google-analytics.com/collect?v=1\u0026amp;t=pageview\u0026amp;dl={{Page URL}}\u0026amp;dt=No%20JavaScript\u0026amp;cid={{Random Number}}\u0026amp;tid=UA-XXXXXXX-X\u0026amp;gtm=GTM-XXXX\nThis sends a very simple pageview hit with no extra parameters or dimensions. The Document Location, which GA uses to parse the page path from, is taken from the {{Page URL}} Built-In Variable, the Document Title of the page is \u0026ldquo;No JavaScript\u0026rdquo;, and the Client ID of the hit is a random number, generated by another Built-In Variable. Remember to substitute your own Google Analytics tracking code for the \u0026amp;tid= parameter. Also, if you want to mimic other GTM hits, add the \u0026amp;gtm= parameter with your container ID.\nAdd any other parameters you might like to. For the full list of available parameters, see this guide.\nI use \u0026ldquo;No JavaScript\u0026rdquo; as the page title because I use that to create the Include filter in Google Analytics:\n  Naturally, you\u0026rsquo;ll want to add a similar Exclude filter to your main reporting profiles.\nIn the Measurement Protocoll call, we can\u0026rsquo;t use a stored client ID in the hit, because cookies are inaccessible in browsers where JavaScript is disabled. This means that you will not be able to stitch hits together as sessions, or sessions as users. Each hit is a new session, essentially. This is why it won\u0026rsquo;t make sense to include these hits in your main reporting profile.\nThere are ways around this restriction. You\u0026rsquo;ll need to build a server-side script which takes the client ID from the _ga cookie sent with each GET request, and renders this as another URL parameter in the iframe URL in the GTM noscript snippet. However, this is way beyond the scope of this simple guide.\nOnce you publish this setup, you should end up with a profile in Google Analytics collecting pageview hits from all visitors who do not have JavaScript enabled in their browsers. You can use this data to get an idea of just how many hits you are actually missing because of these over-cautious visitors. You can also use the average for Pages / Session to get an estimate of how many sessions these hits comprise.\nSummary The idea behind this guide was to introduce the elusive noscript tag of the GTM container snippet. You can use it to push key-value pairs into Google Tag Manager\u0026rsquo;s data model, and you can then use this information to fire any Tags you want to reserve for users without JavaScript.\nIf you have marketing platforms that have specified a \u0026lt;noscript\u0026gt; alternative, you would use this solution to compile the image tag that\u0026rsquo;s usually provided as the JavaScript-less option.\nRemember to come back in a little time to read the next part of this guide: how to get an accurate time on page metric for bounced sessions and exit pages!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/track-file-downloads-in-gtm-v2/",
	"title": "#GTMtips: Track File Downloads In GTM V2",
	"tags": ["auto-event tracking", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "How to setup Google Analytics tracking for visitors who click file download links. Set up the method using Google Tag Manager.",
	"content": " In this #GTMtips post, we\u0026rsquo;ll go over a simple method for tracking file downloads in Google Tag Manager, specifically the new, V2 interface. Also, \u0026ldquo;tracking file downloads\u0026rdquo; means sending Events to Google Analytics, so this is a GA for GTM guide as well.\nTip 15: Set up file download tracking in GTM   Since we\u0026rsquo;re using Google Analytics as the tracking platform, we\u0026rsquo;ll need the following ingredients to make this setup work:\n Event Tag - which fires when a downloadable file link is clicked, and sends the Event to Google Analytics\n Auto-Event Variable for click URL path - to capture the URL path of the clicked link\n Event Trigger - which uses the Link Click trigger type and checks if URL path contains any of the extensions you want to track\n  So start with the Auto-Event Variable, and follow these steps:\n Create new Variable of type Auto-Event Variable\n Name it Click URL Path\n Choose Element URL as the Variable type\n Choose Path as the Component Type\n  I like this method, since using the Component Type \u0026ldquo;Path\u0026rdquo; strips the URL so that only the URI path remains. This means that query parameters, fragments, hostnames, protocols, and ports are all excluded from the string, leaving a much cleaner output.\nFor the Trigger, you need to create a Link Click trigger, where the Click URL Path is matched against a regular expression of all the file extensions you want to monitor. If the whole concept of Link Click tracking is unfamiliar to you, remember to check my guide on auto-event tracking.\n Create a new Trigger, and choose Click as the Event Type\n Name it Event - Link Click on downloadable\n Choose Link Click as the Trigger Type\n Select Wait for Tags and Check Validation if you wish\n If you selected either Wait for Tags or Check Validation, choose Page URL matches RegEx .* as a filter in the \u0026ldquo;Enable When\u0026rdquo; step of the Link Click Trigger creation\n For \u0026ldquo;Fire On\u0026rdquo;, add the following condition: Click URL Path matches RegEx .(ext1|ext2|ext3)$\n  It should look like this:\n  Couple of things to note here. First, if you select either \u0026ldquo;Wait for Tags\u0026rdquo; or \u0026ldquo;Check Validation\u0026rdquo; in the Link Click Trigger settings, you will have an extra step called \u0026ldquo;Enable When\u0026rdquo;. This step is for when GTM should listen for link clicks, so I suggest you put Page URL matches RegEx .* as the only condition.\nSecond, you will need to add the file extensions you want to track in the \u0026ldquo;Fire On\u0026rdquo; condition. For example, if I want to track all PDF, XLSX, PNG, and DOCX downloads on my site, the regular expression would look like this:\n.(pdf|xlsx|png|docx)$\nThis would match any Click URL Path which ends in .pdf, .xlsx, .png, or .docx.\nIf your site has file extensions in capital letters (PNG, XLSX), you\u0026rsquo;ll need to change the operator from matches RegEx to matches RegEx (ignore case).\nFinally, you\u0026rsquo;ll need the Tag itself. It\u0026rsquo;s just your run-of-the-mill Event Tag, and you need to attach the Trigger you just created to it.\nFeel free to be creative with what you add as the Event fields. I\u0026rsquo;ve used a simple Click URL Variable to get the entire URL of the clicked link, but you could do some macro magic and return just the filename or the file extension (see my macro magic article for instructions).\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/track-outbound-links-in-gtm-v2/",
	"title": "#GTMtips: Track Outbound Links In GTM V2",
	"tags": ["auto-event tracking", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "How to track links that lead out of your website in Google Analytics. Setup the tracking using Google Tag Manager.",
	"content": " Last updated: 6 March 2018.\nTracking outbound links is important for many. Identifying the exit paths is almost as important as tracking entrances. In this simple #GTMtips post, I\u0026rsquo;ll show you how to track outbound links with a simple Trigger + Auto-Event Variable combination in the new Google Tag Manager interface.\nFor more information about triggers, variables, and auto-event tracking, here are some of my previous articles on these topics:\n Auto-Event Tracking In GTM 2.0\n Variable Guide For Google Tag Manager\n Trigger Guide For Google Tag Manager\n  Setting up the Variable and the Trigger   Tracking outbound links hinges around two things: a Variable which captures the hostname of the clicked link, and a Trigger, which fires your Event Tag when the hostname is not your domain.\nTo set up the Variable, create a new Auto-Event Variable, and call it Click URL Hostname. You can choose whatever name you want, of course, but this mimics the pattern of the existing Built-In Variables.\nThe Variable should have the following settings:\nType: Auto-Event Variable\nVariable Type: Element URL\nComponent Type: Host Name\nIf you want, you can choose to \u0026ldquo;Strip www.\u0026rdquo;, meaning the Variable will return the same, www-less value for both www.mydomain.com and mydomain.com.\nFor the Trigger, you\u0026rsquo;ll need to create a new Click Trigger which has a filter for your site\u0026rsquo;s hostname.\n Create new Just Links trigger\n Check \u0026ldquo;Wait for Tags\u0026rdquo; and \u0026ldquo;Check Validation\u0026rdquo;\n For the \u0026ldquo;Enable this trigger when\u0026hellip;\u0026rdquo; condition, set Page URL contains /\n Select the radio button for Some Link Clicks\n Set the last condition to: Click URL Hostname does not contain mydomain.com\n  Substitute mydomain.com with your own domain. You can choose another operator, such as RegEx matching, or the exact match \u0026ldquo;does not equal\u0026rdquo; operator, depending on how accurate you want the pattern match to be.\nTo finish off the Trigger, check my Auto-Event Tracking guide if the options confuse you. The most difficult bit of the new Trigger-based listener is the \u0026ldquo;Enable When\u0026rdquo; setting, which determines when the Trigger is actively listening for link clicks. Just add a blanket match to this: Page URL contains /, since it\u0026rsquo;s quite likely that you want to track link clicks on all your site\u0026rsquo;s pages, right?\nFinally, to make your Event tag fire with this new Trigger, just add it to the Tag:\n  If you\u0026rsquo;re wondering how this Trigger works with links that have relative targets, don\u0026rsquo;t worry. The Trigger works for these as well, since it doesn\u0026rsquo;t access the href attribute of the A element. Rather, it grabs the value from the DOM property named href, which will always have a fully-formed URL value with the hostname and all.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/release-gtm-tools-v2-0/",
	"title": "RELEASE: GTM Tools V2.0",
	"tags": ["Google Tag Manager", "gtm tools", "Guide", "tools"],
	"description": "Introducing the latest version of GTM Tools for Google Tag Manager.",
	"content": " (UPDATE 3 Apr 2017: There is a newer version of GTM Tools out, so please ignore this article and read this one instead.)\nSo, the time has come to update my GTM Tools. I released the first toolset in October 2014, and it performed its duties just well enough. Sure, the UI was ugly as hell, and there were bugs along the way, but for cloning containers, macros, and rules, and for visualizing containers, it was just good enough.\nI\u0026rsquo;ve been working on a new version of the toolset, designed specifically for accounts created in the new UI of Google Tag Manager. There\u0026rsquo;s no \u0026ldquo;backwards compatibility\u0026rdquo;, so this version of GTM Tools will, as I wrote, only work with accounts and containers created in the new UI.\n  This article is intended to be the \u0026ldquo;User guide\u0026rdquo; for the tool, so I\u0026rsquo;ll jump straight to the subject matter right after this disclaimer:\nI am not a professional product developer, and GTM Tools v2.0 is not a commercial product.\nThis toolset is my own, personal, intellectual property, with no purpose of making money out of it or making it the best possible product out there. It\u0026rsquo;s got bugs, the code is pretty nightmarish in some places, and I haven\u0026rsquo;t done thorough testing. It\u0026rsquo;s a toolset that you might find useful or then you might not.\nI would still appreciate that you e-mail me (simo(at)simoahava.com) any bugs, errors, or freezes that you come across. Just remember to check the Known Issues part of this guide first.\nThe tool is located in this URL:\nhttp://www.gtmtools.com/\n1. Login And Authentication GTM Tools v2.0 uses your Google Account for authentication. This means that when you first open the tool website, you will need to Sign in with your Google credentials.\n  Once you\u0026rsquo;ve signed in, you will need to authorize GTM Tools v2.0 for access to Google Tag Manager and your Google profile. Specifically, here are the authorization scopes you allow access to:\n  If you refuse to allow access, you will not be able to use the toolset.\nOnce you\u0026rsquo;re in the actual tool interface, you can see the profile you\u0026rsquo;ve logged in with in the upper right corner of the page. You can click this link and Sign out of your Google Account at any time, or you can click Account to access your Google Account settings.\n  2. Home Page The first page you\u0026rsquo;ll see in the tools is the home page. This page is a placeholder, and you should use the navigation bar in the top of the page to move on in the site.\n  The navigation has the following selections in the home page:\n Home – Takes you back to the home page\n GTM Account – This lists all the GTM Accounts you have access to with the signed in Google Account. Note that this list includes GTM Accounts created for the old GTM interface, but these will not work in GTM Tools v2.0, so try to avoid accessing them.\n Library – Takes you to the Asset Library where you can find your stored Containers\n Cart – Shows you how many items you have in your Cart, and by clicking the button you will be taken to the Cart page\n Your Profile – Clicking this shows a drop-down menu, where you can choose to access your Google Account settings and/or Sign Out of your Google Account.\n  3. Account Page **NOTE!** Due to processing reasons, you will only be able to interact with a **PUBLISHED VERSION** of any given Container. If there is no published version, you will not be able to perform any actions on the Container. This is something I intend to fix as soon as the API provides better access to the Container Draft. When you choose a GTM Account in the Accounts navigation, you will be taken to a page that lists all the Containers in the selected GTM Account. If you click a Container name, you will be taken to the respective Container page.\n  If you click the small down arrow next to a Container name, you\u0026rsquo;ll see quick links for the following Container actions:\n Inspect - Takes you to the Inspect Container page, where you can view information about the Container, and where you can add / remove assets from the Container into the Cart\n Visualize - Takes you to the Visualize Container page, where you can view a visualization of the Container\n Clone - Opens a modal dialog that lets you clone this Container\n  Read more about these actions in the following sections of this guide.\n4. Container Page The container page is here more for structural reasons than to add any added value. You can move through it to the individual actions (Inspect, Visualize, Clone), which you can also do from the Account page, as you just learned.\n  The following chapters will include details about the various actions you can take.\nInspect Container On the Inspect Container page, you can see a list of all Tags, Triggers, and Variables in a Container. You will also see information about the current published version by clicking the Version Information panel.\n  The number on the right-hand-side of a panel title tells you how many assets are in each respective category.\nBy expanding an asset category, you\u0026rsquo;ll see a list of all the assets under that category.\n  You will also see three buttons:\n Green plus + for adding the asset to your Cart\n Red minus - for removing the asset from your Cart\n yes in the Links column if there are dependencies (i.e. linked assets) that you should probably add to your Cart as well\n  The green plus will be greyed out if the asset is already in the Cart, and the red minus will be greyed out if the asset is not yet in the Cart. If there are no dependencies, you will only see a dash in the \u0026ldquo;Links\u0026rdquo; column.\nDo not add an asset to Cart if another asset with the same name has already been added. This is not supported by the current version of GTM Tools v2.0, and I haven’t yet prevented this in the code.\nWhen you click on the yes button for dependencies, a modal dialog will open up which lists all the dependencies of the current asset. This means that these dependencies are linked to directly from the asset itself, or from one of the linked assets. It\u0026rsquo;s strongly recommended that you include all linked dependencies when adding an asset to the Cart.\n  You can add a dependency to the cart by clicking the Add link, after which you\u0026rsquo;ll see the text Added next to the dependency.\nVisualize Container The Visualize Container page first shows you a brief description of what the tool does. Once you click the Start visualization button, a full-screen modal dialog will open, and you will be able to see a visualization of all the assets in the Container as well as any links between them.\nThe asset colors are:\n Grey - Built-In Variables\n Green - Tags\n Blue - Variables\n Red - Triggers\n    If you hover your mouse over an asset, any links to or from that asset will be highlighted. The path color is red if the link is from the selected asset, and the path color is green if the link is to the selected asset.\nHovering over the asset will also show information about it in the small box that appears in the center of the visualization.\nClicking an asset name freezes the paths, so that it\u0026rsquo;s easier for you to navigate to the other end of the path.\nClicking Select Hermit Nodes will highlight all the assets that have no links to or from other assets.\n  You can use the search box to find assets. Start typing, and the assets that match whatever you\u0026rsquo;ve typed will be highlighted as you type.\n  Clone Container There are two ways to clone a Container in GTM Tools v2.0. Due to architectural reasons, they are a bit different.\nThe first way is through the Account page and the Container page. So either you choose Clone Container from the drop-down menu next to the Container name in the Account page, or you click the Clone Button on the Container page itself.\n  When you choose this Clone option, you will be able to choose the GTM Account where this Container will be cloned to. You can also choose the same GTM Account as the one from where you’re cloning the Container from.\n  Once you\u0026rsquo;ve chosen the Account and clicked Clone, the process begins, and the source Container with all its assets is cloned to the target Account.\nIf there already is a Container with this name in the target Account, the Container name will be prefixed with \u0026ldquo;copy of \u0026ldquo; during the process.\nThe second way of cloning a Container is with your custom-created Containers. This means that you choose to Clone either directly from the Cart page or from your Asset Library page.\n  If you choose this option, it will be possible to merge the stored Container with an existing Container, or you can choose to create an entirely new Container, if you wish.\n  If you choose New Container, you will need to give the new Container a name. When you click Clone, the new Container will be created in the target Account, and all assets are cloned. If there is already a Container with this name, the new Container’s name will be prefixed with \u0026ldquo;copy of\u0026rdquo; during the process.\nIf you choose an existing Container, the contents in your Cart or in the stored Container will be merged with the assets in the target Container. This means that if there is a naming conflict, i.e. an asset with the same name already exists in the target Container, the asset\u0026rsquo;s name will be prefixed with \u0026ldquo;copy of\u0026rdquo;, and any links to the asset in other cloned assets will be updated accordingly.\nRenaming Containers and assets like this makes merging Containers possible while still preserving the established links between assets in the source Container.\nIf you choose to merge the assets to an existing Container, no existing assets in the target Container are modified in any way, so you don\u0026rsquo;t have to worry about data or integrity loss.\nOnce the Cloning process begins, there\u0026rsquo;s no way to interrupt it.\n5. Cart Page On the Cart page you can see all the assets that you have stored in your Cart. You store assets in the Cart through the Inspect Container page. The assets are listed first by GTM Account name, then by Container name, and finally by asset type.\n  Clicking the Remove link next to an asset removes the asset from your Cart.\nClicking the Clone to container button opens a modal dialog that lets you clone the Cart contents into an existing Container or a new Container.\nClicking the Save cart button opens a modal dialog that lets you save the Cart contents into your Asset Library. This way you can save your favorite Container configurations to be used later.\n  Clicking the Empty cart button flushes the Cart contents.\n6. Asset Library The Library page shows you all your stored Containers. When you click a Container name, you will see how many Tags, Triggers, and Variables are in the stored Container. You\u0026rsquo;ll also be able to see when the Container was created, as well as the description you gave the Container when you saved it.\n  Clicking the Clone button lets you clone this Container into an existing Container or a new Container.\nClicking the Visualize button takes you to the Visualize Container page, where you can see a visualization of all the assets stored in the Container.\n  Clicking the Delete button opens a modal dialog which confirms this action. If you choose to delete the Container, you\u0026rsquo;ll see a success message shortly, after which the page will automatically reload.\n7. Known Issues Here are some of the issues I know exist in the toolset.\n If you try to access accounts created in the old version of GTM, you will run into trouble. Unfortunately, there\u0026rsquo;s no way to weed these out efficiently. This won\u0026rsquo;t be a problem after all accounts are migrated to the new GTM.\n You can add an asset to the Cart even if another asset with the same name is already in the Cart. However, if you do so, you will run into an error when trying to clone the Container. I\u0026rsquo;m going to prevent this is the code, but it didn\u0026rsquo;t make it into this version.\n Currently, all Container actions work only with published versions of the Container. This is a limitation, and I hope to improve it as soon as the API provides better support for accessing the Container draft. At the very least, I intend to allow you to choose the version you want to interact with.\n Most common cause for errors is with naming conflicts. I\u0026rsquo;ve tried to fix most of these by automatically prepending \u0026ldquo;copy of \u0026ldquo; in front of the Container or asset you\u0026rsquo;re trying to clone, but I may have missed some use cases.\n I cache most of the things you work with to reduce the number of API calls that are made. However, the cache is purged for Containers and assets whenever significant changes are made. Nevertheless, there might be situations where you don\u0026rsquo;t see a change even though you just performed an operation with the tools or did something in the GTM interface. In this case, I suggest you wait 15 minutes and then check again, as that is the expiration time for the cache. I will add a switch to manually flush your own cache, but it\u0026rsquo;s not in this version yet.\n  8. Latest releases 17 Nov 2016  Updated error handling to be more informative and less intrusive.\n Migrated from the Channel API to Firebase Realtime Database. As a result, the progress bar is slightly slower (working on it), but it\u0026rsquo;s more stable.\n Created a new container for Library storage since the first one was full. Sharding is done automatically.\n Minor refactoring here and there, but the codebase is still pretty awful.\n  10 Dec 2016  Migrated from cookies in Cart storage to AppEngine Datastore.  9. Summary As I hopefully made clear in the introduction, this toolset is my own playing ground. It\u0026rsquo;s not a fully-formed platform, it\u0026rsquo;s not a sponsored product, and it doesn\u0026rsquo;t have a team of engineers working on it 24\u0026frasl;7. Thus I hope you will find it useful, and I\u0026rsquo;ll do my best to fix bugs and new features, but don\u0026rsquo;t expect Premium-level support from me in making things right.\nUse the toolset at your risk.\nThere\u0026rsquo;s no risk to your existing assets, since I don\u0026rsquo;t have any overwrite features in the toolset. The only thing you can botch up is cloning something into something else, and in that case only the thing you were cloning will suffer. Easy enough to clean up afterward in your GTM account.\nI still hope you find the toolset useful, and I would very much appreciate any feedback that you might want to direct to my developer team (i.e. me).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/enrich-serp-results-using-gtm/",
	"title": "Enrich SERP Results Using GTM",
	"tags": ["Google Tag Manager", "Guide", "SEO"],
	"description": "You can use Google Tag Manager to enrich your content with structured data. This will make your pages stand out in search engine results.",
	"content": " Google has a myriad of ways to make the search engine results page (SERP) livelier. When you input a search query, the engine\u0026rsquo;s mission is to provide you with the most relevant information with as few clicks as possible. Often, this means that you\u0026rsquo;ll see the answer to your query directly in the SERP:\n  See also Dr. Pete\u0026rsquo;s excellent description of variation in the SERP (note that this post is from 2013, and not all the data types are relevant today). As you can see, there are many ways for a site to annotate data found within, and that way provide it for Google to utilize if it so chooses. There\u0026rsquo;s no guarantee that your structured data is picked up by the search engine, but that shouldn\u0026rsquo;t deter you from marking up your content anyway.\nNow, to business. Google recently released a structured data testing tool that accepts JSON-LD as its input. JSON-LD is an offshoot of the JavaScript Object Notation (JSON) data format, mainly in that you can specify linked data nodes between different notation objects.\nThe structured data supported by JSON-LD is still quite limited, but the amount of options will surely amp up in the near future. Currently, you can markup your site content for:\n All Knowledge Graph features\n Event Rich Snippets\n Sitelink search boxes\n  (UPDATE 3 Feb 2016) Support for Reviews and Products! Thanks Claudia Kosny for the tip.\nThe cool thing about this new release is the following quote from the support pages:\n[JSON-LD] lets you embed a block of JSON data inside a script tag anywhere in the HTML...Also, Google can read JSON-LD data even when it is dynamically injected into the page's contents, such as by Javascript code or embedded \"widgets\". Read the last part again. Doesn\u0026rsquo;t that sound like a Custom HTML Tag in Google Tag Manager? You bet it does!\nMarkup structured data using Google Tag Manager You can dynamically inject JSON-LD specifications on your pages using Google Tag Manager. The only stipulation is that the code must be run during the initial page load. This means that you can\u0026rsquo;t dynamically enhance the structured data on the site after the window has loaded, that is, after gtm.load has been pushed into dataLayer. So as long as your structured data tags are executing with the All Pages Trigger, for example, you should be fine.\nHere are some examples of Custom HTML Tags for structured data. Make sure the Tags fire with the All Pages Trigger.\nAnnotate social profiles for Knowledge Graph If your site is included in the Knowledge Graph, it might be a good idea to add your social profiles directly to the SERP, as Marimekko have done:\n  Here\u0026rsquo;s what you need to write into the Custom HTML Tag:\n\u0026lt;script type=\u0026#34;application/ld+json\u0026#34;\u0026gt; { \u0026#34;@context\u0026#34; : \u0026#34;http://schema.org\u0026#34;, \u0026#34;@type\u0026#34; : \u0026#34;Person\u0026#34;, \u0026#34;url\u0026#34; : \u0026#34;https://www.simoahava.com/\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;Simo Ahava\u0026#34;, \u0026#34;sameAs\u0026#34; : [ \u0026#34;http://fi.linkedin.com/in/simoahava\u0026#34;, \u0026#34;http://plus.google.com/+SimoAhava\u0026#34;, \u0026#34;http://www.twitter.com/SimoAhava\u0026#34; ] } \u0026lt;/script\u0026gt; The code above would annotate my Knowledge Graph box (if I ever reach such levels of stardom) with my social profiles directly in the SERP.\nEnable sitelinks search box This, I think, is one of the coolest additions to the SERP. On some sites, you can see a search box directly in the sitelinks. This search box is tied together with the internal search engine of the site, allowing you to directly search for content within the site!\n  To get this to appear, the syntax of the code in the Custom HTML Tag needs to look like this:\n\u0026lt;script type=\u0026#34;application/ld+json\u0026#34;\u0026gt; { \u0026#34;@context\u0026#34;: \u0026#34;http://schema.org\u0026#34;, \u0026#34;@type\u0026#34;: \u0026#34;WebSite\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.simoahava.com/\u0026#34;, \u0026#34;potentialAction\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;SearchAction\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;https://www.simoahava.com/?s={search_term}\u0026#34;, \u0026#34;query-input\u0026#34;: \u0026#34;required name=search_term\u0026#34; } } \u0026lt;/script\u0026gt; Here, I provide the URL and the necessary search query parameter that operate the internal site search engine on my site. Now, if someone were to enter a search term directly in the SERP sitelinks, they will be transported to the search results page within my site for that particular query.\nThings to note Remember that you can combine your various types of structured data into a Custom HTML Tag, and you should do so to reduce the number of tags in your container. The two examples from above would be combined into a single structured data push like this:\n\u0026lt;script type=\u0026#34;application/ld+json\u0026#34;\u0026gt; [{ \u0026#34;@context\u0026#34; : \u0026#34;http://schema.org\u0026#34;, \u0026#34;@type\u0026#34; : \u0026#34;Person\u0026#34;, \u0026#34;url\u0026#34; : \u0026#34;https://www.simoahava.com/\u0026#34;, \u0026#34;name\u0026#34; : \u0026#34;Simo Ahava\u0026#34;, \u0026#34;sameAs\u0026#34; : [ \u0026#34;http://fi.linkedin.com/in/simoahava\u0026#34;, \u0026#34;http://plus.google.com/+SimoAhava\u0026#34;, \u0026#34;http://www.twitter.com/SimoAhava\u0026#34; ] }, { \u0026#34;@context\u0026#34;: \u0026#34;http://schema.org\u0026#34;, \u0026#34;@type\u0026#34;: \u0026#34;WebSite\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.simoahava.com/\u0026#34;, \u0026#34;potentialAction\u0026#34;: { \u0026#34;@type\u0026#34;: \u0026#34;SearchAction\u0026#34;, \u0026#34;target\u0026#34;: \u0026#34;https://www.simoahava.com/?s={search_term}\u0026#34;, \u0026#34;query-input\u0026#34;: \u0026#34;required name=search_term\u0026#34; } }] \u0026lt;/script\u0026gt; Here I\u0026rsquo;ve included the two JSON objects, and inserted them into a single Array (see the square brackets that wrap the two objects), delimited by a comma.\nOnce you\u0026rsquo;ve created your Tag and published the container, remember to test your site with the Structured Data Testing Tool:\n  One thing I noticed with the tool is that it doesn\u0026rsquo;t always work, especially if the HTML of the site is complex. This doesn\u0026rsquo;t mean the structured data didn\u0026rsquo;t validate, it just means there was some error in the process.\nRemember that since this is GTM, you can use your Variables to make the structured data injector more dynamic. Also, if you\u0026rsquo;ve defined dataLayer in your page template, and it has information you think would be useful in the structured data markup, you can pull this data using Data Layer Variables within your structured data markup. This means that you can create a really flexible structured data injector by leveraging GTM\u0026rsquo;s own functionalities.\nThis feature of Google\u0026rsquo;s search crawlers has been long in the waiting. It makes so much sense to be able to inject annotations about your content with JavaScript, instead of having them applied directly to the page template by the CMS. Also, the fact that you can inject the object anywhere, not just in the \u0026lt;head\u0026gt; of the document, is a great asset, since GTM, by default, injects to the end of the \u0026lt;body\u0026gt;.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/create-a-generic-event-tag/",
	"title": "#GTMtips: Create A Generic Event Tag",
	"tags": ["events", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "How to create a generic event tag using Google Tag Manager.",
	"content": " With Google Tag Manager, there are a million different ways to make your tagging setup leaner and more flexible. The reason this should be a priority is because the UI isn\u0026rsquo;t perfect. The more tags you have, the more difficult it becomes to manage your assets.\nIn this #GTMtips post, I show you one of my favorite ways to put your container on a diet.\nTip 13: How to create a Generic Event Tag   I\u0026rsquo;ve seen a lot of containers that suffer from the same problem. They have many Event tags which only differ by the Event that triggers them and/or by the tag fields of Event Category / Action / Label / Value. There\u0026rsquo;s an easy way to reduce redundancy here. It\u0026rsquo;s the Generic Event Tag (you guessed it!).\nTo set it up, you need the following ingredients:\n One Universal Analytics Tag, Event tag type\n Four Data Layer Variables, each for one of the tag fields\n One Trigger, Custom Event type\n  So create the Data Layer Variables first. You need one for each of the most-used Google Analytics Event fields. If you never use Event Value, you can leave it out, and if you use Non-Interaction a lot, you can create a Variable for it, too.\nThe Data Layer Variables have the following composition:\n  So change the fields for Variable Name (the name you\u0026rsquo;ll use in the Tag fields) and Data Layer Variable Name accordingly. I chose the following Data Layer Variable Names:\n eventCategory - for Event Category value\n eventAction - for Event Action value\n eventLabel - for Event Label value\n eventValue - for Event Value value (value value, eh\u0026hellip;)\n  You can choose other names of course, if you wish. Doesn\u0026rsquo;t make a difference.\nNext, you\u0026rsquo;ll need the Trigger. I\u0026rsquo;ve chosen GAEvent as the Event name to match, but you can, again, choose whatever you wish. This is what the Trigger should look like:\n  Nothing too complicated, right?\nFinally, we\u0026rsquo;ll need the tag. When you create the tag, you need to add the Trigger you just created in Step 3 of the tag creation process (What triggers this tag to fire?). Then, you need to add the Variables you created earlier in their respective fields. Here\u0026rsquo;s what my Tag looks like:\n  As you can see, it\u0026rsquo;s just a simple case of adding the Variables to their designated fields, and making sure that the Tag fires whenever the GAEvent value is pushed into dataLayer.\nFinally, you operate this tag with the following command:\ndataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39; : value_for_Event_Category, \u0026#39;eventAction\u0026#39; : value_for_Event_Action, \u0026#39;eventLabel\u0026#39; : value_for_Event_Label, \u0026#39;eventValue\u0026#39; : value_for_Event_Value });  So whenever this code is executed, the Generic Event Tag is fired with the values you added to the dataLayer.push().\nHere\u0026rsquo;s a tip, though. Because Data Layer Variables are linked together with GTM\u0026rsquo;s data model, it\u0026rsquo;s a good practice to always push the undefined value with any of the \u0026lsquo;eventXXXXX\u0026rsquo; fields that you do not use. Otherwise it\u0026rsquo;s possible that the Tag uses some older value you pushed earlier on the page, and you\u0026rsquo;ll have weird-looking events.\nSo, for example, if I want to send an Event to GA which only uses the Event Category and Event Action fields, the push() would look like this:\ndataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39; : \u0026#39;Form Submit\u0026#39;, \u0026#39;eventAction\u0026#39; : {{url path}}, \u0026#39;eventLabel\u0026#39; : undefined, \u0026#39;eventValue\u0026#39; : undefined });  This will ensure that any values eventLabel and eventValue might have had in the data model are erased and will not interfere with your Tag.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/add-konami-code-to-your-site/",
	"title": "#GTMTips: Add Konami Code To Your Site",
	"tags": ["easter egg", "Google Tag Manager", "gtmtips"],
	"description": "Use Google Tag Manager to add a Konami code listener to your website. You can use it to create a fun secret for your website visitors.",
	"content": " You\u0026rsquo;ve probably heard of the Konami Code. It\u0026rsquo;s a cheat code in many Konami games, where the cheat is executed with a sequence of key presses on the keyboard. Since then, it\u0026rsquo;s become one of the staples of video game folk lore, and many websites, games, and applications have their own easter eggs activated with the Konami code.\nThe sequence of keys is:\nup, up, down, down, left, right, left, right, B, A\nFeel free to try it on this site!\nIn this #GTMtips post, I\u0026rsquo;ll show you how to implement the Konami Code on your website with a single, very simple Custom HTML Tag.\nBefore I go on, kudos for the idea goes to the awesome Gerry White, who graciously allowed me to steal his brilliant idea.\nTip 12: Add the Konami Code to your website   The implementation is simple. All you need is a Custom HTML Tag which fires on All Pages. The code in the tag looks like this:\n\u0026lt;script\u0026gt; var els, i, len, title; var konamiCode = \u0026#39;38,38,40,40,37,39,37,39,66,65\u0026#39;; var keyPresses = []; var checkKonami = function(e) { keyPresses.push(e.keyCode); if (keyPresses.slice(keyPresses.length-10).join() === konamiCode) { runKonami(); } }; var runKonami = function() { els = document.getElementsByTagName(\u0026#39;h2\u0026#39;); for (i = 0, len = els.length; i \u0026lt; len; i++) { title = els[i].textContent || els[i].innerText; title = title.trim(); els[i].innerHTML = title.split(\u0026#39;\u0026#39;).reverse().join(\u0026#39;\u0026#39;); } }; document.addEventListener(\u0026#39;keyup\u0026#39;, checkKonami); \u0026lt;/script\u0026gt; Here\u0026rsquo;s what happens in the script:\nvar els, i, len, title; var konamiCode = \u0026#39;38,38,40,40,37,39,37,39,66,65\u0026#39;; var keyPresses = []; \nThe three lines above are variable declarations for the script. The first line defines a bunch of utility variables we\u0026rsquo;ll need later on. The konamiCode variable is a String with the sequence of keys required to execute the easter egg. The key codes and their respective keys are: 38 - up arrow, 40 - down arrow, 37 - left arrow, 39 - right arrow, 66 - B key, 65 - A key.\nThe third line declares the keyPresses Array, whose job is to keep a record of all keys pressed on the page.\nvar checkKonami = function(e) { keyPresses.push(e.keyCode); if (keyPresses.slice(keyPresses.length-10).join() === konamiCode) { runKonami(); } };  The checkKonami function is the callback for the \u0026lsquo;keyup\u0026rsquo; event (see below). In essence, it\u0026rsquo;s called every time a key press is registered on the page. It takes the event object as a parameter (e).\nThe first line, keyPresses.push(e.keyCode);, pushes the key code for the registered key press into the keyPresses Array. The next three lines are an if-block, where the last 10 key codes are evaluated. These are joined into a comma-separated String object, and then compared with the sequence of key codes in the konamiCode String. If these two match, that is if the last ten key presses have the same codes in the same sequence as the konamiCode String, the function runKonami is called.\nvar runKonami = function() { els = document.getElementsByTagName(\u0026#39;h2\u0026#39;); for (i = 0, len = els.length; i \u0026lt; len; i++) { title = els[i].textContent || els[i].innerText; title = title.trim(); els[i].innerHTML = title.split(\u0026#39;\u0026#39;).reverse().join(\u0026#39;\u0026#39;); } };  In the runKonami function you can run whatever code you want to when the Konami code is correctly registered on the website. In my example, I take the text content of every single H2 element on the page, and I reverse the character order.\ndocument.addEventListener(\u0026#39;keyup\u0026#39;, checkKonami);  The final line of JavaScript adds the event listener for the \u0026lsquo;keyup\u0026rsquo; event, and denotes checkKonami as the callback to be invoked each time such an event is registered.\nThis was hopefully a fun example of how to add a custom event listener on the site, and how to manipulate the DOM in a Custom HTML Tag.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/variable-guide-google-tag-manager/",
	"title": "Variable Guide For Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "macros", "variables"],
	"description": "Comprehensive guide to variables in Google Tag Manager. Included are a look under the hood as well as a plethora of examples how to use variables to make your container rock.",
	"content": " (Updated 27 February 2018)\nThe current version of Google Tag Manager was released in October 2014. With the release, we saw a brand-spanking new UI, a lot of new functionalities (revamped auto-event tracking, for example), plus a new terminology to cope with. We moved away from the programming-centric concepts of Macros and Rules to the more tactile variables and triggers.\nIt\u0026rsquo;s difficult to rank the changes. The new Auto-Event Tracking is perhaps most impactful, but the improvements done to triggers and variables, when compared to the previous version of GTM, require attention as well.\n  Thus, I give you my variable Guide for Google Tag Manager. For reference, feel free to take a look at the old macro guide, since especially the different variable types have been left largely untouched.\nIntroduction to Variables In computing terms, variables denote compartments in computer memory, which are reserved for storing values. This is a significant achievement in efficiency, because it means that values can be reused across functions, procedures, and environments. The alternative would be to treat each representation of the same value as unique, temporary, and disposable, creating a mass of redundancy and inefficiency, and making the current computing landscape a whole lot different.\nIn Google Tag Manager, the term variable is used to denote a helper function that your tags, triggers, and other variables can invoke to retrieve values from. Thus, the idea is very similar to the broader concept of computing variables explored in the previous paragraph.\nIn GTM, invoking the variable function is done with a specific syntax:\n{{variable name}}\nAs we\u0026rsquo;ll learn later on, you can\u0026rsquo;t invoke variables wherever you\u0026rsquo;d want to. But in an approved context, the syntax {{variable name}} would run the underlying function of the variable with the name \u0026ldquo;variable name\u0026rdquo;, and pass the value returned by that function to its execution context (the tag, trigger, or variable where the syntax was used).\nOne of the first things all Google Tag Manager containers which run Google Analytics tags should do is this:\n  Here, instead of always typing the tracking code for your web property (UA-XXXXXX-X) into each GA tag, you can create a Constant variable, which stores the value. Thus, whenever the variable name is invoked using the correct syntax, the tracking code returned by the Constant variable will be included in the appropriate tag field. This is something I\u0026rsquo;ve actually written a #GTMtips post about this.\nI will go so far as to say that variables can make or break GTM. When skeptics ask me what is the main benefit of having GTM on the site, I always end up talking about variables. They add a level of flexibility and customization that can really make your tagging lean, efficient, performance-driven, and time-saving.\nAt the same time, variables can be difficult to fathom, especially when we get to the technical details (see below), or when we try to tackle the amazingly multi-faceted and deviously difficult Custom JavaScript variable. I hope this guide will help you get to the bottom of variables, and encourage you to find your own ways of performing magic tricks with your GTM container.\nTechnical details and how-to For you to be able to invoke a GTM variable, you need to be working in a script context, or the template field needs to support variable references.\nA supported template field can be uncovered by looking for the little variable symbol next to a field:\n  As you can see, the \u0026ldquo;Tag firing priority\u0026rdquo; field will not be able to invoke a variable, but the \u0026ldquo;Auto Link Domains\u0026rdquo; will. In fact, if you click the little variable icon, you will see a drop-down list from which you can pick the variable you want to use. This way you don\u0026rsquo;t have to worry about correct syntax, as GTM will do it for you.\n  The other places where you\u0026rsquo;ll frequently run into variables are:\n Triggers\n Custom HTML tags\n Custom JavaScript variables\n  With triggers (remember to read my Trigger guide as well!), you will always need to specify a variable as the target of the trigger condition. Every single trigger condition needs a variable that is evaluated against some value. In fact, the condition builder is created so that you can\u0026rsquo;t possibly not choose a variable. It\u0026rsquo;s obligatory!\n  Note that the value (right-hand) field of the trigger condition is NOT a variable context!\nAs for Custom HTML tags and Custom JavaScript variables, you can call variables from the scripts within, but you won\u0026rsquo;t have the helpful drop-down menu to assist you. You will need to manually type the call, using the correct syntax and the correct (case-sensitive) variable name:\n\u0026lt;!-- Sample Variable call in a Custom HTML Tag --\u0026gt; \u0026lt;script\u0026gt; (function() { alert({{custom alert string}}); })(); \u0026lt;/script\u0026gt; The code above will pop-up a browser alert, where the content will be the string returned by the variable named custom alert string. Note! If the variable doesn\u0026rsquo;t return a string, you might run into problems with the alert method, so you need to be well aware of return types and values at all times.\nIf you try to use a variable that doesn\u0026rsquo;t exist (or whose name you mistyped), you won\u0026rsquo;t be able to perform any operations on the container version (create, publish, etc.). You\u0026rsquo;ll run into an error message that looks like this:\n  So remember to check all the places where you\u0026rsquo;ve manually typed a variable call. It\u0026rsquo;s also possible that you\u0026rsquo;ve jumped the gun and called a variable, but then you forgot to create the variable itself. Retrace your steps and fix any broken links.\nOne cool thing that GTM does for you is this: when you change a variable name, all references to the variable are automatically updated. Even the ones you\u0026rsquo;ve typed in manually into Custom HTML tags and Custom JavaScript variables! This is incredibly time-saving, since you don\u0026rsquo;t have to go through every single reference, rewriting the code to match the new name.\nVariables are resolved according to the following process:\n If the variable is not attached to a trigger or a tag, the variable is never resolved (unless, of course, the variable is referenced from some other variable that is resolved).\n If the variable is referenced in a trigger that is not attached to any tags, the variable is never resolved.\n If the variable is referenced in a trigger that is attached to a tag, the variable is resolved every single time an event key is pushed into dataLayer.\n If the variable is referenced in a tag, the variable is resolved every single time the tag fires.\n  The last one is interesting. When a trigger causes a tag to \u0026ldquo;fire\u0026rdquo;, the process is actually this:\n Variable calls are transformed into the actual function calls (google_tag_manager['containerId'].macro('gtm10'))\n The tag code is injected on the site\n The tag code is executed, and all variable functions within are resolved\n  As you can see, a variable is actually a method of the google_tag_manager object. The parameter that is given to the macro() method is basically \u0026lsquo;gtm\u0026rsquo; plus a unique sequential number. This means that it\u0026rsquo;s very difficult to identify which macro() parameter is associated with which variable, which is why debugging has become an all-important tool in understanding how variables work.\nThe other, common case of variable resolution has to do with trigger conditions. When an \u0026lsquo;event\u0026rsquo; key is pushed into dataLayer, every single trigger that is attached to a tag in your container is evaluated for the \u0026lsquo;event\u0026rsquo; condition. In addition to checking the event value, all variables referenced in the trigger are evaluated, too.\nYou might want to re-read the previous paragraphs to grasp the idea, but this has very severe repercussions on how variables should (and should not be used):\nVariables must never have side effects\nRemember how variables should only be used to return values? Well, sometimes you might be tempted to use a variable to change the state of the global object or to set or push stuff into dataLayer. Don\u0026rsquo;t do it! Because variables can be resolved in multiple ways, and not just in tags as you\u0026rsquo;d expect, you might find yourself creating infinite loops, pushing stuff into dataLayer multiple times, or severely hurting page performance.\nfunction() { // DON\u0026#39;T DO THIS:  window.dataLayer.push({ ... }); // OR THIS:  alert(\u0026#34;test\u0026#34;); // OR THIS:  window.temp = getTempValue(); // DO THIS:  var a = window.thisValue; var b = getSomeOtherValue(); return a + \u0026#39;: \u0026#39; + b; }  If you\u0026rsquo;ve made it this far, congratulations. As a developer, I think it\u0026rsquo;s all-important to understand how variables work beyond the obvious, if only to realize the potential that variables have in improving the efficiency of your work with GTM.\nBuilt-in Variables The new version of Google Tag Manager introduced Built-in variables. These are helpful, most commonly used variables, whose existence is based on binary logic: active / inactive. If the Built-in variable is activated, it can be used as any other variable, and if it\u0026rsquo;s not activated, it can\u0026rsquo;t.\nBuilt-in variables are thus no more than a shorthand for exploiting some of the most frequently used variable types in Google Tag Manager. I find it a bit odd that they\u0026rsquo;re not all activated by default, since there\u0026rsquo;s absolutely no harm in them being available for use.\nYou will find the Built-in variables displayed prominently in the top of the variables screen of your Google Tag Manager Container:\n  If the Built-in variable is listed here, it is active in the container. To add new Built-in variables, click the red CONFIGURE button, and check the box next to each variable you want to add to the container.\n  As with all variables, if the Built-in variable cannot be resolved (e.g. there was no Click action and you want to use Click ID), the variable returns the JavaScript undefined type.\nHere are the Built-in variables with a brief description of what they return:\nPages  Page URL - returns a string containing the full URL of the current page without hash fragment (https://www.simoahava.com/article?parameter=true)\n Page Hostname - returns a string containing the the hostname of the current page (www.simoahava.com)\n Page Path - returns a string containing the relative path of the current page (/article)\n Referrer - returns a string containing the URL of the page which brought the visitor to the current page (https://www.simoahava.com/home/), from document.referrer\n  Utilities  Event - returns a string containing the value stored in the \u0026lsquo;event\u0026rsquo; dataLayer key\n Environment Name - returns the name of the environment currently being previewed (either via the Share Preview link or the environment\u0026rsquo;s container snippet)\n Container ID - returns a string containing the container ID (GTM-XXXXXX)\n Container Version - returns a string containing the current container version\n Random Number - returns a number, randomized between 0 and 2147483647\n HTML ID - returns the identifier of the Custom HTML tag. Used with tag sequencing.\n  Errors  Error Message - returns a string containing the error message dispatched by a JavaScript Error trigger\n Error Line - returns a string containing the line number where the error was thrown\n Error URL - returns a string containing the URL of the script where the error was thrown\n Debug Mode - returns a Boolean (true/false) depending on if the user is in GTM debug mode or not\n  Clicks  Click Element - returns an HTML element that was the target of an auto-event action; this object is retrieved from the gtm.element key in dataLayer\n Click Classes - returns a string contained in the className attribute value of the auto-event element\n Click ID - returns a string contained in the id attribute value of the auto-event element\n Click Target - returns a string contained in the target attribute value of the auto-event element\n Click URL - returns a string contained in the href or action attribute value of the auto-event element\n Click Text - returns a string contained in the textContent / innerText attribute value of the auto-event element\n  Forms These are exactly the same as the Click variables. I\u0026rsquo;m not sure why we need two sets of variables, when one generic \u0026ldquo;Auto-Event\u0026rdquo; type would suffice.\nHistory  New History Fragment - returns a string containing the new URL fragment after a page history change auto-event action is registered\n Old History Fragment - returns a string containing the previous URL fragment\n New History State - returns an object containing the new history state after a pushState() has been registered\n Old History State - returns an object containing the old history state\n History Source - returns a string describing the event that initiated the history change (e.g. popstate or pushState)\n  Videos  Video Provider - returns a string containing the video service being tracked (currently YouTube only supported).\n Video Status - returns a string with the status of the video that caused the trigger to fire. Could be one of 'start', 'pause', 'buffering', 'progress', or 'complete'.\n Video URL - returns a string with the URL of the embedded video.\n Video Title - returns a string with the title of the embedded video.\n Video Duration - returns a number with the total length of the video in seconds.\n Video Current Time - returns a number with the time mark where the user currently is (i.e. when the event was triggered).\n Video Percent - returns a number with the percentage mark where the user currently is.\n Video Visible - returns true or false, depending on if the video was visible in the browser viewport when the event was triggered.\n  Scrolling  Scroll Depth Threshold - returns a number with the value of the scroll tracking threshold that was crossed (e.g. 25 for 25 percent or 25 pixels, depending on which the trigger is configured with).\n Scroll Depth Units - returns a string with 'percent' or 'pixels', depending on which threshold type the trigger is tracking.\n Scroll Direction - returns a string with 'vertical' or 'horizontal', depending on which direction is being tracked with the trigger.\n  Visibility  Percent Visible - returns a number with the percentage of visibility for the element whose visibility is being tracked (e.g. 50 if half of the element is in the viewport).\n On-Screen Duration - returns a number with the total cumulative time (in milliseconds) that the element has been in the viewport when the trigger fires.\n  As you can see, the Built-in variables are just a quicker way to access some of the most common variable types. Read on, and check especially the chapter on variable types, as that will help you understand Built-in variables better as well.\nDebugging Variables In the amazingly wonderful Debug Mode, there\u0026rsquo;s a tab for variables:\n  By clicking that tab, you can explore the state of each variable upon every single dataLayer interaction. As you probably know, every single push to the dataLayer has the potential to change the state of the data used by GTM, which is why you must be able to observe this state with every interaction. And this is what the variables section of the Debug pane enables you to do.\nFor example, here are two different states of dataLayer. The first state is when the Container snippet is first loaded, and the \u0026lsquo;event\u0026rsquo; key is pushed with the value \u0026lsquo;gtm.js\u0026rsquo;:\n  As you can see, I\u0026rsquo;ve selected the \u0026ldquo;Page View\u0026rdquo; event in the left-hand-side navigation of the Debug pane. This corresponds to a dataLayer.push(), where the \u0026lsquo;event\u0026rsquo; key was populated with \u0026lsquo;gtm.js\u0026rsquo;.\nNext, I select the \u0026ldquo;Window Loaded\u0026rdquo; event from the navigation. Here\u0026rsquo;s what the \u0026lsquo;event\u0026rsquo; key looks like in this particular state:\n  As you can see, the value of the \u0026lsquo;event\u0026rsquo; key has changed. So with the debug pane, you can explore the values stored in each variable at any given dataLayer interaction.\nIf a variable has the value undefined, it means that the variable did not resolve. If you see this value in a state where you are certain the variable should have a proper value, it means there\u0026rsquo;s something wrong with your variables, tags, or triggers, and you need to look into it more carefully.\nBy clicking the Tags tab, you can examine what your variables returned in any tag that has fired (or not):\n  You can also look at tags which didn\u0026rsquo;t fire, and focus on the trigger. The visual display will tell you which variable condition did not pass the check, and you\u0026rsquo;ll know there\u0026rsquo;s something for you to debug again:\n  The Debug tool is incredibly useful, as it allows you to double-check how variables work in your current setup.\nVariable Types   There are a number of useful variable types for you to choose from, and you can use the Custom JavaScript variable to create custom variables of your own. Many of the variable types have some cool customization options as well, so you should take the time to study their many uses.\n1. HTTP Referrer   Use the HTTP Referrer variable to identify details about the page that brought the visitor to the current one. The value is retrieved from the document.referrer property. Note: There is a Built-In variable for this (Referrer).\nRETURNS\nString with the URL of the referring page. You can specify a URL component if you wish (see the URL variable for more information about the various component types).\nUSE CASE(S)\nYou could create a trigger which fires when HTTP Referrer does not contain your own domain. This would mean that the user arrived from outside your site to the current page.\n2. URL   The URL variable can be used to access components of the current page URL (default) or of any URL string returned by a variable. This is a very versatile variable type, and is especially useful for traversing query parameters and hash fragments in your URLs. Note: There are Built-In variables for this (Page URL, Page Hostname, Page Path).\nThe Component Types you can choose are:\nFull URL - returns the full URL without the hash fragment, e.g. \u0026lsquo;https://www.simoahava.com/?home=true'.\nProtocol - returns the protocol of the URL, e.g. \u0026lsquo;https\u0026rsquo;.\nHost Name - returns the hostname of the URL without the port number, e.g. \u0026lsquo;www.simoahava.com\u0026rsquo;. You can choose to Strip \u0026lsquo;www.\u0026rsquo; to strip the \u0026lsquo;www\u0026rsquo; subdomain from the hostname.\nPort - returns the port number used in the URL, or \u0026lsquo;80\u0026rsquo; for HTTP / \u0026lsquo;443\u0026rsquo; for HTTPS, if the URL has no port number.\nPath - returns only the pathname in the URL. You can also specify Default Pages to strip pages with names like \u0026lsquo;index.html\u0026rsquo; or \u0026lsquo;index.php\u0026rsquo; from the return string.\nQuery - returns the entire query parameter string (without leading \u0026lsquo;?\u0026rsquo;), if you don\u0026rsquo;t specify a query key. If you do specify a query key, only the value of this key is returned, or undefined if no such key is found in the URL.\nFragment - returns the value of the URL\u0026rsquo;s fragment without the leading \u0026lsquo;#\u0026rsquo;, e.g. \u0026lsquo;anchor1\u0026rsquo;.\nYou can expand the More Settings tab to find a source selector. In this selector, you can choose the variable whose return value the URL variable will access.\nRETURNS\nThe return value for the URL type you specified in the Component Type selection, or undefined if no such component is found in the URL variable. By default, the URL variable that is accessed is the page URL, but you can choose any variable which returns a string with a URL in it.\nUSE CASE(S)\nThis is, again, a very versatile variable. For example, check the following article for an example of how to use the URL variable to fix your site\u0026rsquo;s internal search tracking:\n Fix GA Site Search With Google Tag Manager  3. First Party Cookie   The 1st Party Cookie variable returns the value for the first browser cookie with the name you specify in the Cookie Name field. For example, if you have a cookie called \u0026ldquo;session\u0026rdquo;, you can use the 1st Party Cookie variable to retrieve the value for this particular cookie.\nRETURNS\nString containing the value stored in the cookie, or undefined, if no such cookie exists.\nUSE CASE(S)\nI\u0026rsquo;ve used cookies a lot in my guides. Here are two examples for using cookies:\n #GTMtips: Prevent Repeat Transactions\n #GTMtips: Once userId, Always userId\n  4. Custom JavaScript   The Custom JavaScript variable is surely the most versatile variable in the set. You can use it to run arbitrary JavaScript on the page. It creates a script context, meaning you can also call other variables from within using the appropriate syntax.\nThe Custom JavaScript variable needs to follow two simple rules. First, the script must be wrapped in an anonymous function block (function() { ... }). Second, the function must have a return statement (return somevalue;).\nThe third, unwritten rule is that the function should only return a value. You shouldn\u0026rsquo;t use a Custom JavaScript variable to modify the global namescape by pushing values to dataLayer for example. If you want to tamper with global variables from a function, it\u0026rsquo;s better to create a Custom HTML tag for this purpose.\nRETURNS\nDepends on what you have in the return statement. You can return any variable or value, even other functions, other GTM variables, or nothing (a simple return; is the equivalent of returning the undefined value).\nUSE CASE(S)\nMany of my articles use the Custom JavaScript variable to some extent. Take a look at these to get started:\n Custom Event Listeners For GTM\n Simple RegEx Table For Google Tag Manager\n Macro Magic For Google Tag Manager\n  5. Data Layer Variable   The Data Layer variable is extremely versatile as well. When you create a Data Layer variable, you specify the Data Layer key whose value you want to retrieve. When the variable is resolved, GTM will look for the most recent value for the key in the internal data model. For primitive values (Strings, numbers, Booleans, functions), the variable will return whatever was most recently pushed into the key. For plain objects and Arrays, the variable will return the result of a recursive merge, where only shared keys are replaced.\nYou can use dot notation to access both Data Layer variable keys which have a dot in their name (e.g. gtm.element), or to access properties of DOM element objects (e.g. gtm.element.dataset.name).\nYou can use dot notation to access Array members as well. Square notation won\u0026rsquo;t work, so replace the square notation with dots: products[0].name becomes products.0.name.\nRETURNS\nThe value stored in the Data Layer variable whose name you point out in the Data Layer variable Name field. You can also retrieve the value of an object property, if you are sure that the variable holds an object. To access Array members, use dot notation instead of square notation. You can also specify a Default Value which will be returned if no variable with the given name can be found from the Data Layer when the variable is resolved. If you don\u0026rsquo;t give a default value, the Data Layer variable will return undefined in case no variable with the given name is found.\nUSE CASE(S)\nThe Data Layer variable is your best friend when you want to make the most of Auto-Event Tracking. The Built-In variables and the Auto-Event variable types only give you a handful of DOM properties to choose from in the auto-event element. Use the Data Layer variable to traverse the gtm.element object as you wish.\nRemember to read my two earlier, in-depth articles about the Data Layer:\n The Data Layer\n Google Tag Manager\u0026rsquo;s Data Model\n  6. JavaScript Variable   The JavaScript variable returns the value stored in the global JavaScript variable you specify. Note, this is NOT the same as the Custom JavaScript variable, which is a function declaration.\nRETURNS\nThe value stored in the global JavaScript variable that you specify. If no such global variable exists, the undefined value is returned instead.\nUSE CASE(S)\nHere\u0026rsquo;s an example of using the JavaScript variable with a custom tag. In this example, I show you how to fire a single tag multiple times by increasing a global JavaScript variable counter with each iteration, and then fetching the value of this variable in linked tags and variables.\n Fun With Google Tag Manager: Part 2  7. Auto-Event Variable   Auto-Event variables are used to access the target element of an auto-event action (e.g. Click, Error, Form Submit). When you create a new Auto-Event variable, you need to specify just which component of the target element you want to access.\nElement - Accesses the DOM Element itself that was the target of the auto-event action. This element is stored under the key gtm.element in the Data Layer, and you can create your own, customized auto-event variables using the Data Layer variable, and traversing the gtm.element object as you would any other DOM element. For example, to get the value stored in the ID attribute of the auto-event element\u0026rsquo;s parent, you\u0026rsquo;d create a Data Layer variable which points to gtm.element.parentElement.id. Note: There are Built-In variables for this (Click Element and Form Element).\nElement Classes - Returns the value of the class attribute of the auto-event element. Stored in the Data Layer under the key gtm.elementClasses. Note: There are Built-In variables for this (Click Class and Form Class).\nElement ID - Returns the value of the id attribute of the auto-event element. Stored in the Data Layer under the key gtm.elementId. Note: There are Built-In variables for this (Click ID and Form ID).\nElement Target - Returns the value of the target attribute of the auto-event element. Stored in the Data Layer under the key gtm.elementTarget. Note: There are Built-In variables for this (Click Target and Form Target).\nElement Text - Returns the value of either the textContent or innerText property of the auto-event element. The return value is trimmed of whitespace and normalized to account for differences in how browsers interpret element text. Note: There are Built-In variables for this (Click Text and Form Text).\nElement URL - Returns the value of either the href or the action attribute of the auto-event element. You can further specify just which URL component you want to access (see the section for the URL variable type for more information). Stored in the Data Layer under the key gtm.elementUrl. Note: There are Built-In variables for this (Click URL and Form URL).\nHistory New URL Fragment - Returns the new URL fragment set with a browser history event. Stored in Data Layer under the key gtm.newUrlFragment. Note: There is a Built-In variable for this (New History Fragment).\nHistory Old URL Fragment - Returns the old URL fragment replaced in the browser history event. Stored in Data Layer under the key gtm.oldUrlFragment. Note: There is a Built-In variable for this (Old History Fragment).\nHistory New State - Returns the new state object set with a browser history event. Stored in Data Layer under the key gtm.newHistoryState. Note: There is a Built-In variable for this (New History State).\nHistory Old State - Returns the old state object replaced in the browser history event. Stored in Data Layer under the key gtm.oldHistoryState. Note: There is a Built-In variable for this (Old History State).\nHistory Change Source - Returns a string denoting the event that triggered the history change event (popstate, pushState, replaceState, or polling). Stored in Data Layer under the key gtm.historyChangeSource. Note: There is a Built-In variable for this (History Source).\nRETURNS\nThe Auto-Event variable returns the value appropriate for the selected element type. If no relevant auto-event has been registered, the variable returns the Default Value (if set), or undefined.\nUSE CASE(S)\nThere are many use cases for the Auto-Event variable. To get you started, I suggest you take a look at the following articles:\n Auto-Event Tracking In GTM 2.0\n Advanced Form Tracking In Google Tag Manager\n Google Tag Manager: The History Listener\n  8. DOM Element   You can use the DOM Element variable to retrieve the text content of any given DOM Element. You can also use it to retrieve the value of any attribute of the DOM Element.\nRETURNS\nThe text content of the given DOM Element, or the value of the given attribute (optional). If no DOM Element with the given ID or CSS selector is found, the variable returns the null value.\nUSE CASE(S)\nYou can use this to access any arbitrary DOM Element on the page. This becomes useful if you want to fire an event only if a certain element is on the page.\n9. Element Visibility   The Element Visibility variable lets you know if any particular element was visible in the browser viewport when the trigger fired. Visibility requires that the element be positioned above the fold of the page in the active browser tab. In other words, the element must actually be in sight of the user. The only exception is if there is some other window in front of the browser window where the element is otherwise visible. In this case, GTM would consider the element to still be visible, even though it\u0026rsquo;s not technically viewable by the user.\nRETURNS\nThe variable returns either True / False indicating if the element was visible or not, respectively, or a percentage of how much of the element was visible when the variable was resolved. You can choose which output type to use in the settings of the variable.\nUSE CASE(S)\nYou can set the visibility variable to check an element with CSS selector body, and minimum 1 percent visible. This variable would then tell you if the page was visible in the viewport when the variable was called.\n10. Constant   The Constant variable is a prime example of how variables are reusable. If you have any string of characters that you need to use often, or which you might need to update in the future, it\u0026rsquo;s best to store it as a Constant variable instead.\nRETURNS\nThe Constant variable returns the string you choose to type in the Value field.\nUSE CASE(S)\nThe obvious use case is your Google Analytics web property ID. By storing the UA-XXXXX-X code in the Constant variable, you won\u0026rsquo;t need to look it up every single time you create a new GA tag.\n11. Custom Event   The Custom Event variable returns the value of the \u0026lsquo;event\u0026rsquo; key in the Data Layer. For example, if you run the following code: dataLayer.push({'event' : 'thisEvent'});, then the Custom Event variable would hold the value \u0026lsquo;thisEvent\u0026rsquo; after the push. Note: There is a Built-In variable for this (Event).\nRETURNS\nThe value stored in the \u0026lsquo;event\u0026rsquo; key in the Data Layer.\nUSE CASE(S)\nHonestly, I can\u0026rsquo;t figure out what this variable is for. If I had to guess, it\u0026rsquo;s a remnant of the old GTM, where you could accidentally delete the {{event}} macro and then use the Custom Event macro to bring it back. In the new UI, there\u0026rsquo;s a Built-In variable for Event, and at the time of writing there\u0026rsquo;s also the internal variable _event which you can\u0026rsquo;t delete or deactivate. So there really is no need to create a new Custom Event variable.\n12. Environment Name   The Environment Name variable is similar to Custom Event in that it doesn\u0026rsquo;t really add anything to GTM. There already is a Built-In variable for \u0026ldquo;Environment Name\u0026rdquo;, which you should use instead of creating this User-Defined variable.\nRETURNS\nString with the current environment name if using an environment snippet, or the draft version identifier if in Preview mode. It won\u0026rsquo;t return anything for Live or Latest versions.\nUSE CASE(S)\nUse it to fire tags only if in a certain environment. Remember to read my Environment Guide while you\u0026rsquo;re at it!\n13. Google Analytics Settings   The Google Analytics Settings variable returns a set of Universal Analytics tag settings. This can be used to configure multiple tags at once, consolidating their Custom Dimensions and Fields to set, for example.\nNote that the Google Analytics Settings variable can only be used in a Universal Analytics tag. You can\u0026rsquo;t invoke the variable in other contexts.\nRETURNS\nA configuration of Google Analytics Settings to be used in a Universal Analytics tag.\nUSE CASE(S)\nUse the Google Analytics Settings variable to consolidate tag settings across your Universal Analytics tags. For inspiration, read this article.\n14. Lookup Table   The Lookup Table variable performs any number of lookups that you specify, returning the value of the first match. Since this is a Lookup Table, the value lookup is always exact match and case-sensitive. You can create your own, custom Lookup Table if this is too strict for you.\nThe Input variable specifies the variable which will be used as the input in the lookups. On each row that you add to the table, you give an output value to be returned by the variable, if the input variable is matched with the Input field value of the row. You can chain Lookup Tables together, creating a powerful, efficient, and flexible value lookup for your tags and variables.\nRETURNS\nThe value in the Output field of the first row that is matched against the Input variable. You can also give a Default Value which will be returned if no match is made. If you don\u0026rsquo;t specify a Default Value, the variable will return the undefined value if no match is made.\nUSE CASE(S)\nTake a look at my original article for some ideas:\n Google Tag Manager: The Lookup Table Macro  Lunametrics has also a really interesting guide on automating the Lookup Table variable creation process.\n15. Random Number   The Random Number variable returns a random number between 0 and 2147483647. Note: There is a Built-In variable for this (Random Number).\nRETURNS\nA number, randomized between 0 and 2147483647.\nUSE CASE(S)\nYou can use the Random Number variable to sample your visitors.\n16. RegEx Table   The RegEx Table variable lets you create a pattern-matching table. It functions similarly to the Lookup Table, with the obvious difference that lookups are exact match only, whereas regular expressions are far more flexible in what you can match against. There are some other additional features in the RegEx Table, which you can read about here.\nRETURNS\nWhatever you have defined in each individual Output field, and the Default Value field.\nUSE CASE(S)\nYou can use the RegEx Table with a Just Links trigger to determine what type of link was clicked. See the screenshot above for hints how to do this.\n17. Container ID   This is also a Built-In variable, so use that instead of creating a new User-Defined variable.\nRETURNS\nThe public ID (GTM-XXXXXX) of the Container.\nUSE CASE(S)\nThis is important in tag sequencing, as it\u0026rsquo;s used to signal when a Custom HTML tag has finished completion. You should also send the Container ID as a Custom Dimension in your GTM hits - that way you can see in Google Analytics which hits were sent from which container.\n18. Container Version Number   This is pretty self-explanatory. The Container Version Number returns the version number of the container that is implemented on the site, or QUICK_PREVIEW if you are previewing the workspace draft. Note: There is a Built-In variable for this (Container Version).\nRETURNS\nString with the current GTM Container version number, or _QUICKPREVIEW, if the workspace draft is in preview mode.\nUSE CASE(S)\nAssign a Google Analytics Custom Dimension for the container version ID, which will help you analyze the impact of changes various versions of the GTM container have had. This is a great way to debug your GTM and GA implementations.\n19. Debug Mode   The Debug Mode variable returns true if the user is viewing the container in Preview mode, and false if not. Note: There is a Built-In variable for this (Debug Mode).\nRETURNS\ntrue when the user is in Container Debug mode, and false when not.\nUSE CASE(S)\nWith the Lookup Table variable, you can collect all your GA hits in Debug mode to a separate, test property. Read about this idea in my Macro Magic article.\nYou can also send the Debug Mode value as a Custom Dimension, if you want to collect all hits to the same GA property. This way you can filter with the Custom Dimension and collect all your debug hits to a separate Google Analytics profile.\nSummary I\u0026rsquo;m bold enough to claim that once you understand variables, you can call yourself a Google Tag Master. It\u0026rsquo;s not just what the different variable types are. It\u0026rsquo;s how you use them together to create sense out of the complexity that almost any tag implementation brings in its wake.\nJust remember to pay heed to the technical details as well. If you don\u0026rsquo;t understand the process of how variables are resolved, you\u0026rsquo;ll often run into unexpected situations. Most often it\u0026rsquo;s a \u0026lsquo;race condition\u0026rsquo;, where the variable is trying to access some other data source which isn\u0026rsquo;t ready yet.\nBe respectful of the \u0026lsquo;no side effects\u0026rsquo; rule as well. Do not use variables for anything else except to build a well-formed return statement. If you feel like you need to increase the complexity of your function calls, use a Custom HTML tag instead.\nWere you interested in some other aspect of variables that I didn\u0026rsquo;t cover here? Or do you have a great use case in mind for some variable type? Sound off in the comments, thanks!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-content-enhanced-ecommerce/",
	"title": "Track Content With Enhanced Ecommerce",
	"tags": ["ecommerce", "enhanced ecommerce", "Google Tag Manager", "Guide"],
	"description": "Use Google Tag Manager to track your site content via the Enhanced Ecommerce reports in Google Analytics.",
	"content": " My fingers have been tingling to write this article. Ever since I implemented Enhanced Ecommerce on my blog a couple of weeks ago, I\u0026rsquo;ve been getting such an impressive amount of useful data that it\u0026rsquo;s mind-boggling.\nIn this article, I\u0026rsquo;ll walk you through the steps I went to implement the solution, along with examples of the data I can now access through Google Analytics\u0026rsquo; reporting interface. As you might have guessed, if you\u0026rsquo;ve read my articles before, I implemented Enhanced Ecommerce with Google Tag Manager. Note, this is not a step-by-step guide, but should rather provide inspiration for you to think out-of-the-box when it comes to Google Analytics\u0026rsquo; features.\nEcommerce and content, huh?   You might be surprised at what the premise of this article is. Usually, Ecommerce plugins are used to track transactions on your web store, so what does this have to do with content? Well, I don\u0026rsquo;t have a web store on my blog, but every reader who reads an article is valuable to me. If they are valuable, there must be some way to measure their value, and perhaps use this data to benchmark against future products (i.e. articles) I want to create.\nEnhanced Ecommerce gives you a bunch of useful reports, which you can use to track not only store transactions but any kind of user interaction on your site. You just have to see your site in terms of funnels. This means that you need to translate Ecommerce terminology to match the conceptual framework of your site, whether it\u0026rsquo;s a blog, a web store, a news portal, or a brand site.\nOn my blog, the terminology ended up something like this:\n Product: A blog article.\n Product price: The number of words in the article.\n Product impression: At minimum the title, but usually title + ingress combination of articles on various category pages, and in article sidebars.\n Product list: A page or widget which holds a number of Product impressions. For example, my home page, category pages, tag pages, and related posts lists are all considered Product lists in my Enhanced Ecommerce setup.\n Product list click: A click action on an article title or \u0026ldquo;Read more\u0026hellip;\u0026rdquo; link in the product lists.\n Product detail view: When the article is loaded.\n Add to cart: When scrolling begins on the article. I can assume that the reader wants to \u0026ldquo;buy\u0026rdquo; it if they start scrolling.\n Checkout: The Checkout funnel in my setup is based on scroll tracking. The first step is when the reader reaches one third of the article, the second step when they scroll two thirds, and the last step is when the article end is reached.\n Purchase: Purchase occurs when the checkout funnel is passed through, and a minimum of 60 seconds has elapsed since the article was loaded. This is an arbitrary number of seconds I simply chose to weed out casual readers from actual readers.\n  UPDATE: Thanks to an idea from Robert Petković, I updated the collection method with Product Detail impressions and Add To Cart actions. These were missing from the first version of this article. I also changed the checkout funnel to reflect scroll depth.\nHow to set it up First, here\u0026rsquo;s the Git repository link for this solution: eec-gtm.\nI\u0026rsquo;ll reveal a dirty secret from the get-go: I scrape the DOM for my setup. It\u0026rsquo;s definitely not the most robust way to go, but since I\u0026rsquo;m the developer, the marketer, the owner, and the content creator on my site, I can be safe to know that any changes to the page template are totally under my own control.\nThe way it SHOULD work is to leverage dataLayer. You have a number of options when doing this. You could, for example, store every single product on the page into dataLayer when the page is rendered, and then pick the relevant objects when impressions are loaded, or when user actions like clicks take place. Another way to go is to store the products in some other global JavaScript variable, which is, perhaps, a bit easier to access, but it does pollute the global namespace which should generally be avoided.\nAnyway, I scrape. I\u0026rsquo;m a scraper. I did it for science, for progress, for technology. And because I was a bit lazy and didn\u0026rsquo;t want to customise my WordPress hooks. But, in short, here\u0026rsquo;s how my setup works.\n1. Product impressions On every page which has product lists, I build the ecommerce.impressions Array as soon as the DOM has loaded. In this Array, each object is a single article title (+ ingress) that\u0026rsquo;s visible in one of the possible product lists. Product lists on my site are:\n Main posts - the home page listing\n Category posts - if a visitor has chosen to see all posts in a given category\n Tag posts - if a visitor has chosen to see all posts tagged with a specific tag\n Search results - the list of results you get if you use internal search\n Recent posts - the \u0026ldquo;Recent posts\u0026rdquo; widget in the sidebar\n Recent comments - the \u0026ldquo;Recent comments\u0026rdquo; widget in the sidebar\n GTM Tips - the \u0026ldquo;GTM Tips\u0026rdquo; widget in the sidebar\n  List position is determined by the order of posts in the list. An individual product object would look something like this:\n{ \u0026#39;category\u0026#39; : \u0026#39;analytics\u0026#39;, \u0026#39;id\u0026#39; : \u0026#39;TriggerGuideForGoogleTagManager\u0026#39;, \u0026#39;list\u0026#39; : \u0026#39;Main posts\u0026#39;, \u0026#39;name\u0026#39; : \u0026#39;Trigger Guide For Google Tag Manager\u0026#39;, \u0026#39;position\u0026#39; : 2 }  As you can see, it\u0026rsquo;s very simple. category is the WordPress category assigned to the post (there\u0026rsquo;s only every one category on my articles), id is a truncated version of the article title, name is the name of the article, and list and position define where the impression was listed.\nSo for every impression, I push an object like above into the Array. I also have a Promotion view for my \u0026ldquo;Were you looking for my GTM posts?\u0026hellip;\u0026rdquo; info box on the home page of my site, but this hasn\u0026rsquo;t proven very useful, so I might remove it.\nOn any given page, the Array might look something like this:\n  A very simple setup for a very simple purpose. I send this Array with a Non-Interaction: True Event tag, because I don\u0026rsquo;t want to delay my pageview from firing until the impression Array is built, and I don\u0026rsquo;t want impressions to affect bounce rate.\n2. Product list clicks I track product list clicks using a Link Click trigger. When someone clicks on an article title or the \u0026ldquo;Read more\u0026hellip;\u0026rdquo; link on the product list, I push details about the clicked product into dataLayer, together with the \u0026lsquo;productClick\u0026rsquo; value for the \u0026lsquo;event\u0026rsquo; key, which then triggers an Event tag.\n  Firing this event lets me see the effectiveness of my product lists. It gives me information about how the different lists fare in light of the entire customer journey from product impression to purchase.\n3. The Checkout Flow The checkout flow combines Product Detail impressions, Add To Cart actions, and the checkout flow itself.\nA Product Detail impression is sent as a Non-interaction: True event as soon as the article is loaded. This impression can thus be interpreted as the reader quickly checking out whether or not they want to read the article.\nThe Add To Cart action occurs when the user starts scrolling. The payload is sent with a normal Event tag to Google Analytics. I consider scrolling to be revealing of the reader\u0026rsquo;s intention to consume the content, but it\u0026rsquo;s not a checkout yet, as they might just want to skim the first paragraph.\nThe checkout flow itself is pretty cool. I use the scroll tracking plugin Justin Cutroni wrote about on his site. I\u0026rsquo;ve modified it to work with Google Tag Manager, and I also customised it to work with \u0026ldquo;Purchases\u0026rdquo; as well (see next chapter).\nHere\u0026rsquo;s how it works right now:\n I calculate the length of the content DIV in pixels.\n When the viewport of the user\u0026rsquo;s browser reaches one third of this length, the first checkout step is sent as a normal Google Analytics event. This step is labelled \u0026ldquo;Read one third\u0026rdquo;.\n When the browser reaches two thirds of the content length, the second checkout step is sent as a GA event. This step is labelled \u0026ldquo;Read two thirds\u0026rdquo;.\n When the browser reaches the end of the content DIV, the final checkout step is sent as a GA event. This step is labelled \u0026ldquo;Reached end of content\u0026rdquo;.\n Finally, if the user has reached Step 3 and spent a minimum of 60 seconds on the article page, the \u0026ldquo;Purchase\u0026rdquo; event is sent as well (see next chapter).\n    You\u0026rsquo;ll need to modify this funnel and the setup to match the type of content you write. You might want to change the dwell time from 60 seconds to something else, and you might want to add more steps to the checkout funnel (25 %, 50 %, 75 %, for example). For me, this level of granularity was enough.\n  That\u0026rsquo;s a sample checkout object for the second step of the funnel. As you can see, I have price as one of the properties of the article. Here\u0026rsquo;s the kicker: price is the number of words on the article. Naturally, I\u0026rsquo;ve turned it into a \u0026ldquo;.99\u0026rdquo; number to make it more realistic as an actual price :-) You\u0026rsquo;ll see the usefulness of this once I get to the reports.\n4. Purchase Like I wrote in the previous chapter, a \u0026ldquo;Purchase\u0026rdquo; event is pushed when the checkout funnel is completed, and the visitor has spent 60 seconds on the site. The purchase itself is a perfectly standard Enhanced Ecommerce Purchase object, which might look like this:\n  The transaction ID is basically epoch timestamp plus a string of random characters. The quantity of products in a transaction will always be 1.\nThe analysis So, let\u0026rsquo;s go over my favorite reports and segments. First, there\u0026rsquo;s the Shopping Behavior report:\n  As you can see, this shows the interactions during the selected timeframe. In this example, the timeframe is just one day. I\u0026rsquo;ve removed the absolute numbers, but I\u0026rsquo;ll update this screenshot once I have more data. The behavior funnel is fairly logical. There\u0026rsquo;s around 20 % drop-off on each step, with a larger abandonment leading up to purchase. 15 % of people never open an article, which is interesting! This could also be a measurement error thanks to my DOM scraping, but it\u0026rsquo;s still understandable considering the amount of traffic I get on my blog.\nAlso, 25 % of the people who start scrolling never reach one third of the article. This is also interesting. It means that there\u0026rsquo;s something in the first paragraphs that drives the reader away.\nThis data should next be segmented and carefully analysed. How can I optimise the funnel further? Two immediate concerns I have is the overall low conversion rate (only 25 % of my readers end up reading an entire article while spending more than 60 seconds on the article page), and the fact that only 40 % of people who start reading end up reading the article thoroughly. This is, of course, a sign of normalcy in the blogosphere, but it\u0026rsquo;s definitely something I want to improve.\n  Now this is interesting! Half of my readers start in the checkout funnel, and only half of these reach the end and read for more than 60 seconds. Talk about selective reading! My content is pretty lengthy by average, so it\u0026rsquo;s interesting to see if article length is a factor here. Or maybe some people just jump straight to the comments, which is perfectly understandable. Actually, I should track this as well! Mental note.\nSo there\u0026rsquo;s a big disconnect between starting to read and reaching the end of content. I might have to do something about this. Like, writing more interesting articles. But it\u0026rsquo;s still respectable how many people actually take their time to read the article.\nNaturally, one problem with this Checkout Funnel report is that the checkout funnel varies from article to article. Longer articles have a far higher threshold for hitting the funnel steps (since the steps are dependent on the pixel height of the content DIV), which means I should see a far higher rate for checkouts on shorter articles.\nNext, we have the Product Performance report:\n  Oh, this is so much fun. During the week, almost six million words have been \u0026ldquo;Purchased\u0026rdquo; on my articles! This means that six million words worth of article content passed through the checkout funnel into the Purchase column. Awesome!\n(UPDATE: I\u0026rsquo;m still waiting to get more data before updating this chapter with Buy-to-Detail and Cart-to-Detail rate analyses.)\nIf you look at Average Price, you can see that the list is topped by some of my longer articles. It\u0026rsquo;s still heart-warming to see some shorter ones on the top 10 list, delivering me \u0026ldquo;word revenue\u0026rdquo;.\nSales Performance isn\u0026rsquo;t very useful, since transactions are pretty arbitrary on my blog. I\u0026rsquo;ll jump straight to Product List Performance (sorry about the poor screenshot):\n  Key takeways from this report are that my sidebar widgets aren\u0026rsquo;t really useful. I should probably get rid of them as soon as I can think of something value-adding to put there instead. Well, the \u0026ldquo;Recent posts\u0026rdquo; list has a pretty high number of clicks, so I might preserve that.\n(UPDATE: I\u0026rsquo;m still waiting to get more data before updating this chapter with Product Adds To Cart analysis.)\nMy top-performing list is naturally the home page listing. It has a very respectable CTR of 16.47 %. \u0026ldquo;Category posts\u0026rdquo; and \u0026ldquo;Tag posts\u0026rdquo; are much less popular, but even they attract clicks quite a bit.\n\u0026ldquo;Search results\u0026rdquo; is doing very well, which is important. I want people to find what they were searching for. Naturally, I follow my most searched-for terms like a hawk, getting content ideas at the same time.\nSince I have all this amazing data at my fingertips, I can create a bunch of awesome segments as well:\n Whales: Revenue per user \u0026gt; 10000 - To track readers who\u0026rsquo;ve \u0026ldquo;purchased\u0026rdquo; more than 10,000 words in their lifespan.\n Passers-by: Transactions per user = 1 - To track readers who\u0026rsquo;ve only \u0026ldquo;purchased\u0026rdquo; a single article in their lifespan.\n Skimmers: Transactions per user = 0 AND Event Action exactly matches Checkout - To track readers who\u0026rsquo;ve started the checkout flow but never completed a \u0026ldquo;purchase\u0026rdquo;.\n Loyal readers: (Include Users) Revenue per hit \u0026gt; 3000 - To track readers who only read my longer articles.\n  And many other segments as well! Now I can segment my channels to see which channels bring the most valuable readers. Note that I don\u0026rsquo;t automatically consider it more valuable to have a reader read my longer articles, which is where the whole \u0026ldquo;words as price\u0026rdquo; idea falls down. I enjoy writing short articles as well, and especially my #GTMTips posts are usually a bit shorter length-wise.\nSummary I hope this post has been inspiring. The data I\u0026rsquo;m getting into my reports is so interesting and actionable. It does require tweaking, however, so I might need to work with the checkout funnel, in order to optimise the flow of reading from article load to the end of content.\nWith the help of one of my blog commenters, I\u0026rsquo;ve updated the setup to include Product Detail impressions and Add to Cart actions, but it will still take a week or so to get more data, so you can expect another update to this article soon.\nLet me know if you\u0026rsquo;ve tried something like this or if you have other ideas for tracking content with Enhanced Ecommerce! I\u0026rsquo;m sorry I can\u0026rsquo;t really give you a step-to-step guide at this point, but as I\u0026rsquo;ve done this with DOM scraping, I don\u0026rsquo;t really want to flaunt the solution, since I don\u0026rsquo;t consider it best practices. But they key thing in this article is to inspire you to think of your content in terms of funnels and transactions. I really love the new Enhanced Ecommerce reports, and I hope I\u0026rsquo;ve shown you how flexible they are for other uses as well than just web stores.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/prevent-repeat-transactions/",
	"title": "#GTMTips: Prevent Repeat Transactions",
	"tags": ["ecommerce", "Google Tag Manager", "gtmtips"],
	"description": "Use this method to prevent transactions from being sent to Google Analytics each time the user reloads the thank you page. This is necessary for accurate Ecommerce reporting.",
	"content": " In this tip, we\u0026rsquo;ll take a look at how to leverage a custom first-party cookie to prevent repeat hits of any kind. This is most useful for transactions, since a common problem with Google Analytics (traditional) eCommerce tracking is that a transaction hit is sent again upon subsequent entries to the receipt page, for example using the Back button of the browser. In some cases, and this is not a good practice, a receipt e-mail is sent to the user with a link back to the receipt page, where the transaction is sent over and over again upon entry.\nTip 11: Use a 1st Party Cookie to prevent hit multiplication   Here is the use case:\n User lands on the receipt page\n The transaction tag checks if the transaction ID is in the transaction cookie\n If the ID is in the cookie, the transaction tag does not fire\n If the ID is not in the cookie, the transaction tag fires\n The transaction ID is added to the cookie in the hitCallback of the tag\n  So it\u0026rsquo;s very similar to what I wrote some time ago about firing a tag just once per session.\nFor this to work, you\u0026rsquo;ll need four variables:\n Data Layer Variable for the key transactionId in the transaction payload on the receipt page\n 1st Party Cookie Variable, which retrieves the value of the cookie where all the user\u0026rsquo;s transaction IDs are stored\n Custom JavaScript Variable, which returns true if the transaction ID in the receipt page is found in the cookie\n Custom JavaScript Variable, which returns the callback function, where the current transaction ID is added to the cookie after the transaction tag has fired\n  Data Layer Variable: {{dlv transaction id}} This one is easy. Just create a new Data Layer Variable called {{dlv transaction id}}, and have it point to the variable where the transaction ID is stored on the receipt page (should be transactionId).\n1st Party Cookie: {{cookie user transactions}} Create a new 1st Party Cookie variable called {{cookie user transactions}}, and have it refer to whatever you want your cookie to be called. In this example, I\u0026rsquo;ll use user_transaction_ids.\n  Custom JavaScript: {{js is transaction id in cookie}} The purpose of this variable is to return true if the transaction ID on the thank you page is found in the cookie. This means that one of the conditions of the Transaction Tag firing trigger is a check for if the cookie value is not true. This would mean that the transaction ID has not been fired yet by this user. The code looks like this:\nfunction() { return /(,|^){{dlv transaction id}}/.test({{cookie user transactions}}); }  Custom JavaScript: {{js hitcallback set transaction cookie}} In this Custom JavaScript variable, we\u0026rsquo;ll add the value returned by {{transactionId}} to the cookie that\u0026rsquo;s referenced in the variable we just created above. Since I\u0026rsquo;m assuming the visitor can have multiple transactions, the cookie will be appended with the value, not overwritten. The expiration date depends on the lifetime of a single transaction ID. In my case, I\u0026rsquo;m assuming that they\u0026rsquo;re always unique, so I have an expiration time of two years (completely arbitrary figure). If you know that transaction IDs are not unique, you should make the expiration shorter to reflect this.\nHere\u0026rsquo;s what the {{js hitcallback set transaction cookie}} should have within:\nfunction() { return function() { var d, expires; var cvalue = \u0026#39;\u0026#39;; // Run the code only if a transaction is found in the data layer  if ({{dlv transaction id}}) { d = new Date(); d.setTime(d.getTime() + (2*365*24*60*60*1000)); expires = \u0026#39;expires=\u0026#39;+d.toUTCString(); // If the cookie already exists, append not overwrite  if ({{cookie user transactions}}) { cvalue = {{cookie user transactions}} + \u0026#39;,\u0026#39;; } document.cookie = \u0026#39;user_transaction_ids=\u0026#39; + cvalue + {{dlv transaction id}} + \u0026#39;; \u0026#39; + expires + \u0026#39;; path=/\u0026#39;; } }; }  Set up the tag Finally, you need to set up the tag. The only modifications you need to make are to the firing trigger and the hitCallback field. For the firing trigger, you need to add the following condition:\n{{js is transaction id in cookie}} does not equal true\nThis means that the tag will only fire if the transaction ID on the page template is not found in the cookie. Makes sense, right?\nNext, you need to set up the hitCallback field. So scroll down to More Settings -\u0026gt; Fields To Set, and fill in the values like this:\n  And that should do it.\nSummary Here\u0026rsquo;s what should take place when a user lands on the receipt page:\n The Transaction Tag checks if the transaction ID on the page template (stored in {{dlv transaction id}}) can be found in the value returned by the cookie variable {{cookie user transactions}}.\n If the ID exists in the cookie, it means that a transaction has already been fired with this ID, so nothing is done.\n If the ID doesn\u0026rsquo;t exist, the transaction tag fires.\n After the tag has completed execution, the hitCallback function, {{js hitcallback set transaction cookie}} is invoked.\n This function checks if the cookie already exists. If it does, it appends the current transaction ID to the end of the cookie (using a comma as the separator). If the cookie doesn\u0026rsquo;t exist, a new cookie is created with the transaction ID as its only value.\n This way any repeat visits to the page with the same transaction ID in the template will not cause the tag to fire again.\n  It looks like a complicated way to do things, and on some level it probably is. However, GTM and GA are stateless in the user\u0026rsquo;s browser. The only things they persist are the tracking cookies. Everything else has to be done by the user, which is why we need to manually create the cookies and the logic behind them.\nUPDATE: David Vallejo has written a great guide on how to achieve the same in Enhanced Ecommerce. Check it out!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/trigger-guide-google-tag-manager/",
	"title": "Trigger Guide For Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "rules", "triggers"],
	"description": "Comprehensive guide to Google Tag Manager&#39;s triggers. This trigger guide goes under the hood and gives educational examples of each trigger in use.",
	"content": " Updated 22 January 2018\nIn the new version of Google Tag Manager, one of the most visible and profound changes to the previous version is how tags are fired (and blocked). First of all, there\u0026rsquo;s the obvious terminological distinction: we talk about triggers now, not rules. Second, triggers have become an integral part of the tag creation workflow, and as such have far more significance in the user interface than before.\n  The following text is a standalone article. It\u0026rsquo;s not an update to the guide I wrote for the previous GTM version: Google Tag Manager: Playing By The Rules, and many of the concepts covered therein are still valid.\nTriggers introduce many new features and functionalities (a new way of doing auto-event tracking, for example), which require special attention.\nHere are the contents of this guide:\nAs always, feel free to add your thoughts in the comments after this post, if there\u0026rsquo;s some aspect of triggers that wasn\u0026rsquo;t adequately covered.\n1. What\u0026rsquo;s changed There are three major changes, in my opinion, to how triggers compare with the rules of the previous GTM version.\nI) Triggers are integrated into the workflow Sure, this is more a cosmetic thing, but it\u0026rsquo;s significant. In the previous version of Google Tag Manager, the entry-level for beginners was quite high. This was partly due to the fact that it wasn\u0026rsquo;t clear just what firing rules and blocking rules do. It got even more confusing once you started learning about stuff like implicit events and conditions, and it didn\u0026rsquo;t help that the UI gave very little hints about what to do next.\nIn the new UI, everything is about the workflow. There\u0026rsquo;s actually a question there now: What triggers this tag to fire? Nothing about firing rules or blocking rules, nothing about event conditions, and so forth. Just the simple, quite self-explanatory question. Of course, to understand what \u0026ldquo;fire\u0026rdquo; means, you will need to do some exploration, but the question sets the scene: a tag needs a trigger to fire.\n  So the biggest obvious change is in the UI. Triggers are an integral part of the workflow, and it\u0026rsquo;s impossible to not notice them, as you may have with rules in the previous version.\nII) You don\u0026rsquo;t need to explicitly state the \u0026lsquo;event\u0026rsquo; condition The second major change is how you input the event condition. If you\u0026rsquo;ve read my previous posts about rules, or if you\u0026rsquo;ve paid attention to the developer guides, you\u0026rsquo;ll know that every single tag needs an \u0026lsquo;event\u0026rsquo; push to fire. With \u0026lsquo;event\u0026rsquo; push I\u0026rsquo;m of course referring to a dataLayer.push() command that gives a value to the key labelled \u0026lsquo;event\u0026rsquo;.\n  This time around, you don\u0026rsquo;t need to explicitly state the required Event condition (i.e. the value that \u0026lsquo;event\u0026rsquo; key needs to have for the tag to fire). Instead, you rely on the available trigger types to set this condition up for you. In fact, the only time you have to explicitly state the name of the event is if you use a Custom Event type, and even then you don\u0026rsquo;t have to worry about setting it up as a proper condition. You just give the event its name in the required field (you can also use RegEx matching if you want more flexibility):\n  The point is that since Event is such a super-important part of any tag or trigger, it\u0026rsquo;s taken out of the normal condition-based setup for triggers and elevated to a grander status.\nIII) Auto-event tracking has changed I\u0026rsquo;ve already written a guide on this, and I\u0026rsquo;ll cover some of the concepts in this article as well, but this is really significant. Auto-event tracking is no longer tag-based, as it was in the previous version. Instead, you specify the event (click, link click, form submit, error, history event, or timer) by choosing one of the respective trigger types. Once you create a trigger for an auto-event type, GTM automatically starts listening for these events on your site.\n  This is incredibly convenient, since it reduces clutter in your tags, and it makes event tracking a very central part of any tagging setup (as it should be).\nThese are, in my view, the biggest changes. As a GTM fanboy, my honest and utterly biased opinion is that the improvements are amazing. There\u0026rsquo;s a learning curve, and I know that improvements are made to the UI constantly. But the way that triggers have been integrated into the tag workflow, without compromising any of the features carried over from rules, is a wonderful display of design skill.\n2. Technical overview It\u0026rsquo;s not like I\u0026rsquo;ve reverse engineered the GTM container JavaScript library (well, not all of it), but there are some interesting things to consider when working with triggers.\nFirst of all, as I said above, triggers require a dataLayer.push() or a pre-container-snippet declaration to fire a tag. If a push() command doesn\u0026rsquo;t have an \u0026lsquo;event\u0026rsquo; key, it becomes merely a \u0026ldquo;message\u0026rdquo; that\u0026rsquo;s added to the message bus. It does nothing for tags. You can see this in the debug mode. If there\u0026rsquo;s an \u0026lsquo;event\u0026rsquo; key in the message, the instance gets the name of the event (unless it\u0026rsquo;s one of the three default GTM events, see below) or just \u0026ldquo;Message\u0026rdquo; if there\u0026rsquo;s no \u0026lsquo;event\u0026rsquo; key in the command:\n  So if there\u0026rsquo;s an \u0026lsquo;event\u0026rsquo; key in the push(), a data layer helper object activates and goes through all the active triggers in your container. If any one of these matches the value of the \u0026lsquo;event\u0026rsquo; key, and if all the other conditions in the trigger pass, the tag is injected into the site and its code is executed.\nVery little has changed, then. You will still need to push \u0026lsquo;event\u0026rsquo; values to fire tags. The three default events are still gtm.js (pushed when the container snippet is first rendered in the page template), gtm.dom (pushed when the DOM has loaded), and gtm.load (pushed when the window has loaded):\n  One thing that has changed is how multiple triggers of same type on the same page are handled.\nSince there\u0026rsquo;s no longer a listener tag that you work with, it\u0026rsquo;s more than possible that you can have many link click triggers, for example, activating tags on the same page. It doesn\u0026rsquo;t mean that GTM always attaches a new event listener to the document node, because that would be an exercise in redundancy. Rather, all the triggers that use the same auto-event, e.g. gtm.linkClick, are evaluated when the event occurs.\nThis is fine in most cases, but it\u0026rsquo;s also possible that you have two Link Click triggers, where on one you have \u0026ldquo;Check Validation\u0026rdquo; set to ON, and on the other it\u0026rsquo;s OFF. This means that the first one only fires if the default action of the link click has not been prevented by other scripts, and the latter fires regardless. Since there\u0026rsquo;s just one listener controlling the firing of your tags, GTM leverages the gtm.triggers key in the auto-event object to specify which trigger should fire upon the event:\n  The value of the key is containerID_triggerID. So in this particular example, I had two Link Click triggers firing on the page, and one of them had \u0026ldquo;Check Validation\u0026rdquo; ON. I then clicked a link where I had prevented the default action of the click with event.preventDefault(). Thus, the gtm.triggers key tells our tags that only the trigger where \u0026ldquo;Check Validation\u0026rdquo; was OFF (id 27) is allowed to fire.\nThis makes for a very economical but still extremely robust setup for your auto-event triggers.\n3. Triggers in the workflow There are two obvious paths to creating triggers: 1) through the tag workflow, and 2) via the Triggers menu.\nBoth paths take you essentially through the same steps.\nIn the tag workflow, you can enter the trigger selection screen in three different ways:\n If the tag has no triggers, then clicking the big empty space with \u0026ldquo;Choose a trigger to make this tag fire\u0026hellip;\u0026rdquo; will open the trigger selector.\n If the tag already has triggers, then clicking the blue plus symbol lets you add new triggers to the tag.\n You can also click the ADD EXCEPTION link to add triggers that block the tag from firing.\n    In the trigger selection screen, clicking the blue plus button in the top right corner takes you to trigger creation mode.\nYou can also enter trigger creation mode by browsing to Triggers and clicking the red NEW button in the UI.\nRegardless of which path you take, this is what you\u0026rsquo;ll see:\n  Read on for information how to create your new trigger.\n4. New trigger creation When you start creating a new trigger, you should already have a good idea of which GTM event should fire your tag.\n  The trigger type is essentially a combination of the GTM event and the type of interaction (or event) you want GTM to start listening to.\nHere are the trigger types currently available:\nPage View:\n DOM Ready - fires the trigger on the gtm.dom event, once the browser has loaded the document object model.\n Page View - fires the trigger on the gtm.js event, as soon as the GTM container has loaded.\n Window Loaded - fires the tirgger on the gtm.load event, dispatched once the entire page and all linked resource have completed loading.\n  Click:\n All Elements - fires the trigger on the gtm.click event, dispatched when any element is clicked on the page.\n Just Links - fires the trigger on the gtm.linkClick event, dispatched when a link (\u0026lt;a\u0026gt;) HTML element is clicked on the page.\n  User Engagement:\n Element Visibility - fires the trigger on the gtm.elementVisibility event, when an element becomes visible on the page.\n Form Submission - fires the trigger on the gtm.formSubmit event, dispatched when a form submission is detected.\n Scroll Depth - fires the trigger on the gtm.scrollDepth event, dispatched when the user scrolls the page.\n YouTube Video - fires the trigger on the gtm.video event, dispatched when a video is viewed on the page.\n  Other:\n Custom Event - fires the trigger when an event key is pushed into dataLayer with a custom value.\n History Change - fires the trigger on the gtm.historyChange event, dispatched when a window history event is detected.\n JavaScript Error - fires the trigger on the gtm.pageError event, dispatched when an uncaught JavaScript error is thrown on the page.\n Timer - fires the trigger on the gtm.timer event, dispatched when the timer trigger interval is met.\n  There\u0026rsquo;s bound to be more in the future. Especially the various events you can listen to with JavaScript are still vastly under-utilised (check this post for ideas how to extend them).\n  The next step is to choose any trigger-specific settings. With the DOM Ready trigger, for example, you can delimit the trigger to only fire on specific page URLs.\nIf you choose All (event type), the only condition in the trigger will be the event type. That means that your tag will fire every single time the event you specified is pushed into dataLayer. So if, for example, you chose a Click / All Elements trigger type, and you specify All Clicks as the filter, your tag will fire every single time a click is registered on the site (overkill much?).\n  If you choose Some (event type), you will need to specify the other condition(s) for your tag to fire. These can be anything you like, such as data layer variable values, page path matches, etc. As before, you can specify multiple conditions, but if you do, every single one of these conditions must pass for your tag to fire. There\u0026rsquo;s no either-or relationship here. Conditions are final.\nWith \u0026ldquo;Link Click\u0026rdquo;, \u0026ldquo;Timer\u0026rdquo; and \u0026ldquo;Form\u0026rdquo; triggers, you\u0026rsquo;ll see some extra settings in the Trigger, depending on what settings you choose. With \u0026ldquo;Timer\u0026rdquo;, you can set up the timer that will fire your tag after a given interval (or given intervals), and with Link Click and Form triggers, you might need to specify the conditions for the listener itself (see next chapter).\nAnd that\u0026rsquo;s it. If you\u0026rsquo;re in the tag creation workflow, you will now return to your tag, where you can add other triggers or an exception.\nIf you want to add multiple triggers to a single tag, do note that multiple triggers on the tag are in an either-or relationship. So having multiple triggers on a tag will make the tag fire when any of the triggers fire, which means that your tag can fire multiple times on a page unintentionally.\nHowever, if the underlying event on these multiple triggers is the same (e.g. Click), your tag will, by default, fire only once for every click event regardless of if there\u0026rsquo;s overlap in the triggers. You can change this behavior by opening the tag\u0026rsquo;s advanced settings:\n  Adding exceptions is simple enough. Just click ADD EXCEPTION in the tag\u0026rsquo;s trigger selection, and choose a trigger which will block the firing of the tag.\nWith exceptions, blocking triggers will always win against firing triggers. However, blocking triggers always need a firing trigger with the same underlying event, otherwise they\u0026rsquo;re useless. This is because when an \u0026lsquo;event\u0026rsquo; key is pushed into dataLayer, the blocking trigger can only block a trigger which fires on the same \u0026lsquo;event\u0026rsquo;, since they are evaluated at the same time against the same value of the \u0026lsquo;event\u0026rsquo; key (complicated, I know!).\nRead more about it here: #GTMTips: Block Your Tags With Trigger Exceptions.\n5. Click and Form triggers Since I\u0026rsquo;ve already written about these in my latest auto-event tracking guide, I want to just briefly explain what makes these two triggers special.\nFirst of all, skip the generic Click / All Elemenets trigger. Nothing special about that. It just listens to all clicks on your site, regardless of what element you click.\nThe Just Links trigger, however, only listens for clicks which propagate up to a link (\u0026lt;a/\u0026gt;) node. This means that you can click on a SPAN in a BUTTON in a DIV, but as long as there\u0026rsquo;s a link wrapper somewhere up the ancestral tree, and as long as the event propagates, GTM will register the event as a link click.\nThe Form trigger waits for a submit() event to be dispatched. This means that if some script on your site hijacks the form event and proceeds with some proprietary Ajax function, for example, GTM\u0026rsquo;s listener will not be able to pick it up.\nSo remember these two things: Just Links triggers require a click on a link, and Form triggers require a valid browser form submit event. Both need propagation to work.\nYou might have noticed the two clickable options on these two particular trigger types: Check Validation and Wait For Tags. Once you check either, you\u0026rsquo;ll see an extra step, Enable When, in the Trigger settings:\n  The point with this step is that you\u0026rsquo;ll be able to specify a condition for when the trigger is actively listening for the specified event. The most common condition types you\u0026rsquo;ll use here are page conditions, since you might want to specify that the Form Submit trigger only listens for submit events on pages with forms.\nThe reason this step was introduced is due to how the two checkable options, especially Wait For Tags, work. So let\u0026rsquo;s do a quick overview.\nCheck Validation, when checked, will require that a valid action is propagated to GTM\u0026rsquo;s listeners. With both Just Links and Form this means that there\u0026rsquo;s no event.preventDefault() called by other scripts on the event object before it reaches GTM\u0026rsquo;s handlers.\nHowever, in many cases it\u0026rsquo;s not just that the default action of the event is prevented, in which case GTM\u0026rsquo;s listeners will still pick up the event if Check Validation is OFF. Often you\u0026rsquo;ll see that propagation is stopped as well, which prevents GTM\u0026rsquo;s listeners from picking anything up. Be sure to see my previous two posts on the topic.\nWait For Tags ensures that all tags that fire on the trigger execute first before proceeding with the action of the event. So if it\u0026rsquo;s a Just Links trigger, the redirect (or whatever is the action) is programmatically halted long enough for all dependent tags to complete execution, after which the action is resumed. Same thing with forms.\nAnd this is the reason you need to specify the secondary filter. Since GTM is the one that halts the default action of the event, it\u0026rsquo;s possible that it screws something up in the propagation path. I\u0026rsquo;ve seen cases where the \u0026ldquo;Wait For Tags\u0026rdquo; option caused a pop-up blocker to pick up otherwise perfectly innocent lightboxes. Only by deactivating \u0026ldquo;Wait For Tags\u0026rdquo; was the problem solved.\n NOTE!!! The \u0026ldquo;Wait For Tags\u0026rdquo; can be very invasive on single-page apps, where link handling is completely customized. On single-page apps, an \u0026ldquo;internal\u0026rdquo; link should never lead to a redirect. GTM, however, does not know this. By pausing the event and then proceeding with the default action, it\u0026rsquo;s possible that \u0026ldquo;Wait For Tags\u0026rdquo; causes links to redirect when they shouldn\u0026rsquo;t.\nThus you should always be very careful with Wait For Tags and ONLY activate it on pages where you have THOROUGHLY tested it doesn\u0026rsquo;t interfere with the site\u0026rsquo;s default functionality.\n 6. Triggers in the API Since I\u0026rsquo;ve such a huge fan of the GTM API (see my GTM Tools), I wanted to say a few quick words about triggers and the API.\nTriggers are a pollable resource just like anything else in the API. You can list them, retrieve them, update them, delete them, create them, etc.\n  However, in their current state, there\u0026rsquo;s a complication. If you want to copy a tag from one container to another, the problem is the trigger ID. Each trigger has an ID, which, I think, is roughly the first available number in a sequence starting with 1. If you use a trigger in a tag, the tag will refer to this trigger using this ID.\nNow, when you want to copy this tag to another container, you create a new tag in the target container with this tag resource as the body. The problem is that the target container can already have a trigger with the ID, since they all follow the same logic when assigning the ID!\nThis means that when copying a tag with triggers to another container, what you actually need to do is this:\n First create the trigger(s) in the new container\n Use the object you receive in the response to see what the new trigger IDs are\n Update the tag resource with the new trigger IDs\n Create the tag in the target container\n  It\u0026rsquo;s a pretty complex operation for something as simple as resource cloning, and I hope it will resolve to a simpler solution in the future.\nYou don\u0026rsquo;t have this problem with variables, as variables are referred to by name, not ID.\n7. Tag Sequencing One important thing to know about triggers and tag sequencing is that if a tag is part of a tag sequence (either as a Setup or Cleanup tag), all its triggers are ignored.\nIn other words, tag sequencing trumps triggers. If a tag fires either before or after the main tag in a sequence, it will be completely controlled by the triggers of the main tag. The only way to prevent the tag from firing in a sequence is to pause it.\n8. Summary That\u0026rsquo;s all I have to say about triggers, for now. I\u0026rsquo;m cautiously apprehensive about possible changes to the UI, as I\u0026rsquo;m sure there will be in the near future.\nTo sum it up, triggers work like a charm. It\u0026rsquo;s so important for usability to have them integrated into the workflow as they are now. At the same time, they haven\u0026rsquo;t lost any of their power, quite the contrary. The new, Trigger type -based approach to underlying events is an excellent addition, since it helps us focus on what\u0026rsquo;s important, instead of having to battle with confusing condition syntax.\nThere are things to be improved in the workflow. I don\u0026rsquo;t especially enjoy having to work through the Variables page to prepare my triggers (if the variables I need do not exist), and I think there\u0026rsquo;s still some unification of the UI called for, since, for example, the Some Pages view is so very different from all the other trigger choices.\nPlease sound off in the comments if I\u0026rsquo;ve missed something obvious. I would love to keep this guide as up to date as possible.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/check-if-google-analytics-is-in-page-template/",
	"title": "Check If Google Analytics Is In The Page Template",
	"tags": ["Google Tag Manager", "Guide"],
	"description": "Guide for creating a variable which checks if Google Analytics is hard-coded in the page. This is useful if you want to check for duplicate implementations via Google Tag Manager.",
	"content": " One of the recurring problems in migrating to Google Tag Manager is how to make the transition as smooth as possible. Usually it requires that we agree with the developers on a time when the old code is removed, and at that moment we need to make sure the GTM tags point to the right UA code. This is, of course, only one use case for migrations, as some people do the entire migration in a staging environment, and some just don\u0026rsquo;t care if they lose a little bit of data along the way.\nHowever, the most seamless way to do the transition is to automate it. Make GTM somehow check for the existence of on-page GA, and if it finds it, the tags will not fire. As soon as the on-page GA is no longer found, GTM can go rampart.\nThis is a recurring discussion in our Google+ GTM Community, but this time it began in Twitter. Here\u0026rsquo;s the gist of it:\nI need a GTM rule for GA code existing on the website - suggestions? #measure\n\u0026mdash; Peter O\u0026#39;Neill (@peter_oneill) November 27, 2014  In this post, I wanted to take a shot at what my good friend Peter is looking for, with what I think is the best way to do this.\nNow, there are a number of ways you could go about checking for on-page GA, including:\n Check for existence of GA cookies\n Very unreliable as cookies persist after removing on-page code, and if migration is to the same version of GA, the cookies are the same  Serialize page template, and regex match for script loaders or calls to the tracking objects\n Crazy solution (that I just came up with), and isn\u0026rsquo;t very reliable. Fails completely if scripts are loaded in external JS files  Ask developers to add dataLayer.push() that tells the status of on-page GA\n By far the most reliable solution out there, but the reason most people are looking for a solution like this is to minimize developer intervention  Check for existence of ga or _gaq objects\n Works well if you can bear the wait for the tracking library to load AND execute, as the objects are created in the library code. On some sites, this might be a too long wait, especially if the library is loaded asynchronously. Also, you can rename the ga object, so you\u0026rsquo;d need to identify it first.   But I want to show you what I think is the best way to do it. Feel free to disagree, and I find myself disagreeing with me as well, especially on a complex site! In my opinion, the following solution does the check as early as possible, and it\u0026rsquo;s as reliable as it can be, even though there are some caveats.\nSolution: look for the \u0026lt;script\u0026gt; elements This solution looks for the existence of \u0026lt;script\u0026gt; elements, where either ga.js, analytics.js, or dc.js are loaded.\nI think it\u0026rsquo;s pretty reliable, as if the script element is injected in proper form, it means that the libraries have loaded or have begun to load.\nHere\u0026rsquo;s the Custom JavaScript Macro for this. It returns \u0026ldquo;true\u0026rdquo; if it finds any of the libraries you specify.\nfunction() { var scripts = document.getElementsByTagName(\u0026#39;script\u0026#39;), ga = true, // set to false if you don\u0026#39;t want to check for ga.js  ua = true, // set to false if you don\u0026#39;t want to check for analytics.js  dc = false, // set to false if you don\u0026#39;t want to check for dc.js  i = len = 0; if (ga || ua || dc) { for (i, len = scripts.length; i \u0026lt; len; i += 1) { if (ga \u0026amp;\u0026amp; /www\\.google-analytics\\.com\\/ga\\.js/.test(scripts[i].src)) { return true; } if (ua \u0026amp;\u0026amp; /www\\.google-analytics\\.com\\/analytics\\.js/.test(scripts[i].src)) { return true; } if (dc \u0026amp;\u0026amp; /stats\\.g\\.doubleclick\\.net\\/dc\\.js/.test(scripts[i].src)) { return true; } } } return false; }  So now you can add {{check for scripts}} equals true as a blocking trigger in your GTM GA tags.\nThere are some shortcomings to this method. For example, the page can load the libraries but not do any tracking. This can be true for legacy setups, where only the _gaq.push() commands have been removed, but the library load remains. So naturally, you will have to audit the site before implementing this solution.\nI tested this out a couple of times on my own blog, using it as the blocking rule of my pageview tag, and it seemed to work fine.\nNaturally, since the ga.js snippet is added to the end of the page (stupid, synchronous script), you might need to wait for gtm.dom before checking the blocking rule, especially on heavy pages.\nSummary Remember, this simple solution is only for the transition from on-page GA to GTM. The only thing it does is prevent you from having to sit in front of a computer, constantly refreshing the page to see if the on-page code has been removed.\nA migration requires vigilance, so even if you manage to automate the transition with this solution, you will still need to be alert throughout the process. But you knew this already (didn\u0026rsquo;t mean to sound condescending).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/simple-regex-lookup-table-for-google-tag-manager/",
	"title": "Simple RegEx Table For Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "lookup table", "variable"],
	"description": "Simple way to build a regular expression lookup table in Google Tag Manager.",
	"content": " When our good friends in the Google Tag Manager developer team first introduced the Lookup Table Macro, we were excited. For many of us, it soon became the weapon of choice especially when used as a management and optimization tool for the container itself.\n  However, the macro wasn\u0026rsquo;t considered perfect. In fact, the most frequently heard request had to do with the core functionality of the feature itself: the macro should support operations, that is, predicate logic. It\u0026rsquo;s not enough to just have equal match lookups; people wanted support for operations such as \u0026ldquo;is x larger than y\u0026rdquo; or \u0026ldquo;does y contain x\u0026rdquo;.\nThe thing is, I don\u0026rsquo;t agree with changing the Lookup Table Macro to support these types of operations. Sure, a table whose values you can query with more complex operations than simple lookups would be awesome, but it wouldn\u0026rsquo;t be a lookup table anymore. We\u0026rsquo;d need a different variable type for those use cases.\nIn this post, I\u0026rsquo;ll take a look at just what makes a lookup table a lookup table, and I\u0026rsquo;ll also give you a nifty Custom JavaScript variable that lets you create a regular expression table by yourself. This table lets you query an input variable (e.g. {{Page Path}}) against a number of regular expressions (rows). If a match is made, then some value is returned. So, it\u0026rsquo;s essentially a variation of the Lookup Table, but with regular expressions instead of exact match lookups.\nLook it up! Even though I\u0026rsquo;m a product of the unsurpassed Finnish education system, I suck at ornithology. So you\u0026rsquo;ll excuse me for the following, clumsy metaphor.\nConsider the homing pigeon. It has an intimate knowledge of a location, and it flies to that location. If there is nothing there, it gets confused and poops. If it does find a recipient or a message, it does its thing and coos happily.\nWell, when you have a lookup table, it\u0026rsquo;s the same thing. You use a variable reference to pinpoint to a specific cell in a table. If this cell exists, any value stored within is returned. If the cell doesn\u0026rsquo;t exist, the script gets confused and poops an undefined or an error.\nThis is what makes lookup tables so incredibly efficient. It\u0026rsquo;s all based on binary logic.\nThere are no complex operations, no predicates to be evaluated. It\u0026rsquo;s just a question of \u0026ldquo;does table X have a value under label Y\u0026rdquo;.\nIn JavaScript, a lookup table can be a plain object (most common), or an Array, or even a String. Basically, it can be any Array-like structure.\nIf you use a plain object as a lookup table, it\u0026rsquo;s common to call it an associative array or a hash table, but we\u0026rsquo;ll call them lookup tables here for clarity.\nSo, you can perform lookups on all Array-like structures. The three examples listed above can be used for lookups like this:\n// Plain object var newValue = objectTable[\u0026#39;key\u0026#39;]; // Array var anotherValue = arrayTable[3]; // String var newestValue = \u0026#39;String\u0026#39;[5];  With the plain object, you can also use dot notation in some cases.\nAs you can see, you\u0026rsquo;re directly requesting a specifically labelled value in the table, and if it exists, it\u0026rsquo;s returned to you without any further operations.\nNow, if you were to introduce predicate logic into the mix, with something like table['[Kk]ey'] (fictional example), it would mean that the lookup should check every single cell until a match is made in the table to see if they have either \u0026lsquo;Key\u0026rsquo; or \u0026lsquo;key\u0026rsquo; as their label.\nThis is because with JavaScript data structures, a label can only ever be one thing. With lookup tables, you\u0026rsquo;re requesting for a given label without any variations, e.g. \u0026lsquo;Key\u0026rsquo;, and only that label is thus queried in the table. This is because programming logic dictates that only one cell can exist in the table with that label.\nAs soon as you add predicate logic into the mix, you\u0026rsquo;re forcing the lookup to check every single cell until a match is made, because you can\u0026rsquo;t label cells with regular expressions or dynamic values (e.g. \u0026lsquo;Key/key\u0026rsquo;).\nThe difference between the binary check of the lookup vs. the traversal of a more complex operation becomes clearer when thinking in terms of performance.\nQueries on a lookup table are said to work in constant time. Since you\u0026rsquo;re querying for a specific label in a table of arbitrary size, the complexity of the operation will always be the same. Either the label exists or it doesn\u0026rsquo;t. The table can be huge or it can be miniscule, the performance is always the same.\nPerformance is usually indicated with Big O notation. The notation for constant time (i.e. the lookup) would be O(1).\nWhen using predicate logic, you achieve O(1) only if you match the query with the first cell that is checked. Every subsequent cell that is checked for a match incurs a linear decrease in the performance. Thus, comparison logic is said to work in linear time.\nDescribing linear time operations with O(1) would be fairly optimistic. For this reason, Big O notation tends to describe the worst-case scenario. The worst-case scenario of linear time would be that the value is in the very last cell that is queried. Thus, the notation would be O(n), where n is the number of cells in the table.\nThis also means that the larger the table, the more expensive the operation becomes, in terms of performance.\nWith small tables this difference is pretty trivial, but with large tables and multitudes of chained variables, the performance hit can be significant, especially if it takes time to make the match, and the labels are arbitrary enough that you can\u0026rsquo;t use facilitating data structures or search algorithms.\nSo if you\u0026rsquo;re concerned about performance, and you should be if it\u0026rsquo;s a web page, always use the Lookup Table variable.\nRegEx Lookup Table with Custom JavaScript Well I know you\u0026rsquo;re not satisfied with my explanation, and you\u0026rsquo;re still craving for a more flexible way to fetch values from a table.\nI hope the GTM developers will, at some point, introduce another variable type that\u0026rsquo;s essentially a lookup table but where you can specify the predicate logic used row-by-row.\nUntil then, you can make do with workarounds such as the script below.\nCopy the following code into a new Custom JavaScript Variable:\nfunction() { // Set inputVariable to the input you want to assess  var inputVariable = {{Page URL}}; // Set defaultVal to what you want to return if no match is made  var defaultVal = undefined; // Add rows as two-cell Arrays within the Array \u0026#39;table\u0026#39;.  // The first cell contains the RegExp you want to match  // the inputVariable with, the second cell contains the  // return value if a match is made. The third cell (optional),  // contains any RegEx flags you want to use.  //  // The return value can be another GTM variable or any  // supported JavaScript type.  //  // Remember, no comma after the last row in the table Array,  // and remember to double escape reserved characters: \\\\?  var table = [ [\u0026#39;/home/?$\u0026#39;, \u0026#39;Home Page\u0026#39;], // Row 1  [\u0026#39;\\\\?location=\u0026#39;, \u0026#39;Contact Us Page\u0026#39;], // Row 2  [\u0026#39;/products/[123][0-9]\u0026#39;, \u0026#39;Products 10-39\u0026#39;, \u0026#39;i\u0026#39;] // Row n (last)  ]; // Go through all the rows in the table, do the tests,  // and return the return value of the FIRST successful  // match.  for (var i = 0, len = table.length; i \u0026lt; len; i += 1) { var regex = new RegExp(table[i][0], table[i][2]); if (regex.test(inputVariable)) { return table[i][1]; } } return defaultVal; }  Here\u0026rsquo;s how the variable works:\n First, you give it the input: some variable or value that you want to assess in the table rows\n Next, you insert the rows\n Rows are actually Arrays within the table Array\n The first cell contains the regular expression you want to evaluate against the input (note, you will need to double escape reserved characters!)\n The second cell contains the value that is returned if a match is made\n The third cell is optional, and can contain any regular expression flags (e.g. \u0026lsquo;g\u0026rsquo;, \u0026lsquo;i\u0026rsquo;) you might want to use\n  Finally, there\u0026rsquo;s a little for-loop which loops through each row of the table Array, checking the regular expression against the input variable. If and when a match is made, the specified return value is returned by the function\n If no match is made, the specified default value is returned\n  Remember to edit the rows to match your table. Since it\u0026rsquo;s plain text JavaScript, you could also create the table in Excel (formatting it with the square brackets and all), and then just copy-paste it as plain text to the JavaScript macro body.\nSummary As always, this solution is educational first, a proof-of-concept second, and a usable, out-of-the-box workaround last. So feel free to modify it to your own purposes, or just ditch it completely.\nThe key takeaway from this article should be an understanding of how Lookup Tables work, and how much more complicated they would get if operational logic would be introduced as well. For that reason, my feature request remains that the Lookup Table would be kept as it is, but a new variable type would be introduced, where you can specify the operation on a row-by-row basis. This way, everyone wins.\nBy the way, if you\u0026rsquo;re interested in performance, JavaScript, and other data structures and search algorithms, take a look at this book:\nMichael McMillan: Data Structures and Algorithms with JavaScript\nThe book has the basics summed up really well. The next step would be to grab a book about design patterns and more complex data structures. It\u0026rsquo;s all very educational.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/fix-problems-with-gtm-listeners/",
	"title": "#GTMtips: Fix Problems With GTM Listeners",
	"tags": ["auto-event tracking", "event listeners", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "Tips for how to fix problems with Google Tag Manager&#39;s triggers. Typical issues are that the Just Links of Form triggers do not work.",
	"content": " I\u0026rsquo;ve written about this before here and here, but this issue remains probably the biggest problem users have when implementing Google Tag Manager.\nTip 10: Resolve conflicts with GTM\u0026rsquo;s listeners   The tip title is actually wrong. You\u0026rsquo;re not fixing Google Tag Manager listeners. Rather, you\u0026rsquo;re resolving conflicts that other scripts on your page might introduce.\nGTM\u0026rsquo;s event listening is based on something called event delegation. Event delegation makes use of the document object model (DOM) and its tree-like hierarchy.\nWhen a click occurs on a node, such as a link element, the click event begins to bubble up the DOM tree. It passes through every single ancestral node on its way to the top. This means that instead of attaching a listener to every single link element, GTM attaches the listener on the top-most document node (the document itself). This way it will capture the event once it has bubbled up all the way to the top. It\u0026rsquo;s much more economical to listen for events this way, as you don\u0026rsquo;t have to pollute the elements with individual handlers.\n  A conflict occurs when somewhere along this way up, the event\u0026rsquo;s path is obstructed. The term we use here is that its propagation is stopped. If this happens, GTM\u0026rsquo;s listeners never capture the event, and thus they will never work with your tags.\nThe most common way that propagation is stopped is:\nreturn false; in a jQuery event handler\nIf there\u0026rsquo;s a return false; in your jQuery event handler, propagation is stopped. The return false; statement in jQuery combines both preventDefault() AND stopPropagation() on the event object. There\u0026rsquo;s an easy fix to this: invoke ONLY preventDefault(). This should work almost always, unless there\u0026rsquo;s a specific reason you want propagation to stop.\nFor example:\n// Before - propagation stopped $(\u0026#39;a#toTop\u0026#39;).on(\u0026#39;click\u0026#39;, function() { // some code  return false; }); // After - propagation not stopped $(\u0026#39;a#toTop\u0026#39;).on(\u0026#39;click\u0026#39;, function(e) { e.preventDefault(); // some code });  preventDefault() prevents the default action of the click but it doesn\u0026rsquo;t stop propagation. I\u0026rsquo;d say around 95% of the time, this is enough for your dynamic scripts.\nThere are other ways to stop propagation (such as an explicit call to e.stopPropagation()), but the jQuery scenario is by far the most common one.\nFix it! The first thing you want to try is to uncheck Check Validation in your link click or form submit trigger. If Check Validation is on, it means that GTM\u0026rsquo;s handlers will not fire even with a proper preventDefault(). The listener will only fire if an uninterrupted / untouched event object propagates to the document node.\nThe second thing is to look through your scripts and try to find the offending jQuery / other handlers. Look for hints of propagation being stopped. Fix them yourself or ask your developers to fix them. Look for custom AJAX functions as well, especially with forms. With forms, it\u0026rsquo;s possible that a submit() is never called. Instead, an AJAX POST request is sent to a backend validator or something.\nThe third thing you should try is the best: talk to your developers. Educate them. Tell them that GTM\u0026rsquo;s listeners require that clicks and form submits propagate to the document node. If they get that, they should be able to fix it. If they don\u0026rsquo;t understand this, make them learn the basics of JavaScript again.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-analytics-page-load/",
	"title": "Google Analytics And The Page Load",
	"tags": ["dom", "google analytics", "Google Tag Manager", "Guide"],
	"description": "An article describing how Google Analytics interacts with, and is influeced by, the page load of the web browser. The rendering process has implications for your web analytics setup.",
	"content": " If you use Google Analytics, Google Tag Manager, or any JavaScript-based data collection or analytics platform, have you ever stopped to wonder how they actually work? I mean, you obviously care about getting the data in, but are you taking the machinations of these tools for granted?\nThis is something I\u0026rsquo;ve been thinking about for a long while, because I\u0026rsquo;m not so sure that many who work with these platforms actually understand how the browser and the web page interact.\nThat doesn\u0026rsquo;t make sense. And it scares me a little.\nSince the predominant paradigm for web analytics today revolves around JavaScript, it\u0026rsquo;s important to have a sense of what the weak links in this technology are. Also, even before JavaScript kicks in, there are certain aspects of the page load process that you need to observe to get better quality data.\nFortunately, even the most basic understanding of these leads to elucidation: No, the tools do not cover 100 % of the visits to your site, no, \u0026ldquo;pageviews\u0026rdquo;, \u0026ldquo;sessions\u0026rdquo;, and \u0026ldquo;users\u0026rdquo; should not be taken literally, and no, it\u0026rsquo;s most often not Google Tag Manager or Google Analytics that\u0026rsquo;s at fault when tracking on your site fails. You\u0026rsquo;ll find the real culprit by opening the JavaScript console on your darling website, but don\u0026rsquo;t forget to close this dimension rift to the nether pits of the hell of all hells once you\u0026rsquo;re done, lest some of the demon spawn gets through.\n  The core of this article boils down to a simple statement:\nThe only way to evaluate the quality of the data you use is to understand how it was collected. Keeping this in mind, I want to take a look at the page load sequence in the user\u0026rsquo;s browser, and what implications the different parts of the load process have on Google Analytics tracking.\nThe sequence of events in the page load   This short essay (or long rant, however you want to see it) is split into a number of sections. Each section represents a stage in the intricate process of what takes place in the user\u0026rsquo;s browser when they visit your website. Each part of this process has implications for how you can and should track the interactions this user has with your content.\n The Request - What happens when a user types an address into the location bar of the browser, and what are the pressure points for web tracking.\n The Render - How the browser turns the source code into a living document.\n The Race - How asynchronous JavaScript works, what race conditions are, and what you should watch out for.\n The Interaction - Once the page is loaded, how are user interactions measured, and what are the biggest pitfalls here.\n  As always, I wrap up with a summary.\n  Everything starts with the request.\nWhen a user types your website address into the browser\u0026rsquo;s location bar, the desired outcome is usually that they see a web page. In order for this to happen, the browser uses the HTTP protocol to issue a request to the machine that hides behind the address.\nIf there is a web server at that endpoint, if that endpoint has mapped the requested address to some resource, and if the request is valid (there\u0026rsquo;s no additional authentication required, firewalls don\u0026rsquo;t block the request, no security policies are violated etc.), the web server sends an \u0026ldquo;OK\u0026rdquo; response, most commonly with a status code 200, and the document that was mapped to the address in the response body.\nThis document is usually an HTML template file, i.e. the page source code, and the browser\u0026rsquo;s job is to turn this document into a dynamic web page.\nI mean, obviously, it\u0026rsquo;s a much more intricate and complex process than this, but the key interaction here is what happens when the web server receives the request.\nFor successful collection of data to Google Analytics, there are some things here that you need to be aware of.\n1) 404 - Resource not found If there is no resource mapped to the address the user requested, it means that the web server has to respond with a \u0026ldquo;resource not found\u0026rdquo; error. Now, at this point your web server should be configured so that if there is no resource to send to the user, a \u0026ldquo;Page not found” template is served instead.\nYou should have GA running on this page with a tag that tracks pageviews. 404 page tracking is a wonderful addition to the toolset of any savvy webmaster-slash-analyst.\nIf you haven\u0026rsquo;t set up a template, the user might see the default error page served by your web server (they\u0026rsquo;re usually pretty horrible), or, lacking that, the browser will cook up an error message instead (even more horrible). The key here is that if you don\u0026rsquo;t have a custom template with the GA tracking code, you won\u0026rsquo;t be able to track these hits in Google Analytics. For example, my GTM Tools serves the following, unhelpful, untrackable default page if no resource is found:\n  This is a bad practice. Use a custom template instead.\nCheck the Lunametrics post if you want to see a great way of tracking 404 errors in GA and GTM!\n2) Redirects If you\u0026rsquo;ve set up a redirect server-side, you must remember preserve query string parameters in the redirect! If you strip them out in the redirect, you\u0026rsquo;ll risk losing important campaign tracking information.\nThis is essential to preserving data quality!\n3) Single-page apps If your website is essentially a single-page app, where instead of the expected HTTP GET request, the user\u0026rsquo;s browser sends POST calls, the rules of traditional page tracking change a little.\nYou can no longer trust the reset that occurs with every page load, since there are actually no page loads after the first one. Instead, you\u0026rsquo;re going to have to come up with a new terminology for tracking your visitors. For some it\u0026rsquo;s scroll tracking, via events or virtual pageviews, and for some it\u0026rsquo;s tracking user interactions with the page, such as clicking on tabs or call-to-action buttons, and for some it\u0026rsquo;s invoking GTM\u0026rsquo;s history listener, which reacts to changes in browser state.\nIf you\u0026rsquo;re using Google Tag Manager, an important aspect of these single-page apps is that the dataLayer object is not reset as it is with page refreshes. That\u0026rsquo;s because in a web context, the painstakingly rendered web page with all its variables, objects, elements, texts, links, images, and other clutter is recreated with every page refresh. In other words, objects on a given page do not persist to other pages. With a single-page app, there is no page refresh, so there\u0026rsquo;s no purge. The data layer is alive for the entire time the user stays on the page, meaning it\u0026rsquo;s more than possible that anything you store into dataLayer and send to GA might be sent with subsequent hits as well.\nWith single-page apps, then, you need to be aware of the state of dataLayer at all times, and if necessary you need to emulate a page refresh by deleting keys that you don\u0026rsquo;t want to persist:\ndataLayer.push({ \u0026#39;key_to_be_deleted\u0026#39; : undefined });  4) Don\u0026rsquo;t be idiot\u0026hellip;idiosyncratic Finally, an important aspect of interacting with the web server is that many analytics platforms expect standard behavior from your server. So don\u0026rsquo;t whip up your own custom responses if just the regular \u0026ldquo;200 OK” will do. If you don\u0026rsquo;t serve standard responses, it\u0026rsquo;s possible that callbacks are not executed, hits don\u0026rsquo;t get sent, and valuable data is lost again.\nThe key takeaway here is this:\nAdhere to best practices in template handling and server responses - your analytics tool will thank you with good data.   When the browser receives the source code, it does something inexcusable. It gives the website a break. You see, one of the reasons JavaScript is reviled and browser wars are raging is because errors are glossed over. Your site can have the most horrendous source code, but depending on the browser, it turns into an amazing, well-crafted, dynamic web document.\nIt\u0026rsquo;s much like what Auto-Tune does to talentless singers. The music industry uses Auto-Tune to turn pitchy Idol dropouts into pop stars. In much the same way, the web browser turns a hideous piece of anti-code into a web page without actually telling the developer bluntly that they\u0026rsquo;ve done a poor job.\nNow, we can argue that Auto-Tune is a good thing, and we can argue that it\u0026rsquo;s great that the browser helps you like this. But having a machine correct your singing is no excuse to stop trying to reach the correct pitch naturally, and having a browser fix your source code problems is no reason not to aim for good markup.\nFor analytics, this browser behavior has some implications.\nBecause every browser wants to be a bit better than the next, they have their own ways of parsing source code. Sometimes these idiosyncrasies are subtle enough to not make a dent, but sometimes they erupt into full-blown compatibility issues, polyfills, and disgruntled developers. At the heart of this tragedy is the analyst, who only wanted to know how many people leave a specific form field empty when submitting the contact form.\n// Classic example of browser compatibility checking if (document.addEventListener) { // For real browsers  document.addEventListener(\u0026#39;click\u0026#39;, handleClick); } else { // For IE8 and earlier  document.attachEvent(\u0026#39;onclick\u0026#39;, handleClick); }  To combat these problems in the render process, it\u0026rsquo;s often wise to adopt a framework. If you\u0026rsquo;re tracking the \u0026ldquo;traditional way\u0026rdquo;, jQuery is something you might want to take a look at. If you\u0026rsquo;re using Google Tag Manager, well, you\u0026rsquo;re already using a JavaScript framework. By leveraging the built-in features of GTM, such as auto-event tracking and tag templates, you\u0026rsquo;re externalizing cross-browser woes to Google Tag Manager. It\u0026rsquo;s the framework\u0026rsquo;s job to take care that any features you want to use work across the wide variety of browsers and devices.\nIn some cases, even the smartest browser won\u0026rsquo;t help you. These are called single points of failure, because they essentially disrupt the current execution context when an error occurs. If you run JavaScript such as the Universal Analytics tracking snippet in your page template, a single syntax error will break the current script context and the code will fail. Again, your browser is probably trying to be helpful and doesn\u0026rsquo;t raise any alarms if this happens, so you\u0026rsquo;ll need to do some debugging. Make the JavaScript console of your browser your new best friend. Use it religiously for debugging.\n  It\u0026rsquo;s a shame if your entire tracking plan for a website fails because of a mistyped quote or a missing semicolon. Also, remember to watch out for formatted quotes. If you copy-paste from a document where quotes are formatted in some unorthodox way (such as Microsoft Word), you might run into trouble with JavaScript compilers, which expect regular, unformatted quotes in the code.\nSo the key takeaway in the render process is:\nMake sure that your [markup is valid](http://validator.w3.org/), and that your [JavaScript is flawless](http://jslint.com/). If your JavaScript is getting too complex to manage, take a look at a sustainable framework that will take some of the management overhead away.   JavaScript is single-threaded. This means that at any given time, only a single line of JavaScript can be executed. Thus, JavaScript is, by nature, blocking. Every line of JavaScript that is executed on the page template blocks the template until the line of code has been executed.\nBefore asynchronous JavaScript became the norm, we resorted to adding potentially risky JavaScript to the end of the document, at the very bottom. This reduced the risk of breaking down your entire web page if the JavaScript refused to agree with the browser. Also, if really large, external JS files were loaded, these calls were added to the end of the page as well, because the loading and the execution of the external file were queued in succession, meaning some severe page blocking would take place.\nWell, today, we have asynchronous JavaScript. At the heart of asynchronous JavaScript are callbacks, which are functions that are executed once some action, usually a network request, is processed. So if, for example, your script performs an HTTP request, asynchronous JavaScript initiates the request, but immediately returns to the next line of code in the page template. As the request progresses, the callbacks are executed as soon as there\u0026rsquo;s a spot open in the event queue. This way the code doesn\u0026rsquo;t block the page load, as it\u0026rsquo;s run \u0026ldquo;in the background\u0026rdquo;, only executing the callbacks once they are invoked by the original function.\nAnother place where you\u0026rsquo;ll see asynchronous requests is when loading external JS libraries. Google Analytics and Google Tag Manager are both loaded asynchronously. This means that the request for loading the JavaScript file is sent asynchronously, and when the file is loaded and available, only then is the code within executed (and when there\u0026rsquo;s a spot in the event queue). This way you can add these external library loads to the top of the page, ensuring that their load process begins as early as possible into the page load, but without risking them blocking your other code from running.\nThe downside of asynchronous JavaScript is that we can\u0026rsquo;t really predict when a given script will finish executing. We\u0026rsquo;ll know when it finishes thanks to the callbacks, but we can\u0026rsquo;t pinpoint this moment in the page load sequence beforehand.\nThis behavior leads to something called race conditions. Race conditions occur when two scripts are loaded asynchronously, and the latter requires that the former complete first. An example would be event tracking in GA. You don\u0026rsquo;t want to send an event hit before the pageview hit completes, because otherwise you\u0026rsquo;ll end up with warped sessions, where landing page is (not set):\n  If race conditions are at play, it doesn\u0026rsquo;t matter that the event hit began its execution after the pageview. What matters is that the event can finish first, because we can\u0026rsquo;t control asynchronous execution once it begins.\nFor GA and GTM, it\u0026rsquo;s important that you recognize potential race conditions on your page. If you want to increase the odds of the pageview being sent before any subsequent hits, for example, you could set all other hits to wait at least until the DOM of the page has been loaded. This safety measure usually adds a tiny overhead to the execution of the tag that waits for DOMComplete, and it more often than not means that the pageview has had ample time to complete before any further hits are sent.\nIf it\u0026rsquo;s not business critical data, you can even use the window load event as the hook for your other hits. The window has loaded when the page and all associated scripts have finished loading. If your code pushes data to GA after window load, it\u0026rsquo;s almost 100 % certain that the pageview has finished executing. However, if you have a heavy page full of big, uncached images (boo!), and heaps of external JS files to load (boo boo!), it might be too long a wait for some impatient visitors. Thus any hits that wait for window load might not get sent, as the user has already navigated to another page.\nThe best way to make sure that asynchronous scripts load in sequence, and thus to avoid race conditions, is to use the callback of a successful hit as the trigger for the subsequent hits. So in your pageview, you can use the hitCallback parameter to specify what happens once the tag has successfully fired. In this callback function, you can tell your other tags that it\u0026rsquo;s ok to fire. With Google Tag Manager, using hitCallback together with dataLayer makes it really easy to introduce some order into things.\nUnderstanding race conditions is really important with eCommerce as well, especially if you use client-side HTTP requests to get the transaction data. It\u0026rsquo;s all too common to see a transaction tag executing before the transaction data is available.\nThe takeaway of The Race is:\nMap out the dependencies between your tags, eradicate race conditions by using callbacks, and leverage asynchronous loading as much as possible.   Well all this page load stuff is marginally interesting, but it might not play a role in your idea of what web analytics is for, even though it should. But what you\u0026rsquo;re definitely interested in is how to track interactions on the site.\nInteraction is a loaded term, because it\u0026rsquo;s often difficult to pinpoint just what we mean by a user interaction. A click is surely an interaction, but is scroll an interaction? What about mouse movement, is that interaction? How about the shifting of the user\u0026rsquo;s gaze to a different part of the site, surely that\u0026rsquo;s not interaction? Well, it might be.\nThe thing is that depending on what you want to track, you might be facing a lot of problems in implementing the system that collects the data. Something as simple as a click handler can be difficult to implement if you\u0026rsquo;re not aware of what possible conflicts there are with your other JavaScript handlers.\nThis conflict resolution covers around 75 % of the most frequently asked questions about Google Tag Manager. I\u0026rsquo;ve written about this extensively before, so if you want in-depth details around the event propagation problem, take a look at this article:\nWhy Don\u0026rsquo;t My GTM Listeners Work?\nThe key here is to understand how the document object model works, especially in terms of event delegation. Often it\u0026rsquo;s most economical to add just a single listener on a page, and then just pick up events using event delegation. However, if you have conflicting script on the page, this might not work, and you have to come up with a workaround. Here\u0026rsquo;s a simplified version of the problem:\n  This visualization shows how the submit() event starts propagating up the document tree, and once it reaches GTM\u0026rsquo;s listeners on the document node the auto-event tracking kicks in. It also shows you what happens if there\u0026rsquo;s an intruding call to stopPropagation() on the event object.\nBut that\u0026rsquo;s GTM. When you\u0026rsquo;re tracking with traditional GA, you can again use jQuery for easy, cross-browser event handling. The thing is that the more you leverage different frameworks, the more possibilities there are that things go awry.\nWith interaction tracking, it\u0026rsquo;s so important to establish a discussion with your front-end developers. If you start injecting stuff onto the site that doesn\u0026rsquo;t play well with existing script infrastructure, you\u0026rsquo;ll have far bigger problems than data pollution. Your forms might not work any more, tabs which were supposed to change the content dynamically start redirecting you to completely different pages, elements flicker in and out annoyingly, and so forth.\nSo the key takeaway for interaction tracking is this:\nOnly track what you think is useful to track, and always test thoroughly for conflicts The Summary I hate just scratching the surface in articles, but we\u0026rsquo;re already past 3,000 words and if you made it this far you deserve a huge thank you.\nAnalytics is all-encompassing. It can permeate every single platform you use, aggregating information from a wide variety of data sources in one, centralized location. However, to get your web analytics working to the max, I strongly believe that an understanding of the page load process, even on a high level, is crucial. This article only scratched the surface, so you might want to take a look at the following resources to expand your mind:\n The Request: How Browsers Work\n The Request: Google Analytics And 301\u0026frasl;302 Redirects\n The Render: Optimizing Content For Different Browsers\n The Render: QuirksMode: Compatibility overview\n The Race: Asynchronous JavaScript Programming\n The Race: #GTMTips: hitCallback And eventCallback\n The Interaction: Custom Event Listener for GTM\n The Interaction: Google Tag Manager Events Using HTML5 Data Attributes\n  "
},
{
	"uri": "https://www.simoahava.com/gtm-tips/migrate-containers-to-new-ui/",
	"title": "#GTMtips: Migrate Containers To New UI",
	"tags": ["container", "Google Tag Manager", "gtmtips", "new ui"],
	"description": "Tips on how to migrate containers from the first version of Google Tag Manager to the revamped, second version.",
	"content": " If you haven\u0026rsquo;t lived in a barrel, you should know by now that a new version of Google Tag Manager has been released. You can find the new version at http://tagmanager.google.com/, and there\u0026rsquo;s already a bunch of good articles about the new UI out there. I want to point out two: \u0026ldquo;Setting up GA via GTM\u0026rsquo;s new UX\u0026rdquo; by Krista Seiden, and \u0026ldquo;Google Tag Manager Refresh – 6 Things You Need to Know\u0026rdquo; by Jonathan Weber from Lunametrics. Both are wonderful run-throughs of the new features, and should get you up-to-date with what\u0026rsquo;s changed.\nOK, I\u0026rsquo;ve written something as well, namely a guide for using GTM\u0026rsquo;s event listeners in the new UI. This guide was warranted, as the whole approach to automatic event handling has changed quite a bit in the transition from the old version to the new.\nLet\u0026rsquo;s get back on track. This tip is all about migration. Officially, all old accounts will be migrated to the new UI sometime in the beginning of 2015, but if you want to take a head start, you can do the migration yourself!\nTip 9: Migrate a container to the new UI   To migrate a container, you need to export a container file in the old UI, and then you need to import this as a new version in an existing container in the new UI.\nNote! Since you\u0026rsquo;re using a new container in the new UI to import the old container into, the container ID (GTM-XXXXX) will change. This means that if you want to use this new container on your site, you will need to edit the container snippet accordingly!\nSo here\u0026rsquo;s the process in easy-to-follow steps.\n1) Export container In the old account, go to the container you want to export. Technically, you\u0026rsquo;re not going to export a container, since that\u0026rsquo;s just a chassis for all the assets within. Instead, you\u0026rsquo;re going to export a container version. This means that after you click Export Container, you will need to select the version you\u0026rsquo;ll be exporting.\n  After you select the version, you\u0026rsquo;ll have a chance to preview the JSON (JavaScript Object Notation) file you\u0026rsquo;ll be downloading. Unless you\u0026rsquo;re really into debugging the nuts and bolts of a container file, you can just divert your attention to the Download button under the text field. Yes, click it now.\n  2) Import container This next step requires two things:\nFirst, you need to have an account created in the new UI, and a container within that account that you can access. If you have neither, just browse to http://tagmanager.google.com/ and follow the instructions. Honestly, it\u0026rsquo;s really easy.\nSecond, you need to navigate to the container in the new UI, and you need to import the file you just downloaded in the old UI. So, go to the container, and specifically the Admin section.\n  Once you click Import Container, you will first need to choose the container file you just downloaded. So do that.\nNext, you have two options. Either Overwrite or Merge. Both create a new version of the container using your imported file, but the difference is that Overwrite is a clean refresh, where only the assets you import will exist in the new version. Merge will do what it says, and merge the assets you import with anything that existed in the latest version of the target container.\nI\u0026rsquo;m a purist when it comes to migrations. A migration needs to be clean and simple, with as little interference in the process as possible. This means that I recommend choosing Overwrite, since you\u0026rsquo;re probably working with a new account or at least a new container anyway.\nSo, after choosing the file, checking Overwrite, and clicking Continue, you should see something like this:\n  Feel free to doubt yourself at this point, it\u0026rsquo;s normal. Just click Confirm and you can fix any problems in the container version.\nIf it\u0026rsquo;s a new container you created in the new UI, you\u0026rsquo;ll most probably see the five variables in the deleted column. No need to panic. This is just because the container you\u0026rsquo;re migrating does not utilize built-in variables, as they were only introduced in the new UI. Thus, the built-in variables are deactivated upon migration, and they are also confusingly reported as being deleted.\nPossible issues First of all, double-check all your tags, triggers and variables. No, triple-check, quadruple-check, and then check again.\nIf you find problems, I mean real problems like triggers looking completely different than what they used to (variables changing place, etc.), take a screenshot, report it in the Google Tag Manager community in Google+, and then fix the discrepancies manually.\nOne thing I do suggest you do is start activating the built-in variables, and using them in your triggers and tags. Also, make sure you do the transition to the new, trigger-based auto-event tracking in your event tracking tags!\nMigrations are never easy. They\u0026rsquo;re not supposed to be. But feature parity between the old version of GTM and the new version is almost 1:1, so just by importing your container, it should work pretty nicely out of the box.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/auto-event-tracking-gtm-2-0/",
	"title": "Auto-Event Tracking In GTM 2.0",
	"tags": ["auto-event tracking", "Google Tag Manager", "gtmtips", "Guide", "new ui"],
	"description": "Introducing auto-event tracking for Google Tag Manager. Auto-event tracking means the automatic handling of events such as clicks and form submits via your Google Tag Manager container.",
	"content": " In the new version of Google Tag Manager, auto-event tracking has received a considerable usability upgrade. It might seem quirky at first, especially if you\u0026rsquo;re used to the old auto-event tracking method, but the logic behind the new setup is brilliant.\n  The most important distinction is that auto-event tracking isn\u0026rsquo;t something you control with separate tags anymore. Rather, it\u0026rsquo;s now entirely trigger-driven, meaning you activate and specify the auto-event tracking of your choice using tag triggers (triggers are what ye olde folk used to call rules).\nThe trigger types If you\u0026rsquo;ve used the new UI, you might have noticed how triggers are now grouped together logically. For example, you have your Click Triggers (which include both \u0026ldquo;Click\u0026rdquo; and \u0026ldquo;Link Click\u0026rdquo; trigger types):\n  I\u0026rsquo;ll get to how these triggers are set up in just a bit, but the important thing to understand is that the auto-event trigger controls both when your actual tag fires as well as when the auto-event listener should be active. That\u0026rsquo;s a huge simplification, since you no longer need a separate, discrete tag to control your auto-event listener with.\nThen you have your Form Triggers:\n  And you also have auto-event triggers for History events, JavaScript Errors and Timers, as before.\nSo remember:\nThe auto-event trigger determines when your tag fires AND when the listener is active.\nThat\u0026rsquo;s the new auto-event tracking in a nutshell.\nHow to set it up But if this was just a \u0026ldquo;in a nutshell\u0026rdquo; post, I would shame my reputation as someone who writes increasingly long guides when a simple, to-the-point, concise, non-repetitive, efficient, and disambiguated utterance would suffice (this sentence proves my point). So, here\u0026rsquo;s a step-by-step how to set up some useful listeners.\nWhen you create a trigger for an auto-event, such as a Click trigger or a History trigger, they will always be on. What does this mean? Well it means exactly what I wrote. For example, when you create a Click trigger – regardless of what filters you have in place for the actual tag which uses it – every single click on every single page will create the gtm.click event. Go ahead, try it! You can\u0026rsquo;t limit the Click trigger type to only fire on certain pages.\nThere are two notable exceptions to this.\nWhen you create a Timer, Link Click or a Form trigger, you will need to specify when that trigger is enabled, if you\u0026rsquo;re using the Wait For Tags or Check Validation options. This is because these listeners can behave erratically when other scripts on your page interrupt or control the event propagation flow. It\u0026rsquo;s thus not always prudent to have one of these triggers firing on a page where they might not play nicely with your other scripts.\nYou control when these special triggers are enabled using the Enable When step in the trigger settings:\n  You will only see this option on the Timer, the Link Click, and the Form trigger type, when you\u0026rsquo;ve selected Wait For Tags or Check Validation. This filter lets you delimit the trigger to only be active on certain pages, for example. It\u0026rsquo;s best to start with a broad match (Page URL matches RegEx .*), and then modify it appropriately if problems arise.\nThe conditions for when a Tag that uses this trigger should fire are set in the Fire On step:\n  I hope this distinction is now clear. Enable When is for determining when the trigger listens for events, and Fire On is for when the tag should fire if the event is recorded.\nSo, back to the step-by-step. Here\u0026rsquo;s the key process:\n Create the tag you want to be triggered by the auto-event (e.g. Event tag for Google Analytics)\n Add the trigger you want to use for the tag (e.g. Click or Form)\n In the trigger settings, specify what other conditions beside the Click or Form Submit you want in place for the tag (e.g. Click ID equals X or Form URL contains Y)\n If it\u0026rsquo;s a Link Click or Form trigger, you need to also specify on what conditions should the auto-event listener itself be active\n  Let\u0026rsquo;s go over this step-by-step. I\u0026rsquo;ll create a tag which sends an event whenever someone clicks on a link which redirects out of my domain. An external link, in layman\u0026rsquo;s terms.\n1. Built-in variables First things first. The new UI introduced something called Built-In Variables. These little checkboxes let you quickly enable your most used variables for your tags to utilize. As I want to trigger the tag only when the clicked link HREF does not point to my domain, I will need to activate the Click URL variable. In the old UI, it\u0026rsquo;s the same thing as the {{element url}} macro, just simplified here for your convenience.\n  You\u0026rsquo;ll see me using it in just a bit.\n2. Set up your tag Next, create your tag. I\u0026rsquo;ll be using a Universal Analytics / Event tag for this. Let\u0026rsquo;s just stop short of adding the trigger:\n  Nothing surprising here, right?\n3. Create your trigger Next, we need to create the Link Click trigger that makes this tag go BOOM. So, click on Click in the Triggers list to enter the Choose from existing Click Triggers (if you already have click triggers) or the Add a new trigger view if this is your first one. Whatever the case, you should now be in the process of creating a new Click trigger for your tag:\n  In Step 2, you\u0026rsquo;re asked to select Trigger Type. Choose Link Click from this list, and you should see two new options in this same step:\n Wait For Tags - if you want the listener to wait for any tags to fire before proceeding with the original action (i.e. link redirect)\n Check Validation - if you only want the listener to activate when a proper link click is registered\n  It\u0026rsquo;s a good idea to start with both checked, and then if it doesn\u0026rsquo;t work, debug by unchecking first one and then the other.\nNote that since we\u0026rsquo;re creating a (Link) Click trigger, the underlying condition is that a click has occurred, so you don\u0026rsquo;t have to specify the gtm.(link)click event anymore! All you need to specify in these filters are the other conditions you might want to use to have your tag fire only under specific circumstances.\nIf you choose either Wait For Tags or Check Validation, Step 3 requires that you enter the condition for when the listener should be active and listening for clicks. Like I suggested before, start with a broad match like Page URL matches RegEx .*, test it thoroughly, and if some pages prove problematic, exclude them with a URL condition.\n  Step 4 is for specifying what happens when a (link) click event is registered. If a tag has this trigger attached to it, you should now specify any other conditions you want to check to make the tag only fire for certain link clicks, for example. Because we want to track external link clicks, we\u0026rsquo;ll start by choosing Some Clicks, and then entering the following Fire On condition:\n  So, by having Fire On: Click URL does not match RegEx simoahava.com, we\u0026rsquo;re making sure that any tag that uses this trigger is only fired if the click event is registered on a link pointing away from the simoahava.com domain.\nAnd that\u0026rsquo;s it! The way you read the settings from Step 1 to Step 4 is roughly this:\nThis Link Click - External Link asset is a trigger of type Link Click. It will listen for link clicks on all pages where this container is installed on. When a link click event is registered, this trigger will activate any tag it is attached to only if the clicked link element URL does not match the regular expression pattern simoahava.com. The link click listener will also wait for any tags to fire before proceeding with the link redirection and only activate if the action is a valid link click.\nSo, this is now 95 % of auto-event tracking in the new UI. It\u0026rsquo;s trigger-based, so you just need to get your trigger right and everything will work smoothly. Save the trigger and return to the tag.\n4. Fill in the rest of your tag The rest is just regular tag creation. Remember to give your tag a name. You can use the other built-in variables (such as Page Path) to populate your fields, just like in the old UI.\n  And that should be it. Remember to test with the Preview mode to make sure the tag only fires when external clicks are registered!\n  It\u0026rsquo;s important to notice that gtm.linkClick events are registered as usual with every link click, since my Link Trigger was set to be active with {{url}} matches RegEx .*. But it\u0026rsquo;s the first set of filters that make sure my tag only fires when the clicked element HREF doesn\u0026rsquo;t contain simoahava.com.\nSummary The new setup might seem daunting at first. It\u0026rsquo;s a bit confusing now, I admit, and I hope the UI will be improved. For some, it\u0026rsquo;s been difficult to distinguish between the first set of filters on the trigger (that determine when the tag fires), and the second set of filters on the Link Click and Form trigger types (that determine when the listener is active). This should be made more intuitive.\nHowever, having trigger-based auto-event tracking is very logical, indeed. A listener should, after all, only exist to fulfil a condition on a marketing tag. They have no inherent value as tags themselves. It\u0026rsquo;s thus counter-intuitive to have a listener as a tag when its sole purpose is to create the foundations for a firing or blocking trigger.\nAs soon as you grasp the interplay between tags and triggers in this way, you\u0026rsquo;ll have a nice Eureka moment. Feel free to share that moment in the comments below :)\nI only touched upon how the new UI works, and especially the new Built-In Variables only received a cursory glance, but I honestly love working with the new UI. Everything is more streamlined and the workflow is much clearer. I hope you\u0026rsquo;ve found it useful as well!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/once-userid-always-userid/",
	"title": "#GTMtips: Once userId, Always userId",
	"tags": ["Google Tag Manager", "gtmtips", "universal analytics", "user id"],
	"description": "How to persist the User ID across sessions, even if the user is not logged in. Implement with Google Tag Manager.",
	"content": " The User ID is definitely one of the coolest things about Universal Analytics, if used correctly. It might reveal some surprising insights about your visitors, since now you\u0026rsquo;re not restricted to analysing visitors as just browser or device instances as before, but rather you can build your stories around all the touch points the user might have had on their journey to and through your web properties.\nWith this simple tip, you can extend User ID tracking to return users without them needing to authenticate. This is done with a cookie.\nNote! This means that the User ID will often persist on public computers, so the person you\u0026rsquo;re tracking might not actually be the same human (it might also be a llama with some tech skills).\nThis idea was inspired by the comments in Annie Cushing\u0026rsquo;s blog post: Why Google Analytics User Metrics Are BS (For Most Sites). Especially the comments by John Mitchell and Christopher Mason were particularly insightful.\nTip 8: User ID for non-authenticated return users   The process is pretty much this:\n When users authenticate, the user ID should be stored in dataLayer\n When subsequent Universal Analytics tags are fired, the \u0026amp;uid; key should first check if the User ID is in dataLayer\n If it is, then a cookie is written in the user\u0026rsquo;s browser with this User ID, and finally the value is returned to the tag\n If the User ID is not in dataLayer, GTM checks if it\u0026rsquo;s stored in a cookie, and if it is, the cookie value is returned\n If there is no such cookie, nothing is returned and the User ID parameter will not get sent\n  So, for this to work you\u0026rsquo;ll need three variables. First one is {{uid in datalayer}}, and it\u0026rsquo;s a simple Data Layer Variable where the variable name it points to is whatever you have configured by your website. I\u0026rsquo;ll user userId in this example.\n  So when a user logs in, the website should push their User ID into dataLayer like so:\ndataLayer.push({ \u0026#39;userId\u0026#39; : \u0026#39;AAA-123\u0026#39;, \u0026#39;event\u0026#39; : \u0026#39;authentication\u0026#39; });  This shouldn\u0026rsquo;t come as a surprise, right? That\u0026rsquo;s how you should do it in any case. The \u0026lsquo;event\u0026rsquo; push fires the Event Tag which sends the user ID to Google Analytics. Nothing ground-breaking here, yet.\nNext, you\u0026rsquo;ll need two other variables. The first one is a 1st Party Cookie variable, which looks for whatever cookie name you\u0026rsquo;ve decided to store the user ID in. I\u0026rsquo;ll use userId again for consistency, but note that it\u0026rsquo;s a pretty common name, and you don\u0026rsquo;t want to overwrite other cookies written by your scripts.\n  Finally, you\u0026rsquo;ll need a Custom JavaScript Variable, which we\u0026rsquo;ll call {{user id}}. Its task is to perform the algorithm described in the beginning of this chapter.\nfunction() { if ({{uid in datalayer}}) { var d = new Date(); d.setTime(d.getTime()+1000*60*60*24*365*2); var expires = \u0026#39;expires=\u0026#39;+d.toGMTString(); document.cookie = \u0026#39;userId=\u0026#39; + {{uid in datalayer}} + \u0026#39;; \u0026#39;+expires+\u0026#39;; path=/\u0026#39;; return {{uid in datalayer}}; } else if ({{uid in cookie}}) { return {{uid in cookie}}; } return; }  And, finally (phew! this was supposed to be a simple tip), you need to edit your Universal Analytics tags to fetch the {{user id}} for the \u0026amp;uid;:\n  And that will do it.\nRemember, this isn\u0026rsquo;t for everyone. There\u0026rsquo;s no inherent benefit of always tracking return users unless it\u0026rsquo;s something you consider necessary for you to achieve your business goals. Sometimes it\u0026rsquo;s a business requirement itself to track return users who don\u0026rsquo;t authenticate. And don\u0026rsquo;t forget the warning about public computers. You might want to edit this script to only work for mobile phones and tablets, since it\u0026rsquo;s less likely that they have as many users as a library computer might.\n"
},
{
	"uri": "https://www.simoahava.com/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": "   I\u0026rsquo;ve written a bunch of tools to help you use and debug Google Tag Manager and Google Analytics. I\u0026rsquo;m neither a professional product developer nor am I a visual designer, and both correlate with how the tools look like and what their user experience is :)\nNevertheless, I only create tools that I want to use myself, and being a sort of power-user especially in the development side of things, I do think that these little utilities provide added value to your tag management needs.\nTo read more about each individual tool, see the respective menu item under TOOLS, or go directly from the list below.\n GTM Tools - Tools for managing your Google Tag Manager containers and assets at www.gtmtools.com.\n Chrome Extensions - I\u0026rsquo;ve written two extensions: GTM Sonar for debugging Google Tag Manager\u0026rsquo;s auto-event tracking, and Internalize, which lets you set yourself as internal traffic when browsing a website.\n Google Analytics Validator - Google Sheets Add-on, which lists all your GA accounts, properties, and views. Then, it lets you build a sheet of all their Custom Dimensions and whether these Custom Dimensions have collected any data in the past 7 days. Add it to Sheets here.\n Google Analytics Custom Dimension Manager - Google Sheets Add-on, which lets you build a source sheet of Custom Dimensions, and then apply these to any property you want (updating or skipping existing dimensions, and creating new ones if missing). Add it to Sheets here.\n GTM Tools by Simo Ahava - Google Sheets Add-ons, which let you manage your Google Tag Manager containers, tags, triggers, and variables. Add it to sheets here.\n customTask Builder - A tool which lets you build your own customTask script by selecting different components to include in the callback.\n  "
},
{
	"uri": "https://www.simoahava.com/analytics/introducing-gtm-tools/",
	"title": "Introducing GTM Tools",
	"tags": ["api", "Google Tag Manager", "gtm tools"],
	"description": "Introducing GTM Tools, a toolset built for the management of your Google Tag Manager accounts, containers, and assets within.",
	"content": " I\u0026rsquo;ve written a completely revamped version of this toolset for Google Tag Manager V2.\nWell, I just yesterday published the first of my GTM API tools (the Container Visualizer), and I vowed that I wouldn\u0026rsquo;t release the other tools for a number of reasons.\nThe reasons were good, in my opinion (especially the part about the tools being ugly as crap), but on the other hand I don\u0026rsquo;t want to keep anyone away from the amazing potential of the new API.\nSo here are all the tools I\u0026rsquo;ve written so far. Note that all tools have been written for the \u0026ldquo;old UI\u0026rdquo;, i.e. there are no triggers or variables that you can manage yet. I\u0026rsquo;ll get around to treating these new features in future releases.\n  Feel free to play around. There are surely errors here and there, and I\u0026rsquo;d be grateful if you could e-mail or Tweet me the trace stack what you\u0026rsquo;ll see if you encounter an error.\nYou can find the tools here: www.gtmtools.com.\nAlso, be patient. It\u0026rsquo;s still running on the free App Engine quota, because I don\u0026rsquo;t want to start asking for money from people who want to use these tools. I\u0026rsquo;ll see if I can upgrade to better quotas in the near future.\nContainer Cloner The first tool lets you copy entire containers from one account to another. Cloning a container means cloning everything in it, apart from user permissions. So you\u0026rsquo;ll see your tags, rules, and macros all whooshing from one account to another.\n  Here\u0026rsquo;s how it works:\n Choose an account from which you want to transfer the containers\n Choose an account to which you want to transfer the containers\n Choose one or multiple containers from the source column\n Click \u0026ldquo;Move Containers\u0026rdquo;\n If everything is fine, click \u0026ldquo;CLONE CONTAINERS\u0026rdquo; to start cloning\n  You won\u0026rsquo;t be able to clone a container within the same account, nor can you copy a container if a container with the same name already exists in the target account.\nTag / Rule / Macro Cloner The three other cloners can be bunched up into one description, since they have a very similar mode of operation. Basically, you choose a source container and a target container, and then the assets you want to clone.\nThe tool prevents assets with the same name being copied, and I might add an option to either overwrite or add a (copy) or something if there is a name conflict.\nAnother thing to note is that the cloner only clones the \u0026ldquo;shell\u0026rdquo; of the tag, rule, or macro. If there are references within these assets to other assets (tags macros, rules referencing macros, and macros referencing other macros), these dependencies are NOT cloned in this version, so you\u0026rsquo;ll have to remember to go through the new assets and clone any dependencies that are missing. Otherwise your container will not publish, as it will alert that a macro which doesn\u0026rsquo;t exist has been referred to.\n  And here\u0026rsquo;s how the cloners work:\n Choose source account and container\n Choose target account and container\n You can sort the results from A to Z, and you can show Macro and Tag types by clicking the respective buttons\n Choose the assets you want to copy from the source container\n Click \u0026ldquo;Move Tag(s) / Rule(s) / Macro(s)\u0026rdquo;\n If the move is successful, you\u0026rsquo;ll see the assets-to-be-cloned in the target container with an asterisk (*) next to them\n Click \u0026ldquo;CLONE TAGS / RULES / MACROS\u0026rdquo; to start the cloning process\n  Please let me know if you run into trouble. I know there are some errors that still pop up every now and then.\nContainer Visualizer I wrote about the Container Visualizer in a recent post, so be sure to read that. It\u0026rsquo;s definitely my favorite tool of the bunch!\nSummary These tools showcase the powers of the API. You can really do awesome stuff, and save a LOT of time.\nFuture releases of the tools will include:\n Mass Update tool, which lets you add a condition to multiple rules at once, or a rule to multiple tags at once\n Cloners for the new UI assets (triggers and variables)\n General support for \u0026ldquo;GTM 2.0\u0026rdquo; (the new UI and assets)\n Some sort of dependency checking for the cloners, which would let you copy all dependencies (e.g. linked macros and rules) as well\n  I\u0026rsquo;m always happy to receive feedback, but I\u0026rsquo;d like to remind you that I\u0026rsquo;m not a professional product developer, nor am I looking to productize these tools or make them something they aren\u0026rsquo;t. At least for now. I really wanted to just show what the API can do, and create little tools which I want to use myself. I\u0026rsquo;ve been using the Cloner tools for some time now, and they\u0026rsquo;ve made my life SO much easier.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/container-visualizer-google-tag-manager/",
	"title": "Container Visualizer for Google Tag Manager",
	"tags": ["api", "Google Tag Manager", "tools"],
	"description": "Introducing the container visualizer, a part of the GTM Tools toolset built for Google Tag Manager management.",
	"content": " [UPDATE:] Quite a lot of people had trouble accessing the tool after I published this post. This should now be fixed.\nSo, AWESOME stuff. The new Google Tag Manager UI and API have just rolled out, and I can finally start revealing the stuff I\u0026rsquo;ve been working on :)\nI\u0026rsquo;m not going to go into the new UI in this post. I just want to give a huge thanks to the GTM team for working on the UX with such dedication. The big problem with GTM so far has been that newcomers and non-developers (and why not developers as well) don\u0026rsquo;t get the flow of the tool. There\u0026rsquo;s no indication of \u0026ldquo;what to do next\u0026rdquo;, or \u0026ldquo;what\u0026rsquo;s taking place right now\u0026rdquo;. These are some of the things that have been remedied in this release.\nBut the API. Oh man, the API. I love it. It lets me do such cool things with it. I\u0026rsquo;ve got a bunch of tools in the prototype-stage, including:\n Container Cloner (copy container(s) from account to account)\n Tag Cloner (copy tag(s) from container to container)\n Macro Cloner (copy macro(s) from container to container)\n Rule Cloner (copy rule(s) from container to container)\n Container Visualizer (read more below)\n  I\u0026rsquo;m not ready to go public with them for two reasons: 1) I\u0026rsquo;m still using the free App Engine plan, meaning quotas will burst if dozens of people start cloning GTM assets at the same time (yes, I\u0026rsquo;m that confident about the tools\u0026rsquo; popularity), and 2) I\u0026rsquo;m not a visual developer, so the tools look like crap.\n(UPDATE: I caved and made the other tools public as well. See this post for more info.)\nBut there is one tool I want to make public now, because I\u0026rsquo;m so furiously proud of it. So here we go.\nContainer Visualizer It\u0026rsquo;s a little tool that lets you visualize all links and relationships between the tags, macros, and rules of a container.\n  You can find the tool here: Container Visualizer (GTM Tools @SimoAhava). I haven\u0026rsquo;t tested extensively across browsers, so it might look a bit different depending on which browser you use.\nHere\u0026rsquo;s how it works:\n First you need to authenticate your Google ID to use the API\n Next, choose an account whose container you want to inspect\n Then choose a container in that account\n Now you should see the diagram with all your nodes\n Hover over a node to see its connections\n Click a node to freeze its state (click again anywhere to release)\n Click \u0026ldquo;Select hermit nodes\u0026rdquo; to select nodes with no links\n Start typing to find a specific tag, macro, or rule\n Click \u0026ldquo;Full screen\u0026rdquo; to view a larger version of the visualization\n  I think this is a pretty darn sweet tool to see how vibrant your container is. If you have the average container, you should see a lot of links to the {{event}} macro and the {{url}} macro, but if you want a healthy container, you should see very few hermit nodes or assets with just single links.\nFor the visualization, I did some heavy modifications to the Hierarchical Edge Bundling visualization built with the amazing d3.js library.\nTechnology-wise it\u0026rsquo;s all Python, JavaScript, and HTML templates.\nI\u0026rsquo;ll try to muster up the courage to publish the other apps in my GTM Tools @SimoAhava collection soon.\nLet me know what you think about the whole idea of visualizing your data assets!\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/datalayer-declaration-vs-push/",
	"title": "#GTMtips: dataLayer Declaration Vs. .push()",
	"tags": ["datalayer", "Google Tag Manager", "gtmtips"],
	"description": "Recognize the difference between a dataLayer declaration and a dataLayer.push(), and always use the latter when working with Google Tag Manager.",
	"content": " Here\u0026rsquo;s a tip on how to avoid a horrible, horrible mistake with Google Tag Manager.\nTip 7: Always use .push() with dataLayer   When you assign a value to a variable using the equals ( = ) sign, you are actually reallocating the variable to a new value, and the garbage collection system of the runtime environment sweeps the previous value to bit heaven.\nLet\u0026rsquo;s put it simply: if you redefine dataLayer after the GTM container snippet, you will break GTM\u0026rsquo;s proprietary functions. No, I\u0026rsquo;m not trying to be dramatic, it\u0026rsquo;s the truth. You cause havoc because GTM modifies the native push() method that all Arrays have, adding stuff of little importance such as a listener which fires tags when an \u0026lsquo;event\u0026rsquo; key is pushed!.\nBy redefining dataLayer your tags will no longer fire. Oops!\nBut hey, we\u0026rsquo;re often instructed to use variable assignment when creating dataLayer before the container snippet. Right? Well, yes, that\u0026rsquo;s what we\u0026rsquo;re instructed to do but that\u0026rsquo;s not necessarily the best practice. Having just one declaration there works like a charm, but what about:\n\u0026lt;script\u0026gt; dataLayer = [{ \u0026#39;businessCriticalVar\u0026#39; : \u0026#39;businessCriticalVal\u0026#39; }]; \u0026lt;/script\u0026gt; ... some other code ... \u0026lt;script\u0026gt; dataLayer = [{ \u0026#39;anotherCriticalVar\u0026#39; : \u0026#39;anotherCriticalVal\u0026#39; }]; \u0026lt;/script\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- GTM Container Snippet --\u0026gt; Well, you might have guessed it. The second assignment overwrites the first one, and dataLayer only has anotherCriticalVar available for the benefit of your tags.\nSo how to avoid this?\nSimple: use only push() when interacting with dataLayer. That way you\u0026rsquo;ll never overwrite anything in the Array, you\u0026rsquo;ll just add new stuff to the end.\nIn GTM tags (Custom HTML, for example), you can just go ahead and use dataLayer.push(), since you can be 100 % sure that dataLayer is an Array with a push() function (the container snippet takes care of this for you). But when you\u0026rsquo;re working on the page template, where it\u0026rsquo;s not necessarily a given that dataLayer has been defined as an Array, always use the following syntax to safeguard against problems:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#39;someVar\u0026#39; : \u0026#39;someVal\u0026#39; });  The first line basically checks if a global variable called dataLayer has already been declared. If it has, it\u0026rsquo;s left alone and execution proceeds to the push() block. If, however, dataLayer has NOT been defined, the first line then assigns a new, empty Array to it. This ensures that the following push() will always work.\nSo here\u0026rsquo;s the recap:\n When working on the page template, always check whether or not dataLayer has been defined, and initialize it as a new Array if necessary\n Always, ALWAYS, use push() when interacting with dataLayer\n  DISCLAIMER: The window.dataLayer = window.dataLayer || []; fails if dataLayer HAS been defined but not as an Array. This is probably quite rare, but you should be aware of what variable has been assigned to GTM by looking at the container snippet\u0026rsquo;s self-invoking function parameters.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/ecommerce-tips-google-tag-manager/",
	"title": "eCommerce Tips For Google Tag Manager",
	"tags": ["ecommerce", "enhanced ecommerce", "Google Tag Manager", "Guide"],
	"description": "Tips for setting up Google Analytics Ecommerce and Enhanced Ecommerce tracking via Google Tag Manager.",
	"content": " I\u0026rsquo;ve noticed that setting up eCommerce in Google Tag Manager (and now the new Enhanced ecommerce) is very difficult for many. I\u0026rsquo;m sure part of the problem is that eCommerce is for many users the moment that GTM forces you to take steps in to the developer\u0026rsquo;s domain, since it\u0026rsquo;s obvious that you\u0026rsquo;ll need to add some code to the web page.\nThis isn\u0026rsquo;t a tutorial on how to do eCommerce in Google Tag Manager. To get started, you\u0026rsquo;ll want to check out the official documentation. Sure, it might be inaccurate in places, and especially the translations are lacking, but dataLayer form and function is nicely described within.\nEnhanced Ecommerce (UA) Developer Guide Google Analytics Ecommerce\nThis article has tips and answers to some frequently asked questions around eCommerce. Hopefully they will help you understand how eCommerce and Google Tag Manager work together.\nThe process in a nutshell Here\u0026rsquo;s how eCommerce and Google Tag Manager conspire to get you the all-important data of your web transactions.\n Your eCommerce platform and/or your Content Management Solution (CMS) render the source code\n If the page includes transactional information, this source code must include all required details about the transaction in the dataLayer object\n When the tag which carries the transaction to GA fires, it will look at the dataLayer object\n If it finds all the required information within, it will send the transaction hit to GA\n    Most of the following chapters will shed more light on these points, but the key thing to remember is this:\nYour eCommerce and/or CMS platform do almost all the work in tracking your transactions.\nThe backend solution, whether it\u0026rsquo;s your CMS or a dedicated eCommerce platform such as Magento, or even a WordPress plugin (such as WooCommerce), has to do the grunt work of populating the keys in the data layer.\nWith a Python-based application, the page template might look like this:\ndataLayer.push({ \u0026#39;transactionId\u0026#39; : \u0026#39;{{ transactionId }}\u0026#39;, });  With PHP, it might look like this:\ndataLayer.push({ \u0026#39;transactionId\u0026#39; : \u0026#39;\u0026lt;?php echo $transactionId ?\u0026gt;\u0026#39;, });  With QBASIC, it might look like this:\ndataLayer.push({ \u0026#39;transactionId\u0026#39; : \u0026#39;PRINT T$; GOTO END\u0026#39; });  OK, the QBASIC script was fictitious, I was trying to be funny. But nostalgia, right? Right?\nSo don\u0026rsquo;t expect GTM to come up with values for these variables magically. You will need a developer to help you here, and you will need a cooperative backend platform.\nNow, sometimes you might be tempted to scrape the DOM for eCommerce information. That means that you have some JavaScript in place which retrieves all the necessary transactional data from elements on the page, such as headings, body text, even image ALT texts.\nThis is not the recommended approach!\nThere are many, excellent reasons for decoupling semantic information (information with no inherent value to what is rendered in the browser document) from the presentational layer. This is what the data layer was invented for. I strongly suggest you avoid taking the seemingly easy path of scraping on-page elements, especially with business-critical transactional tags.\nNote, however, that some aspects of Enhanced eCommerce as it stands today might actually benefit from a combination of DOM scraping and dataLayer utilization. We\u0026rsquo;ll go over this later in the post.\nHere are the actual tips:\n dataLayer before GTM\n Use a custom event\n Make sure all the data is there\n Don\u0026rsquo;t forget your JavaScript\n Enhanced eCommerce is special\n  And we\u0026rsquo;ll wrap it up with a neat summary.\ndataLayer before GTM This is a very common problem. The tag that carries your transaction information fires before the transaction data is in dataLayer. D\u0026rsquo;uh!\nWhen a tag fires, it has access to the current state of all variables in the global namespace. dataLayer is one of them. If dataLayer doesn\u0026rsquo;t have the required variables on the moment that the transactional tag fires, you won\u0026rsquo;t see data from that hit in GA.\nHere\u0026rsquo;s an example. This is what your normal eCommerce tag looks like:\n  As you can see, there are VERY few options to work with. You just set Track Type to Transaction, add a rule, and you\u0026rsquo;re good to go.\nThe point is that this tag will fire as soon as the container snippet is loaded, i.e. when the container snippet pushes 'event' : 'gtm.js' into dataLayer. Because the tag looks into dataLayer for the transaction details, they have to be there by the time the tag fires!\nThus, this will work:\n\u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; dataLayer.push({ \u0026#39;transactionId\u0026#39;: \u0026#39;1234\u0026#39;, \u0026#39;transactionAffiliation\u0026#39;: \u0026#39;Acme Clothing\u0026#39;, \u0026#39;transactionTotal\u0026#39;: 38.26, \u0026#39;transactionTax\u0026#39;: 1.29, \u0026#39;transactionShipping\u0026#39;: 5, \u0026#39;transactionProducts\u0026#39;: [{ \u0026#39;sku\u0026#39;: \u0026#39;DD44\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;T-Shirt\u0026#39;, \u0026#39;category\u0026#39;: \u0026#39;Apparel\u0026#39;, \u0026#39;price\u0026#39;: 11.99, \u0026#39;quantity\u0026#39;: 1 },{ \u0026#39;sku\u0026#39;: \u0026#39;AA1243544\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Socks\u0026#39;, \u0026#39;category\u0026#39;: \u0026#39;Apparel\u0026#39;, \u0026#39;price\u0026#39;: 9.99, \u0026#39;quantity\u0026#39;: 1 }] }); \u0026lt;/script\u0026gt; \u0026lt;!-- Google Tag Manager --\u0026gt; \u0026lt;noscript\u0026gt;\u0026lt;iframe src=\u0026#34;//www.googletagmanager.com/ns.html?id=GTM-P8XR\u0026#34; height=\u0026#34;0\u0026#34; width=\u0026#34;0\u0026#34; style=\u0026#34;display:none;visibility:hidden\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/noscript\u0026gt; \u0026lt;script\u0026gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-P8XR\u0026#39;);\u0026lt;/script\u0026gt; \u0026lt;!-- End Google Tag Manager --\u0026gt; As you can see, the data is before the container snippet, so the dataLayer object is populated with all the required variables by the time the tag fires.\nHowever, this will NOT work:\n\u0026lt;!-- Google Tag Manager --\u0026gt;; \u0026lt;noscript\u0026gt;\u0026lt;iframe src=\u0026#34;//www.googletagmanager.com/ns.html?id=GTM-P8XR\u0026#34; height=\u0026#34;0\u0026#34; width=\u0026#34;0\u0026#34; style=\u0026#34;display:none;visibility:hidden\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/noscript\u0026gt; \u0026lt;script\u0026gt;(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\u0026#39;gtm.start\u0026#39;: new Date().getTime(),event:\u0026#39;gtm.js\u0026#39;});var f=d.getElementsByTagName(s)[0], j=d.createElement(s),dl=l!=\u0026#39;dataLayer\u0026#39;?\u0026#39;\u0026amp;l=\u0026#39;+l:\u0026#39;\u0026#39;;j.async=true;j.src= \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39;+i+dl;f.parentNode.insertBefore(j,f); })(window,document,\u0026#39;script\u0026#39;,\u0026#39;dataLayer\u0026#39;,\u0026#39;GTM-P8XR\u0026#39;);\u0026lt;/script\u0026gt; \u0026lt;!-- End Google Tag Manager --\u0026gt; \u0026lt;script\u0026gt; dataLayer.push({ \u0026#39;transactionId\u0026#39;: \u0026#39;1234\u0026#39;, \u0026#39;transactionAffiliation\u0026#39;: \u0026#39;Acme Clothing\u0026#39;, \u0026#39;transactionTotal\u0026#39;: 38.26, \u0026#39;transactionTax\u0026#39;: 1.29, \u0026#39;transactionShipping\u0026#39;: 5, \u0026#39;transactionProducts\u0026#39;: [{ \u0026#39;sku\u0026#39;: \u0026#39;DD44\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;T-Shirt\u0026#39;, \u0026#39;category\u0026#39;: \u0026#39;Apparel\u0026#39;, \u0026#39;price\u0026#39;: 11.99, \u0026#39;quantity\u0026#39;: 1 },{ \u0026#39;sku\u0026#39;: \u0026#39;AA1243544\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;Socks\u0026#39;, \u0026#39;category\u0026#39;: \u0026#39;Apparel\u0026#39;, \u0026#39;price\u0026#39;: 9.99, \u0026#39;quantity\u0026#39;: 2 }] }); \u0026lt;/script\u0026gt; This time, the transaction data is pushed after the container snippet has loaded, and there\u0026rsquo;s a very strong possibility that the data is not rendered in dataLayer when the Transaction Tag fires.\nThe same applies to any data you might try to move in a Custom HTML Tag. The Custom HTML Tag fires at its earliest with {{event}} equals gtm.js, because that\u0026rsquo;s the earliest possible event to fire your tags on. However, your transaction tag is ALSO firing on that event, meaning there\u0026rsquo;s a possibility that your transaction tag will fire first, and thus won\u0026rsquo;t find the transaction details in dataLayer. You can try to rectify this with Tag Priority, but in this case it would be better to look at the next tip.\nUse a custom event If you can\u0026rsquo;t push your data into dataLayer before {{event}} equals gtm.js fires, or if there\u0026rsquo;s even the tiniest possibility that the data won\u0026rsquo;t be rendered in time, you could just as well push a custom event of your own.\nFor example, if you\u0026rsquo;re using a Custom HTML Tag to build your eCommerce dataLayer, add an \u0026lsquo;event\u0026rsquo; push in there, which you\u0026rsquo;ll then use as the firing rule for your transactional tags:\n\u0026lt;script\u0026gt; dataLayer.push({ ... eCommerce properties ..., \u0026#39;event\u0026#39; : \u0026#39;transactionComplete\u0026#39; }); \u0026lt;/script\u0026gt; Then your transactional tag needs to fire on {{event}} equals transactionComplete. This way you\u0026rsquo;ll be 100 % certain that the data is in dataLayer by the time the tag fires, because the trigger event is pushed at the same times as the transactional data!\nMake sure all the data is there The developer guides tell you exactly what variables are required. In traditional eCommerce, here\u0026rsquo;s what your Transaction Tag will look for:\nTransaction ID - transactionId Transaction Total - transactionTotal Product Name - name Product SKU - sku Product Price - price Product Quantity - quantity\nIf any of these fields are missing from dataLayer, the Transaction Tag will not get sent.\nOh, and also: transactionId and sku need to be unique. If you have multiple transactions with the same ID, or if you have many products with the same SKU, your data will be skewed.\nWith Enhanced eCommerce, there are many more fields to observe, so be sure to read both the Google Tag Manager Developer Guide (linked to in the beginning of this post), as well as the general guide for Enhanced eCommerce in Google Analytics.\nDon\u0026rsquo;t forget your JavaScript We\u0026rsquo;re in the developers\u0026rsquo; domain here. Don\u0026rsquo;t forget that. Here are some things you should check first if your tags are not firing:\nEach object key requires a value - If you want to omit a property from the push, either send it with an empty string, or drop it out of the push altogether. Don\u0026rsquo;t send it without a value at all:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;purchase\u0026#39; : { \u0026#39;actionField\u0026#39; : , // WRONG! This key requires a value  ... }); dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;purchase\u0026#39; : { \u0026#39;actionField\u0026#39; : \u0026#39;\u0026#39;, // BETTER!  ... });  Know when to add a comma to the end of the line - If the properties are siblings of each other, that is, they have the same parent, then each line must end in a comma except the last line. Here\u0026rsquo;s how it should go:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { // No comma, starts a new hierarchy  \u0026#39;purchase\u0026#39; : { // No comma, starts a new hierarchy  \u0026#39;actionField\u0026#39; : {\u0026#39;list\u0026#39; : \u0026#39;Apparel Gallery\u0026#39;}, // Comma, followed by a sibling  \u0026#39;products\u0026#39; : [{ // No comma, starts a new hierarchy  \u0026#39;name\u0026#39; : \u0026#39;product1\u0026#39;, // Comma, followed by a sibling  \u0026#39;id\u0026#39; : \u0026#39;12345\u0026#39; // No comma, last member in current object  },{ // Comma, since there are two objects in this \u0026#39;products\u0026#39; Array  \u0026#39;name\u0026#39; : \u0026#39;product2\u0026#39;, // Comma, followed by a sibling  \u0026#39;id\u0026#39; : \u0026#39;23456\u0026#39; // No comma, last member in current object  }] // No comma, last member in current object  } // No comma, last member in current object  }, // Comma, followed by a sibling  \u0026#39;event\u0026#39; : \u0026#39;transactionComplete\u0026#39; // No comma, last member in current object });  Respect the type requirements - Let\u0026rsquo;s first address the elephant in the room. Always, always remember to use a period as the decimal separator in a number, not a comma. When passing a numeric value, the comma can be horribly misinterpreted:\n... \u0026#39;price\u0026#39; : 33,75, // WRONG! \u0026#39;quantity\u0026#39; : 1 ...  Here, the browser interprets the first comma as the property separator, and the 75, that follows is not a syntactically valid key-value pair, and will result in an error. Here\u0026rsquo;s how it should look:\n... \u0026#39;price\u0026#39; : 33.75, \u0026#39;quantity\u0026#39; : 1 ...  Now the number is actually a number, with a period as the decimal separator.\nWith enhanced eCommerce, the type for price and other monetary values is confusingly Currency, which is not a JavaScript type, but just use a string with the decimal as the separator, e.g.\ndataLayer.push({ \u0026#39;ecommerce\u0026#39;: { \u0026#39;currencyCode\u0026#39;: \u0026#39;EUR\u0026#39;, // Local currency, type string  \u0026#39;impressions\u0026#39;: [ { \u0026#39;name\u0026#39;: \u0026#39;Triblend Android T-Shirt\u0026#39;, // Name, type string  \u0026#39;id\u0026#39;: \u0026#39;12345\u0026#39;, // ID, type string  \u0026#39;price\u0026#39;: \u0026#39;15.25\u0026#39;, // Price, type string  \u0026#39;brand\u0026#39;: \u0026#39;Google\u0026#39;, // Brand, type string  \u0026#39;category\u0026#39;: \u0026#39;Apparel\u0026#39;, // Category, type string  \u0026#39;variant\u0026#39;: \u0026#39;Gray\u0026#39;, // Variant, type string  \u0026#39;list\u0026#39;: \u0026#39;Search Results\u0026#39;, // List, type string  \u0026#39;position\u0026#39;: 1 // Position, type number  }] ...  So remember: respect the type requirements. A number is written as just the plain number, using a period as the decimal separator: 15.35. No quotes there. A string is a combination of characters wrapped in single or double quotes: \u0026rsquo;T-shirt\u0026rsquo;.\nEnhanced eCommerce is special I\u0026rsquo;ve alluded to Enhanced eCommerce a couple of times already, but now it\u0026rsquo;s time to tackle the beast. If you thought there was a lot of dataLayer this and JavaScript that in the previous tips, you\u0026rsquo;re going to overload with all the development effort that Enhanced eCommerce requires.\nLet\u0026rsquo;s start with the obvious:\nYou do not use the Transaction tag type for Enhanced eCommerce.\nThe Transaction tag is for traditional eCommerce, and as the Enhanced eCommerce dev guide clearly states:\n\u0026ldquo;Important: The Enhanced Ecommerce plug-in should not be used alongside the Ecommerce (ecommerce.js) plug-in for the same property.\u0026rdquo;\nSo don\u0026rsquo;t confuse the two. Enhanced eCommerce gives you a far more granular and funnel-like look at how visits progress in terms of your purchase funnel.\nThe thing is, with Enhanced eCommerce all hits are piggy-backed on top of existing tags, such as Pageview and Event. The key is to remember to set Enhanced eCommerce features on in the settings of your tags, AND to use dataLayer to carry the data through the tag to Google. Again, you will need to make sure that dataLayer is initialized with all the required data before the tags fire.\n  With Enhanced eCommerce, all the previous tips apply tenfold. That\u0026rsquo;s because there are so many more variables to appreciate, so many more type requirements to observe, so many more ways to get the data flowing to GA.\nAnother important thing about the new feature is that any tag which has Enhanced eCommerce enabled will only process whatever was in the most recent \u0026lsquo;ecommerce\u0026rsquo; variable push to the dataLayer. So if you have, for example:\ndataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;impressions\u0026#39; : ... } }); dataLayer.push({ \u0026#39;ecommerce\u0026#39; : { \u0026#39;detail\u0026#39; : ... } });  Only the latter push will be processed by your tag which fires on {{event}} equals gtm.js. This is because the \u0026lsquo;ecommerce\u0026rsquo; object is still processed with \u0026ldquo;version 1\u0026rdquo; of the data layer, where repeated pushes of the same object name are not merged. Thus each new push overwrites the previous value of the object. In any case, it\u0026rsquo;s crucial that you take this into account. What it means, in practice, is:\nIf you have many Enhanced eCommerce actions / items you need to send in a single tag, you must combine them in a single dataLayer.push()!\nNeedless to say, it will be practically impossible to implement eCommerce with the new features without involving your developers. After all, you are combining on-page actions (clicks, impressions) with the information in dataLayer. Even on the best of days, those two don\u0026rsquo;t mix well.\nHere are some general tips for Enhanced eCommerce:\n dataLayer has a maximum length of 300 items. A search page on a large web store can have hundreds and hundreds of products, especially if you utilize lazy load methods, or something similar. So try to populate dataLayer with as much information pre-load as possible, and refrain from dynamically adding data into the structure.\n Sometimes the page elements might be dynamic. For example, you might need to account for sorting the items according to different criteria, or the same item might be in different categories, depending on what sort methods the user has chosen. In those cases you might need to scrape Page Category, for example, from the DOM, and push it into the product listing in the data model. Be sure to read this guide for information how to update existing products in GTM\u0026rsquo;s data layer.\n Start small and scale up, if the task seems too big to comprehend. Start with tracking the shopping cart, checkout funnel, and purchases. Next plan and implement the path from product impression, to product click, to product detail view. Finally, work yourself around promotions, campaigns, and refunds, if you wish.\n If you want to send multiple items using a single Enhanced eCommerce enabled GTM tag, you need to combine the items into a single push. Only the most recent dataLayer.push() with the \u0026lsquo;ecommerce\u0026rsquo; key is processed by your Enhanced eCommerce enabled GTM tag! An even better practice is to always include an \u0026lsquo;event\u0026rsquo; key in your post-container-snippet pushes, and use this \u0026lsquo;event\u0026rsquo; key to fire your tag with every single \u0026lsquo;ecommerce\u0026rsquo; push to dataLayer.\n  Summary The trouble with eCommerce is that it\u0026rsquo;s so deep in the developers\u0026rsquo; domain, but it involves a tool mainly directed at marketers. Naturally, this demands that communication between the technical and the non-technical stakeholders must flow naturally.\nBiggest problems occur when the developers do not understand eCommerce, its purposes, or how transactional information is passed through dataLayer into the analytics platform. Also, sometimes non-developers want to tackle eCommerce on their own, because they\u0026rsquo;ve had success with the TMS thus far, and soon they\u0026rsquo;ve bitten more than they can chew.\nThe truth is that eCommerce requires a lot of knowledge transfer between the people who plan and the people who implement. Otherwise simple problems like failure to appreciate JavaScript type requirements, or what product details need to be represented in dataLayer, will cause errors.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/hitcallback-eventcallback/",
	"title": "#GTMtips: hitCallback And eventCallback",
	"tags": ["callback", "Google Tag Manager", "gtmtips", "Guide"],
	"description": "You can use hitCallback to execute commands after the Google Analytics tag has completed, and eventCallback to execute JavaScript after the dataLayer event has completed. Both in Google Tag Manager.",
	"content": " This time we\u0026rsquo;ll take a look at two different, JavaScript-y features of Google Analytics and Google Tag Manager. Callback as a concept should be familiar to anyone who\u0026rsquo;s ever used a programming language. It\u0026rsquo;s basically a piece of code that is passed as an argument to some function, so that when this second function has completed, the callback is executed.\nFor web analytics, callbacks are hugely important, since they allow you to impose a firing order for your asynchronous tags. Asynchronous tags, as you might know, abhor order and precision, so sometimes it\u0026rsquo;s necessary to use a callback to have at least an inkling of predictability in your tag jungle.\nTip 6: hitCallback and eventCallback   Here\u0026rsquo;s the difference:\nhitCallback - hitCallback is a feature of the analytics.js collection library. It lets you provide a callback function for each tag separately. If you want to, for example, fire some tag directly after your pageview has fired, you might want to use hitCallback to push an event into dataLayer, and then use that event to fire your second tag. Or you might do something really wacky, such as use hitCallback to fire a single tag multiple times.\nThe key thing here is to make sure that the Custom JavaScript Macro which holds the callback function returns a function which does all the work. This is important, since otherwise the function expression in your callback macro would fire TWICE: first when the tag is written and executed, and again when the callback is fired.\neventCallback - eventCallback is pure GTM. If you push a dataLayer event into the message queue, you can also push the eventCallback key as well. The value of the key would be the callback function. As soon as all tags which fire on the event that you pushed have executed, your callback function will fire.\ndataLayer.push({ \u0026#39;key1\u0026#39; : \u0026#39;value1\u0026#39;, \u0026#39;key2\u0026#39; : \u0026#39;value2\u0026#39;, \u0026#39;event\u0026#39; : \u0026#39;fireTags\u0026#39;, \u0026#39;eventCallback\u0026#39; : function() { alert(\u0026#39;ALL tags which fire on {{event}} equals fireTags have now fired\u0026#39;); } });  So in the code example above, as soon as all tags that have the firing rule {{event}} equals fireTags have executed, the function in the callback will fire.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/chain-macros-lookup-tables/",
	"title": "#GTMtips: Chain Macros In Lookup Tables",
	"tags": ["Google Tag Manager", "gtmtips", "macros"],
	"description": "You can chain Google Tag Manager lookup tables together to create a powerful and flexible way to fetch dynamic data from a number of sources.",
	"content": " One of the cool things about using a tag management solution is that you can leverage variables like never before. In Google Tag Manager, these variables are referred to as macros, and you can identify a macro with the syntax of {{macro name}}. In this tip I\u0026rsquo;ll show you how you can actually call macros from other macros, using a Lookup Table as an example.\nTip 5: Chain Macros In Lookup Tables (And Other Macros)   It\u0026rsquo;s not just Lookup Tables, either. You can pretty much use a macro in any field where there is a script context (because macros are JavaScript functions and require a script context to be run). Valid fields are, for example, Custom HTML Tags, Custom JavaScript Macros, Google Analytics tag fields, and so on.\nLeveraging macros like this is a really cool way to make your tag setups more flexible AND leaner at the same time. In the picture above, I use two Lookup Tables, chained together, to achieve the following:\n1) If the hostname of the page is A or B, then return the respective Tracking ID 2) If the hostname is C and Debug Mode is on, then return the respective Tracking ID 3) If the hostname is C and Debug Mode is false, then return the respective Tracking ID\nSo instead of having a bunch of tags to accommodate for all this variations, I can just have a single tag and let macros do the work.\nJust remember, chaining too many macros together can quickly become a management nightmare. Only use macros to return a calculated value, never to set or push anything by themselves.\nHere\u0026rsquo;s some further reading for you:\n Macro Guide For Google Tag Manager\n Macro Magic For Google Tag Manager\n  "
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-data-model/",
	"title": "Google Tag Manager&#39;s Data Model",
	"tags": ["data layer", "data model", "Google Tag Manager", "Guide"],
	"description": "A detailed description and walkthrough of Google Tag Manager&#39;s internal data model and how it interacts with the on-page dataLayer structure.",
	"content": " It\u0026rsquo;s time for MeasureCamp again! As before, I want to write an accompanying post for my session, since there\u0026rsquo;s always so much more to say than the time slot allows for. So, the topic of this article is the data model used by Google Tag Manager to process digital data in your data layer.\nThis post also picks up where I left in my previous foray into the data layer. However, where the first article aimed to be generic (since the data layer should be generic), this post will look at how GTM uses the information in the generic data layer, and how it processes this information to work with the proprietary features of the tool.\n  The diagram above should elucidate my point (fear my PowerPoint-to-image skills).\nWe have data passing through your backend systems to your website. Some of this data is used to build the website with its visuals and functionalities, and some of this data is stored in the data layer to be used by other tools and applications connected to the website.\nGoogle Tag Manager doesn\u0026rsquo;t access the data layer\u0026rsquo;s structure directly, since that would compromise the data layer\u0026rsquo;s generic and tool-agnostic purpose. Rather, it pulls data from the data layer, stores it in its internal, abstract data model, and uses that to process the digital data.\nSince we live in a multi-vendor world, where web tools and applications are popping up like mushrooms after rain, it\u0026rsquo;s important to respect the generic data layer. It\u0026rsquo;s up to the sophistication of the tool itself to use this data, but it must be done in a non-invasive manner - using pull methods rather than push.\n   dataLayer Data Model     Tool-agnostic Tool-specific   Generic Unique   Accessed directly Accessed via helper   Structured Abstract    There\u0026rsquo;s a difference between data layer and data model. To some it might seem very subtle, but in reality it\u0026rsquo;s what ensures that the data layer remains a free-for-all, standardized container for data. The data model, on the other hand, is built according to each platform\u0026rsquo;s own specifications, but the way it communicates with the data layer must be clean and perhaps even standardized, since only that way can we ensure that a single tool doesn\u0026rsquo;t ruin the data layer for all.\nSetting up the test The most familiar way of accessing GTM\u0026rsquo;s data model is through the Data Layer Variable Macro. When you call this macro type, the following happens:\n The macro polls the data model through an interface method\n If a key with the given variable name is found, its value is returned\n If no key is found, undefined is returned instead\n  For the purposes of this article, I\u0026rsquo;ll now create a tester, which shows you how the data model works. The tester is a Custom HTML Tag which fires upon a certain event (\u0026lsquo;dlTest\u0026rsquo;). When it fires, it prints the content of the Data Layer Variable Macro into the JavaScript console.\n  The macro itself is just a Data Layer Macro which refers to variable name testKey:\n  So now, whenever I want to see what the key testKey contains in the data model, I only have to type the following in the console:\ndataLayer.push({'event' : 'dlTest'});\nNext, I\u0026rsquo;ll publish my container, and try this out. This is what the console looks like now if I run the event:\n  The undefined is what the macro actually returns. false is returned because the event push triggered a tag.\nAdd and modify the key Let\u0026rsquo;s start simple. I\u0026rsquo;ll add some values to the key, and see how the macro reacts:\n  Here are the pushes in order:\n 'string' - string\n 1 - number\n [1, 2, 3] - Array\n {'key' : 'value'} - object\n true - boolean\n function() { return undefined; } - function\n  As you can see, the interface get() function only returns the latest value. dataLayer, however, holds all the values:\n  Here are the key takeaways:\n The data model is not the same thing as data layer. All the values I pushed above can be found in the data layer, but only the most recent value is stored in the data model\n When pushing a value of different type, the previous value is completely overwritten in the data model\n  That\u0026rsquo;s pretty simple, right? Well, let\u0026rsquo;s try updating the value with another value of the same type next.\n  Here are the pushes in order:\n 'string' + 'newString' =\u0026gt; 'newString'\n 1 + 5 =\u0026gt; 5\n [1, 2, 3] + [4, 5] =\u0026gt; [4, 5, 3] *HUH?\n {'key' : 'value'} + {'newKey' : 'value'} =\u0026gt; {'key' : 'value', 'newKey' : 'value'} *WTF?\n  The primitive values work as expected. Pushing another value of the same type just overwrites the previous value. However, the Array and the plain object behave very strangely.\nThis is because when you\u0026rsquo;re pushing an Array on top of an Array or a plain object on top of a plain object, the interface performs a recursive merge. That is, it checks whether the keys within the object or Array that are being pushed already exist. If they do, their values are updated, but all the other keys are left alone.\nIt\u0026rsquo;s easy to understand if you look at how the plain object behaves.\nFirst, you push an object with the key \u0026lsquo;key\u0026rsquo; with the value \u0026lsquo;value\u0026rsquo;. Next, you push an object with the key \u0026lsquo;newKey\u0026rsquo; with the value \u0026lsquo;value\u0026rsquo;. Now, \u0026lsquo;key\u0026rsquo; is not the same thing as \u0026lsquo;newKey\u0026rsquo;, so the plain object is updated, not replaced.\nBut what about the Array? I\u0026rsquo;m pushing [4, 5], which have nothing in common with [1, 2, 3]. Shouldn\u0026rsquo;t the end result be\n[4, 5], or [1, 2, 3, 4, 5], or even [[1, 2, 3], [4, 5]]?\nSurely [4, 5, 3] is a bug?\nNope, if you know your JavaScript. An Array is a type of an object. It, too, has keys with which you can access the values within. The keys start from 0 and go up until there are no more members in the Array. So, the first Array looks actually something like this:\n[1, 2, 3] Key 0 : Value 1 Key 1 : Value 2 Key 2 : Value 3\nThe second Array looks like this:\n[4, 5] Key 0 : Value 4 Key 1 : Value 5\nNow, the recursive merge spots these shared keys (0 and 1), and updates their values accordingly. The third key (2) is not touched, since the Array that was pushed second had no value for it.\nWe\u0026rsquo;ll explore how to add data to existing Arrays soon enough.\nRemoving a key from the data model If you have a single page app, and the data layer persist throughout the session, you might want to delete some variables from the data model every now and then. Just removing the key from dataLayer won\u0026rsquo;t be enough:\n  Here\u0026rsquo;s what happens:\n I push \u0026lsquo;simoahava\u0026rsquo; as the value of \u0026lsquo;testKey\u0026rsquo;, this is registered by the macro\n I delete this entire object from dataLayer\n I verify this by looking at the contents of dataLayer\n However, the data model still holds the latest value\n  This is actually an important feature of the data model. The data model treats dataLayer as a queue or a message bus, if you will. It operates on a first in, first out principle, meaning that as soon as something is pushed into dataLayer, it is processed and its values are stored into the data model.\nIt wouldn\u0026rsquo;t work if the data model should remove a key if it is dropped from dataLayer. You might have multiple pushes of the same key with different values (take \u0026lsquo;event\u0026rsquo;, for example). How would the data model know if you\u0026rsquo;re just cleaning up objects from the global Array structure rather than asking for them to be removed from the data model?\nA remove method in the interface might be a good idea, but it\u0026rsquo;s just as easy to take the generic approach and push undefined as the value of the key. This will store undefined into the data model as well, meaning it will be, for all intents and purposes, as if the key no longer exists.\n  That\u0026rsquo;s how simple it is.\nThe command array This is where I left you hanging earlier. Say you want to update an Array by adding members to the end or into the middle. It\u0026rsquo;s very difficult to do in a generic way, since you first need to retrieve the Array from the data model, add members to the end or to the middle, and then push it back. And all has to happen within the data layer, because you don\u0026rsquo;t want all the other tools and platforms that use the data layer to be left outside.\nThe way to do this is to use a special command array. It enables you to access methods of the value type you have stored in the data model.\nHere\u0026rsquo;s how it works. I\u0026rsquo;m going to update an Array [1, 3] first with two new members using push(), so that it becomes [1, 3, 4, 5]. Next I\u0026rsquo;ll do a splice(), where I add the number 2 to its rightful place. Observe closely.\n  As you can see, the command array has its special syntax. First of all, you need to push an Array into the data layer, not an object as you normally would.\nNext, the first member of the Array needs to be a string which holds the actual command. All the rest of the members in the command array are arguments to this command.\nThus, testKey.push(4,5) becomes ['testKey.push', 4, 5], and testKey.splice(1,0,2) becomes ['testKey.splice', 1, 0, 2].\nThis way you can do some cool things with the values stored in the data model without having to access them directly. Using the data layer ensures that other tools and applications can benefit from your modifications as well.\nCustom methods The last thing I\u0026rsquo;ll show you is how to perform some custom transformations on the values stored in the data model.\nLet\u0026rsquo;s say I\u0026rsquo;m storing a bunch of products and stores in the data layer. This data is provided by the backend system. As it turns out, one of the store names is misspelled, and this needs to be fixed in the data model. Performing a series of gets and sets would be cumbersome and very ineffective. Instead, I can just push a function which does this whole thing in a simple for-loop.\n  When you push a function into the data layer, this will be the interface of the data model on the page. It exposes two methods: get(key) and set(key, value).\nFirst, I use get() to retrieve the value of 'testKey'. Then, I do a for-loop which goes over each member in the 'testKey' Array, looking for the typo. If a typo is found, then it\u0026rsquo;s corrected there and then. Because I\u0026rsquo;m dealing with objects, you don\u0026rsquo;t have to push anything back into the data model, since you\u0026rsquo;ve actually copied an object reference, not the object itself.\nDon\u0026rsquo;t worry about that object mumbo-jumbo. The key here is that I performed a transformation on the data in the data model by using the data layer. This way other vendors and tools can benefit from the change as well. I could have just as well directly accessed the public method of the interface, but that would not be the generic way to do things.\nSummary This has been a complicated post, I know, but here are the things you should have learned.\n The data layer on the page and the data model used by the tag manager are not the same thing\n The data layer is generic, tool-agnostic, and can be accessed by all applications that can tap into the global namespace\n The data model is internal to the tag manager, it\u0026rsquo;s abstract (no Arrays here), and it has a public interface with just two methods\n Certain values (Arrays, plain objects) behave erratically when you try to update them with a regular push\n You should always do all additions, removals, and transformations by using the data layer, and not by accessing the interface of the data model directly\n  If you want to geek it up a little, take a look at the Data Layer Helper specification in GitHub, written by GTM\u0026rsquo;s own Brian Kuhn. That\u0026rsquo;s where most of the lessons here were picked up.\nIt\u0026rsquo;s so important to understand the subtleties of the data layer and the data model. The one is (or should be) tool-independent, the other is a proprietary feature of the tool. One can be standardized to serve multiple vendors and platforms, the other should cater to the idiosyncrasies of each tool separately.\nMy presentation \u0026ldquo;Google Tag Manager For Nerds\u0026rdquo; from MeasureCamp V\n"
},
{
	"uri": "https://www.simoahava.com/analytics/use-page-visibility-api-google-tag-manager/",
	"title": "Use Page Visibility API With GTM",
	"tags": ["Google Tag Manager", "Guide", "JavaScript", "visibility"],
	"description": "How to use the Page Visibility API in Google Tag Manager for improved accuracy of web analytics tracking.",
	"content": " The Page Visibility API for web browsers is pretty sweet. It lets you poll, using some new properties of the document object, whether or not the current page is visible to the user. Visibility is hidden if the page is not open in the current browser tab instance, or if the browser window has been minimized.\n  In this post, I\u0026rsquo;ll give an example of how features of the Page Visibility API could be used with Google Tag Manager. Do note, however, that browser support for the API pretty much excludes all IE versions older than 10 from the scope of this article.\nIn this example, we\u0026rsquo;ll set up some tags, rules, and macros which will help us avoid receiving pageviews for pages which have been opened in tabs but were never read. I don\u0026rsquo;t know about you, but having a pageview for a page which wasn\u0026rsquo;t viewed sounds counter-intuitive. The pageview will only get sent once the page first becomes visible.\nThe Visibility Listener First, we\u0026rsquo;ll create a visibility listener. What it does is dispatch a browser event every time the visibility state of a page changes.\n Create a new Custom JavaScript Macro {{visibility prefix}}\n Add the following code within (inspired by this article):\n  function() { var prefixes = [\u0026#39;moz\u0026#39;, \u0026#39;ms\u0026#39;, \u0026#39;o\u0026#39;, \u0026#39;webkit\u0026#39;]; if (\u0026#39;hidden\u0026#39; in document) { return \u0026#39;\u0026#39;; } // Loop through each prefix to see if it is supported.  for (var i = 0; i \u0026lt; prefixes.length; i++) { var testPrefix = prefixes[i] + \u0026#39;Hidden\u0026#39;; if (testPrefix in document) { return prefixes[i]; } } return; }   Create a new Custom JavaScript Macro {{visibility hidden}}\n Add the following code within:\n  function() { switch ({{visibility prefix}}) { case \u0026#39;\u0026#39;: return document[\u0026#39;hidden\u0026#39;]; case \u0026#39;moz\u0026#39;: return document[\u0026#39;mozHidden\u0026#39;]; case \u0026#39;o\u0026#39;: return document[\u0026#39;oHidden\u0026#39;]; case \u0026#39;webkit\u0026#39;: return document[\u0026#39;webkitHidden\u0026#39;]; default: return; } }   Create a new Custom HTML Tag\n Add the following code within:\n  \u0026lt;script\u0026gt; if (typeof {{visibility prefix}} !== \u0026#39;undefined\u0026#39;) { var visibilityEvent = {{visibility prefix}} + \u0026#39;visibilitychange\u0026#39;, hiddenState = {{visibility hidden}}, visibilityChanged = function() { if (typeof hiddenState !== \u0026#39;undefined\u0026#39;) { dataLayer.push({ \u0026#39;event\u0026#39; : \u0026#39;visibilityChange\u0026#39; }); } }; // Attach visibility listener to document  document.addEventListener(visibilityEvent, visibilityChanged, false); } \u0026lt;/script\u0026gt;  Set tag to fire upon {{event}} equals gtm.js  First we create a utility macro which returns the required browser prefix for setting up the listener and for testing visibility state. In the next macro, we retrieve the state of the document (true: document is hidden, false: document is visible).\nFinally, in the tag we create a listener for changes in page visibility. If visibility changes, a dataLayer event is pushed.\nWe will utilize this data in the following example.\nBlock Pageview Until Page Is Visible So the point here is to not send a pageview to Google Analytics until the page becomes visible. This applies to all your events as well, so you\u0026rsquo;ll need to add these same rules and functions (modified to match the original firing logic) to your event tags, or you might end up having sessions with only events and no pageviews. This is to be avoided.\nHere\u0026rsquo;s the logic:\n When the pageview is first set to fire (usually {{event}} equals gtm.js), use page visibility as a blocking rule. If the page is hidden, do not fire the tag.\n When the page becomes visible, use the visibility event as a trigger for the tag.\n When the pageview has fired, use its hitCallback to prevent the visibility listener from triggering the tag again.\n  So, let\u0026rsquo;s get going.\n Create a new Custom JavaScript Macro {{visibility callback}}\n Add the following code within:\n  function() { return function() { if (typeof {{visibility prefix}} !== \u0026#39;undefined\u0026#39;) { var visibilityEvent = {{visibility prefix}} + \u0026#39;visibilitychange\u0026#39;; document.removeEventListener(visibilityEvent, visibilityChanged); } } }   In your pageview tag, create a new rule with the following two conditions, and add it to the tag. Keep all the old rules in place as well!\n {{event}} equals visibilityChange\n {{visibility hidden}} equals false\n  In your pageview tag, add the following Blocking Rule\n {{visibility hidden}} equals true  In your pageview tag, browse all the way down to Fields to Set, and add a new field\n Field name: hitCallback\n Value: {{visibility callback}}\n   And that should do it. This is a long chain of actions, but it follows the path described in the beginning of this section.\nConclusions The Page Visibility API is pretty cool, but it\u0026rsquo;s first and foremost designed to save resources. Use it to stop a video from playing when the tab is not focused, or to stop an image carousel from proceeding.\nWith Google Tag Manager, you could do a number of things, such as:\n Block pageview for non-visible pages (explored in this post)\n Send visibility during pageview as a Custom Dimension (to track if the page is opened in a new tab or directly)\n Track visibility change as a GA event (to see if people focus on your content)\n Pause Timer Listener when page is hidden, and restart it when it becomes visible\n  And so on.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/undefined-dimensions-wont-get-sent/",
	"title": "#GTMtips: Undefined Dimensions Won&#39;t Get Sent",
	"tags": ["Google Tag Manager", "gtmtips", "JavaScript", "undefined"],
	"description": "By making sure that unneeded variables are resolved to undefined, Google Tag Manager automatically drops the from tags.",
	"content": " This might not sound like a tip to you. You might think, \u0026ldquo;Dimensions won\u0026rsquo;t get sent? Sounds like a bug!\u0026rdquo;. You\u0026rsquo;re wrong. This is one of the awesome features of the GA API, and it\u0026rsquo;s key to making your tag setups leaner when sending data to Google Analytics.\nTip 4: Undefined dimensions are left out of GA hits   Note that \u0026lsquo;undefined\u0026rsquo; here means the special value undefined in JavaScript. For a refresher, check this post. If you use a macro in a dimension field of Google Tag Manager\u0026rsquo;s Universal Analytics tags, this dimension will be left out of the hit payload if its return value is undefined.\nThe hit itself will get sent, but the dimension will just be dropped out.\nHow is this awesome? Well, you might have thought until now that you need two tags for each version of the dimension reference: one for when it has a value, and one when its value is undefined. The latter version doesn\u0026rsquo;t have the dimension field populated at all.\nYou don\u0026rsquo;t have to go through this duplication of tags if you learn to use the power of undefined in your GTM macros. Just make sure the value is really undefined and not 'undefined', which is a String.\nIt\u0026rsquo;s not just Custom Dimensions this works with. Any fields that are translated into dimensions behave the same way, meaning you can use this to send pretty darn efficient virtual pageviews as well, as they use the Document Path field in your tags.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/data-layer/",
	"title": "The Data Layer",
	"tags": ["data layer", "datalayer", "Google Tag Manager", "governance"],
	"description": "An overview of the Data Layer in Google Tag Manager, and a detailed description of its use and application in websites.",
	"content": " Writing this article is dangerous. Data Layer is two marketers short of becoming a buzz word. This occasion will be heralded by articles such as \u0026ldquo;Data Layer Is Dead\u0026rdquo;, \u0026ldquo;This Developer Implemented A Data Layer And You\u0026rsquo;ll Never Guess What Happened Next\u0026rdquo;, and other examples of the kind of content generation whose propagation should be prevented by military force. This is not one of those articles, I hope, but rather an honest look at what Data Layer is from a number of perspectives.\n  And there are many perspectives, indeed. The terminology itself is difficult to pin down. In this article, I will consider Data Layer to comprise the following definitions:\n The description of business requirements and goals, aligned in a format that is readily transferrable to technical specifications\n The concept of a discrete layer of semantic information, stored in a digital context\n  I will also use the variable name dataLayer to denote the data structure used by Google Tag Manager for storing, processing, and passing data between the digital context and the tag management solution. I also prefer the term digital context to website, for example, since the Data Layer can be used in a variety of context, not just a public-facing web environment.\nThe Data Layer most explored in this article is the one that is firmly rooted in the DMZ between developers and marketers. It\u0026rsquo;s very much a technical concept, since its existence is justified by the limitations imposed by certain web technologies (JavaScript, for example) upon how browsers interact with applications (Google Tag Manager, for example). At the same time, Data Layer is, and ought to be, owned at least partly by marketers, analysts, executives, designers, and communication professionals, who draft the business requirements and goals that are satisfied by data collection methods.\nIn other words, it\u0026rsquo;s very common that the governance of Data Layer is debated hotly among different stakeholders of the \u0026ldquo;data organization\u0026rdquo; within a company. Since, as we will learn, it\u0026rsquo;s a generic data model that can be used by all applications that interface with your digital data, it\u0026rsquo;s very difficult to draft a governance model that would satisfy all parties. This, too, we\u0026rsquo;ll explore in this post.\nIn the end I\u0026rsquo;ll share some great resources for learning more about Data Layer, since this post will not be a deep-dive (even though it is wordy).\nWhat Is The Data Layer To put it shortly, a Data Layer is a data structure which ideally holds all data that you want to process and pass from your website (or other digital context) to other applications that you have linked to.\nThe reason we use a Data Layer is because sometimes it is necessary to decouple semantic information from other information stored in the digital context. This, in turn, is because if we reuse information already available, there\u0026rsquo;s a risk that once modifications are done to the original source, the integrity of the data will be compromised.\nA very common example is web analytics tracking. You might have a Data Layer which feeds data into your analytics tool about the visitor. Often, this data isn\u0026rsquo;t available in the presentational layer, or in the markup at all. This data might be, for example, details about the visitor (login status, user ID, geolocation), metadata about the page (optimal resolution, image copyrights), or even information that\u0026rsquo;s already in the markup, but that you want to access in a more robust way.\nThis duplication is often seen in eCommerce data. Instead of \u0026ldquo;scraping\u0026rdquo; transactional details from the header or content of the page, it\u0026rsquo;s more reliable to use the Data Layer to carry this information, since only this way is the data uncoupled from the website proper, meaning it is less subject to errors when markup is modified.\nIf, for example, you were inclined to use data stored in a H2 heading of the HTML markup in the thank you page, a single change to the markup or the format of the information in this HTML element would compromise data collection from the site to your tracking tool. If, however, the data were stored in a Data Layer with no link to the presentational layer, there is a far smaller risk of unexpected changes occurring (though it\u0026rsquo;s definitely not impossible).\nSo, in short, the Data Layer is a data structure for storing, processing, and passing information about the context it exists in.\nThe Data Layer: The Non-Technical Perspective For the marketer, the analyst, the executive, the communications officer, or other non-developer, the Data Layer is actually a list of business requirements and goals for each subset of the digital context.\nFor a web store, for example, business requirements and goals might include transactional information (what was purchased), user data (who made the purchase), spatial and temporal details (where was the purchase made in and at what time), and information about possible micro conversions (did the user subscribe to product updates).\nFor another part of the same website, the business requirements and goals might include simply details about which social media channel brought the user to the website, or which pages the user has viewed more than once.\nThese are not technical specifications, but clearly defined lists of items that need to be collected in order to satisfy the business goals set for each business area of the website or other digital context.\nIdeally, the Data Layer carries information which can be used by as many different tools / users / stakeholders as possible, but it\u0026rsquo;s very common that idiosyncrasies emerge. This is why it\u0026rsquo;s extremely important to treat the Data Layer as a living, agile model, not a stagnated, monolithic, singular entity.\nSimilarly to any aspect of digital analytics, a Data Layer should also be treated as something that\u0026rsquo;s constantly in flux. The data it holds must be optimized, elaborated, divided, conjoined, cleaned, refactored, and questioned as often as new business requirements emerge, or when previous goals were not beneficial to the business.\nGoogle Tag Manager\u0026rsquo;s dataLayer Since there\u0026rsquo;s no existing standard for the data model explored in this article (the effort is under way, though), the Data Layer can have many technical guises. The technical perspective I\u0026rsquo;ve chosen is the one that has evolved through Google Tag Manager. This is because I think, and I\u0026rsquo;m only slightly biased here, that dataLayer is one of the more elegant implementations of a structured data model in the web environment.\ndataLayer is a JavaScript Array, which holds data in key-value pairs. The key is a variable name in String format, and values can be any allowed JavaScript type. This is an example of dataLayer with different data types:\ndataLayer = [{ \u0026#39;products\u0026#39;: [{ \u0026#39;name\u0026#39;: \u0026#39;Kala Ukulele\u0026#39;, \u0026#39;tuning\u0026#39;: \u0026#39;High-G\u0026#39;, \u0026#39;price\u0026#39;: 449.75 },{ \u0026#39;name\u0026#39;: \u0026#39;Fender Stratocaster\u0026#39;, \u0026#39;tuning\u0026#39;: \u0026#39;Drop-C\u0026#39;, \u0026#39;price\u0026#39;: 1699 }], \u0026#39;stores\u0026#39;: [\u0026#39;Los Angeles\u0026#39;, \u0026#39;New York\u0026#39;], \u0026#39;date\u0026#39;: Sat Sep 13 2014 17:05:32 GMT+0200 (CEST), \u0026#39;employee\u0026#39;: {\u0026#39;name\u0026#39;: \u0026#39;Reggie\u0026#39;} }];  Here we have values such as an Array of objects (the products), numerical values (price), an Array of Strings (stores), a date object, and a nested object (the employee name).\nThe point here is that dataLayer is generic and tool-agnostic. As long as it behaves like your typical JavaScript Array, it won\u0026rsquo;t be restricted to just one tool. The information in the dataLayer object above can be used by any application which has access to the global namespace of this page.\nHow the data within this Array is processed is thus left to the tool. In Google Tag Manager, for example, an intermediate helper object is used to process data in dataLayer, which is then stored in an internal, abstract data model within the tool itself. This ensures that dataLayer can stay generic and tool-agnostic, but the data within is processed to comply with the idiosyncratic features of Google Tag Manager.\nThe helper object used by Google Tag Manager has a number of interesting features, such as:\n A listener which listens for pushes to dataLayer. If a push occurs, the variables in the push are evaluated.\n Get and set methods which process / manipulate dataLayer as a queue (first in, first out), and ensure that the special values (objects, Arrays) within the data model can be updated and appended correctly.\n The ability to access commands and methods of objects stored in dataLayer, and the possibility of running custom functions in the context of the data model.\n  These are all transparent to Google Tag Manager\u0026rsquo;s users, of course, but they explain why, for example, the Data Layer Variable Macro can access dotted variable names (gtm.element) and properties (gtm.element.id) equally, and also why you can push multiple values with the same key into dataLayer but only the most recently pushed value is available for tags which fire after the push.\nSince the abstract data model within Google Tag Manager only respects the most recent value of any variable name, the organization must decide where and when Data Layer as a business component becomes dataLayer the Array structure. This is the topic of the next chapter.\nFrom Business Goals To Technical Implementation The most common approach, I believe, is that the business requirements and goals are translated into a set of key-value pairs, which must be rendered / deployed by server-side code, so that dataLayer is populated with all the necessary data before the GTM container snippet loads.\nNaturally, you could do it with client-side code, and it doesn\u0026rsquo;t have to be pre-populated, but business-critical data is best secured if it\u0026rsquo;s rendered into dataLayer at the earliest possible moment in the page load, so that data loss is minimized if the user decides to leave the page before dataLayer has rendered.\nHere\u0026rsquo;s an example. We have a page with the following business requirements that we want to track as business goals:\n User ID - because we want to track the entire user journey, not just session-by-session or device-by-device\n Internal user - because we want to filter out our own employees\u0026rsquo; traffic from the data\n Weather at time of visit - because we want to see how weather affects visit behavior\n  This is a simple, albeit nonsensical, list of business requirements that have a direct impact on how we track goals for this part of the website. This list needs to be appended with more information, such as what are example values for these variables, what is their scope (hit, session, user, product, for example), should they persist (stay on from page to page), and so on. I won\u0026rsquo;t do this now, since it\u0026rsquo;s very much up to how your organization handles projects which span across different departments or business domains.\nAnyway, an example of dataLayer, rendered before the container snippet, might look like this:\n\u0026lt;script\u0026gt; window.dataLayer = window.dataLayer || []; dataLayer.push({ \u0026#39;userId\u0026#39; : \u0026#39;abf5-3245-ffd1-23ed\u0026#39;, \u0026#39;internalUser\u0026#39; : true, \u0026#39;weather\u0026#39; : \u0026#39;Cloudy\u0026#39; }); \u0026lt;/script\u0026gt; \u0026lt;!-- GTM Container Snippet Code Here --\u0026gt; As you can see, the data is rendered before the GTM container snippet, so that all tags that fire as soon as GTM is loaded can use this data.\nDo note that you can and will use dataLayer within the confines of Google Tag Manager as well, since your tags or other on-page libraries might well push data into the structure after this pre-load sequence. I don\u0026rsquo;t think these dynamic pushes or data exchanges need to be documented as carefully, since they occur solely in the domain of the tool that does the pushes. Thus, documentation and version control is left up to the sophistication of the tool itself.\nThe reason you need to put a lot of thought behind the pre-rendered dataLayer is because each new stakeholder makes the question of governance a bit more complex.\nGovernance Of The Data Layer Coming up with a good governance model is difficult. Coming up with one for a data structure which is at the mercy of a number of different parties, all with varying levels of expertise (and general interest), is even more difficult.\nNevertheless, a well-defined, structured, and formalized governance model is probably the one thing that will prevent your analytics organization from imploding due to missteps in operating with a Data Layer.\nA governance model, in this context, is a document (or documentation) which describes as clearly as possible the Data Layer, its parts, the business domains it\u0026rsquo;s deployed in, its various owners, its version history, its variables, how risk management is handled, etc.\nThis is a very fluid concept, and it really depends on the organization how they want to organize themselves around this project, but ideally this is the kind of governance model I\u0026rsquo;d be happy to work with:\nI Introduction\n- Purpose of the document\n- Who this document is for\n- Table of contents\nII Version History\n- What was revised\n- When it was revised\n- By whom it was revised\nIII Ownership\n- What does ownership mean\n- Who owns the process\n- What are the rights and privileges of the owner\nIIIa Stakeholders\n- Who have a stake in Data Layer (tools, platforms, departments, agencies, third parties)\n- What is their role\n- What are their rights and privileges\nIIIb Technical Specifications\n- Who owns the technical Data Layer (IT, most often, or a very enlightened marketer)\n- What is their role\n- What are their rights and privileges\nIIIc Management\n- Who owns the business requirements (head of marketing, or some similar role in the client organization)\n- What is their role\n- What are their rights and privileges\nIV Process Distribution\n- What parties use Data Layer\n- What are their special requirements\n- How to avoid conflicts between different stakeholders\nV Risk Management\n- What are the risks\n- What is their severity\n- What is their probability\n- Who owns the risks (and any actions taken to mitigate them).\nVI Data Layer Management Model\n- How to plan for updates\n- How to implement updates\n- Who deploys the updates\n- Who tests the updates\n- Who needs to be notified\n- Who updates the document\n- How to avoid conflicts\nVII Data Layer Technical Description\n- What is the underlying data structure\n- How is this structure translated into each tool\u0026rsquo;s own data model\n- Are there reserved variable names or other potential sources of conflict\nVIII Data Layer Variables\n- Business requirements translated to data layer variables\n- Sorted by business domain\n- Example values, scope, parameters, expected types\n- Where the data comes from\n- How the data is used\n- And so on\u0026hellip;\nI know, it looks horrible. And probably unusable for many. However, having a document like this that is also constantly updated not only provides you with some contractual security, but it also keeps everyone up to date on the most recent structure and format of Data Layer.\nDoes this document need to be consulted / updated when you create a new JavaScript code snippet which calculates the number of images on the page?\nProbably not.\nDoes this document need to be consulted / updated when you\u0026rsquo;re implementing a conversion pixel which also uses Transaction Value?\nMost likely.\nDoes this document need to be consulted / updated when you\u0026rsquo;re deploying enhanced eCommerce?\nAbsolutely.\nIt doesn\u0026rsquo;t have to be larger than life or a huge complication. Just have some concrete description of Data Layer available at all times, and at the very least, agree in writing on how the Data Layer is updated and by whom. This way you\u0026rsquo;ll save a lot of trouble in the long run, when unwarranted changes are about to happen.\nConclusions And Further Reading I think Data Layer is a very difficult concept to grasp. This isn\u0026rsquo;t just because for most it\u0026rsquo;s a technical thing, but because most don\u0026rsquo;t realize it\u0026rsquo;s also very much a list of business requirements.\nTranslating business goals to a well-formed, lean, and 100 % utilized Data Layer is really difficult. I honestly think one of the biggest mistakes is to follow the waterfall model, where a huge list of requirements is jotted down in the beginning of the project, then translated into a Data Layer which appears on every single page on the site, and after that point the structure is never touched again.\nThis doesn\u0026rsquo;t work.\nThe waterfall model is flawed thanks to human fallibility. We simply can\u0026rsquo;t design or predict the final shape of something as vast as an entire layer of semantic data, which might cover almost every single aspect of our digital context. It has to be agile. There has to be a mutual understanding that the shape of the layer becomes clearer with time.\nStart small and scale up, if you have time. If you\u0026rsquo;re in a rush, focus solely on the business-critical requirements.\nWhatever you do, make sure there\u0026rsquo;s a process in place which lets you suggest modifications to Data Layer quickly. This requires a lot of lubrication, education, and knowledge transfer. That\u0026rsquo;s why I think the most important thing in any data project is to start with educating all parties about what the other parties are doing in the project. Make the marketers more development-minded and the developers more respectful of your marketing efforts.\nThat way everyone wins, and you\u0026rsquo;ll have a beautiful Data Layer in no time.\nFurther reading:\n Google Tag Manager Dev Guide by Google\n Make Analytics Better With Tag Management And A Data Layer by Justin Cutroni\n Unlock The Data Layer: A Non-Developer\u0026rsquo;s Guide To Google Tag Manager by Dorcas Alexander / Lunametrics\n The dataLayer Structure in JavaScript 101 For GTM: Part 1\n  P.S. If anyone knows a really good article about governance of semantic data, I\u0026rsquo;d love to read it and link to it in this post.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/gtmtips-rules-nutshell/",
	"title": "#GTMtips: Rules In A Nutshell",
	"tags": ["Google Tag Manager", "gtmtips", "Guide", "rules"],
	"description": "Google Tag Manager&#39;s rules in a nutshell. Rules govern how tags fire based on dataLayer.push events.",
	"content": " Rules are the cornerstone of Google Tag Manager. As with any critical element in a system, they are easy to get wrong. This tip is just a refresher on how GTM firing and blocking rules work.\nTip 3: Google Tag Manager rules in a nutshell   So, let\u0026rsquo;s go through these points one-by-one.\nEvery tag requires a firing rule to work - this is a given. Without a firing rule, your tag will not be written in the document object, and it will never be executed.\nEvery firing rule requires an {{event}} condition - this is a bit more complex. Every time an \u0026lsquo;event\u0026rsquo; variable is pushed with some value into dataLayer, every single rule on every single tag will be evaluated against this value. Thus, every tag needs some value lookup for {{event}} in their firing rules.\n{{event}} equals gtm.js is the \u0026ldquo;default\u0026rdquo; event - if there\u0026rsquo;s no explicit {{event}} condition in your firing rule, GTM will evaluate the tag as having {{event}} equals gtm.js as its firing rule. This event occurs at the earliest possible moment when the GTM Container Snippet is written on the page.\nA single rule can have many conditions - but every single condition must be matched for this rule to work as a trigger. You can introduce some OR-logic into conditions by using e.g. {{event}} matches RegEx ^gtm.(js|linkClick)$, but this is generally better to do with multiple firing rules rather than this crude manipulation of rule conditions.\nA single tag can have many firing rules - this is very important! Every single firing rule that the tag has can and will fire the tag if the rule conditions are met. Thus, if you have a rule {{event}} equals gtm.dom (fire the tag after DOM has loaded) AND {{url path}} matches RegEx ^/thankyou$, this tag will fire once on every page, and twice on the /thankyou-page: first for {{event}} equals gtm.js and second for {{event}} equals gtm.dom! Note that the tag will still fire only once for a given event. So even if you manage to botch things by having three {{event}} equals gtm.js rules in a single tag, the tag will fire just once when the event occurs.\nA blocking rule overrides any firing rule - if you have a blocking rule, it will override any firing rule you might have on the tag. For example, if the firing rule is {{url}} matches RegEx .* and the blocking rule is {{url path}} matches RegEx ^/thankyou$, the tag will fire on all pages except the /thankyou-page. The good thing about using blocking rules is that the same rule you block this tag can be used as a firing rule on some other page, e.g. the actual /thankyou-page for your Transaction Tag!\nA tag is written and run only when the firing rules activate it - thus, the moment the firing rule activates the tag, the tag is added to the document object and any macros referred to in the tag are evaluated. This is important, since it means that by the time the tag fires, any macros it refers to have to be available. Many eCommerce setups have failed because the Transaction Tag fires before the eCommerce payload is in the dataLayer.\nOne thing about macros (this is an extra tip). When a tag fires, all macros referred to in the tag are resolved. This means that it\u0026rsquo;s extremely difficult to know, especially with large implementations, how many times any macro will be resolved upon any event, as you can refer to the same macro in as many tags as you wish. Thus, it is highly recommended that you do not use macros to set or push data.\nSo be careful! As the wise members of the GTM product team always remind us: macros should not have side effects. They should be for value retrieval only - not to set or push data.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/check-referrer-for-previous-page-url/",
	"title": "#GTMtips: Check {{referrer}} For Previous Page URL",
	"tags": ["Google Tag Manager", "gtmtips", "Guide"],
	"description": "Use the referrer variable in Google Tag Manager to see where the visitor came from to your website.",
	"content": " Here\u0026rsquo;s a simple way to check what was the source of the visitor\u0026rsquo;s arrival to the current page. It\u0026rsquo;s done by utilizing the {{referrer}} macro, which comes out-of-the-box in any GTM setup.\nTip 2: Use {{referrer}} to see where the visitor came from   You might want to also explore the Component Types and create new macros for {{referrer path}} and {{referrer host name}} for example:\n  By default, you see, the {{referrer}} macro returns the entire URL of the previous page. Sometimes it\u0026rsquo;s more economical to check only against the URL Path or the Host Name of the previous page. This is where the Component Types kick in.\nAlso, remember that if the previous page was not on the current domain (i.e. it\u0026rsquo;s an entrance to the site), this shouldn\u0026rsquo;t automatically be treated as the landing page of the session, when thinking in Google Analytics terms. A session can include many entrances to the site, if they occur within a 30 minute time window and if they are direct or cross-domain traffic.\nThis tip is useful if you want to fire tags or populate macros depending on if the user came from a specific location, for example one of your social media channels.\n"
},
{
	"uri": "https://www.simoahava.com/gtm-tips/save-gatc-constant-string-macro/",
	"title": "#GTMtips: Save GATC In A Constant String Macro",
	"tags": ["Google Tag Manager", "gtmtips", "Guide"],
	"description": "Save the Google Analytics tracking ID as a constant variable in Google Tag Manager.",
	"content": " I wanted to try something new (and, naturally, I\u0026rsquo;m running out of content ideas), so let me introduce the hashtag #gtmtips. I hope others contribute as well, but I will be adding a new tip as often as possible. I\u0026rsquo;ve got maybe 20 tips in store right now, and I\u0026rsquo;m writing new ones all the time. So without further ado, here\u0026rsquo;s\u0026hellip;\nTip 1: Save GATC In A Constant String Macro   This is an easy one, and everyone should already be doing this in one way or another. The point is that you shouldn\u0026rsquo;t use strings in fields which are often used. Save the string in a macro, so all you have to do is refer to the macro in all your tags. That way, if the string ever changes (for example, when transferring to another property), you don\u0026rsquo;t have to rewrite the field in all your tags.\nDead simple!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/persist-datalayer-google-tag-manager/",
	"title": "Persist dataLayer In Google Tag Manager",
	"tags": ["api", "datalayer", "Google Tag Manager", "Guide", "JavaScript", "localstorage"],
	"description": "A script that lets you persist dataLayer variables from one page to the next when using Google Tag Manager.",
	"content": " If you know your JavaScript, you know that all variables, functions, objects, resources, and data in the document get rewritten with every page load. In other words, every single page refresh builds the page from scratch, and the state of the document before the page refresh is left drifting in the ocean of oblivion.\nGoogle Tag Manager\u0026rsquo;s dataLayer is also one such entity. It gets rewritten with every page load, so it\u0026rsquo;s not possible to have a dataLayer variable persist from one page to the other without using cookies or, as I\u0026rsquo;m going to show in this guide, the HTML5 Web Storage API. For web analytics, this is a bit of a shame. It forces us to think of things in the scope of a single page, when rarely anything worth mentioning has a lifespan that short.\nBefore we begin, take a look at what Shay Sharon expertly wrote two years ago about the persistent dataLayer. In his solution, cookies are used to carry the dataLayer across page refreshes. It\u0026rsquo;s a good patch, and it performs the task admirably. However, the thing with cookies is that they can be deleted (and usually are). Also, the length of the cookie string is limited (though 4KB is still plenty), and there\u0026rsquo;s always the fact that cookies are resolved with every single page load (since they are part of the document object).\nData in browser storage, on the other hand, is actually pretty difficult to delete on a granular level, it has a huge quota, and it\u0026rsquo;s only retrieved and stored on demand. Also, using localStorage (more about this soon), you have the data stored indefinitely, so user-level storage is very easy to implement.\n(UPDATE: Remember that browser local storage should be treated the same as cookies when observing the cookie laws of your country. Thanks to Martijn Visser for pointing this out (he\u0026rsquo;s from the Netherlands, and they have pretty much the strictest interpretation of the cookie law in place.))\n  In this guide, I\u0026rsquo;ll give you an API of sorts to save, load, replace, and delete items from the local storage. I use a 30 minute expiration for data in localStorage to mimic session-length storage.\nIntroducing localStorage localStorage stores data indefinitely in your browser\u0026rsquo;s own storage compartment. It has a larger-than-needed size limit (around 5MB), and data is handled more securely than with cookies. Cookies, you see, are written on the document every time you load a page, and this introduces potential security risks.\nItems in localStorage, on the other hand, are retrieved only when called. This way all the data you store will be picked up on demand, and all you need to do is make sure your script handles the data correctly (which is what I\u0026rsquo;ll do for you in this guide).\nIn localStorage, data is written as key-value pairs, but unlike with dataLayer, both the key and the value need to be of String type. This means that in order to save stuff from dataLayer, which can hold any types of values, to localStorage, some object serialization and type conversion needs to take place (Object =\u0026gt; String). Similarly, the reverse needs to take place when loading data from localStorage and pushing it to dataLayer.\nThe Persistent dataLayer API Without further ado, allow me to introduce the Persistent dataLayer API. Copy the following code into a Custom HTML Tag, and read on.\n\u0026lt;script\u0026gt; (function() { // Declare some utility variables  var retrievedDL = \u0026#39;\u0026#39;, getDL = {}, saveDL = {}, persistEvent = /^persist(Save|Replace)/, timeNow = new Date().getTime(), timeStorage = \u0026#39;\u0026#39;, persistTime = 1000*60*30; // Expiration in milliseconds; set to null to never expire  // Only works if browser supports Storage API  if(typeof(Storage)!==\u0026#39;undefined\u0026#39;) { retrievedDL = localStorage.getItem(\u0026#39;persistDL\u0026#39;); timeStorage = localStorage.getItem(\u0026#39;persistTime\u0026#39;); // Append current dL with objects from storage  var loadDL = function() { if(retrievedDL) { dataLayer.push(JSON.parse(retrievedDL)); // dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;DLLoaded\u0026#39;});  } } // Save specified object in storage  var storeDL = function() { for (var i = 0; i \u0026lt; dataLayer.length; i++) { if (persistEvent.test(dataLayer[i].event)) { saveDL = dataLayer[i]; delete saveDL.event; getDL = JSON.parse(retrievedDL) || {}; for (var key in saveDL) { if (saveDL.hasOwnProperty(key)) { getDL[key] = saveDL[key]; } } localStorage.setItem(\u0026#39;persistDL\u0026#39;, JSON.stringify(getDL)); } } } var deleteDL = function() { localStorage.removeItem(\u0026#39;persistDL\u0026#39;); } switch ({{event}}) { case \u0026#39;gtm.js\u0026#39;: if (retrievedDL \u0026amp;\u0026amp; timeStorage) { if (persistTime \u0026amp;\u0026amp; timeNow \u0026gt; Number(timeStorage) + persistTime) { deleteDL(); } else { loadDL(); } } break; // Delete dataLayer variables  case \u0026#39;persistDelete\u0026#39;: deleteDL(); break; // Replace dataLayer variables  case \u0026#39;persistReplace\u0026#39;: retrievedDL = null; // Save dataLayer variables  case \u0026#39;persistSave\u0026#39;: storeDL(); break; } localStorage.setItem(\u0026#39;persistTime\u0026#39;, JSON.stringify(timeNow)); } })(); \u0026lt;/script\u0026gt; The tag will need the following firing rule:\n{{event}} matches RegEx ^(gtm.js|persist(Save|Replace|Delete))\nHere\u0026rsquo;s a rundown of how the API works, before I go into the technical stuff:\n With every page load, dataLayer variables stored in localStorage are retrieved and pushed into dataLayer.\n When pushing an object with \u0026lsquo;event\u0026rsquo;: \u0026lsquo;persistSave\u0026rsquo;, all variables in the same push (e.g. \u0026lsquo;pageCount\u0026rsquo; and \u0026lsquo;author\u0026rsquo; in dataLayer.push({'event': 'persistSave', 'pageCount': '5', 'author': 'Simo-Ahava'});) are saved to localStorage. If a variable with the same name already exists in localStorage, it is updated with the new value.\n When pushing an object with \u0026lsquo;event\u0026rsquo;: \u0026lsquo;persistDelete\u0026rsquo;, all dataLayer variables in localStorage are deleted.\n When pushing an object with \u0026lsquo;event\u0026rsquo;: \u0026lsquo;persistReplace\u0026rsquo;, all existing dataLayer variables in localstorage are deleted, and all variables in the dataLayer.push() are saved.\n  So remember the following commands:\ndataLayer.push({'var1': 'value1', 'var2': 'value2', **'event': 'persistSave'**}); stores \u0026lsquo;var1\u0026rsquo; and \u0026lsquo;var2\u0026rsquo; (with values) to localStorage.\ndataLayer.push({'var1': 'value1', 'var2': 'value2', **'event': 'persistDelete'**}); deletes all saved dataLayer variables in localStorage; doesn\u0026rsquo;t store anything.\ndataLayer.push({'var1': 'value1', 'var2': 'value2', **'event': 'persistReplace'**}); deletes all saved dataLayer variables in localStorage; stores \u0026lsquo;var1\u0026rsquo; and \u0026lsquo;var2\u0026rsquo; (with values) to localStorage.\nA few additional details:\n With every page load, variables are loaded from localStorage and pushed to dataLayer. Even though the tag itself fires on {{event}} equals gtm.js, there\u0026rsquo;s a slight delay when processing data through the Storage API. This means that usually the variables appear in dataLayer after gtm.dom but before gtm.load.\n Every interaction with localStorage, resets the 30 minute expiration timer. If a page load occurs so that the last interaction was over 30 minutes ago, all saved dataLayer variables in localStorage are deleted.\n Before saving the data, dataLayer variables are serialized into a String. When loading from localStorage, they are parsed from JSON back to their original types. Thus Arrays, objects, and primitive values are restored to their original types before pushed back into dataLayer.\n  Technical stuff Let\u0026rsquo;s go over the code (almost) line-by-line.\n(function() { ... })(); \nThe function is wrapped in an IIFE (immediately invoked function expression). This is because I want to avoid using the global scope when utilizing so many different variables. Scoping the variables to this function ensures that I don\u0026rsquo;t mess with global variables of some other library, for example.\nvar retrievedDL = \u0026#39;\u0026#39;, getDL = {}, saveDL = {}, persistEvent = /^persist(Save|Replace)/, timeNow = new Date().getTime(), timeStorage = \u0026#39;\u0026#39;, persistTime = 1000*60*30; // Expiration in milliseconds; set to null to never expire  Here I introduce a bunch of utility variables. If you want to have the storage persist for ever and ever, set persistTime = null;.\nif(typeof(Storage)!==\u0026#39;undefined\u0026#39;) { retrievedDL = localStorage.getItem(\u0026#39;persistDL\u0026#39;); timeStorage = localStorage.getItem(\u0026#39;persistTime\u0026#39;); ... }  Only run the API if the browser supports HTML5 Web Storage. It\u0026rsquo;s basically only a problem with IE versions older than 8. I saw no reason to provide an alternative for them, since if you\u0026rsquo;re still using IE7 or older, you deserve a horrible browsing experience.\nCheck Shay Sharon\u0026rsquo;s excellent post I linked to in the beginning for a cookie-solution to the persistent dataLayer. That should work with your crappy, out-of-date browser.\nvar loadDL = function() { if(retrievedDL) { dataLayer.push(JSON.parse(retrievedDL)); // dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;DLLoaded\u0026#39;});  } } ... case \u0026#39;gtm.js\u0026#39;: if(retrievedDL \u0026amp;\u0026amp; timeStorage) { if(persistTime \u0026amp;\u0026amp; timeNow \u0026gt; Number(timeStorage)+persistTime) { deleteDL(); } else { loadDL(); } } break;  With every page load, parse the dataLayer variables in localStorage back to their original types, and push them into dataLayer as a single object. If you want to set a trigger event to fire your tags after the variables have been loaded from localStorage, uncomment the line with \u0026lsquo;event\u0026rsquo;: \u0026lsquo;DLLoaded\u0026rsquo;. This way you can have your dependent tags fire on {{event}} equals DLLoaded to ensure that they have access to the stored variables.\nAlso, if the variables in storage expire (default is 30 minutes since last interaction), no data is loaded and the variables are deleted from localStorage. If you\u0026rsquo;ve set persistTime = null;, then there\u0026rsquo;s no expiration for the data in storage, and the variables are stored until they are manually deleted.\nWhen a dataLayer.push(); is made so that the object that is pushed contains the property \u0026lsquo;event\u0026rsquo;: \u0026lsquo;persistSave\u0026rsquo;, the function storeDL() is run.\nFirst, the function removes the \u0026lsquo;event\u0026rsquo; property from the object that was pushed into dataLayer. This is done because you don\u0026rsquo;t want to store the trigger event itself in localStorage. (Another possibility is to just skip the \u0026lsquo;event\u0026rsquo; property when storing properties into localStorage.)\nNext, each property in this dataLayer object is pushed into the object that was found in localStorage. Thus, all variables that were already stored are updated with new values, and new variables are appended.\nFinally, the object, now serialized into a string of keys and values, is stored in localStorage, waiting to be loaded with a new page refresh.\nIf the \u0026lsquo;event\u0026rsquo; was \u0026lsquo;persistReplace\u0026rsquo;, then this the storeDL() is run as well, but all dataLayer variables in storage are replaced with the new variables.\nvar deleteDL = function() { localStorage.removeItem(\u0026#39;persistDL\u0026#39;); } ... case \u0026#39;persistDelete\u0026#39;: deleteDL(); break;  If the trigger event was \u0026lsquo;persistDelete\u0026rsquo;, all dataLayer variables in localStorage are deleted.\nlocalStorage.setItem(\u0026#39;persistTime\u0026#39;, JSON.stringify(timeNow));  Finally, every time the script is run, the current time is saved as a timestamp in localStorage.\nConclusions I\u0026rsquo;ve noticed that many people have been aching for a persistent dataLayer. I\u0026rsquo;m pretty sure this post will become obsolete as soon as the GTM team choose to deploy such a feature into the product itself, but until then, this should serve you well.\nAnd if nothing else, at least you got to learn about yet another really cool JavaScript API!\nDo you have suggestions for the API? Or maybe you have a sweet use case for persistent variables that you might want to share with others?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/node-relationships-gtm/",
	"title": "Node Relationships And GTM",
	"tags": ["auto-event tracking", "event listener", "Google Tag Manager", "Guide", "JavaScript"],
	"description": "Simple variable to check whether or not two nodes are &#34;related&#34; in the document object model. You can do this via Google Tag Manager.",
	"content": " There\u0026rsquo;s a much easier, native-to-GTM way to do this now: the Matches CSS Selector.\nBehind this tragically boring title is a simple solution to many problems with Google Tag Manager\u0026rsquo;s auto-event tracking. The common denominator to these problems is poor website markup. Selectors are used sparingly, and element hierarchy is messy. This disregard for proper node relationships means you have to resort to Data Layer Variable Macros which look like\ngtm.element.parentElement.parentElement.id\nto identify the element that was the target of the event. In other words, there\u0026rsquo;s no robust, unique identifier with which you could identify the targeted element, so you have to go either up or down the Document Object Model to find something you can latch on to.\nThis is not a stable solution.\nThe more steps there are in your selector chain, the more chances there are of you either miscalculating the required steps, or some code on some page template producing a hierarchy which you didn\u0026rsquo;t account for, resulting in a loss of hits.\nIn this guide I introduce a pretty simple solution. It explores the concept of node relationships by using a simple DOM function to do so. The whole thing is still a workaround, and you should definitely try to talk with your developers about how to mark up your elements with proper identifiers.\n(By the way, for markup ideas, here are two excellent articles about using data attributes as identifiers:\nTracking Clicks Using Custom Data Attributes - LunaMetrics\nGoogle Tag Manager Events Using HTML5 Data Attributes - SwellPath)\nAnyway, this guide will demonstrate a pretty simple DOM (Document Object Model) function with which to check whether a given element (e.g. {{element}}) is an ancestor of some other element (e.g. a top-level menu wrapper). The rule will look something like this:\n  As usual, there\u0026rsquo;s the easy method and then there\u0026rsquo;s the advanced method (which isn\u0026rsquo;t really that advanced at all).\nThe easy method The easy method is really just about checking the node relationship between a given element, such as {{element}}, and a specific parent element. This is useful if you only have one or two cases where this is an issue.\nThe DOM method we\u0026rsquo;ll be using is Node.contains.\nHere\u0026rsquo;s the Custom JavaScript Macro, which is the motor of the solution, in all its simplicity:\n{{node contains element}}\nfunction() { var controlElement = document.querySelector(\u0026#39;#parentId\u0026#39;); return controlElement \u0026amp;\u0026amp; controlElement !== {{element}} ? controlElement.contains({{element}}) : false; }  And then your firing rule will be something like:\n{{node contains element}} equals true\n{{event}} equals gtm.linkClick\nFeel free to use any other auto-event tracking type you wish.\nThis will only fire the tag if a click occurs on a link which is a direct ancestor of an element with ID parentId. A cousin or a long-lost blood brother will not do; the nodes must have a direct ancestral relationship.\nSo that was easy, right? What about when you have multiple ancestor-descendant-relationships you want to explore? You could create a rule and macro for each, but a far more robust way is to use a Lookup Table or a Custom JavaScript macro.\nThe advanced method The idea with the advanced method is to vary the the node against which you control the event element, depending on some parameter. In this particular example I use {{url path}} to determine which control node to choose, and a Custom JavaScript macro to return the new query selector.\nSo let\u0026rsquo;s say I have three page templates:\n Home page (url path === \u0026lsquo;/\u0026rsquo;), where I want to track clicks on links in the main navigation (id === \u0026lsquo;#mainNav\u0026rsquo;)\n Product pages (url path === \u0026lsquo;/products/*\u0026lsquo;), where I want to track clicks in any of the three Call-to-action page elements (class === \u0026lsquo;call-to-action\u0026rsquo;)\n All other pages, where I want to track clicks on links in the footer (tag name === \u0026lsquo;footer\u0026rsquo;)\n  Now, to complement the Custom JavaScript macro above, I want the query selector to be dynamic, depending on which of the above conditions is true. So let\u0026rsquo;s modify the macro just a little bit:\nfunction() { var controlElement = document.querySelector({{get query selector}}); return controlElement \u0026amp;\u0026amp; controlElement !== {{element}} ? controlElement.contains({{element}}) : false; }  So it\u0026rsquo;s the same, but the document.querySelector() fetches the query string from a macro called {{get query selector}}.\nAnd what does this macro look like? Well, to satisfy the three requirements I listed above, this is what you\u0026rsquo;ll get:\nfunction() { var homeRegex = /^\\/$/, productRegex = /^\\/products\\//; if(homeRegex.test({{url path}})) { return \u0026#39;#mainNav\u0026#39;; } else if (productRegex.test({{url path}})) { return \u0026#39;.call-to-action\u0026#39;; } return \u0026#39;footer\u0026#39;; }  This returns a different string every time, depending on which condition is satisfied by the URL path of the document.\nYou can now create a unique tag for each of these three variations, still referencing the same macro in the rule, because it will return true/false depending on which condition is satisfied. If you want a more verbose check than just Boolean true/false, you can modify the original macro to return the query selector itself, after which you can modify the rule accordingly:\nfunction() { var controlElement = document.querySelector({{get query selector}}); return controlElement \u0026amp;\u0026amp; controlElement !== {{element}} \u0026amp;\u0026amp; controlElement.contains({{element}}) ? {{get query selector}} : false; }  This piece of code returns \u0026ldquo;#mainNav\u0026rdquo; if the click occurred on the home page navigation, \u0026lsquo;.call-to-action\u0026rsquo; if the click occurred on any of the three call-to-action elements on the home page, or \u0026lsquo;footer\u0026rsquo; for all other cases. Then, if you have a tag which should only fire on clicks on the product page calls-to-action, the rule would look like this:\n{{event equals gtm.linkClick}}\n{{node contains element}} equals .call-to-action\nAnd that\u0026rsquo;s it for the advanced method. Remember that one of the huge perks of using a tag management solution is the opportunity to consolidate your tags and make the whole setup so much leaner. Using Custom JavaScript macros for advanced lookups or the Lookup Table macro for simple value retrievals is usually the key to reducing the weight of your implementation.\nConclusions This was a very basic guide on a sweet little method of the DOM Node object not many seem to be aware of. The point here is that instead of building vast selector chains, where each link is weaker than the one before it, you can just use an all-encompassing ancestor lookup, which reduces the chance of error.\nIf you want to get real flashy, there\u0026rsquo;s always the Node.compareDocumentPosition() method, which returns a bitmask representing the relationship between two nodes. It doesn\u0026rsquo;t take just ancestry into account, it also looks for descendant relationships, which might be useful in some cases. However, it\u0026rsquo;s not in the scope of this guide, and I\u0026rsquo;m pretty sure that most of the problems can be solved with the ancestor lookup.\nJavaScript is fun! Google Tag Manager is fun-ner!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/custom-event-listeners-gtm/",
	"title": "Custom Event Listeners For GTM",
	"tags": ["Google Tag Manager", "Guide", "JavaScript", "listeners"],
	"description": "How to create custom event listeners in Google Tag Manager. This is arguably one of the best ways to enhance Google Tag Manager tracking on your website.",
	"content": " (UPDATE 1 Oct 2014 Due to a change in how macros work in Debug Mode, the {{generic event handler}} macro no longer works when testing in Debug Mode. That means that you\u0026rsquo;ll have to test your custom listener in a live container (I know, ouch!). If you want to test in Debug Mode, you\u0026rsquo;ll have to skip using the {{generic event handler}} as a macro, and instead copy the inner function into the Custom HTML Tag, give the function a name, and use that as the callback in addEventListener or attachEvent.\nAlso, to preserve the \u0026lsquo;gtm.\u0026rsquo; namespace for native GTM features only, I have changed the prefix of the custom event name from \u0026lsquo;gtm.\u0026rsquo; to \u0026lsquo;event.\u0026rsquo;)\nWhen the good folks at Mountain View introduced auto-event tracking for Google Tag Manager, a collective sigh was heard around the world (I\u0026rsquo;m just slightly exaggerating).\nFinally, the true power of GTM was unleashed.\nWith auto-event tracking, one of the more difficult aspects of web analytics, tracking user interactions beyond the page load, was greatly simplified.\n  However, as a species we are in a perpetual state of dissatisfaction.\nWhen we got the Click, the Link Click and the Form Submit, we wanted more. So then we got the History listener. Again, we wanted more. And we got the Error listener. And then we wanted more again.\nTo satisfy this undying thirst for more listeners, the community has been very helpful. In fact, before you read on, I want you to familiarize yourself with Doug Hall\u0026rsquo;s excellent post on extending GTM\u0026rsquo;s auto-event listeners. The following guide will expand upon the ideas put forth by Doug, while striving to approach the elegance of his prose and wisdom.\nI\u0026rsquo;ve also written many posts on GTM\u0026rsquo;s listeners. I\u0026rsquo;ll link to them at the end of this article.\nWhat follows is a step-by-step guide to creating a generic listener for all the various events you want to capture that are not yet captured by GTM\u0026rsquo;s own listeners. Once GTM introduces a proprietary listener for whatever event you want to handle, it would be best to start using that.\nThe listener prototype The prototype of the custom event listener will require two components:\n A Custom HTML Tag for each listener type you want to activate (e.g. change, blur, copy)\n A generic Custom JavaScript Macro, which returns the handler function that pushes the event into the dataLayer\n  As you can see, it looks pretty simple. And it is. As long as you observe proper design patterns and best practices, these two components will get you far.\nThe generic event handler macro Let\u0026rsquo;s start with the macro, since it\u0026rsquo;s the truly generic component here.\nThe macro returns a function, which serves as the handler for the listener you\u0026rsquo;ll create in the next step. For this function to be as generic as possible, it will be agnostic as to what the event was. It will do this by accepting the Event object as its parameter, and parsing that for all the data it needs.\nShowing is easier than telling, so here\u0026rsquo;s the code for you to copy-paste:\nMacro Name: {{generic event handler}}\nMacro Type: Custom JavaScript\nfunction() { return function(e) { dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;event.\u0026#39;+e.type, \u0026#39;gtm.element\u0026#39;: e.target, \u0026#39;gtm.elementClasses\u0026#39;: e.target.className || \u0026#39;\u0026#39;, \u0026#39;gtm.elementId\u0026#39;: e.target.id || \u0026#39;\u0026#39;, \u0026#39;gtm.elementTarget\u0026#39;: e.target.target || \u0026#39;\u0026#39;, \u0026#39;gtm.elementUrl\u0026#39;: e.target.href || e.target.action || \u0026#39;\u0026#39;, \u0026#39;gtm.originalEvent\u0026#39;: e }); } }  This, in my opinion, is a pretty close emulation of how GTM\u0026rsquo;s listeners work. What\u0026rsquo;s important is that the object pushed into dataLayer does its best to mimic the design pattern of GTM\u0026rsquo;s own listeners.\nLet\u0026rsquo;s go over the code line-by-line.\nreturn function(e) { ... } is the wrapper. The point here is that this macro must return a function, since the listener we\u0026rsquo;ll create in the following chapter requires a function or object as a parameter. If the macro wouldn\u0026rsquo;t return a function but rather run the code itself, you\u0026rsquo;d be sending some weird empty events every time the listener tag is written to the page template.\ndataLayer.push({ ... }); is where the magic happens. Here the triggered event is pushed into dataLayer by observing the design patterns of GTM\u0026rsquo;s own listeners. Now, you can observe these patterns if you want, or you can use your own syntax. I\u0026rsquo;m a big fan of symmetry, which is why I prefer to follow GTM\u0026rsquo;s syntax. This might result in some conflicts if GTM introduces a similar event listener out-of-the-box, but in that case it would be a good idea to migrate to this proprietary listener anyway.\n'event': 'event.'+e.type, pushes a value into the \u0026lsquo;event\u0026rsquo; data layer variable. It takes the type property from the event object, which is a string representing what type of listener was fired, e.g. \u0026ldquo;change\u0026rdquo;, \u0026ldquo;blur\u0026rdquo;, \u0026ldquo;copy\u0026rdquo;. So if the event was of type change, this push would actually look like: 'event': 'event.change'. (By the way, remember E-Type?)\n'gtm.element': e.target, pushes the element the event occurred on into the dataLayer variable \u0026lsquo;gtm.element\u0026rsquo;. This is a design pattern, and if you look at your click listeners and link click listeners, a similar object is always found in those as well. The idea here is that you can then use your Data Layer Variable Macro to explore properties of this \u0026lsquo;gtm.element\u0026rsquo; object if you want to dig deeper into the DOM.\n'gtm.elementClasses': e.target.className || '', pushes the class of the event target into the variable \u0026lsquo;gtm.elementClasses\u0026rsquo;. If there is no class on the HTML object, an empty string is pushed instead.\n'gtm.elementId': e.target.id || '', pushes the ID of the event target into the variable \u0026lsquo;gtm.elementId\u0026rsquo;. If there is no ID on the HTML object, an empty string is pushed instead.\n'gtm.elementTarget': e.target.target || '', pushes the target of the event target (sounds weird) into the variable \u0026lsquo;gtm.elementTarget\u0026rsquo;. If there is no target attribute on the HTML object, an empty string is pushed instead.\n'gtm.elementUrl': e.target.href || e.target.action || '', pushes either the href or the action attribute of the event target into the variable \u0026lsquo;gtm.elementUrl\u0026rsquo;. If there are no such attributes on the HTML object, an empty string is pushed instead.\n'gtm.originalEvent': e is my own addition to this design pattern. Every now and then you might want to access the original event, exposed by the listeners. With GTM\u0026rsquo;s out-of-the-box listeners, this is currently not possible, since they only expose the e.target property of this event object. However, especially if you want to do stuff like identify clicks created by code and not by the user, access to the event object is a must. I hope this will be a standard feature in GTM\u0026rsquo;s own listeners as well.\nSo that\u0026rsquo;s what the macro looks like. It\u0026rsquo;s possible some of the patterns need more work, and nothing is stopping you from extending the number of variables that are pushed into the dataLayer. I consider these variables to be the minimum set you\u0026rsquo;ll need in order to provide enough information for your tags while still remaining economical and conscious of best practices.\nThe listener tag Now that we have our generic event handler, the next step is to create a tag which sets up the listener. The key here is recognizing just which listener you want to set up. Also, for symmetry\u0026rsquo;s sake I will only show how to prime the event listener on the document node, because that\u0026rsquo;s the generic way AND the way GTM\u0026rsquo;s own proprietary listeners work. If you want, you can attach the listeners to specific DOM nodes, which reduces the risk of propagation problems, but as a solution it won\u0026rsquo;t be as generic any more.\nFirst, here\u0026rsquo;s the listener code itself. Put this in a Custom HTML Tag, and add a firing rule which uses either {{event}} equals gtm.js if you\u0026rsquo;re attaching the listener on the document node, or {{event}} equals gtm.dom if you\u0026rsquo;re listening on specific HTML elements.\n\u0026lt;script\u0026gt; (function() { var eventType = \u0026#34;change\u0026#34;; // Modify this to reflect the event type you want to listen for  if (document.addEventListener) { document.addEventListener(eventType, {{generic event handler}}, false); } else if (document.attachEvent) { document.attachEvent(\u0026#39;on\u0026#39; + eventType, {{generic event handler}}); } })(); \u0026lt;/script\u0026gt; On the first line, you specify just what type of event you want to listen for. For the full list of supported types, follow this link. Remember, you can also dispatch and listen to your own custom events, which makes this solution even more flexible. Here\u0026rsquo;s MDN\u0026rsquo;s excellent guide on creating and triggering events.\nAnyway, here\u0026rsquo;s a list of some of the most popular event types:\n beforeunload - Fire a listener when the window, the document, and all resources are about to be unloaded (e.g. when someone is closing the browser window).\n blur - An element has lost focus (e.g. the user has left a form field). Note, this doesn\u0026rsquo;t bubble by default, meaning a listener on the document node won\u0026rsquo;t be able to catch it. To activate event delegation, you\u0026rsquo;ll need to set the last parameter in the document.addEventListener() call to true instead of false.\n change - The value of an element changes between receiving and losing focus (e.g. the user enters a form field, types something in, and leaves the field).\n click - A click is registered on an element (use GTM\u0026rsquo;s Click Listener instead).\n contextmenu - The right mouse button is clicked.\n copy - Text is copied to the clipboard.\n cut - Text is cut to the clipboard.\n dblclick - A double-click is registered on an element.\n focus - An element has received focus (e.g. the user has left a form field). Note, this doesn\u0026rsquo;t bubble by default, meaning a listener on the document node won\u0026rsquo;t be able to catch it. To activate event delegation, you\u0026rsquo;ll need to set the last parameter in the document.addEventListener() call to true instead of false.\n keydown - A key is pressed down.\n keyup - A pressed down key is released.\n mousedown - The mouse button is pressed down.\n mouseenter - The mouse pointer is moved over the element where the listener is attached. Won\u0026rsquo;t really work if the listener is on the document node.\n mouseleave - The mouse pointer is moved off the element where the listener is attached. Won\u0026rsquo;t really work if the listener is on the document node.\n mouseout - The mouse pointer is moved off the element where the listener is attached or one of its children.\n mouseover - The mouse pointer is moved over the element where the listener is attached or one of its children.\n mouseup - The pressed down mouse button is released.\n orientationchange - The orientation (portrait / landscape) of the screen changes.\n reset - A form is reset.\n scroll - A document view or element is scrolled.\n submit - A form submit is registered (use GTM\u0026rsquo;s Form Submit Listener instead).\n  When the Custom HTML Tag is written on the page, it attaches the listener of your choice on the document node. The event handler is the generic event handler function you created in the previous chapter. Then, when the event occurs, the function is executed with the event object as its parameter. This event object is then parsed and pushed into dataLayer with a bunch of properties that you can access with the Data Layer Variable Macro.\nExample with the Change Listener Here\u0026rsquo;s a simple example. I have some form fields on a web page. Whenever a value of a form field changes, i.e. a user writes / edits / deletes text in it, I want to push a virtual pageview with the URL path /form/(field-name)-(field-value). So if the form field\u0026rsquo;s name is \u0026ldquo;search\u0026rdquo; and value is \u0026ldquo;GTM\u0026rdquo;, I want to send the virtual pageview with the path /form/search-GTM.\nSo let\u0026rsquo;s get started. I have my {{generic event handler}} macro which I created earlier, and I have my Change Listener Tag firing on {{event}} equals gtm.js as you can see:\n  Next, I\u0026rsquo;ll need to create two new Data Layer Variable Macros to capture the field name and field value, respectively. First, here\u0026rsquo;s the Data Layer Variable Macro {{field name}}:\n  As you can see, I use \u0026ldquo;(not set)\u0026rdquo; as the placeholder if the field has no name attribute.\nAnd here\u0026rsquo;s the Data Layer Variable Macro {{field value}} for the field value:\n  Again, I use \u0026ldquo;(not set)\u0026rdquo; if the field has no value.\nFinally, I\u0026rsquo;ll need my virtual pageview tag. It\u0026rsquo;s just a normal Universal Analytics pageview tag, but it uses the Document Path field. Also, the firing rule for this tag needs to be {{event}} equals event.change, so that the tag fires only when a \u0026lsquo;change\u0026rsquo; event is registered by the custom listener.\n  I concatenate the string \u0026ldquo;/form/{{field name}}-{{field value}}\u0026rdquo;, since the macros are resolved at runtime, and I\u0026rsquo;ll end up with a nice, clean URL path.\nI manage to test this live by typing text into the search field and leaving the field. The event.change listener fires, and my debug panel shows that the Document Path has been processed correctly:\n  Naturally, don\u0026rsquo;t forget to check GA\u0026rsquo;s Real Time report to verify the data is flowing in correctly.\nConclusions This post was about creating a generic event handler for all your custom listener needs. I urge you to explore beyond the out-of-the-box setups that GTM provides. However, once there\u0026rsquo;s overlap with GTM\u0026rsquo;s features, I strongly suggest you leverage the tag manager\u0026rsquo;s own listeners, since that will ensure that they\u0026rsquo;ll stay up-to-date with possible changes under the hood. I also recommend that you try to observe best practices, and that you emulate GTM\u0026rsquo;s design patterns to your best ability.\nLike I said, I\u0026rsquo;ve written a lot about GTM\u0026rsquo;s listeners in various posts. Here are some guides you might enjoy reading as well:\nWhy Don\u0026rsquo;t My GTM Listeners Work? This is still one of the most asked questions I get. Please, read this post. You\u0026rsquo;ll learn about event delegation, and why so often interfering code prevents events from bubbling up to GTM\u0026rsquo;s listeners. Here\u0026rsquo;s a more recent rant on the topic: My Google+ rant.\nGoogle Tag Manager: The DOM Listener You can use MutationObserver to listen for changes on the page that occur without an actual event firing or page refreshing.\nGoogle Tag Manager: The History Listener A review of GTM\u0026rsquo;s History Listener.\nAlso, I allude to listeners in most of my Google Tag Manager posts, so be sure to read the rest of them if you have time.\nThis was a long and rather advanced guide. Go and eat an ice cream, you\u0026rsquo;ve earned it!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/javascript-101-gtm-part-2/",
	"title": "JavaScript 101 For GTM: Part 2",
	"tags": ["best practices", "google analytics", "Google Tag Manager", "Guide", "JavaScript"],
	"description": "Second part of a two-part post which introduces core JavaScript concepts for Google Tag Manager.",
	"content": " It\u0026rsquo;s been an awesome summer, with temperatures soaring in the global warming range throughout our northern country. The heat has given me ample reason to not be near a computer, but now it\u0026rsquo;s time to mine some JavaScript wisdom again. Here\u0026rsquo;s the second part of my JavaScript for Google Tag Manager series. The first part focused on GTM specific tips and tricks, and I hope that while reading it, you were treated to another grand example of the flexibility of this wonderful tool.\nThis second part was supposed to be more about general JavaScript practices, but I saw myself going back to the DOM with every step. So the theme here is the elusive Document Object Model. It\u0026rsquo;s a defining quality of JavaScript in web development, and understanding its mechanics is key to understanding how tag management solutions work as well.\nHere\u0026rsquo;s the list of topics:\n The Document Object Model (DOM)\n The DOM API\n JavaScript injection + GTM\n Handling false\n  Here we go again. I implore you to take a look at the list of resources I linked to in the previous post. They should serve you really well in your journey towards JavaScript enlightenment.\n1. The Document Object Model (DOM) Here\u0026rsquo;s a very, very simplified account of how a browser works:\n The browser sends a request to the web server to retrieve a web document\n This document is just an annotated source code file, so it needs to be parsed into a format the browser can interpret\n The document is parsed into a parsed node tree, whose syntax is very standardized\n The node tree is then rendered as a web page, which can be viewed in the browser window\n The node tree is actually the Document Object Model (DOM), which also provides an interface for interacting with elements in the tree\n  In short, what you see when looking at the page source of a web page in your browser is just that: the source code of the page. It isn\u0026rsquo;t the final product, since the source code is parsed into a format which can be better understood by browsers.\n  If you\u0026rsquo;ve messed around with a tag management system or with JavaScript, chances are you already know all this. The DOM is both a representation of on-page elements and an interface (more on this in the next chapter) which describes a standard for interacting with these elements. It\u0026rsquo;s called the Document Object Model because the HTML elements you lovingly create in your source code are represented as objects, or nodes, or branches of a tree, in a top-level object called document. So when you tag a section of text as a DIV element in HTML, you are actually creating a new node with tag name DIV into the document hierarchy as a new element that can be interacted with.\nSo the DOM and your HTML document are related, in that they share the same elements, but they are not the same thing. The DOM is the browser\u0026rsquo;s interpretation of the HTML document. The fact that it\u0026rsquo;s standardized makes sure that all your sloppiness in HTML markup is glossed over in a perfectly structured DOM.\nIf you want to take a look at what the document object looks like for any given page, just open a JavaScript console, type document and press enter.\n  Almost all JavaScript that interacts with a page (such as analytics tags) utilizes the DOM. This is because representing a document with a collection of objects allows for scripting languages such as JavaScript to mimic the syntax of more traditional, object-oriented programming languages. Also, using a standardized set of objects and functions in the DOM normalizes the potentially chaotic and horrible markup that many, many web pages out there display.\nThe thing about the DOM is that if you understand its basic functions and if you read up on the standard, you should be inspired to create better markup as well. If the ID attribute was just a CSS selector to you before, after realizing what a crucial part it plays in the unique identification of a single DOM node, you\u0026rsquo;ll be more inclined (hopefully) to utilize it in the future in all relevant markup situations.\nThe DOM is a huge standard and there\u0026rsquo;s lots to learn. The best way to learn is to inspect objects in the model by utilizing the JavaScript console. Reading up on GTM articles is a good way to brush up your skills as well, since almost all GTM customizations have to do with manipulating the DOM in some way.\nThere\u0026rsquo;s also the Browser Object Model (BOM), which is a de facto standard for interacting with the browser window. The BOM houses the window object, which, in turn, contains all the global variables and functions of the page AND the document object. So when you type document in the JavaScript console, you are actually accessing the window.document object.\nConfusing? Perhaps, but in the end it\u0026rsquo;s all quite logical. The DOM is a necessary interface between the client and the HTML document, because so much of today\u0026rsquo;s web development revolves around dynamic and often subtle modification of the web pages. That\u0026rsquo;s how you get your animations, transitions, event handlers and so forth to work.\nFURTHER READING:\n Document Object Model description (MDN)\n W3Schools HTML DOM guide\n JavaScript Window - the Browser Object Model (W3Schools)\n  2. The DOM API The DOM API is actually the DOM itself (remember, it\u0026rsquo;s a standard for interacting with the document), but for clarity\u0026rsquo;s sake I use the term API here (application programming interface). Interacting with the document is done via the methods and objects exposed by the API.\nWhen using JavaScript (as most often is the case) to interact with the DOM, all calls should naturally be in the context of a \u0026lt;script\u0026gt; element. This means that you either fetch the JavaScript in the declaration itself, or you add the code inline. Certain attributes such as \u0026ldquo;onclick\u0026rdquo; allow you to add JavaScript directly to the context of a HTML element without using \u0026lt;script\u0026gt;, but the most common instance is having the \u0026lt;script\u0026gt; tag in place.\nThere are many functions and objects you can access via the DOM, so I won\u0026rsquo;t go into too much detail here. However, I will add an example of what DOM manipulation means in terms of HTML vs. JavaScript. Here\u0026rsquo;s a typical HTML passage in a normal web page:\n\u0026lt;div id=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;header\u0026#34;\u0026gt;Why Four Strings Is Enough\u0026lt;/span\u0026gt; \u0026lt;p class=\u0026#34;paragraph\u0026#34;\u0026gt;Many dismiss the ukulele because it only has four strings. However, it has more strings than a typical balalaika.\u0026lt;/p\u0026gt; \u0026lt;div id=\u0026#34;request-access\u0026#34;\u0026gt; \u0026lt;p class=\u0026#34;paragraph\u0026#34;\u0026gt;Request access to ukulele vault by sending mail to \u0026lt;span class=\u0026#34;email\u0026#34;\u0026gt;uku@lele.com\u0026lt;/span\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; So there are some unique elements where I utilize the ID attribute, and some elements which are reused, represented by the CLASS attribute. It\u0026rsquo;s important to remember that if you use ID, you should only ever have one such element on the page. Otherwise you will make life difficult for anyone wishing to manipulate the element using the DOM API (plus it won\u0026rsquo;t be valid HTML).\nHere are some examples of JavaScript functions I can use to interact with the document:\nvar content = document.getElementById(\u0026#34;content\u0026#34;);  This stores the whole #content node with all its children into the JavaScript variable content. I can then use other functions of the DOM to manipulate the node further.\ncontent.setAttribute(\u0026#34;id\u0026#34;, \u0026#34;main-content\u0026#34;);  Changes the ID attribute of the #content DIV to #main-content. Here I utilize the JavaScript object where I stored the entire #content node just before.\nvar classArray = document.getElementsByClassName(\u0026#34;paragraph\u0026#34;);  Stores all elements with CLASS .paragraph in an Array object referred to as classArray.\nconsole.log(classArray[0].innerHTML);  Writes the entire HTML content of the first P element with class .paragraph into the console.\nalert(document.getElementById(\u0026#34;request-access\u0026#34;).children.length);  Pops up a dialog box with the number of child nodes for the HTML element with ID #request-access. In this case, the alert will contain the number 1.\nThere are many, many ways to interact with the document, its objects and functions using the interface of the DOM. You should be pretty comfortable with these especially if you want to do some advanced tag management and web analytics tweaking.\nFURTHER READING:\n Functions and properties of individual elements in the document (MDN)  3. JavaScript injection + GTM Now that you understand perfectly how the DOM works, you\u0026rsquo;re ready for the next big thing: code injection.\nThe whole premise of a JavaScript tag management system revolves around code injection. That\u0026rsquo;s why you\u0026rsquo;re fine with just adding the container snippet into your source code when installing GTM. By adding this seemingly harmless piece of code into your source code, you\u0026rsquo;re actually giving permission to the gtm.js library to inject more and more code, elements, and functions into your DOM.\nAnd what is this injected code? Your tags and macros, of course!\nLet\u0026rsquo;s see how injection works with a simple example of adding a new \u0026lt;script\u0026gt; node into the HEAD of the document:\nvar s = document.createElement(\u0026#34;script\u0026#34;); s.innerHTML = \u0026#34;alert(\u0026#39;Injection successful\u0026#39;);\u0026#34;; document.head.appendChild(s);   Line 1: A new SCRIPT element is created, but it isn\u0026rsquo;t attached anywhere yet\n Line 2: Some code is added into the content of the new tag\n Line 3: The new element is added as the last child of the document HEAD\n  If you copy-paste this code into a JavaScript console, you should see the pop-up dialog with \u0026ldquo;Injection successful\u0026rdquo;.\nIn this code you utilize the DOM with createElement() and appendChild() functions, the innerHTML property, and the document and document.head elements in the tree. If you now look at your elements (not the source code) by opening the developer tools of your favorite browser, you should see this new element as the last child of the HEAD.\n  All the Custom HTML tags you create via GTM are added to you page in a similar fashion. When you visit a page where such a tag is set to fire, the script is injected the moment the firing rule triggers. Any code in the tag is run there and then.\nThis also highlights the dangers of using a tag management solution to fix / hack errors in your web page. Code injection is brutal in the sense that any code within is run verbatim. There are no default checks in place to prevent your code from messing with global objects or your carefully crafted content. Since the DOM API opens all elements in the tree for manipulation, it\u0026rsquo;s very easy to create AND destroy something beautiful.\nSo be careful.\nFURTHER READING:\n The Container Snippet: GTM Secrets Revealed\n document.createElement() with examples (MDN)\n  4. Handling false This was all too easy so far, so I\u0026rsquo;ll leave you with something truly mind-boggling.\nI\u0026rsquo;ve written about this phenomenon before, and I still think its key to understanding how GTM and JavaScript work together.\nFirst of all, I apologize in advance. JavaScript\u0026rsquo;s treatment of \u0026ldquo;falsy\u0026rdquo; values such as undefined, null, and false is notoriously difficult to understand. Not only is it difficult to understand, it\u0026rsquo;s even more difficult to teach in an understandable manner.\nWhen talking about \u0026ldquo;truthy\u0026rdquo; and \u0026ldquo;falsy\u0026rdquo; values, we\u0026rsquo;re not talking strictly about values which are either true or false. Rather, we mean values which are coerced to either true or false in a Boolean context. Boolean is a type which holds either true or false as its value, and a context is Boolean if some statement hinges on whether the expression evaluates to either true or false.\nAn if-clause is probably the most used Boolean context. The following piece of code is a prototypical example of type coercion:\nif(t) { ...do something if t evaluates to true... } else if (!t) { ...do something if t evaluates to false... }  The if-clause is run if t is true, but it doesn\u0026rsquo;t mean the value of t needs to be true. Rather, the value of t needs to be \u0026ldquo;truthy\u0026rdquo;. The else-clause is run if the value is not \u0026ldquo;truthy\u0026rdquo; but \u0026ldquo;falsy\u0026rdquo; (oh my those are stupid terms).\nSo in this context, t is coerced to Boolean values. It\u0026rsquo;s easier to go through the values which evaluate to false, since there are only six of them.\nundefined\nnull\nfalse\n0\n\u0026rdquo;\u0026rdquo;\nNaN\nSo if a variable holds any of these values, it would evaluate to false in a Boolean context.\nStill with me? Good. For GTM, we are particularly interested in the values undefined and null.\nundefined is a value (and a type, actually) reserved for variables which have either been declared but have no type assigned to them (via value assignment), OR have not been declared at all. This is very relevant for JavaScript, since often and especially with dynamic web pages many variables receive a value and type only after a specific user interaction (such as a click). If a function is executed before such an interaction and without the check for undefined, the function execution will fail in an ugly JS error.\nThe two simplest ways to safeguard your variable execution are:\nif(!t) { alert(\u0026#34;t is falsy and perhaps undefined!\u0026#34;); } if(typeof(t) === undefined) { alert(\u0026#34;t is undefined or has not been declared!\u0026#34;); }  The difference is that using the logical not operator (!) is recommended when you know the variable has been declared but are not certain if it has a value assigned yet, whereas the typeof() operator should be used when you are not certain if the variable has been declared at all.\nThe logical not operator is literally \u0026ldquo;not\u0026rdquo;, so if(!t) { ... } is read as if (t is false is true) { \u0026hellip;run this code\u0026hellip; }. Thus, the if-clause is only run if t is one of the \u0026ldquo;falsy\u0026rdquo; values listed in the beginning of this chapter.\nI can see your head spinning - again, I apologize!\nThe thing is, you shouldn\u0026rsquo;t really use typeof(var)===undefined, since you should always be able to see whether a variable has been declared either by looking at the immediate local function context or by looking for the variable in the global object.\nYes, let me explain this as well.\nJavaScript has static scope. This means that variables are either always global or scoped to the function they are wrapped in. If a variable is scoped to a function and if you\u0026rsquo;ve observed best practices in your programming, you should quickly see whether or not a variable has been declared by the time your code is run.\nvar globalVar; // global variable function t() { var localVar; // local variable  secondVar; // global but bad code } alert(localVar); // error since trying to access local variable outside function  Another thing to note is that if a variable is scoped globally, it will be a property of the global window object. Thus, you can use the logical not operator to check for its absence:\nif(!window.t) { something... } // run something if t is not a global variable ... if(!t) { something... } // referenceError if t is not a global variable  When working with GTM and GA, a very important thing to understand is how the DOM API works with elements that are not found on the page. You see, a function such as getElementById() or getElementsByTagName() will always return an object. An object, if you remember, was not among the \u0026ldquo;falsy\u0026rdquo; values listed in the beginning. However, this object will have the special value null if the actual HTML element is not found on the page.\nIf you stretch your memory again, null was among the values that are \u0026ldquo;falsy\u0026rdquo;. Thus:\nvar t = document.getElementById(\u0026#34;test\u0026#34;), // \u0026#34;test\u0026#34; exists, will return the DOM element  y = document.getElementById(\u0026#34;testy\u0026#34;); // \u0026#34;testy\u0026#34; does not exist, will return object with value null if(typeof(\u0026#34;t\u0026#34;) === undefined) { // does nothing  alert(\u0026#34;t is undefined\u0026#34;); } if(!t) { // does nothing  alert(\u0026#34;t resolves to false\u0026#34;); } if(t===null) { // does nothing  alert(\u0026#34;t is null\u0026#34;); } if(typeof(\u0026#34;y\u0026#34;) === undefined) { // does nothing  alert(\u0026#34;y is undefined\u0026#34;); } if(!y) { // will alert the following message  alert(\u0026#34;y resolves to false\u0026#34;); } if(y===null) { // will alert the following message  alert(\u0026#34;y is null\u0026#34;); }  So the tips of this chapter are:\n1.Use the global window object and the logical not operator as a fallback in case a variable hasn\u0026rsquo;t been declared in global scope.\n2. Read through your code to see if a variable has been declared in local (function) scope OR if you\u0026rsquo;re lazy, use the fallback if(typeof(variable)===undefined) { do something; }.\n3. Either use the logical not operator with a DOM element, e.g. if(!someDOMElement), OR check for null, e.g. if(someDOMElement===null), to fall back in case a DOM element you are referencing is not found in the DOM.\nYou don\u0026rsquo;t want to write a long block of code only to see it miserably explode in JavaScript error mayhem thanks to race conditions or faulty declarations.\nFURTHER READING:\n JavaScript logical operators (MDN)\n JavaScript undefined (W3Schools)\n Truthy and falsy values in JavaScript\n  5. Conclusions I\u0026rsquo;m a huge, HUGE fan of JavaScript. I love it so much I\u0026rsquo;m seriously considering naming my first-born with initials that spell JS (Jebediah Simo, for example). I also think that anyone wanting to extend the capabilities of Google Analytics, and DEFINITELY anyone working with Google Tag Manager, should understand at least the basics.\nThere\u0026rsquo;s a lot to learn, and the splintered mess of cross-browser issues doesn\u0026rsquo;t make it any easier. However, lots of ridiculously smart engineers are working on the standard, so if things go smoothly, we should see some pretty cool and facilitating additions in the next release of the language.\nRemember, an excellent place for advice on JavaScript, especially related to GA and GTM, is Google+. Be sure to follow the communities, and drop a line if you need any assistance with your code.\nGoogle Analytics community in Google+\nGoogle Tag Manager community in Google+\n"
},
{
	"uri": "https://www.simoahava.com/analytics/internalize-google-analytics-v1-0/",
	"title": "Internalize for Google Analytics v1.0",
	"tags": ["chrome", "extension", "google analytics", "JavaScript"],
	"description": "Introducing the Internalize Google Chrome extension. You can use it to set your traffic as internal, which is then useful for filters in Google Analytics.",
	"content": " I created a new Chrome Extension: Internalize for Google Analytics. This is its very first version. It only works on websites with Universal Analytics.\nClick here to download Internalize for Google Analytics v1.0\nThe idea is that with the extension you can push a custom dimension value to your currently active session. You can then use a profile filter in GA to block traffic with this custom dimension value. It\u0026rsquo;s useful when blocking internal traffic with more traditional means (IP address or various GTM workarounds) won\u0026rsquo;t work.\nHow to use it  Create new session-scoped custom dimension in GA property settings\n Make note of the index number of this new dimension\n Go to the website whose traffic is being tracked to the property\n Click the extension to open a pop-up\n Add the index number to its designated place in the pop-up\n Click the button \u0026ldquo;Enable Internalize\u0026rdquo;\n  This sends a non-interaction event to the active session. The Event Category is \u0026ldquo;Internalize\u0026rdquo; and the Event Action is \u0026ldquo;Enable\u0026rdquo;.\n  A custom dimension value \u0026ldquo;true\u0026rdquo; is sent with this event, and it is this value that you should filter in your profile settings.\n  The screenshot above assumes that the name of the new custom dimension is \u0026ldquo;Internal\u0026rdquo;.\nHow it works The extension first checks if Universal Analytics is implemented on the page. If it is, the extension icon turns blue to indicate that it\u0026rsquo;s ready to operate.\nOnce you add the index number and click \u0026ldquo;Enable Internalize\u0026rdquo;, the XMLHttpRequest() object is used to send a data package to Google Analytics servers. This payload contains the following:\n The tracker ID of the first \u0026lsquo;ga\u0026rsquo; object found on page\n The client ID of the first \u0026lsquo;ga\u0026rsquo; object found on page\n The event data with the custom dimension\n  A cookie with a 30 minute expiration is written as well to prevent multiple pushes in a short period of time.\nUpcoming features There are some caveats right now. First of all, you can send the event to ANY Universal Analytics website, because it accesses the \u0026lsquo;ga\u0026rsquo; object found on the page. This is obviously a problem, and even though there\u0026rsquo;s not too much damage you can cause with a clickable browser extension (which sends non-interaction data), it\u0026rsquo;s still annoying to see extra hits on your site.\nAlso, it only works with the first \u0026lsquo;ga\u0026rsquo; object found on the page, so if you have multiple Universal Analytics properties tracked on a single page, this will only work on one of them.\nSo here\u0026rsquo;s a feature list I\u0026rsquo;ve drawn up for the near future:\n Add an Options panel\n Choose domains for which the extension will only work (now it works for all)\n Choose a tracker ID for which the extension will only work (it will look for this tracker ID from the \u0026lsquo;ga\u0026rsquo; object)\n Choose whether just a cookie is set or whether the Measurement Protocol is used as well\n Add support for multiple tracker IDs\n  Working with internal traffic is a pain, and I hope this extension helps some of you with unwanted hits.\nClick here to download Internalize for Google Analytics v1.0\n"
},
{
	"uri": "https://www.simoahava.com/analytics/fix-ga-site-search-google-tag-manager/",
	"title": "Fix GA Site Search With Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "JavaScript", "site search"],
	"description": "How to fix Google Analytics site search tracking on your website, if it has features that make it difficult to track internal site search via Google Tag Manager.",
	"content": " Analyzing what people write in your site search field is pretty much one of the smartest things you can do for your website tracking. If certain terms pop up over and over again in internal search reports, it means that your site is not providing the answers people are looking for, meaning you have an excellent opportunity to provide supply for the demand!\n  However, not all site search applications are trackable out-of-the-box. In this post, I go over three scenarios, and I provide three solutions for tackling internal site search problems in Google Tag Manager.\n1) No query parameter in URL\nGoogle Analytics\u0026rsquo; site search settings require a query parameter in the URL, e.g. https://www.simoahava.com/search?q=analytics. Often, however, the site search tool does not apply a query parameter to the URL. Rather, the keyword might be as a typical URL folder, like https://www.simoahava.com/search/analytics.\nThis is pretty commonplace. You might have seen this phenomenon in Drupal websites. It\u0026rsquo;s easy to fix with a URL macro and the page field in your pageview tag.\n2) No search term in URL\nThis is a bit more difficult, since you can\u0026rsquo;t use the URL anymore. This means that the URL stays the same (or has some generic search path), and you need to look into on-page elements for information on what the user searched for. Some DOM scraping and the page field should do the trick.\n3) Nothing on the page to use\nThis is the most difficult scenario to handle, since there\u0026rsquo;s nothing on the page for you to latch on to. Perhaps the search term isn\u0026rsquo;t iterated (stupid), or it\u0026rsquo;s not contained in a DOM element (stupid, stupid). This time, we\u0026rsquo;ll try to get the value of the search field in the form submit event, and pass that as a virtual pageview.\n1) No query parameter in URL   I see this pretty often. You have a search tool but it doesn\u0026rsquo;t utilize a query parameter for the search term. Rather, it displays the keyword in a virtual folder in the URI. Nothing wrong with that, though every CMS should let you choose how the search terms are displayed in the URL.\nThis is what you\u0026rsquo;re going to do:\n In your ordinary pageview tag, you click open the Fields to set setting, and you add a new field with page as the field name. Field value would be the reference to a Custom JavaScript Macro {{search path}}.\n This macro will look for the search term in the URL\n If it finds a search term, it will return the modified document path with the search term as a query parameter\n If no search term is found, the macro returns false, meaning the document path will not be modified, and the pageview will fire normally\n  That\u0026rsquo;s the beauty of GTM, again. Since the macro returns false for non-search pageviews, you\u0026rsquo;ll just need the one, single, normal, ordinary pageview tag to cover all the searches as well. No need for extra tags, woohoo!\nSo, let\u0026rsquo;s say that the site search term is displayed like it\u0026rsquo;s displayed on www.drupal.org: /search/site/keyword. The {{search path}} macro should first check if the URI starts with /search/site/, and if it does, it should return whatever comes after, properly modified into a proper path.\nHere\u0026rsquo;s the code for the {{search path}} macro:\nfunction() { var regex = /^\\/search\\/site\\/(.*)/; if(regex.test({{url path}})) { return \u0026#34;/search/site?q=\u0026#34; + regex.exec({{url path}})[1]; } return; }  The regular expression looks at the {{url path}} macro (which stores the current URI of the page), and if the path starts with /search/site/, it returns a modified version of the URI with the search term appended as the value of the query parameter q. Change this parameter to reflect whatever you want to have in your Google Analytics view\u0026rsquo;s site search settings.\nFinally, just edit your pageview tag, add a new field to Fields to set, set page as the field name, and add your macro as its value. That\u0026rsquo;s all there is to it!\n  Don\u0026rsquo;t forget to do some Preview \u0026amp; Debugging, and also check with a debugger like WASP to see if the path gets sent correctly for search terms (and correctly for all other pages as well!).\n  2) No search term in URL OK, this one is a bit trickier. In this case, there\u0026rsquo;s no search term in the URL for you to use. This solution requires that the search term is explicitly presented in an HTML element we can grab onto. The best way is to have it in a span or div with a unique ID attribute. Since it\u0026rsquo;s the best way, it\u0026rsquo;s the one I\u0026rsquo;ll be using in this example, with a \u0026lt;span\u0026gt; element as the wrapper. Feel free to get creative with the DOM if your search term is hidden deeper in the page.\n  For this to work, this is what happens:\n In your ordinary pageview tag, you click open the Fields to set setting, and you add a new field with page as the field name. Field value would be the reference to a Custom JavaScript Macro {{search path}}\n This macro will look for the search term in the HTML element with the ID you specify, using a new DOM Element Macro {{search term}}\n If it finds a search term, the {{search path}} macro will return the modified document path with the search term as a query parameter\n If no search term is found, the macro returns false, meaning the Document Path will not be modified, and the pageview will fire normally\n  First, let\u0026rsquo;s create the DOM Element Macro {{search term}}.\n  Replace the Element ID field with whatever your page is using.\nNext, we\u0026rsquo;ll need to edit the Custom JavaScript Macro {{search path}}:\nfunction() { if({{search term}} \u0026amp;\u0026amp; {{search term}} !== \u0026#39;null\u0026#39;) { return \u0026#34;/search/site?q=\u0026#34; + {{search term}}; } return; }  So first we check if an element with the ID you specify exists. If it does, the macro returns \u0026quot;/search/site?q=\u0026lt;keyword\u0026gt;\u0026quot; as the document path, same as in the previous example. If no such element is found, the macro returns false, and the original document path (i.e. the URI of the page the visitor is on) is sent.\nThe final step is the same as before: edit your pageview tag, add a new field to the Fields to set, set the field name to page, and add this {{search path}} macro as the field value.\nOh, and don\u0026rsquo;t forget to preview, debug, and test, test, test.\n3) Nothing on the page to use This is bleak, but it happens. There\u0026rsquo;s absolutely nothing in the document object model that you can use to grab the search term. The URL is blank, there\u0026rsquo;s no search term printed on the page, no fairies whispering in your ear, NOTHING. I know, it sucks. Fire your developer. Just kidding. No, seriously, fire them. Yeah, I\u0026rsquo;m just kidding.\nI\u0026rsquo;ve chosen to fix this using form tracking. It basically requires that your search field has some unique identifier you can grab hold of in the submit event. I hope you have a proper ID for the field (or at least a CLASS or NAME!). I\u0026rsquo;m using ID here, again, but feel free to modify the script to get the value of the page.\nThe thing is, you\u0026rsquo;ll need to send a virtual pageview with the form submission, and it will have the search term in the Document Path as in the previous examples. However, if you send a new pageview with the search, you\u0026rsquo;ll be double-counting your search views, since you\u0026rsquo;ll be sending a pageview for when the search page loads as well! You don\u0026rsquo;t want that. That\u0026rsquo;s why this case is a bit more complex, as you\u0026rsquo;ll be using a browser cookie to carry the search term into the search page pageview, so you can then use that as the document path.\nHere\u0026rsquo;s what\u0026rsquo;s happening:\n Have a Form Submit Listener tag firing on all pages\n Create a new Custom HTML Tag which fires upon {{event}} equals gtm.formSubmit, i.e. when a form is submitted\n In this tag verify that a search was made, and retrieve the search term using a DOM Element Macro {{search field value}}\n In the tag, save this search term in a new browser cookie named \u0026ldquo;keyword\u0026rdquo;\n Create a new 1st Party Cookie Macro {{cookie search term}}, which retrieves this cookie value\n In the {{search path}} Custom JavaScript Macro, check if cookie exists; if it does, use that as the virtual page path\n Utilize {{search path}} as the value of a new field in the Fields to set settings of the Tag. Set the field name to page and the macro as the field value.\n Create a new Custom JavaScript Macro {{searchCallback}}, which deletes the cookie in the callback function of the pageview tag\n  PHEW!\nFirst, the Form Submit Listener. This is easy, just create a new tag of type Form Submit Listener, and have it fire on all pages.\n  After that, create the DOM Element Macro {{search field value}}. Be sure to change the Element ID setting to the ID of the form field your webpage uses in site search.\n  Next, create a new Custom HTML Tag which fires upon {{event}} equals gtm.formSubmit. Have the following code within:\n\u0026lt;script\u0026gt; if({{search field value}} \u0026amp;\u0026amp; {{search field value}} !== \u0026#39;null\u0026#39;) { document.cookie = \u0026#34;keyword=\u0026#34;+{{search field value}}+\u0026#34;;path=/\u0026#34;; } \u0026lt;/script\u0026gt; Here we look for an HTML element with the ID \u0026ldquo;search-field\u0026rdquo;, and with a VALUE attribute. If this is found, then the content of this attribute is set into a new cookie named \u0026ldquo;keyword\u0026rdquo;. This is, in fact, whatever was typed into the search field at the time of form submission.\n(NOTE! If there are multiple forms on a page, you might want to enhance this tag with a check that it was actually the search form that was submitted. It\u0026rsquo;s possible that another form is submitted with text in the search field, and this script would then falsely interpret this event as a submission of the site search form.)\nNext, create a new 1st Party Cookie Macro, which retrieves the value from the \u0026ldquo;keyword\u0026rdquo; cookie. Call this {{cookie search term}}.\n  Next, modify the Custom JavaScript Macro {{search path}} to look like this:\nfunction() { if({{cookie search term}}) { return \u0026#34;/search/site?q=\u0026#34; + {{cookie search term}}; } return; }  So, first we check if the cookie exists. If it does, then its value is returned as a properly formatted Document Path for the pageview tag.\nFinally, create a new Custom JavaScript Macro {{searchCallback}}, which looks like this:\nfunction() { if({{cookie search term}}) { return function() { document.cookie = \u0026#34;keyword=;path=/;expires=Thu, 01-Jan-70 00:00:01 GMT\u0026#34;; } } return; }  This looks for the \u0026ldquo;keyword\u0026rdquo; cookie, and if one is found, then the cookie is deleted. This is extremely important, since you don\u0026rsquo;t want to keep on sending the virtual pageview with every single page load! Cookies are deleted by setting their expiration date to the past.\nPut these all together in your pageview tag, utilizing the Fields to set with both hitCallback and page populated accordingly.\n  Why have the cookie deletion in the hitCallback and not in the macro which returns the document path? Well, two reasons:\n A macro shouldn\u0026rsquo;t be used to set anything. The callback macro is obviously an exception, since it RETURNS a function which sets something.\n There\u0026rsquo;s some weird race condition in play, and if you refer to the 1st Party Cookie macro in the same script which also deletes the cookie, the macro returns an undefined. I\u0026rsquo;ll have to research this phenomenon a bit more.\n  This was way more difficult than the other methods, and let\u0026rsquo;s face it: If you need to resort to the form submission, you should probably flog your developer first. Make them create a site search engine that actually works with analytics, since it really is one of the best things you can measure.\nConclusions I was long overdue a traditional tutorial post, so I hope you\u0026rsquo;ve enjoyed this one. I\u0026rsquo;m still working on the JavaScript for GTM: Part 2 (check Part 1 here), but now I\u0026rsquo;m also dreaming about the mini-vacation that starts tomorrow.\nHowever, if this post raises any questions, if you have other ideas for tracking site search, or if you have a problem you need help with, feel free to drop a line below in the comments! Nothing like a JavaScript challenge to make summer more fun.\nHave a great, warm, relaxing summer, my friends! Live life to the fullest, and dream of JavaScript and all things wonderful.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/javascript-101-gtm-part-1/",
	"title": "JavaScript 101 For GTM: Part 1",
	"tags": ["Google Tag Manager", "Guide", "JavaScript"],
	"description": "Part one of a two-parter, where I introduce some key JavaScript concepts for successful Google Tag Manager management and use.",
	"content": " Here\u0026rsquo;s the link to part 2 of this JavaScript guide.\nThe thing about Google Tag Manager, or any JavaScript tag manager for that matter, is that there\u0026rsquo;s JavaScript involved. In fact, the tool itself is just a JavaScript library with some additional bells and whistles (such as a management UI). This means that to make the best of it, some knowledge of JavaScript is warranted, and that\u0026rsquo;s the point of this post.\nThis will not be a how-to or JavaScript for dummies, but rather a description of how JavaScript should be managed within GTM. However, I have added some of my favorite JavaScript learning resources to the mix, if you want to start from the beginning. JavaScript is a pretty easy programming language to learn, partly because it\u0026rsquo;s been \u0026ldquo;dumbed down\u0026rdquo; and standardized so much over the years. The biggest difficulty with JavaScript, in my opinion, has nothing to do with the language itself. The biggest problem, by far, is how JavaScript is interpreted by the browsers out there. At its best, the same piece of code works perfectly across all browsers in existence. At its worst, you\u0026rsquo;ll have to add complex cross-browser fallbacks to make sure your code runs even on certain modern browsers.\nThe good thing about using GTM, or any library, is that the library itself usually takes care of cross-browser concerns for you. With GTM, however, this is limited to the tag and macro templates that you use. When you start adding custom JavaScript yourself, it\u0026rsquo;s up to you to be wary of cross-browser support for your scripts.\nQuirksmode.org is a pretty awesome resource if you want to find out more about browser compatibility.\nWithout further ado, let\u0026rsquo;s go the guide:\n Favorite resources\n JavaScript in Google Tag Manager\n The dataLayer structure\n Interacting with dataLayer\n Custom HTML tag\n Custom JavaScript macro\n  This is, again, just the first of a two-part series. I\u0026rsquo;m sorry, I\u0026rsquo;m just lazy. The sun is finally shining here, I\u0026rsquo;m looking at the garden, and for some reason the notion of outdoors, smell of freshly cut grass and the sweet liberation only a can of cold beer can provide are edging their way to the top of the \u0026ldquo;things I\u0026rsquo;d rather be doing than blogging\u0026rdquo; list, which is a very, VERY short list indeed.\n1. Favorite resources Here are some resources to get you going on your JavaScript learning trail:\nWEBSITES:\nCodecademy - Interactive learning portal for a number of different programming disciplines. Their JavaScript track is excellent to get you started with the language.\nCode School - Another training portal. Their JavaScript track is good as well.\nw3schools.com - Better as a reference than as a learning resource, but lots of good content nonetheless.\nMDN Web API Interfaces - Reference tool for all the web APIs you\u0026rsquo;ll ever need.\nBOOKS:\nDouglas Crockford - JavaScript: The Good Parts - One of the best books on JavaScript best practices out there (intermediate to advanced).\nNicholas Jakas - Professional JavaScript for Web Developers - My favorite JavaScript book. The most complete guide out there.\nMarijn Haverbeke - Eloquent JavaScript - Excellent book on JavaScript, with a free digital edition!\nBLOGS:\nDailyJS - Daily tips on JavaScript.\nDavid Walsh Blog - Lots of stuff on web development, with many in-depth articles on JavaScript.\nJoe Zim\u0026rsquo;s JavaScript Blog - Actionable tips and guides for JavaScript and related frameworks.\nThese are my favorite resources. If you have more suggestions, let me know via e-mail or in the blog comments.\n2. JavaScript in Google Tag Manager In almost all of my Google Tag Manager posts, I use JavaScript in one way or another to get the task done. That\u0026rsquo;s because JavaScript is THE language of Google Tag Manager. The library itself is a JavaScript library, and all the bells and whistles of the UI are meant to control the type of JavaScript that the tool injects on the web page.\nHowever, you can\u0026rsquo;t just go around shooting JS code wherever you like. In the GTM UI, JavaScript can only be added in the context of a script. Currently, there are two places which accept JavaScript code raw and unfiltered: the Custom HTML Tag and the Custom JavaScript Macro. So don\u0026rsquo;t try to write JavaScript in other tag fields, it won\u0026rsquo;t work.\n  So if you want to perform custom JavaScript functions, you will either need to create a Custom HTML Tag which executes some code, or if you want to use JavaScript to access DOM elements, for example, you might want to create a Custom JavaScript macro. We\u0026rsquo;ll get to these soon, don\u0026rsquo;t worry.\nFURTHER READING:\n Google Tag Manager Developer Guide  3. The dataLayer structure A JavaScript tag management solution is based on code injection. This means that the code it executes on your site is alien to the page template. The only thing the page template originally has is the container snippet. This snippet acts as the invitation for GTM to perform its magic on your page.\nBecause GTM injects the code it wants to execute, it\u0026rsquo;s vital that it uses its own data structure. If there was no proprietary data model, all the variables GTM would be accessing / modifying would run the risk of causing conflicts with other libraries. For instance, say you have a global variable pageHeader created by your developers, and it stores the main header of your page template. Then GTM comes along and uses pageHeader to manipulate the document title that is pushed to Google Analytics. Because it accesses the same global variable that you use to store on-page information, the risk that GTM would break your page template becomes a horrible reality.\nWith dataLayer, successful (read: smart) use of GTM is restricted to only those variables that are exposed within the dataLayer structure. Thus the only risk you run is having another library which ALSO uses dataLayer (spelled exactly like that). The better known that the dataLayer standard becomes, the less of a risk this will be, since other libraries will know to avoid using this name.\ndataLayer is a JavaScript object of the type Array. An Array is a special type of object. The difference is that in JavaScript, objects have properties, whereas Arrays have members. An Array member can be an object.\nObject properties are defined with specific notation, e.g.:\nvar sampleObject = {\u0026#39;First-name\u0026#39;: \u0026#39;Simo\u0026#39;}; alert(sampleObject[\u0026#39;First-name\u0026#39;]); alert(sampleObject.First-name); // Error!  So this is an object, not an Array. If you want to get the terminology straight, in the first line I created an object using object literal notation. That\u0026rsquo;s the curly bracket thingamajig there. In the second line, I retrieved the \u0026lsquo;First-name\u0026rsquo; property of the object by using square bracket notation. You could also use dot notation to access object properties (third line), but with \u0026lsquo;First-name\u0026rsquo; that would cause a NaN (Not a Number) error, because the hyphen in the name is interpreted as a minus sign. Thus JavaScript in its infinite wisdom is misguided enough to think that sampleObject.First returns a number of which another number name is subtracted. But never mind, this was just a detour.\nThe thing to understand about dataLayer is that an Array behaves a bit differently than your run-of-the-mill JavaScript object. First of all, an Array is like a table or queue, however you want to look at it. You can add multiple members to it, and any one of these members can be of any JavaScript type, such as objects.\nIn GTM, dataLayer is (almost) always interpreted as an Array of objects. Thus you can have the sampleObject I created above as a member of dataLayer:\nvar dataLayer = [{\u0026#39;First-name\u0026#39;: \u0026#39;Simo\u0026#39;}];  As you can see, it doesn\u0026rsquo;t matter any more that the object was called \u0026lsquo;sampleObject\u0026rsquo;, since from this moment on it will only be referenced to using its index number in the Array. Index numbers start from 0, so if this is the first object in the array, it\u0026rsquo;s reference is dataLayer[0]. The next object that is added to the Array would have index number 1, and so on.\nYou can access object properties in an Array using the same notation as you just learned of in the beginning of this chapter. However, first you need to know which index the object whose property you want to access resides in.\nSo, if you\u0026rsquo;re still following me, to access the \u0026lsquo;First-name\u0026rsquo; property of the FIRST dataLayer index, you\u0026rsquo;d need to use something like this:\nalert(dataLayer[0][\u0026#39;First-name\u0026#39;]);  This would pop up a dialog with \u0026ldquo;Simo\u0026rdquo;. However, in GTM you don\u0026rsquo;t need to worry about dataLayer index numbers, since you can just use the Data Layer Variable Macro. I\u0026rsquo;ll have more about interacting with dataLayer in the next chapter.\nFURTHER READING:\n w3schools: JavaScript Arrays\n MDN: Working with JavaScript objects\n  4. Interacting with dataLayer In GTM, you basically interact with dataLayer in three different ways:\n First, you define dataLayer as an Array\n Next, you push objects and properties into dataLayer\n Finally, you access these properties using a Data Layer Variable Macro\n  Let\u0026rsquo;s go through these step-by-step.\nYou define dataLayer by declaring the variable and setting its type to Array. The most common way to do this is to use literal notation:\nvar dataLayer = [];  This tells your page that a new variable called dataLayer has now been declared, and the square brackets define its type as Array. After this, you can start pushing stuff into the structure, or if you have some properties that you already want to push, you can just add them to the declaration:\nvar dataLayer = [{ \u0026#39;pageTitle\u0026#39;: \u0026#39;Homepage\u0026#39;, \u0026#39;visitorType\u0026#39;: \u0026#39;Loyal customer\u0026#39;, \u0026#39;loggedIn\u0026#39;: true }];  So here I create dataLayer as an Array (that\u0026rsquo;s the square brackets) with a single object (that\u0026rsquo;s the curly brackets) with three properties (that\u0026rsquo;s the \u0026lsquo;key\u0026rsquo;: \u0026lsquo;value\u0026rsquo;,) stuff. As you can see, there\u0026rsquo;s no comma after the last property. Also, true does not have single quotes around it, since I\u0026rsquo;m storing a value of Boolean type (true/false) and not a string.\nThe thing about the dataLayer declaration is that it should only ever be done once. You see, every time you redeclare a variable, its previous reference is overwritten! You have to be really careful about this, since if your developers accidentally add the dataLayer declaration twice on your page, its previous properties will be overwritten by the second declaration. That\u0026rsquo;s why its safest to declare the structure once and then just consistently use push() for all modifications later.\nThe push()-method is what all Arrays come equipped with. Using this method adds an object to the end of the Array, creating a new index for it automatically. Thus nothing is overwritten. You can have a dozen objects with exactly the same properties in dataLayer, and you\u0026rsquo;d get no errors. Note that GTM\u0026rsquo;s Data Layer Variable Macro has a way of navigating around this issue (see below).\nTo push a new object into dataLayer, the following notation should be used:\ndataLayer.push({\u0026#39;loggedIn\u0026#39;: false});  This just pushed a new object into dataLayer with a single property: \u0026lsquo;loggedIn\u0026rsquo; with the value false. So I can easily have dataLayer with two objects, both with property \u0026lsquo;loggedIn\u0026rsquo; being something different. That doesn\u0026rsquo;t matter, since they\u0026rsquo;re in separate objects.\n  Trying to push the same property twice into the SAME object would not result in an error, either. However, only the last property would remain in the object.\nThe thing about push() is that it won\u0026rsquo;t work if dataLayer hasn\u0026rsquo;t been declared as an Array. That\u0026rsquo;s why in your page template the following is a good way of prefixing the dataLayer.push() call:\nwindow.dataLayer = window.dataLayer || []; dataLayer.push(...);  The first line checks if dataLayer has already been declared. If it has, all is well, but if it hasn\u0026rsquo;t, it is then and there declared as an Array. This basically makes it so that the push() method will almost always work. The only way it won\u0026rsquo;t work is if dataLayer HAS been declared but as something other than an Array (pretty rare situation).\nNote that when working in GTM (Custom HTML and Custom JavaScript), you won\u0026rsquo;t have to add this check to your code, since the GTM container snippet will always declare dataLayer for you if you haven\u0026rsquo;t done so explicitly in the page template.\nFinally, the way that the Data Layer Variable Macro works is that when you give it a property whose value it must return, it starts going through the dataLayer properties one by one, starting from the newest. If it finds a property with the name you gave, it returns its value and stops traversing dataLayer. So if you have two objects in dataLayer with the property \u0026lsquo;loggedIn\u0026rsquo;, only the most recent property value will be returned by the Data Layer Variable Macro.\nIn layman\u0026rsquo;s terms, this means that for Google Tag Manager, pushing an object into dataLayer with a property that already exists in dataLayer overwrites the previous property value with the new one. Of course, it doesn\u0026rsquo;t really overwrite anything, but the Macro is only interested in the latest value.\nThere is a quirky exception to this, and that is if you push an Array into dataLayer.\nIf you then push another Array with the same name, GTM will only \u0026lsquo;overwrite\u0026rsquo; those Array indices that are shared by the two Arrays, but if the first Array had more indices, then those will remain for GTM to use. Allow me to demonstrate:\ndataLayer.push({\u0026#39;products\u0026#39;: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;]}); ... dataLayer.push({\u0026#39;products\u0026#39;: [\u0026#39;e\u0026#39;, \u0026#39;f\u0026#39;]});  In the first line, I push an Array with four members (a, b, c, d). A bit later on, I push another Array with the same name, but this time with just two members. If GTM would be consistent, the second time around the Data Layer Variable Macro would have just two members in the \u0026lsquo;products\u0026rsquo; Array, but right now GTM works so that it just overwrites the first two indices in the Array. Thus the Macro would actually see \u0026lsquo;products\u0026rsquo;: [\u0026lsquo;e\u0026rsquo;, \u0026lsquo;f\u0026rsquo;, \u0026lsquo;c\u0026rsquo;, \u0026rsquo;d\u0026rsquo;]. This is a bit buggy to me, as to be consistent the second Array push should make it so that the Macro only accesses the values in the second Array.\nPhew, this was a lot of information, I hope you\u0026rsquo;re still with me here.\n5. Custom HTML Tag A Custom HTML Tag allows you to inject HTML markup in the site. This means that if you want to run custom JavaScript in a Custom HTML Tag, you need to create the script context for the code. In HTML, you establish a script context with the \u0026lt;script\u0026gt; element:\n\u0026lt;div id=\u0026#34;html_markup_here\u0026#34;\u0026gt;This is still just normal HTML markup\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; alert(\u0026#34;And this is JavaScript!\u0026#34;); \u0026lt;/script\u0026gt; If you try to run JavaScript without the script block, you\u0026rsquo;ll run into some serious validation errors.\nNote that you don\u0026rsquo;t need the legacy type=\u0026ldquo;text/javascript\u0026rdquo; attribute in your \u0026lt;script\u0026gt; tags, unless you\u0026rsquo;re still using HTML4 (gasp) and you want your code to validate. All modern browsers can do the math and make the logical conclusion that a SCRIPT element with JavaScript code inside should be interpreted as, surprise surprise, JavaScript.\n6. Custom JavaScript Macro In Google Tag Manager, a macro is designed to return a value when it is called. That\u0026rsquo;s why you have all those cool out-of-the-box macros out there, which each return some amazing piece of information about the site, the page, or the visitor.\nIf you haven\u0026rsquo;t already, be sure to read my macro guide, as it sheds more light on this topic.\nWith a Custom JavaScript Macro, it\u0026rsquo;s function (pun intended) is also to return a value. If there\u0026rsquo;s no return statement or if the macro isn\u0026rsquo;t wrapped in a function (only functions can return values), you\u0026rsquo;ll run into errors in GTM.\nSo here are the things to remember:\n1. Always wrap your Custom JavaScript macro in an anonymous function.\n2. Always return a value (any value) with a Custom JavaScript macro\nAn anonymous function is a function without a name. Why is this necessary? Well, you don\u0026rsquo;t create a function in a macro so that you call it on a whim using its name. No, the sole reason for a JS macro\u0026rsquo;s existence is that it\u0026rsquo;s called and its value is resolved at the same time, using the {{macro}} syntax of GTM. This is, again, one of the ways GTM ensures that global variables are not being messed about with. If you could name your functions, you might be using a name reserved for some other library. This would potentially have nightmarish results.\nAnd why return a value? Well, to reiterate, a macro\u0026rsquo;s function is to return a value. When you call a JS macro, it resolves some operation right then and there with all the data available at the moment it was called. It then returns a value based on this operation. What would be the function of using the macro syntax {{macro}} in your fields if not to retrieve a value? Stop asking silly questions.\nAn example of a proper Custom JavaScript macro:\nfunction() { return window.location.href.toLowerCase(); }  Here you have an anonymous function declared on the first line, a return statement with the operation on the second line, and the closing of the function block on the third line.\nWhen this macro is called, it returns the URL of the current page transformed into lower case. This is a prototypical GTM Custom JavaScript Macro. It\u0026rsquo;s just an anonymous function which does not accept parameters. Thus its sole objective is to return a value, based on some operation on some other value that can be found in the document object model (more on this later). Remember that you can access other macros in your Custom JavaScript Macros, so you can do a lot of pretty complex stuff with Custom JavaScript macros. For example, the following macro returns the first folder in the URL path (e.g. \u0026ldquo;simo\u0026rdquo; in /simo/articles/analytics):\nfunction() { return {{url path}}.split(\u0026#34;/\u0026#34;)[1]; }  A Custom JavaScript Macro is probably the most versatile tool you have available in your GTM toolbox, and you should definitely check out my other Google Tag Manager posts for creative ways to use them.\nConclusions Phew, that was a lot information there. I\u0026rsquo;m going to have to split this into a two-parter, just to keep me motivated :)\nI hope you take a look at the JavaScript resources I wrote of in the first chapter. Even if you\u0026rsquo;re well versed in the craft of client-side programming, most of the time its good to refresh your knowledge with some \u0026ldquo;basic stuff\u0026rdquo;.\nThe thing with GTM is that in addition to functioning like your average JavaScript library, it comes along with certain proprietary features that require you to adapt your JavaScript skills somewhat. The purpose of this (and the following article) are just that: make you knowledgeable of what GTM requires from you and the code you create.\nHere\u0026rsquo;s the link to part 2 of this JavaScript guide.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/fun-google-tag-manager-part-2/",
	"title": "Fun With Google Tag Manager: Part 2",
	"tags": ["Google Tag Manager", "Guide", "Tips"],
	"description": "Second part of a two-part JavaScript post, going over fun things you can do in Google Tag Manager.",
	"content": " Apologies for leaving you hanging. It\u0026rsquo;s now almost three weeks since I published the first part of this post, and I\u0026rsquo;m sure you\u0026rsquo;ve been holding your breath ever since.\nThere\u0026rsquo;s been a lot going on since the last post. First, my favorite sports team in the world, San Antonio Spurs, won their fifth NBA championship from the defending champs, Miami Heat. Next, my wife and I moved to our new house, and we\u0026rsquo;ve been remodeling ever since. It\u0026rsquo;s been hectic with work and life getting mixed up in a potpourri of saw dust and web analytics, but now it\u0026rsquo;s time to return back to the wonderful world of Google Tag Manager!\nI promised you four new tips in this one, but I\u0026rsquo;m going to top myself and give you six gems from the world of tag management. Here\u0026rsquo;s what you\u0026rsquo;ll get:\n dataLayer declaration and push\n Using eventCallback in dataLayer.push()\n Stopping a Timer Listener\n Naming and version control conventions\n Fire a single tag multiple times\n {{true}} and {{false}}\n  dataLayer declaration and push Google Tag Manager uses dataLayer as its own proprietary data model. dataLayer is a JavaScript object of Array type. This means that it has some methods unique to Arrays, such as push().\n(See my comment to this post here for an overview of how to access Array objects vs. object properties.)\nThe thing is, you can\u0026rsquo;t use dataLayer.push() if you haven\u0026rsquo;t declared dataLayer as an array first. The repercussions of this are that if you try to use dataLayer.push() before dataLayer has been declared as an Array, or if it\u0026rsquo;s been declared as something different (such as a normal object or string), you\u0026rsquo;ll get some errors:\n  So here\u0026rsquo;s the first tip:\nYou need to declare dataLayer as an Array before you can use its push() method.\nTo turn dataLayer into an array, you need the following code before the container snippet:\nvar dataLayer = [];  If you don\u0026rsquo;t declare it with this explicit statement, then GTM will declare dataLayer for you. This is very important, since it ensures that you will always have dataLayer available for your tags.\nThe thing with JavaScript objects and primitives (numbers, strings, etc.) is that if you redefine a JavaScript entity, its previous state will be overwritten! JavaScript entities are dynamic, so you can redefine a string as an object, an Array as a number, and so forth without any difficulty. There\u0026rsquo;s also no way of protecting a global variable such as dataLayer from being redefined as a different type, so precautions must be taken so that you don\u0026rsquo;t mess things up.\nWhy is this important? Well, if you have more than one dataLayer declaration on your page template OR in your GTM tags, you will erase all previous information in the structure! Oops. Here\u0026rsquo;s an example:\nvar dataLayer = [{\u0026#39;pageCategory\u0026#39;: \u0026#39;home\u0026#39;, \u0026#39;logged-in\u0026#39;: \u0026#39;true\u0026#39;}]; ... var dataLayer = [{\u0026#39;event\u0026#39;: \u0026#39;allDone\u0026#39;}];  After the first line of code, dataLayer has a single object with two properties: pageCategory and logged-in. A little on further down the code is the second declaration. Now, after this code is run, dataLayer will still only have one object, but with just the event property! Can you see how harmful this is? None of the previous information is recoverable after this.\nThe safest way to prevent this is to preface the ONLY dataLayer declaration on the page with the following line:\nwindow.dataLayer = window.dataLayer || [];  And then only use dataLayer.push() to add objects to the Array. This line ensures that if dataLayer has already been declared, it won\u0026rsquo;t be overwritten. It\u0026rsquo;s not foolproof, since it doesn\u0026rsquo;t test whether the global variable dataLayer is of type Array or not, but I think it\u0026rsquo;s good enough. If you have another JavaScript library which HAPPENS to use a variable called dataLayer as well, you might be in trouble. But this is what testing and debugging is for.\nSo here\u0026rsquo;s my final tip for this section:\nDeclare dataLayer JUST ONCE and use dataLayer.push() for all interactions afterwards.\nIn your GTM tags you can just use dataLayer.push(), and you don\u0026rsquo;t need to check whether dataLayer exists or not, since GTM declares it for you in the container snippet. But when working on the page template, you need to be extra careful not to overwrite the Array.\nUsing eventCallback in dataLayer.push() You can use the eventCallback dataLayer variable in the push() method to execute code after all dependent tags have fired. I know, that was a mouthful but it\u0026rsquo;s really simple. Take this example:\ndataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;fireEvent\u0026#39;, \u0026#39;eventCallback\u0026#39;: function() { console.log(\u0026#34;Event has fired\u0026#34;); } });  Well, it\u0026rsquo;s a pretty lousy example, but it does what it\u0026rsquo;s meant to. After all tags that fire upon {{event}} equals fireEvent have completed, the eventCallback function will execute and you should see the text in the JavaScript console.\neventCallback is, in essence, a shorthand for the proprietary hitCallback feature that you can invoke in your Google Analytics tags.\nYou can use this for a quick callback, such as waiting for all tags to fire before a link redirects or pushing a second event as the callback to impose a rudimentary tag firing order.\nStopping a Timer Listener You know of the Timer Listener, right? You can use it to have an event push every X milliseconds. You can limit the number of times the timer fires, or you can just let it fire from here to eternity.\n  The thing is, you might want to halt the listener before the limit is reached. For example, if you\u0026rsquo;re using the Timer Listener to send pulses reflecting the time the user has spent digesting content, for example, you might want to halt it once the reader reaches the end of the page to keep your events from being cluttered with timer hits.\nTo halt a timer, you need to use the window.clearInterval() method. It requires a parameter, namely the ID of the timer that is firing.\nGTM\u0026rsquo;s timer listener is your run-of-the-mill JavaScript setInterval() timer, and its ID is stored in, what else, a dataLayer variable called gtm.timerId. So to halt the timer, you need to send the content of gtm.timerId as the parameter of window.clearInterval(). For this to work, you\u0026rsquo;ll need to create a new Data Layer Variable Macro which refers to gtm.timerId:\n  After this, whenever you want to halt a timer, all you have to do is have the following line of JavaScript in your Custom HTML tag or your Custom JavaScript macro:\nwindow.clearInterval({{timer id}});  This will halt the most recently fired timer. So if you have multiple timers, you might have to edit the code somewhat to find the proper timer (easiest way to do this is to use {{event}} equals your_timer_event as one of the rule conditions of the tag that stops the timer).\nNaming and version control conventions GTM doesn\u0026rsquo;t exactly shine when it comes to managing a bucketload of tags, macros, and rules (TMRs). Because of this, it\u0026rsquo;s really important to adopt a good naming convention so that you can make sense of what you have in your container.\nFor alternative approaches (more explicit naming to satisfy the in-tool search), check Doug Hall\u0026rsquo;s original, excellent post on online-behavior. A more recent post by Justin Goodman covers similar ground.\nI use a very simple naming convention in all my TMRs. It scales pretty nicely, as it works in large enterprise implementations as well as in smaller containers. Also, the most important thing is that it\u0026rsquo;s readable.\nHere\u0026rsquo;s what I use.\nTAGS\nTag type - purpose\nHTML - Weather API Call\nHTML - Social Share Tracking\nUA - Page View Tracking\nListener - Link Click\nListener - Click\nHaving the tag type is pretty redundant since you can see that in the second column of the tag list. However, I enjoy that it makes the list look a bit less cluttered.\n  RULES\nKey macro - trigger\nEvent - gtm.js\nEvent - Outbound Link Click\nURL - Thank you page\nThe key macro is what drives the rule. Most often its an {{event}}, but every now and then you might have the same event across many rules, and then you\u0026rsquo;ll need to use some other macro to express the difference between the two rules. An example of this is the URL rule above. It\u0026rsquo;s underlying {{event}} is gtm.js, so I have to use the URL condition to make it different from all the other gtm.js rules.\nMACROS\nWhat is returned\nRandom Number\nDebug Mode Status\nElement URL\nURL Hostname\nWith macros, we\u0026rsquo;re only interested in what they return, since that\u0026rsquo;s what macros are used for. So in the macro name, it\u0026rsquo;s important to express just what is returned when the macro is called.\nAs for version control, my tip is this:\nName your versions AND add notes!\n  That\u0026rsquo;s it. It\u0026rsquo;s so important to annotate your container versions with information what was updated and what changed. This is the only way to stay on top of your game, especially if you\u0026rsquo;re dealing with a huge version history. Be pedantic about this and make sure it\u0026rsquo;s part of your quality assurance process for tag management!\nFire a single tag multiple times Here\u0026rsquo;s a common problem: You have multiple trackers firing on the same domain, but you want to use just one tag for them. Well, currently GTM doesn\u0026rsquo;t have a switch with which you can fire the same tag multiple times with different parameters, so you\u0026rsquo;d need to create a separate tag for each tracker.\nHowever, there\u0026rsquo;s a workaround. You can use hitCallback, the Lookup Table Macro and a global JavaScript variable to fire your tag multiple times with different values in the fields!\n(Note: GTM\u0026rsquo;s Debug mode doesn\u0026rsquo;t let you push items into dataLayer, even if you\u0026rsquo;re doing it from a returned function (which is totally valid). Unfortunately this means that you won\u0026rsquo;t be able to test this solution in the Debug mode, and you\u0026rsquo;ll have to publish the container to test it.)\nHere\u0026rsquo;s what you need:\nJAVASCRIPT VARIABLE MACRO {{tag callback counter}}:\n  LOOKUP TABLE MACRO {{tracker name}}:\n  HITCALLBACK MACRO {{tag callback function}}:\n  So, before we check how the tag is set up, let\u0026rsquo;s go over these macros. The {{tag callback counter}} is a JavaScript variable macro which refers to the global JS variable you set up later in {{tag callback function}}. The idea here is that the {{tracker name}} Lookup Table macro returns a different string, depending on what the counter is. Every time the callback is executed, the counter goes up by 1.\nThe key is to use your first tracker as the default value of the Lookup Table macro. This is because when the tag first fires (on {{event}} equals gtm.js), the JavaScript variable that {{tag callback counter}} refers to will not exist yet (since it\u0026rsquo;s defined in the CALLBACK of this tag).\nWhen the callback is executed, a GTM event is pushed into dataLayer and the counter value is increased by one. You define the maximum number of times the tag should fire with the maxRepeat variable in the callback function. Just remember to have a row for each iteration in the Lookup Table, otherwise the tracker in the Default Value field of the Lookup Table will be returned for each iteration that doesn\u0026rsquo;t have a row in the table!\nIn your tag, add the following in the Fields to Set:\n  This will ensure that the callback function is executed every time the tag has fired.\nNow that you have your Lookup Table, you can use it in the Tracker Name field of your tag:\n  Using the macro here makes it so that with every iteration of the tag, a different value is set as the Tracker Name, thanks to the Lookup Table and the counter that increases by 1 with every pass.\nFinally, you need to add TWO rules to the tag. That\u0026rsquo;s two rules, not two conditions. The rules are\n{{event}} equals gtm.js\nand\n{{event}} equals tagCallback\n  Having two rules means that the tag will fire when and if either one is matched. So first it will fire upon {{event}} equals gtm.js, since that\u0026rsquo;s the event that is pushed when GTM is first loaded. Next, it will fire every time {{event}} equals tagCallback, so twice in my example. Thus, the tag fires three times with three different tracker names.\nYou could use this also if you have different properties you want to track to. Just replace the tracker names with UA-XXXXX-Y codes and you\u0026rsquo;re set!\nHere\u0026rsquo;s a quick recap of what happens:\n Tag is fired upon {{event}} equals gtm.js. Since {{tag callback counter}} can\u0026rsquo;t find the global variable, the Lookup Table macro {{tracker name}} returns the default value, which is localTrackerA\n When the tag has fired, the counter is created with value 0, and the tagCallback event is pushed into dataLayer\n tagCallback triggers the tag again, and this time the Lookup Table finds the counter with value 0, and returns localTrackerB\n When the tag has fired, the counter number is increased to 1, and the tagCallback event is pushed into dataLayer\n tagCallback triggers the tag for the third time, and again the Lookup Table finds the counter with value 1, thus rollupTracker is returned\n The hitCallback is fired again, but this time the maximum number of repeats is reached and the function just returns an undefined value. Thus, no callback event is pushed into dataLayer, and the tag does not fire again.\n  I think this is an amazing feat of strength from dynamic macros and the callback function. This should make any enterprise setup much, MUCH leaner.\n{{true}} and {{false}} This one\u0026rsquo;s a quicky but pretty important. Create two Custom JavaScript macros:\n{{true}}\nfunction() { return true; }  {{false}}\nfunction() { return false; }  Why, you ask? Well, let\u0026rsquo;s say you want to set the Anonymize IP setting to true for one domain and false for two other domains (this idea came from Carmen Mardiros, by the way!). You want to use a Lookup Table Macro to achieve this, but when your Lookup Table aligns domains with the return value of \u0026ldquo;true\u0026rdquo; and \u0026ldquo;false\u0026rdquo;, you notice that things don\u0026rsquo;t work as you\u0026rsquo;d like them to. The problem is that if you add text to a field in GTM, it is always cast to string type. Anonymize IP requires Boolean type, otherwise it fails.\nTo circumvent this problem, instead of typing \u0026ldquo;true\u0026rdquo; and \u0026ldquo;false\u0026rdquo; into GTM\u0026rsquo;s fields, use the macros you just created. They return true and false in proper Boolean type! This way you will be able to pass the correct value types to the settings which require Boolean values.\nNaturally, this should be fixed by adding Boolean true and false as possible values in all GTM fields.\nConclusions Well there you have it! Another round of GTM magic. I can\u0026rsquo;t wait to experiment more and uncover even more cool stuff to share with you. Be sure to join our amazing Google+ community which has served as inspiration for most of these tips.\nAlso, if you happen to be in any of the following upcoming conferences, come say hi to me:\n Google Analytics conference in Stockholm (August 2014)\n Web Analytics Wednesday in Copenhagen (September 2014)\n Conversion Conference in London (October 2014)\n eMetrics in London (October 2014)\n Marketing Festival in Brno (October-November 2014)\n  "
},
{
	"uri": "https://www.simoahava.com/analytics/fun-with-google-tag-manager-part-1/",
	"title": "Fun With Google Tag Manager: Part 1",
	"tags": ["Google Tag Manager", "Guide", "macros"],
	"description": "First part of the two-part Google Tag Manager post, where we go over fun things you can do with JavaScript.",
	"content": " It\u0026rsquo;s time to dig into my tip library for some pretty cool things you can do with Google Tag Manager to enhance your site tagging. Some of these are macro magic through and through, some of these are best practices, and some of these are things that will make your life easier while managing a tag management solution.\n  I\u0026rsquo;ve split this post into two parts to make it more Hobbit and less Lord Of the Rings length-wise.\nHere\u0026rsquo;s what you\u0026rsquo;ll find within this first part:\n Unbind jQuery\n Undefined fields are not sent to GA\n Track copy event\n Errors as events\n  Keep your eyes peeled for the second part.\nI know, the anticipation is probably killing you.\n1. Unbind jQuery I\u0026rsquo;m not a huge fan of jQuery. I mean, it\u0026rsquo;s definitely useful, since it simplifies a lot of the difficult and error-prone syntax that complex JavaScript entails. At the same time, I enjoy complex challenges, and learning the hard way has definitely made me a better developer.\nIn my experience, and this is definitely a very marginal view, jQuery introduces a certain degree of, erm, sloppiness. I know the \u0026ldquo;it\u0026rsquo;s too easy\u0026rdquo; argument is infantile, but in some cases the lack of transparency to what\u0026rsquo;s actually happening in the code can invite some pretty poor development work. In a way, jQuery is more about reading a manual than about actually creating code, and that sucks. Especially with event handlers, some development decisions are clearly influenced by how easy it is to bind the handlers to elements.\nFor Google Tag Manager, this is all too familiar. An innocuous return false; or e.stopPropagation() will prevent your GTM listeners from ever retrieving the DOM event. Often the only reason propagation is cancelled like this is the fact that the code was copy-pasted from some Stack Overflow discussion completely unrelated to your website\u0026rsquo;s markup.\nOK, sorry for the rant. Here\u0026rsquo;s what I suggest. Whenever your GTM listener doesn\u0026rsquo;t fire when it should, open the JavaScript console and type the following line of code there\u0026hellip;\nif(typeof(jQuery)!==\u0026#39;undefined\u0026#39;){jQuery(\u0026#39;body\u0026#39;).find(\u0026#39;*\u0026#39;).off();}  \u0026hellip;and press enter. Then try clicking or form submitting again.\nWhat this simple line does is it unbinds all jQuery event handlers from all HTML elements in the document body. If your GTM listener works after this, it means that there\u0026rsquo;s some interfering jQuery script. The next step is to find the problematic script, and ask your developer to fix it so that propagation isn\u0026rsquo;t prevented.\n(Be sure to check out my Chrome extension, where this feature is handily one button click away!).\nOr you can choose the hacker route. If you find the interfering script, and if you find the function that\u0026rsquo;s grabbing your clicks or submits and preventing propagation, you can use a Custom HTML tag to fix it.\nNOTE! This is a hack. Be sure to test, test and TEST before publishing a container where you unbind jQuery. Also, it wouldn\u0026rsquo;t hurt to consult with someone who has an understanding of just what event handlers are used on the site.\nLet\u0026rsquo;s say you have a Back To Top button which is not sending clicks to GTM\u0026rsquo;s listeners. You find the code in one of the page assets, and it looks something like this:\njQuery(\u0026#39;.top-of-page, a[href=\u0026#34;#top\u0026#34;]\u0026#39;).click(function () { jQuery(\u0026#39;html, body\u0026#39;).animate({ scrollTop: 0 }, 400); return false; });  As you can see, the dreaded return false; is there. That\u0026rsquo;s what\u0026rsquo;s stopping the events from climbing up the DOM tree.\nTo fix this, create a new Custom HTML tag with the following code within:\n\u0026lt;script\u0026gt; jQuery(\u0026#39;.top-of-page, a[href=\u0026#34;#top\u0026#34;]\u0026#39;).off(\u0026#39;click\u0026#39;); jQuery(\u0026#39;.top-of-page, a[href=\u0026#34;#top\u0026#34;]\u0026#39;).click(function(e) { e.preventDefault(); jQuery(\u0026#39;html, body\u0026#39;).animate({ scrollTop: 0 }, 400); }); \u0026lt;/script\u0026gt; If jQuery and the problematic script are loaded in the \u0026lt;head\u0026gt; of your template, you can have this tag fire on {{url}} matches RegEx .*. If they\u0026rsquo;re loaded elsewhere (like in the footer of your page), you might need some other event rule such as {{event}} equals gtm.load.\nOn the first line, I unbind the original click handler. Then, I add e as an argument of the new click function. This e contains the event object, and I can then use its preventDefault() method to stop the original action of the click without stopping its propagation. Finally, I remove the return false; from the end of the function.\nNaturally, you\u0026rsquo;ll need to test, test, test and then test some more whether this hack breaks down your entire site or not.\nOf course, it\u0026rsquo;s not just jQuery that might interfere with your listeners. It might be vanilla JavaScript or some other library. This chapter focuses on jQuery simply because it\u0026rsquo;s so widely spread that most of the time it really is the source of the problem.\n2. Undefined fields are not sent to GA Here\u0026rsquo;s a fun fact about the Google Analytics API: if a field such as Custom Dimension is undefined when the GA endpoint is called, the Custom Dimension is left out of the payload. How is this fun? Well, it introduces an opportunity to make your tags a bit more dynamic.\nIt would be nice to get a list of all the fields that behave this way, and also how they behave with other return values such as false or 0.\nSo, let\u0026rsquo;s say you have a Custom Dimension such as blog author that you want to send with your page view tags. Naturally, you only set the blog author on blog pages. You don\u0026rsquo;t want to send a dummy value like \u0026ldquo;empty\u0026rdquo; or \u0026ldquo;n/a\u0026rdquo; on other pages on your site, so you\u0026rsquo;re absolutely certain that you need two tags: one when the blog author is populated (and can be sent as a Custom Dimension), and one on all the other pages (where the Custom Dimension will be left out of the tag).\n  However, thanks to how the GA API works, you only need one tag. Just make sure that the macro which returns the Custom Dimension value resolves to undefined type when the dimension doesn\u0026rsquo;t have a value. There are a bunch of ways you can do this:\nfunction() { var t; var y = \u0026#34;\u0026#34;; return t; // returns undefined type  return; // returns undefined type  return undefined; // returns undefined type  return false; // returns boolean type  return y; // returns string type  return x; // throws ReferenceError }  As you can see, returning false, an empty string, or a variable which hasn\u0026rsquo;t been declared will not do.\nThe cool thing about GTM is that if you have a Data Layer Variable Macro which doesn\u0026rsquo;t resolve, it will be automatically set to undefined type, meaning a Custom Dimension which refers to this macro will not get sent. So the best way to navigate through this particular scenario is to have blog-author declared in the dataLayer declaration before the container snippet on the page template. If the page isn\u0026rsquo;t a blog page, then this declaration can just be left out.\n\u0026lt;script\u0026gt; var dataLayer = [{\u0026#39;blog-author\u0026#39;: \u0026#39;Simo Ahava\u0026#39;}]; // Blog author declared, dimension will get sent \u0026lt;/script\u0026gt; ... \u0026lt;script\u0026gt; var dataLayer = []; // Blog author not declared, dimension will not get sent \u0026lt;/script\u0026gt; Then, when you create a Data Layer Variable Macro, on pages with blog-author in the array, it will fire the Custom Dimension with the blog author\u0026rsquo;s name as the value. On all other pages the dimension will not get sent.\nOnce you familiarize yourself with JavaScript and understand all the different ways how GTM and JavaScript resolve variables to undefined type, you can get really creative with this feature, making your tags even more leaner.\n3. Track copy event Ever wondered how often people copy text using CTRL+C or some other means? Well, wonder no more, because now you can track it as an event!\nCreate this simple Custom HTML tag:\n\u0026lt;script\u0026gt; var c = document.getElementById(\u0026#34;entry-content\u0026#34;); if(typeof(c)!==\u0026#39;undefined\u0026#39;) { c.addEventListener(\u0026#39;copy\u0026#39;, function(evt) { dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;copy\u0026#39;}); }); } \u0026lt;/script\u0026gt; This is a very simple script that pushes the dataLayer event \u0026lsquo;copy\u0026rsquo; whenever someone copies something on your page within the HTML element with ID entry-content (e.g. \u0026lt;div id=\u0026quot;entry-content\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;).\nBe sure to change the element whose content you want to track with the event listener to match the markup on your website.\nYou can make it more versatile by exploring the contents of the evt argument, which is the event object. Its target property contains the HTML element which was the target of the event. Here are some ideas:\n... dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;copy\u0026#39;, \u0026#39;copy-id\u0026#39;: evt.target.id, \u0026#39;copy-content\u0026#39;: evt.target.innerHTML}); ...  And so on. Note that evt.target stores the element where the copy event started. So if the copy action takes place over multiple paragraphs, headers, or spans, for example, you\u0026rsquo;ll only be able to observe the properties of the first element targeted by the action.\n4. Errors as events Google Tag Manager has this cool thing called the JavaScript Error Listener. This fires whenever an unchecked exception occurs on the site. For example, consider the following:\nvar myText = \u0026#34;Hello!\u0026#34;; alert(myTxt); // Unchecked ReferenceError, will fire GTM\u0026#39;s error listener  // Exception caught, will not fire GTM\u0026#39;s error listener try { alert(myTxt); } catch(e) { console.log(e.message); }  With GTM\u0026rsquo;s error listener, you can send each uncaught error as an event to Google Analytics. You can then analyze these events to find problems with your scripts. If you have a huge site, you might get hundreds of these errors, so you\u0026rsquo;ll need to adjust the code to perhaps only listen for certain pages or errors.\n  I\u0026rsquo;m hoping at some point we can have the listener fire only for errors propagated by GTM\u0026rsquo;s tags and macros. This way you can debug your GTM installation without having to worry about all the other errors on your website (even though you definitely should!).\nTo get the listener up and running, do the following:\n Create a new JavaScript Error Listener tag\n Have it fire on all pages (or some other rule of your choice)\n Create a new rule Event - gtm.pageError, where {{event}} equals gtm.pageError\n Create three new Data Layer Variable macros:\n {{Error - Message}}, where variable name is gtm.errorMessage\n {{Error - Line}}, where variable name is gtm.errorLineNumber\n {{Error - URL}}, where variable name is gtm.errorUrl\n  Create a new Event tag and configure it to your liking\n Make sure the Event tag fires on the rule you created in (3)\n    Remember to set the Non-Interaction Hit parameter of the Event tag to true. You don\u0026rsquo;t want to kill your bounce rate with errors on your site!\nIf you\u0026rsquo;re seeing a lot of Script error. hits, it means that the errors occur in JavaScript resources loaded from other domains. Due to browser / cross-domain security policies the actual error name and message are obfuscated.\nConclusions The second part of this post is on its way. I didn\u0026rsquo;t want to puke too much text into a simple tips \u0026amp; tricks post, but this one is 1800+ words already, so\u0026hellip; :) Topics in the next post are:\n dataLayer declaration vs. dataLayer.push()\n How to stop a GTM timer listener\n Adopting a proper naming convention\n Annotating container versions with names and notes\n  Anyway, I love nothing better than to explore the versatility of Google Tag Manager. There\u0026rsquo;s so much you can do with JavaScript, DOM API, and the Google Tag Manager library!\nAll that\u0026rsquo;s required is a bit of know-how with JavaScript and the Document Object Model, a lot of creativity, and a lot of testing, previewing and debugging.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/gtm-sonar-v1-2/",
	"title": "Google Tag Manager Sonar v1.2",
	"tags": ["chrome", "Google Tag Manager", "gtm sonar"],
	"description": "Introducing the GTM Sonar chrome extension, which lets you debug Google Tag Manager&#39;s event tracking.",
	"content": "That\u0026rsquo;s right, I changed the name! Huge thanks to Paul Gailey for the inspiration.\nGet the latest version of GTM Sonar here.\nJust a minor update this time. I added some informative text to the pop-up, along with an error screen if something goes wrong.\n  Another change is that now when an element is added to debugDL, a counter on the Browser Action icon will start climbing, representing the number of objects in the array. Cool!\nSo, my to-do list is really short now. The only thing I have in mind right now is boring stuff like refactoring the code, improving error handling and the such. If you have ideas for the extension, let me know!\nHere\u0026rsquo;s the updated version history:\nv1.2 - June 1, 2014\n Added a badge icon which increases in count every time an event is pushed into debugDL\n Improved the pop-up instructions\n If the extension doesn\u0026rsquo;t work, an error message will be displayed in the pop-up\n Changed the name of the extension to GTM Sonar (thanks Paul Gailey for the idea!)\n  v1.1 - May 26, 2014\n Added a popup to control debugger functions\n Added a switch to kill all jQuery binds\n Added the choice of Click Listener, Link Click Listener and Form Submit Listener\n  v1.0 - May 23, 2014\n First release version\n Clicking the Browser Action halts all click events and sets up the debugDL object\n Clicking anywhere on the page stores the gtm.click event in debugDL\n Clicking the Browser Action again removes all scripts and event handlers injected by this extension\n  "
},
{
	"uri": "https://www.simoahava.com/analytics/gtm-auto-event-listener-debugger-v1-1/",
	"title": "GTM Auto-Event Listener Debugger v1.1",
	"tags": ["chrome extension", "development", "Google Tag Manager"],
	"description": "Update to the GTM Sonar Chrome extension, which lets you debug Google Tag Manager&#39;s event tracking.",
	"content": " (Last updated June 2014: Read the latest post on the extension, GTM Sonar v1.2.)\nI updated my Chrome Extension, GTM Auto-Event Listener Debugger v1.1. I released the first version a couple of days ago. The extension can be used to debug Google Tag Manager\u0026rsquo;s auto-event tracking and its compatibility with web page markup.\nDownload the latest version here.\nI did some major changes, and here\u0026rsquo;s the rundown.\n I transferred all debugger actions into a pop-up, which opens when you click the Browser Action. The debugger is still tab-specific, so it can have different states in different tabs. Also, The Browser Action still turns green when the debugger is enabled for current tab.\n I added a radio button list for you to choose the listener type from. I didn\u0026rsquo;t want to enable multiple listeners at once, because halting the click event had implications for form submits as well. The three listeners are now:\n Click Listener : Halts default action of all clicks on page, and upon clicking on the page, pushes gtm.click and other data into debugDL\n Link Click Listener : Halts default action of all clicks on page, and if clicked element is a link, pushes gtm.linkClick and other data into debugDL\n Form Submit Listener : Halts default action of all forms on page, and upon submitting a form, pushes gtm.formSubmit and other data into debugDL\n  I added a switch with which you can kill all jQuery binds on the page. The switch is only available if jQuery is found on the page. When you click the switch, all jQuery handlers are cancelled. The idea behind this is that by killing the event handlers, you can verify if jQuery is preventing the listeners from working. I did this simply because more often than not this has been the problem. The switch can be used just once. To get the event handlers working again, you need to reload the page.\n Basic functionality is still as it was, though I\u0026rsquo;ve made some improvements here and there. It still needs quite a bit of refactoring, as I\u0026rsquo;m pretty sure my JavaScript is just too complex. The visuals could be improved as well, but I\u0026rsquo;d rather have the basic stuff work first and only then start twiddling with the decorations.\n  Screenshots         Information about the version upgrade Be sure to download the extension here, and read the release notes. I\u0026rsquo;ve added a short bit on version history into the release notes (along with more detailed instructions), so you can now follow the development cicle as well.\nThe to-do list now contains the following items (thanks for your feedback!):\n Improve error handling\n Show badge icon which represents number of objects in debugDL\n Show a tooltip or some other visual signal when an event is successfully pushed into debugDL\n  Let me know if you have any improvements in mind.\nHalting the default action of clicks and submissions will not be enough on some pages. With complex sites, there\u0026rsquo;s usually a lot of other JavaScript interfering with this simple script, so no matter what you try to do, the clicks and submits still redirect you. In those cases, the only thing I can suggest for you to do is try to hit ESC or click the STOP button in your browser as soon as you\u0026rsquo;ve performed the action. This should be enough to cancel the action but still enable the data to be pushed into debugDL.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/debugging-auto-event-tracking-gtm/",
	"title": "Debugging Auto-Event Tracking in GTM",
	"tags": ["chrome extension", "development", "Google Tag Manager"],
	"description": "Introducing the GTM Sonar Google Chrome extension, which you can use to debug Google Tag Manager&#39;s event tracking.",
	"content": " (Last updated June 2014: Read the latest post on the extension, GTM Sonar v1.2.)\nMany of the Google Tag Manager articles on this blog could be considered hacks, in that they extend the out-of-the-box features of GTM in ways that will surely not be officially supported by Google. The crux of the problem is that lots of folks are taken by surprise when GTM refuses to work properly on their site, or when they have trouble tracking key elements on the page template.\nAuto-event tracking is a very common denominator when problems with GTM arise. It\u0026rsquo;s a wonderful feature that lets you automatically tag and track actions on the webpage using event listeners, but there are many issues with conflicting JavaScript and shoddy markup that might prevent auto-event tracking from working altogether.\nTo help you in establishing the current state of your template, I give you the GTM Auto-Event Listener Debugger Chrome Extension (name under construction). It should be a welcome tool for you if you want to debug your page template and your on-page elements with automatic click tracking in mind.\n  First things first: download the GTM Auto-Event Listener Debugger here.\nDisclaimer Markup woes should always be resolved with site developers first and a licensed therapist second. Most of the time it\u0026rsquo;s just a question of whether best practices have been observed, such as identifying unique elements with IDs, grouping similar styles together with classes, or having a consistent layout hierarchy. These are all issues that should be fixed in the CMS (or the template), because they facilitate development work on the website in the future as well.\nHowever, there are many reasons why a rapport with the developers can\u0026rsquo;t be established. You might be a hired hand with only GTM and web analytics as your domain. The developers might know squat about web development. The organization might insist upon rigid processes and bureaucracy to get anything done, and that just won\u0026rsquo;t sit with your vision of agile analytics.\nWhatever the case, sometimes you just have to hack your way through the shortcomings of your CMS or your page template. If nothing else, at least you\u0026rsquo;ll have a proof-of-concept in your hands to deliver to the developers.\nInstructions To use the debugger, first make sure you\u0026rsquo;ve enabled it in Tools -\u0026gt; Extensions of your Chrome browser. If it\u0026rsquo;s enabled, you should see a red target icon on your extension pane.\n  The actual steps of using the debugger are simple:\n Browse to a web page you want to debug\n Click the red target (it should turn green to signal that the debugger is running)\n Click anywhere on the page\n Open JavaScript Console in Chrome, type debugDL, and press Enter\n    When you switch the debugger on, it does two things: 1) it halts the default action of all clicks on the page, 2) when you click an element, it stores its details in the debugDL array in identical format to the GTM listeners.\nWhy prevent default action of clicks? Simple, for debugging reasons it\u0026rsquo;s better if you stay on the same page for testing stuff. Halting the default action prevents links from working. Because debugDL is an object in the current document, it will persist only for the page you\u0026rsquo;re on (similar to how dataLayer works).\nAnd why store the object in debugDL and not dataLayer, for example? Well, I wanted this debugger to not screw up with any existing frameworks, so you can play around freely. Sure, someone else might have come up with the name \u0026ldquo;debugDL\u0026rdquo; in other libraries or extensions, but I\u0026rsquo;ll take my chances.\nWhen you turn the debugger off (by clicking the target again), the default action of click events is returned. The debugDL array is not erased, however, and you can continue to view its contents for as long as you\u0026rsquo;re on the page.\nThe debugging part begins when you start going through debugDL. Every click is registered in identical format to what you\u0026rsquo;d get if you had a GTM Click Listener active.\nWhat\u0026rsquo;s the point? The idea is to test your page template if it works with GTM listeners.\nOr maybe you want to plan ahead and choose the properties of the clicked element (or its parents or siblings) you want to access in your macros.\nOr maybe you want to see if the click events are propagating to the GTM listeners, which operate on the top document node.\nMy favorite reason is this: I do a LOT of debugging for people, and I\u0026rsquo;m not always given access to their preview / debug container. So there\u0026rsquo;s actually no listener firing on the page, and I have to guess by looking at markup and by reverse engineering their JavaScript to identify why click listeners might not work.\nWith this extension, I can debug the site without needing an actual GTM click listener at all.\nTechnical stuff If you know your Chrome Extensions, you\u0026rsquo;ll know that they operate in an isolated environment. What this means in practice is that you can\u0026rsquo;t access variables created by the page in the extension.\nThis has implications for this listener as well, because I want to store data in the window.debugDL array.\nTo circumvent this problem, when you turn the debugger on, it injects a script block into your page template, which creates the object. This script block also primes the click listener on the document node. When you then click anywhere on the page, another injection is done in the form of a push into debugDL.\nInjecting stuff sucks, but it\u0026rsquo;s the only way (as far as I know) to modify variables in the window object through the extension.\nWhen you turn the debugger off, it removes the event listener and all custom script blocks created by the extension.\nNote also that the debugger actions are unique to whichever tab the debugger was activated in. This means that you can have multiple tabs open, each with their own instances of the debugger running or not. Cool, huh?\nWhat\u0026rsquo;s next? Since this is my first foray into Chrome Extensions, there\u0026rsquo;s a lot of fine-tuning to be done. Here\u0026rsquo;s a list of stuff I\u0026rsquo;ve thought about doing in the near future. I\u0026rsquo;ve also requested beta-testing from the wonderful people in the Google+ GTM community, so I hope I\u0026rsquo;ll have more features on the drawing board soon!\n A toggle to unbind all jQuery click handlers on the site – to test if interfering jQuery is the reason your clicks aren\u0026rsquo;t being registered by auto-event listeners\n Add a Link Click Listener function as well – to only register clicks on link elements\n Add a Form Submit Listener function as well – since around 75 % of all listener woes have to do with form submissions, this is really a no-brainer\n Add other event handlers, such as mouseover, keydown, change – to demonstrate the power of automatically tracking all user-based actions\n Make it prettier and flashier\n Think of a better name for the extension\n  "
},
{
	"uri": "https://www.simoahava.com/personal/year-in-review-2013-2014/",
	"title": "Year In Review 2013-2014",
	"tags": ["personal"],
	"description": "Overview of years 2013-2014 in the life of Simo Ahava and this blog.",
	"content": " \u0026hellip;or How My Organic Traffic Went Through The Roof.\nIt\u0026rsquo;s been one of the craziest 365 days in my life, and I thought it would be apt to write a bit about all the stuff that\u0026rsquo;s taken place. I haven\u0026rsquo;t really been talking about myself in my guides and other previous posts, so please indulge me, for once!\nThe beginning A year ago I had just quit my job at my previous employer, Innofactor Plc. When I quit, I\u0026rsquo;d been working as a product owner for Microsoft SharePoint CMS (content management system) components, and I wasn\u0026rsquo;t really seeing any future in it. To be honest, I still don\u0026rsquo;t think \u0026ldquo;Microsoft SharePoint\u0026rdquo; and \u0026ldquo;CMS\u0026rdquo; should ever be uttered in the same sentence, but Innofactor did do some pretty cool stuff that made the relationship between the two a bit smoother.\nAnyway, a good friend of mine called me and told me that there was an SEO job open at the digital marketing agency he was working at. Well, I jumped at the chance because\n He\u0026rsquo;s a great guy and I wouldn\u0026rsquo;t mind working with him\n The job would involve more interaction with clients (which I missed)\n SEO was something I\u0026rsquo;d been doing as a freelancer for a long time, and I didn\u0026rsquo;t mind making it my profession\n  So now I found myself working at NetBooster, a pan-European digital marketing agency. Our Helsinki office is small, but we have a dedicated crew doing their absolute best to deliver more value to our clients.\nAbout a week before my work started, I created this blog at www.simoahava.com. I wanted a channel through which I could write about my experiences in digital marketing.\nMy first posts sucked. They really did.\nThe problem with SEO I very soon noticed a number of problems with SEO, especially for someone working at a digital agency. First of all, no matter how hard we try to be on top of things, reading up on the latest trends, algorithm changes, penalties, recoveries, exposés, etc. it will always be nigh impossible to deliver this knowledge to our clients. Part of the problem is that especially in Finland there\u0026rsquo;s still a lot of \u0026ldquo;old-school\u0026rdquo; SEO being shipped around, where shady agencies are delivering black hat links, 200€-per-month maintenance packages (what the hell can you do with 200€ per month???), and promising stuff to clients that will never bring actual profit or ROI to them.\nTrying to promote content-based strategies instead of mindless ranking tactics to companies still deeply entrenched in the latter is very difficult. It\u0026rsquo;s obvious SEO can\u0026rsquo;t be confined to a silo in today\u0026rsquo;s multi- and omni-channel marketing world, but for some reason we still get heaps and heaps of RFPs where this is exactly what the client wants.\nSEO is really, really, REALLY easy. Just create good quality content regularly, and market it naturally. Stop laughing, it\u0026rsquo;s the truth! If you don\u0026rsquo;t believe me just read Jeff Sauer\u0026rsquo;s excellent post on his SEO views.\nJust for a point of comparison, here\u0026rsquo;s what my organic traffic looks like from day 1 of the blog to today:\n  That\u0026rsquo;s from 0 to almost 7,000 monthly sessions from organic sources. I know, it\u0026rsquo;s not HUGE but I must remind you of the following things:\n I have never ever built a single link for my blog\n I have never ever spent a single second on keyword research for my posts\n A blog focusing mainly on Google Tag Manager is pretty niche\n I do not promote my posts in social media\n  OK, I\u0026rsquo;ll have to clarify the last bit. I do \u0026ldquo;promote\u0026rdquo; them, in that I use them to start a discussion in Google+. I don\u0026rsquo;t do the promote-once-in-the-morning-then-again-in-the-afternoon-then-again-in-a-week stuff because I\u0026rsquo;m just not comfortable in promoting my own posts. I let others do that for me.\nSo SEO is really simple. I get a lot of content ideas from my blog comments, which is why, I guess, they always seem to answer some search intent.\nDigital analytics If you\u0026rsquo;ve been reading my blog, you\u0026rsquo;ll know it\u0026rsquo;s mostly about web analytics. Google Analytics, to be more precise.\nI don\u0026rsquo;t hide the fact that I think data is the only stable thing in the turbulent world of marketing. Or rather, the only stable strategy in a business where strategies pop up like zits after a weekend of booze and chocolate.\nThe thing I learned during this year of intense interaction with clients in workshops, seminars, consultation projects, and so forth is that there\u0026rsquo;s a LOT of untapped opportunity in how data is utilized.\nBecause I\u0026rsquo;m very developer-minded, the first opportunity is in data collection. It\u0026rsquo;s not enough to just pull page view hits and then observe changes in standard metrics. Remember, Google Analytics is a tool for millions of businesses, and these standard configurations must cater to all these needs and not just the needs of your lumber yard or clothing store.\nIf you want to dig into how data collection can be optimized, I suggest you take a look at what people (including myself) have been writing about tag management.\nHowever, I really enjoy reading stuff by Googlers such as Avinash, Justin, and Daniel, because they get it right.\nThey know it\u0026rsquo;s not just about data, but rather the insights derived thereof and the people, the analysts, doing the interpretive work.\nA smart data collection method will only get you so far. A smart data analyst will take your business to the stars.\nThe people, the wonderful people Another reason this has been a great year is because I think moving to the world of digital marketing and especially digital analytics has been my professional break-through. I\u0026rsquo;ve met so many wonderful people over the months that I can\u0026rsquo;t even keep count.\nMy blog and my activity in Google+ (I love, LOVE that platform!) have brought along all the following awesomeness:\n More conference invitations than I can keep up with\n Guest post requests (still haven\u0026rsquo;t had time to do any)\n Podcast interviews\n The culmination of my developer ambitions (secret is revealed at the end of this post)\n  And many other things.\nI\u0026rsquo;ve never ever seen a developer / professional community as vibrant as the ones surrounding Google Analytics and Google Tag Manager. I think it\u0026rsquo;s awesome that the Google engineers and product managers themselves work with us in these communities, awaiting input and feature (and bug) requests, and contributing to the discussions.\nThe conferences have been awesome, and I have to single out two which should be on the list of \u0026ldquo;must-visit\u0026rdquo; for all analysts and marketers out there:\nSuperweek (Hungary) - Situated on top of a mountain, with rolling fog and clouds enveloping the hotel grounds, this conference is set in a very The-Shining-esque milieu. Nevertheless, it\u0026rsquo;s still one of the top conferences in digital today. It\u0026rsquo;s going to be organized in January 2015, make sure you don\u0026rsquo;t miss it.\nMeasureCamp (London) - A true unconference for beginners, experts, and enthusiasts in digital analytics. The atmosphere is amazing, and the sessions are truly inspiring (even if they\u0026rsquo;re ad hoc or in a game show format).\nI\u0026rsquo;m working hard to get a strong web analytics / digital marketing community in Finland as well, but this requires time and effort that I can\u0026rsquo;t spare alone. Luckily we\u0026rsquo;ve started doing a lot of little networking events here in Finland, and maybe some day we can boast our own eMetrics, SMX, or Superweek.\nPersonal stuff Personally, it\u0026rsquo;s also been one of the most amazing and massive years of my life.\n  I got married in August to the most wonderful, beautiful, amazing woman in the world. She\u0026rsquo;s my best friend and she means the world to me. Someone who can put up with my all-around geekiness should deserve a medal. We also had a really fun honeymoon doing a crazy road trip in the United States. That\u0026rsquo;s 2 weeks and 3,000 miles of driving, with a loop from New York City - New Orleans - New York City.\nWe also just bought our dream house, and I can\u0026rsquo;t wait for us to move in.\nOn a sadder note, my grandmother of 98 years (!) passed away late April, and this made the very over-worked month of May even more difficult to endure.\nLife has its ups and downs, I guess. Luckily, this past year has been almost overwhelmingly full of positive twists and turns, so I consider myself very fortunate.\nMeet the newest Google Developer Expert I was just added to the Google Developer Expert program as one of the fewer than hundred (at the time of writing) individuals and one of the just four Google Analytics experts, whose job is to evangelize, educate, write, and develop Google\u0026rsquo;s products from a developer perspective. It doesn\u0026rsquo;t make me a Google employee, but it is a sign of appreciation from Google for the work I\u0026rsquo;ve put into making Google Tag Manager more accessible to developers and marketers alike.\nThis is a huge thing for me, since I\u0026rsquo;ve never considered myself a developer. I guess that must change now :)\nThanks to the GDE team at Google for accepting me to the program, and special thanks to Mr. Daniel Waisberg for supporting me throughout the process and Mr. Nico Miceli for the great chat we had around GDE stuff in my first interview.\nThanks also to everyone reading my blog posts, and thanks to the Google Tag Manager team for making such a fun product to write about!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/simple-split-test-google-tag-manager/",
	"title": "Simple Split Test With Google Tag Manager",
	"tags": ["custom html", "Google Tag Manager", "Guide", "macros"],
	"description": "How to write a simple split A/B test using only Google Tag Manager for handling the test, and automatically collecting the data to Google Analytics.",
	"content": " Over the last couple of posts I\u0026rsquo;ve mainly been doing proof-of-concept (POC) tests with Google Tag Manager. The great thing about a POC is that you don\u0026rsquo;t really need to have any viable results or insight-driving technological innovations. The point is to showcase some feature of the platform on which the experiment was conducted.\nIn this post, I\u0026rsquo;ll take a care-free step into the world of POCs again. My goal is to do a simple split test in order to identify which variant of a landing page (or key element thereof) produces the most conversions.\nThis isn\u0026rsquo;t a replacement for any of the REAL A/B testing tools out there. Rather, this is a way for me to showcase yet another way to utilize the wonderful complexity of GTM\u0026rsquo;s JavaScript wizardry.\nAnyway, this is what you\u0026rsquo;ll (hopefully) take with you after reading this post:\n How to modify a DOM element\n How to set a cookie\n How to show a different variation to 50 % of users\n  Combine these and you have a split test in the making!\nThe end result This is how it\u0026rsquo;s going to go down. Exactly 50% of people viewing the experiment page will see the following button:\n  This is also the control variant. It\u0026rsquo;s the one I\u0026rsquo;ve used for years and years to make millions upon millions to my faithful followers (just kidding). However, I want to see if a more nonchalant approach to click baiting would work (and I want to appeal to the younger, less critical demographic), so this is the test variant shown to the other 50%:\n  So I\u0026rsquo;ll be measuring just how many clicks each of these buttons collect. In the end, I should see it in my reports both as events and as a Custom Dimension. Here\u0026rsquo;s what a goal conversion report would look like for the two variations.\n  It\u0026rsquo;s not exactly hard science, but it got the job done. Surprisingly, the control variant was stronger, producing more conversions (who would\u0026rsquo;ve guessed?!).\nSetting up GTM For this experiment, you\u0026rsquo;ll need the following:\n 1st Party Cookie Macro {{Split Variation Cookie}}\n Random Number Macro {{Random Number}}\n Custom HTML Tag\n Custom Dimension\n Universal Analytics Event Tag\n  1st Party Cookie Macro You\u0026rsquo;ll need a 1st party cookie to make sure the same user sees the same variant every time s/he visits the page. So when the variant is first assigned to the user, this cookie is also written. The cookie will return the value of the variant, which is important for the Event Tag and Custom Dimension as well.\n Create a new 1st Party Cookie Macro\n Name it Split Variation Cookie\n Set Cookie Name to splitVar\n  So something like this:\n  This macro will return the value of cookie splitVar which, as we will soon learn, stores the variant the user should see during the experiment.\nRandom Number Macro I\u0026rsquo;ll use the Random Number Macro to sample 50 % of my visitors. It\u0026rsquo;s a nice trick, and I first saw it on Dan Russell\u0026rsquo;s blog.\n Create a new Random Number Macro\n Name it Random Number\n  Here we go:\n  So every time this macro is called, it returns a value between 0 and 2147483647. Can you see how useful this is for sampling? If I check if {{Random Number}} \u0026lt; 0.5*2147483647, it should return true 50 % of the time.\nCustom HTML Tag This is where the magic happens. You\u0026rsquo;ll need a Custom HTML Tag to perform a wide variety of things: modify the DOM element, identify the user\u0026rsquo;s preferred variant, set and read a cookie, etc\u0026hellip;\nLet\u0026rsquo;s start with the code itself. This is what the tag should have. Remember to have it fire on all pages on which the experiment is run.\n\u0026lt;script\u0026gt; function testVariant() { controlElement.style.backgroundColor=\u0026#34;#000099\u0026#34;; controlElement.innerHTML=\u0026#34;**Click here if you want, whatever**\u0026#34;; return variantTwo; } var controlElement = document.getElementById(\u0026#34;call-to-action\u0026#34;), // Set ID of control element  variantOne = \u0026#34;clickDollars\u0026#34;, // Variation 1 name  variantTwo = \u0026#34;clickWhatever\u0026#34;, // Variation 2 name  variant = variantOne, randomNumSample = 1073741824; if(!{{Split Variation Cookie}} \u0026amp;\u0026amp; controlElement) { // If cookie isn\u0026#39;t set run code  if({{Random Number}} \u0026lt; randomNumSample) { variant = testVariant(); // For 50 % of hits, fire Variation 2  } var d = new Date(); // Create cookie  d.setTime(d.getTime()+1000*60*60*24*730); var expires = \u0026#34;expires=\u0026#34;+d.toGMTString(); document.cookie = \u0026#34;splitVar=\u0026#34;+variant+\u0026#34;; \u0026#34;+expires+\u0026#34;; path=/\u0026#34;; } else if({{Split Variation Cookie}} == variantTwo \u0026amp;\u0026amp; controlElement) { // If user has only seen Variation 2  variant = testVariant(); } \u0026lt;/script\u0026gt; Let\u0026rsquo;s go over this code.\nLines 2–6 contain the code which modifies a pre-set DOM element. Thus this function operates the actual split test, showing a different variation of the landing page for 50 % of users. This function returns the name of variation 2.\nLines 8–12 set up some variables for this script to work. Change call-to-action in getElementById(\u0026ldquo;call-to-action\u0026rdquo;); to match the ID attribute of the HTML element you want to dabble with on the page. Change string values for variationOne and variationTwo to match how you want to name or two variants. These values will be used in your GA reports. Finally, the variable randomNumSample contains a numerical value exactly 50 % of the maximum the Random Number Macro can return.\nLines 14–21 first test if you\u0026rsquo;ve already been assigned a variation by checking your cookies. If no cookie is found, you\u0026rsquo;re a new user, and a variation must be assigned to you. In this case, the script randomly assigns you either the control variant (the default, \u0026ldquo;clickDollars\u0026rdquo;) or the test variation (\u0026ldquo;clickWhatever\u0026rdquo;). Next, it writes this information in a cookie which will stay with you for a long time.\nLines 22–24 are executed if the cookie is found. In this case, if the variant that was assigned to you was the test variation, the DOM altering function from the beginning (see lines 2–6) is run again to make sure you always see the same variation of the landing page. If the variant that was assigned to you was the control variation, nothing happens, since that\u0026rsquo;s the default version of the landing page.\nSome things to note. First of all, the cookie is set for two years, so it mimics the _ga cookie. The point is that the user should always see the same variation (provided they\u0026rsquo;re using the same browser). For some split tests this isn\u0026rsquo;t necessary, so you can change the code to forgo the cookie check. Also, all the functions test for undefined values (both of the cookie and the control element), so I didn\u0026rsquo;t see the need to add unnecessary try\u0026hellip;catch blocks or anything else.\nPro tip - Make use of the rarely utilized custom firing schedule for this tag to make sure your experiment only runs a certain time:\n  Custom Dimension You\u0026rsquo;ll need to create a new user-scope Custom Dimension, so that you\u0026rsquo;ll have one additional segment to play around with in your data.\n Go to Google Analytics admin, and choose the property you\u0026rsquo;ll be tracking these hits to\n Choose Custom Definitions \u0026gt; Custom Dimensions, and create a new user-scope CD\n Give it a descriptive name (I named mine just Test variation)\n Make note of dimension index\n  So something like this:\n  You could also use a session-scope or even a hit-scope dimension, depending on the scope of your test. However, even though I\u0026rsquo;m not a professional CRO practitioner (far from it!), I see the benefit of observing interactions on a multi-visit, user-level rather than the relatively tiny realm of a single visit or hit. However, some web design questions can probably be answered on a more limited scope, I guess.\nUniversal Analytics Event Tag The last bit you\u0026rsquo;ll need is some event that\u0026rsquo;s firing and sending your data to Google Analytics. Because I\u0026rsquo;m observing a button (that I\u0026rsquo;ve encased in an \u0026lt;a href...\u0026gt; element), I\u0026rsquo;m also using a Link Click Listener. If that says nothing to you, be sure to check out my guide on auto-event tracking.\nSo anyway, I\u0026rsquo;ve got a Link Click Listener firing on the test page. What I want to know is just what variant the user was seeing when they clicked the button. This is how I\u0026rsquo;ll count my conversions and determine which variant was the winner. I\u0026rsquo;ll also send the Custom Dimension with the event, so that the user is properly annotated with the variant name. I\u0026rsquo;m sending the CD with the event simply because it\u0026rsquo;s convenient for the scope of this article. You should definitely send it with the pageview, so that you can segment your visitors properly (e.g. out of people who saw the control variant, how many clicked the button; out of people who saw the test variant, how many clicked the button).\nMy Event Tag looks like this:\n  As you can see, I\u0026rsquo;m using the cookie value (\u0026ldquo;clickDollars\u0026rdquo; or \u0026ldquo;clickWhatever\u0026rdquo;) to annotate the event and the Custom Dimension! What a nice way of saving time and resources. So when someone clicks on the default variation, for example, the Event Tag will send something like this to GA servers:\nEvent Category: Call-to-action\nEvent Action: clickDollars\nEvent Label: /call-to-action-page/subscribe/\nDimension 1: clickDollars\nRemember to change the index number of the dimension to match the CD you created in the previous chapter!\nThe firing rule I\u0026rsquo;m using is simply:\n{{event}} equals gtm.linkClick\n{{element id}} equals call-to-action-link\nThis rule will thus only fire when a click occurs on an element with ID \u0026ldquo;call-to-action-link\u0026rdquo;. Conveniently, this just happens to be my control element.\nConclusions Well here it is. A simple split test done solely with GTM and some JavaScript magic. Now let me reiterate: this is hardly the best way to do split testing (we\u0026rsquo;re still waiting for Content Experiments to make their way to GTM + Universal Analytics..) but it does showcase the power and might of a tag management system. I am, after all, directly manipulating an on-page element without touching server-side or front-end code! That\u0026rsquo;s amazing\u0026hellip;and scary.\nBefore you start fiddling with your DOM (wow, that sounded dirty), make sure you know just what you\u0026rsquo;re doing and to which element. This is crucial, because you don\u0026rsquo;t want to accidentally set off a full-scale website redesign without actually, you know, intending to.\nNote also that because you\u0026rsquo;re changing the element in an asynchronously loading tag, it\u0026rsquo;s more than possible that the user will see the control variant before the script overwrites it with the test variant. This isn\u0026rsquo;t a good thing, as if the control group realizes they\u0026rsquo;re participating in an experiment, it will hurt the reliability of the results.\nThere are a couple of nice things to snag from this to your other scripts. Make use of the set-cookie function I wrote in the Custom HTML tag. It\u0026rsquo;s a versatile solution, and I\u0026rsquo;ve actually used it before as well. The random number sampling is simply genius, and I love how easy it is to operate!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/send-mail-upon-google-tag-manager-event/",
	"title": "Send Mail Upon Google Tag Manager Event",
	"tags": ["Google Tag Manager", "Guide", "JavaScript", "php"],
	"description": "Add a simple send mail PHP script to your Google Tag Manager tags, sending email whenever an event occurs.",
	"content": " Let\u0026rsquo;s say you want to set up a rudimentary email alert system in your Google Tag Manager implementation. Say, for example, you want to receive an email every time an uncaught error occurs on your website. It\u0026rsquo;s not a very good use case, since a large website can spawn hundreds of uncaught exceptions in a short period of time, but let\u0026rsquo;s just pretend for now.\nIf you know your JavaScript, you\u0026rsquo;ll know that you can\u0026rsquo;t send mail using client-side code. That\u0026rsquo;s a browser security thing, and I completely understand it. However, a vast majority of websites are created using a CMS which might provide some mail function or hook for you to use. And even if you don\u0026rsquo;t have a cooperative web server (or there\u0026rsquo;s no way you can persuade your developers to help), you could use any one of the online email APIs that are out there.\nIn this post, I\u0026rsquo;ll show two easy ways of getting your mail sent: using the mail() function in PHP, and using Mandrill\u0026rsquo;s API. My use case will be simple: every time an uncaught exception occurs on the website, an email is sent to my address with details about the error. I\u0026rsquo;ll be using the JavaScript Error Listener to catch the error and push it into the mailer.\nWord of warning: The examples in this post are very rudimentary and serve simply to show you what the basics are of sending your emails using GTM. Before you start coding a mailer system of your own, make sure you familiarize yourself with the documentation so that you don\u0026rsquo;t accidentally or unintentionally open a door for mail spammers.\nBefore you start For this to work, you\u0026rsquo;ll need the GTM JavaScript Error Listener up and running, with a couple of macros ready to collect data on the uncaught errors.\nSo first, set up the error listener with a firing rule of your choice. I have it running on all pages, but if you want to monitor just a specific page, feel free to change the rule.\n  Next, you\u0026rsquo;ll need three macros: one for the error message, one for the faulty URL, and one for the line number where the faulty code was found.\n{{Error - MSG}}\nMacro Type: Data Layer Variable\nData Layer Variable Name: gtm.errorMessage\n{{Error - URL}}\nMacro Type: Data Layer Variable\nData Layer Variable Name: gtm.errorUrl\n(NOTE: At the time of writing, this macro will return an empty string. However, I\u0026rsquo;m sure it will be fixed soon. Until then, you can use the default {{url}} macro instead.)\n{{Error - LINE}}\nMacro Type: Data Layer Variable\nData Layer Variable Name: gtm.errorLineNumber\n  And then you\u0026rsquo;re good to go.\nSend mail with PHP If your site has been built with PHP, you can use the built-in mail() function to send your emails. (If your site runs on WordPress, you should also take a look at the wp_mail() function which is a bit more robust!)\nFor this method to work, you\u0026rsquo;ll need two things:\n A Custom HTML Tag in your GTM setup to send the data payload to the PHP script\n A PHP script which processes the data and sends it\n  The Custom HTML Tag below uses jQuery to send the POST request, so you\u0026rsquo;ll need to make sure that jQuery is loaded before the Custom HTML is run. I\u0026rsquo;m not a huge fan of jQuery or really any JS framework stacked on top of GTM, but for making POST requests using AJAX, it\u0026rsquo;s a huge help.\nSo anyway, here\u0026rsquo;s what the Custom HTML Tag looks like:\n\u0026lt;script\u0026gt; var data = { errorUrl: {{Error - URL}}, errorLine: {{Error - LINE}}, errorMsg: {{Error - MSG}} }; jQuery.ajax({ type: \u0026#34;POST\u0026#34;, url: \u0026#34;/wp-content/uploads/email.php\u0026#34;, data: data }); \u0026lt;/script\u0026gt; Like I said, it\u0026rsquo;s really bare-bones. You should add some validation code, maybe utilize the success, error and complete callbacks and so forth.\nThe first bit is about building the payload. I\u0026rsquo;m doing that by creating an object literal, which is populated by the values retrieved by the error macros created earlier. So when an error occurs, the object data might have the following key-value pairs:\nerrorUrl: https://www.simoahava.com/\nerrorLine: \u0026ldquo;3\u0026rdquo;\nerrorMsg: \u0026ldquo;Uncaught ReferenceError: myFunction is not defined\u0026rdquo;\nThe next bit is about using jQuery\u0026rsquo;s ajax() function to send the data with a POST request to the custom PHP script. You\u0026rsquo;ll need to specify the location of the script for this to work.\nI wrote a very simple mail script, which you can find below. Save this as email.php and store it in a location you can refer to in the POST request.\n\u0026lt;?php if($_POST){ $message = \u0026#39;Uncaught exception on page \u0026#39; . $_POST[\u0026#39;errorUrl\u0026#39;] . \u0026#39;, line \u0026#39; . $_POST[\u0026#39;errorLine\u0026#39;] . \u0026#39;: \u0026#39; . $_POST[\u0026#39;errorMsg\u0026#39;]; mail(\u0026#34;XYZ@XYZ.com\u0026#34;, \u0026#34;[GTM simoahava.com] Uncaught error\u0026#34;, $message); } ?\u0026gt;  Again, very simple. The PHP basically waits for a POST request, after which it populates a variable $message with the payload data. Next, it utilizes the mail() function to send mail to my email with the subject [GTM simoahava.com] Uncaught error, and the error data in the message body.\nTa-da! You\u0026rsquo;ve just created your email alert system using some simple jQuery and PHP. Here\u0026rsquo;s what a sample email looks like:\n  Send mail with the Mandrill API Mandrill is an online mailing system, which provides a pretty flexible framework for sending mail using their JSON API. I chose it simply because it\u0026rsquo;s free (you have to pay if you send more than 12,000 mails per month using Mandrill), and because it looks pretty simple to set up.\nTo get things up and running, you\u0026rsquo;ll need two things:\n Mandrill API key\n A Custom HTML Tag to send the payload data to the API\n  To get the API key, browse to http://mandrill.com/signup/, and sign up for access. Once you log in for the first time, you should click on the \u0026ldquo;Get API Keys\u0026rdquo; button.\n  In the next screen, choose the \u0026ldquo;+ New API Key\u0026rdquo; to generate a new API key for you. You should immediately see your newly generated key in the list below.\n  And that\u0026rsquo;s it for setting up your Mandrill account. What you need to do next is create the Custom HTML Tag which negotiates with the Mandrill API to send your mail. Here\u0026rsquo;s what this tag should look like:\n\u0026lt;script\u0026gt; var data = { \u0026#34;key\u0026#34;: \u0026#34;IVrVuUMfhLFbY97Rjjp1ug\u0026#34;, \u0026#34;message\u0026#34;: { \u0026#34;text\u0026#34;: \u0026#34;Uncaught exception on page \u0026#34; + {{Error - URL}} + \u0026#34;, line \u0026#34; + {{Error - LINE}} + \u0026#34;: \u0026#34; + {{Error - MSG}}, \u0026#34;subject\u0026#34;: \u0026#34;[GTM simoahava.com] Uncaught error\u0026#34;, \u0026#34;from_email\u0026#34;: \u0026#34;simo@simoahava.com\u0026#34;OB, \u0026#34;from_name\u0026#34;: \u0026#34;GTM Simo\u0026#34;, \u0026#34;to\u0026#34;: [ { \u0026#34;email\u0026#34;: \u0026#34;simo@simoahava.com\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;Simo Ahava\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;to\u0026#34; } ] }, \u0026#34;async\u0026#34;: true }; jQuery.ajax({ type: \u0026#34;POST\u0026#34;, url: \u0026#34;https://mandrillapp.com/api/1.0/messages/send.json\u0026#34;, dataType: \u0026#34;json\u0026#34;, data: data }); \u0026lt;/script\u0026gt; As you can see, you need to add a bit more information into the payload object to satisfy the requirements of the Mandrill API.\nThe code itself is pretty similar to when we sent the POST request to the PHP script, with the notable exception of having to declare the dataType parameter explicitly as \u0026ldquo;json\u0026rdquo;.\nWhen the mail is sent successfully, you should again see a pretty hideous email in your inbox. By the way, take a look at Mandrill\u0026rsquo;s reports. You\u0026rsquo;ll see some pretty interesting data on your API use, so if you want to build this into a whole email-system-thing, you can use Mandrill\u0026rsquo;s powerful features to diagnose your mail traffic.\n  Conclusions Sending mail via Google Tag Manager doesn\u0026rsquo;t happen with just a click of a button. Because browser security prevents you from sending email directly with JavaScript (i.e. GTM), you\u0026rsquo;ll need to access either server-side methods or some external API. This post provided very rudimentary examples of both scenarios.\nIf you want to build on this idea, be sure to make your code as waterproof as possible. Hijacking someone\u0026rsquo;s mail script is a really easy way to cause a lot of damage in the form of spam. Also, I don\u0026rsquo;t like the fact that you have to provide the Mandrill API key \u0026ldquo;in the open\u0026rdquo;, so you might want to look at Mandrill\u0026rsquo;s PHP client as a way to use Mandrill\u0026rsquo;s API to send the mail server-side.\nAnd before you try anything, the API key I created was just for testing purposes, it no longer exists.\nAnyway, perhaps at some point GTM will support sending mail via GTM\u0026rsquo;s own protocols, which will make this post nice and obsolete, but until then: have fun!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-dom-listener/",
	"title": "Google Tag Manager: DOM Listener",
	"tags": ["extension", "Google Tag Manager", "Guide", "JavaScript"],
	"description": "Create a DOM listener using Google Tag Manager. This can be used to detect dynamic changes in the page layout.",
	"content": " In this post, I\u0026rsquo;ll walk you through a tutorial on how to create a Google Tag Manager extension. This extension will be a new listener, whose sole job is to listen for changes in the HTML and CSS markup on the page.\nThe reason I\u0026rsquo;m teaching you how to create a DOM listener is simple. Ever so often I come across people asking for help, but they are unable to touch on-page code. Usually the problem is magnified with form handlers, since the developers might have installed some custom jQuery form manager, for instance, which simply refuses to cooperate with GTM\u0026rsquo;s form listeners. That is why you might want to fire a GTM event when a certain message pops up on the screen, for example.\nWith a DOM listener, you can fire a GTM event every time something changes on the page. Well, not every time. Actually, in this example you\u0026rsquo;re restricted to element insertion and attribute changes. A working use case might be form validation: if you want to track invalid forms, maybe by sending the content of the validation error message with an event, you might just as well create a DOM listener. This listener will then trigger when an error message appears on the page.\nDISCLAIMER: To be truthful, I feel quite strongly about using hacks such as this to fix faulty markup or an otherwise shoddy tag implementation. The main idea behind this post is to introduce a feature of JavaScript which can alleviate some of your tag management pains. However, if you find that you need hacks such as the DOM listener to circumvent development problems on your website, I would strongly suggest that you take this up with your developers and try to come up with a solution which works with GTM\u0026rsquo;s standard features.\nThe premise To create the DOM listener, I will leverage an API known as MutationObserver. This little piece of magic will create an observer object, which triggers every time a mutation takes place. This mutation can come in different sizes and shapes, but for the purposes of this guide, I will listen for two kinds of mutations, for two kinds of use cases:\n Node insertion - when a new \u0026lt;span class=\u0026quot;error\u0026quot;\u0026gt; is injected in the DOM\n CSS style change - when a previously hidden \u0026lt;span class=\u0026quot;error\u0026quot;\u0026gt; is displayed\n  So the first use case is when your form injects a new SPAN element into the DOM upon an error. The script will check if the injected node is really the error message, and if it is, it pushes a dataLayer event with the content of the SPAN (the message itself).\nThe second use case is when an invalid form causes a hidden SPAN to appear, with the error message within.\nListening for node insertion is a bit different than listening to an attribute change. A node insertion listener can be primed on any node on the DOM, meaning you have much more to work with in terms of flexibility. Listening for attribute changes requires you to pinpoint exactly which node you want to observe, and the attribute change will be reported for that node only.\nPreparations Here are the ingredients:\n A page where a \u0026lt;span class=\u0026quot;error\u0026quot;\u0026gt; is either inserted or revealed with a CSS style change\n Custom HTML tag(s)\n  My test page code looks like this (I combined both use cases into one here):\n\u0026lt;script\u0026gt; function addHTML() { var myDiv = document.getElementById(\u0026#34;contents\u0026#34;); var newSpan = document.createElement(\u0026#34;span\u0026#34;); newSpan.className = \u0026#34;error\u0026#34;; newSpan.innerHTML = \u0026#34;This form contained errors\u0026#34;; myDiv.appendChild(newSpan); } function changeCSS() { var mySpan = document.getElementsByClassName(\u0026#34;error\u0026#34;)[0]; mySpan.style.display = \u0026#34;block\u0026#34;; } \u0026lt;/script\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; onClick=\u0026#34;addHTML();\u0026#34;\u0026gt;Add span with .innerHTML\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; onClick=\u0026#34;changeCSS();\u0026#34;\u0026gt;Add span with CSS\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;contents\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;error\u0026#34; style=\u0026#34;display: none;\u0026#34;\u0026gt;This form contained errors\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; Let\u0026rsquo;s just quickly go over this page.\nFirst, you have two functions. The function addHTML() will insert the following in the DIV#contents below:\n\u0026lt;span class=\u0026quot;error\u0026quot;\u0026gt;This form contained errors\u0026lt;/span\u0026gt;\nThe insertion is done upon clicking a link whose text is \u0026ldquo;Add span with .innerHTML\u0026rdquo;.\nIn the second function, the SPAN.error is already in the DOM, but it\u0026rsquo;s been hidden with a display: none CSS command. When the link labelled \u0026ldquo;Add span with CSS\u0026rdquo; is clicked, this style directive will be changed to display: block.\n  This is just my test page. Obviously you\u0026rsquo;ll need to navigate around your current implementation to make things work.\nFinally, you\u0026rsquo;ll need your custom HTML magic. The next two chapters will go over the tags and the code you\u0026rsquo;ll need to write for them.\nCase 1: node insertion In this use case, a new node (\u0026lt;span class=\u0026quot;error\u0026quot;\u0026gt;) is inserted into a DIV on the page. The markup on the page looks something like this:\n\u0026lt;script\u0026gt; function addHTML() { var myDiv = document.getElementById(\u0026#34;contents\u0026#34;); var newSpan = document.createElement(\u0026#34;span\u0026#34;); newSpan.className = \u0026#34;error\u0026#34;; newSpan.innerHTML = \u0026#34;This form contained errors\u0026#34;; myDiv.appendChild(newSpan); } \u0026lt;/script\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; onClick=\u0026#34;addHTML();\u0026#34;\u0026gt;Add span with .innerHTML\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;contents\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; So as you can see, there\u0026rsquo;s an empty DIV (#contents), which is then appended with a new SPAN, created by the function addHTML() which, in turn, waits for a click event on the link on the page.\nNow, the next step is to create the listener itself. You\u0026rsquo;ll need to use the MutationObserver API to listen for any node which is inserted into the observed target. The node itself can be on any level in the DOM hierarchy, but I chose the DIV#contents to keep things simple. When a node is inserted, a dataLayer push is done with a new GTM event and the text content of the SPAN.\nHere\u0026rsquo;s what you Custom HTML Tag should look like:\n\u0026lt;script\u0026gt; var contentDiv = document.querySelector(\u0026#34;#contents\u0026#34;); var MutationObserver = window.MutationObserver || window.WebKitMutationObserver; var observer = new MutationObserver(function(mutations) { mutations.forEach(function(mutation) { if(mutation.type===\u0026#34;childList\u0026#34; \u0026amp;\u0026amp; mutation.addedNodes[0].className===\u0026#34;error\u0026#34;) { dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;newErrorSpan\u0026#39;, \u0026#39;spanErrorMessage\u0026#39;: mutation.addedNodes[0].innerHTML}); observer.disconnect(); } }); }); var config = { attributes: true, childList: true, characterData: true } observer.observe(contentDiv, config); \u0026lt;/script\u0026gt; OK, OK, lots of stuff going on here. Let\u0026rsquo;s go through the script and see what it does. First, you create a reference to the DIV you will be listening to. I\u0026rsquo;m using the querySelector() function, because it\u0026rsquo;s a nice way to combine CSS selectors and JavaScript.\nNext, you create the MutationObserver itself by first tackling a known cross-browser issue with WebKit browsers. The observer listens for mutations of type childList (a new child node is inserted) and checks if the first added node has CSS class \u0026ldquo;error\u0026rdquo;. You\u0026rsquo;ll have to modify this code if the SPAN with the error is not the first node that your script inserts into the DOM.\nIf such a mutation is detected, a GTM event is pushed into dataLayer (newErrorSpan), and the error message contents are sent as a data layer variable as well. Note that I use innerHTML to get the contents of the SPAN. If your SPAN has HTML formatting within, you might want to use innerText instead.\nThe disconnection means that after this particular mutation takes place, no further mutations are listened for. So if someone keeps on pushing the \u0026ldquo;submit\u0026rdquo; button, the observer will shut down after the first error. You might want to remove this line if you want to track ALL the potential errors your visitor propagates on the form.\nLastly, I create a configuration for the MutationObserver and prime it on the DIV.\nAnd that\u0026rsquo;s it for node insertion. If you set this new listener to fire on pages where the SPAN with class \u0026ldquo;error\u0026rdquo; is created in a DIV with ID \u0026ldquo;contents\u0026rdquo;, a dataLayer.push() will take place every time the SPAN is inserted into the DOM. Try it for yourself!\n  Case 2: CSS change In this case, you have a hidden SPAN with the error message, which is then revealed when the form validation fails. Here\u0026rsquo;s what the HTML might look like:\n\u0026lt;script\u0026gt; function changeCSS() { var mySpan = document.querySelector(\u0026#34;.error\u0026#34;); mySpan.style.display = \u0026#34;block\u0026#34;; } \u0026lt;/script\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34; onClick=\u0026#34;changeCSS();\u0026#34;\u0026gt;Add span with CSS\u0026lt;/a\u0026gt; \u0026lt;div id=\u0026#34;contents\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;error\u0026#34; style=\u0026#34;display: none;\u0026#34;\u0026gt;This form contained errors\u0026lt;/span\u0026gt; \u0026lt;/div\u0026gt; So I have a simple SPAN within a DIV with the error message. This is initially set to display: none, but when the link is clicked, the display status is changed to block.\nAs for your Custom HTML Tag, you\u0026rsquo;ll need something like this:\n\u0026lt;script\u0026gt; var spanError = document.querySelector(\u0026#39;.error\u0026#39;); var MutationObserver = window.MutationObserver || window.WebKitMutationObserver; var observer = new MutationObserver(function(mutations) { mutations.forEach(function(mutation) { if (mutation.type===\u0026#34;attributes\u0026#34; \u0026amp;\u0026amp; mutation.target.style.display===\u0026#34;block\u0026#34;) { dataLayer.push({\u0026#39;error\u0026#39;: \u0026#39;modErrorSpan\u0026#39;, \u0026#39;spanErrorMessage\u0026#39;: mutation.target.innerHTML}); observer.disconnect(); } }); }); var config = { attributes: true, childList: true, characterData: true } observer.observe(spanError, config); \u0026lt;/script\u0026gt; It\u0026rsquo;s pretty similar to the previous one but with one or two small changes. First, you\u0026rsquo;re not listening to the DIV, you\u0026rsquo;re listening to the actual node you know will be the target of the style change. This is important, and it means that you have to know exactly what the target will be when creating this script.\nNext, in the observer itself, you\u0026rsquo;ll need to specify just what the style change was. I used simply a change from display: none to display: block, but you might have something different in your code. So don\u0026rsquo;t forget to change the content of the if-clause to match what the new style is.\nThe benefit here is that you\u0026rsquo;re listening to just one single node, so there\u0026rsquo;s a performance boost. I\u0026rsquo;ve got the observer.disconnect(); again, but you might want to remove that if you want to send events perpetually for each invalid click of the submit button.\nDon\u0026rsquo;t forget to test.\n  Conclusions This might seem like a cool hack to you. After all, you\u0026rsquo;re listening for changes on the page without actually any page refresh happening! Also, you\u0026rsquo;re extending GTM\u0026rsquo;s default listeners so you\u0026rsquo;re kind of like a Google engineer, right?\nWell, remember what I said in the disclaimer of this text. This is a hack, a circumvention, a band-aid, designed to overcome problems with your markup or your JavaScript. Having a custom form handler which doesn\u0026rsquo;t propagate a proper form submit event (which is required by GTM\u0026rsquo;s default form submit listener) is a bit suspect and reeks of bad practices. So before you resort to this DOM listener, make sure you exhaust all other, more orthodox possibilities with your developers.\nThen again, you might not need this to overcome any development problems, but rather to complement your current tag setup. In that case, go crazy! It\u0026rsquo;s an excellent way to add more flexibility to your tags. Do note the cross-browser support, however. Support is not comprehensive enough to warrant using this listener as a firing rule for some business-critical tag.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/accuracy-test-gtm-default-events/",
	"title": "Accuracy Test Of GTM Default Events",
	"tags": ["firing rules", "Google Tag Manager", "test"],
	"description": "A test to check how long it typically takes for DOM Ready and Window Loaded triggers to fire after GTM has loaded. This test was run on my site.",
	"content": " If you know your Google Tag Manager, you know that GTM pushes three data layer events into the queue when any page with the container snippet is rendered. Each of these three events signals a specific stage in the page load process. Here are the events (be sure to read my guide on GTM rules to understand further what these events do):\n gtm.js - This is pushed into the data layer as soon as GTM is initialized and the container is loaded. This is also the default event for all rules without an explicit event macro rule as a condition. Basically, if you want something to happen at the earliest possible moment, you need to have {{event}} equals gtm.js as the rule\n gtm.dom - When the DOM has been populated with on-page elements, this event is pushed into the data layer. If you have HTML elements or dependent JavaScript snippets loaded at the very bottom of the page template, having your tag fire upon {{event}} equals gtm.dom will ensure that these latecomers can be used in your tags\n gtm.load - Once the window has finished loading, along with all images, scripts, and other assets, gtm.load is pushed into the data layer. If you have scripts or DOM elements that take a long while to load, and you want to be 100 % sure that they have loaded before your tags fire, using {{event}} equals gtm.load as a firing rule for your tag might be wise\n    Now, having said that, I wanted to test just how accurate gtm.dom and gtm.load are as trigger events. If I were to have my most important tag, GA page tracking, fire upon either one, just how many hits will I miss compared to the default {{url}} matches RegEx .* rule?\nI know there will be some losses in accuracy, because any delay in firing a tag increases the risk of the person viewing the page clicking a link or closing the browser before the tag has had a chance to fire. But just how much data is actually lost?\nResults in brief: If you don\u0026rsquo;t want to go through the rest of the article and are just interested in results, here\u0026rsquo;s what I found. Using gtm.dom as the trigger is almost as reliable as using gtm.js. With gtm.load, you\u0026rsquo;ll see far more missed hits, but it might still be within an error margin you find acceptable. However, it is important to remember that the actual results will vary depending on your DOM and page load times. If you have a complex page template with a lot of dynamically created content, huge images, lots of external assets, etc., you\u0026rsquo;ll see a higher error rate than with my humble blog.\nThe premise Here\u0026rsquo;s how I set up the test:\n I used my own blog as the guinea pig. I wanted an actual \u0026ldquo;live\u0026rdquo; environment to test with, and my blog is a pretty good example of a standard GTM setup\n For exactly 28 days, I had two non-interaction events firing: one upon {{event}} equals gtm.dom and one upon {{event}} equals gtm.load\n After 28 days, I could compare the number of events to page views to get the number of hits I\u0026rsquo;d miss if I chose gtm.dom or gtm.load over the default gtm.js\n  The test time was from the beginning of Wednesday, 12 March 2014 to the end of Tuesday, 8 April 2014.\nSome details about my setup:\n  (By the way, I\u0026rsquo;m renaming my TMRs (tags, macros, rules) at some convenient point in the near future, so don\u0026rsquo;t read too much into my current naming schema.)\nThere\u0026rsquo;s a \u0026ldquo;Dwell and scroll\u0026rdquo; tag, which starts to work its magic upon gtm.dom. Basically, it waits 30 seconds, looks for a scroll action by the visitor, and if both the timeout and a scroll have taken place, it sends a bounce-rate-killing event to GA.\nThere\u0026rsquo;s also a tag for my weather script. This is pretty expensive in terms of performance, since it makes two external API calls. However, it only fires during the first page view of a session, and it initiates with gtm.js. The more expensive weather API call is also done asynchronously.\nFinally, there\u0026rsquo;s my page load time script, set to fire on gtm.load, some event pushes and my listeners.\nMy tag setup is really lightweight. There shouldn\u0026rsquo;t be any major reason why my tags would cause gtm.dom or gtm.load to be delayed, unless the weather scripts starts to timeout in the external resource calls.\nIn my GA account, I don\u0026rsquo;t filter out my own hits; actually, I don\u0026rsquo;t have a single filter on my blog profile. I know, you probably have a big, nasty look of disgust on your face right now. But you know what, I never thought I\u0026rsquo;d get enough traffic to care, and now that I do, I still don\u0026rsquo;t really care. Furthermore, I find it difficult to move to a new, filtered profile, since I don\u0026rsquo;t have any historical data. OK. Stop chucking that lettuce at me. I\u0026rsquo;ll go and create a filtered profile right now!\nThe results - page views Here\u0026rsquo;s what I found out:\n Total page views: 12,167\n Total gtm.dom events: 12,115 (-52, 99,6 %)\n Total gtm.load events: 11,945 (-222, 98,2 %)\n  Well, that\u0026rsquo;s pretty good! Based on this result, I wouldn\u0026rsquo;t hesitate to recommend you to use {{event}} equals gtm.dom if you have even the slightest concern that some vital data in the DOM is required in your tags. Also, gtm.load does pretty well, though I do believe that a near 2 percent error rate might be too much for some large eCommerce sites. My site is very lightweight, so a more complex and flashy site with a significantly longer average page load time will surely have more missed gtm.load hits.\nHowever, I had to probe further. If you remember, I had a couple of other events firing on every page view as well. Because of this, I\u0026rsquo;d like to take a look at visits to see if there\u0026rsquo;s some discrepancies between page views sent and visits recorded.\nThe results - visits I performed this analysis by segmenting out visits without a single gtm.dom or gtm.load test event. Here\u0026rsquo;s what I found:\n  Hold on\u0026hellip; what?\nAlmost 4 percent of all visits occurred without a single gtm.dom or gtm.load test event. So, I must have visits without a single page view, because the number of visits without these GTM events exceeds the number of pageviews without them. And yes, this confirms my suspicions:\n  So here\u0026rsquo;s the deal: I have a bunch of visits without a single gtm.dom or gtm.load event being fired, and almost 85 % of these visits don\u0026rsquo;t have a landing page, i.e. a single page view hasn\u0026rsquo;t been sent.\nInteresting.\nWell, when I look at the event catalog for these \u0026ldquo;ghost visits\u0026rdquo;, I see a bunch of my adjusted bounce rate events and my weather events.\n  The interesting thing (not visible in these tables) is that my adjusted bounce rate event actually has more total events than unique events, which would mean that these visits had multiple page loads which didn\u0026rsquo;t send an actual page view to Google Analytics! How screwed up is that?\nAlso, because my weather script did fire on a number of occasions, and still my test events weren\u0026rsquo;t pushed, I\u0026rsquo;ll have to believe that something interfered with my test events. Remember, my \u0026ldquo;NoBounce\u0026rdquo; event waits 30 seconds before firing a hit AND it waits for gtm.dom before initializing. This couldn\u0026rsquo;t be just a case of gtm.dom and gtm.load not being pushed into the data layer. This was clearly a case of my test scripts just refusing to fire!\nRemember also, I don\u0026rsquo;t have any filters on my profile, so I\u0026rsquo;m not filtering out page views and just seeing the events. Just over 3 percent of all my visits are completely page-view-less!\nThis is weird, but I\u0026rsquo;ll just chalk it up to an error margin associated with increased granularity in measurement. I know I shouldn\u0026rsquo;t be picking on micro-level phenomena such as this, but it still makes me wonder. Are page-view-less visits thanks to some configuration I have in GTM, or should they be attributed to the visitor?\nBy the way, I looked through every single report in GA, and they didn\u0026rsquo;t reveal anything out of the ordinary. It would be interesting to pursue this further, but for the purposes of this test, this is all more just a fascinating detail than anything that you or I can learn from.\nConclusions Apart from the weirdness with the page-view-less visits, I\u0026rsquo;m still comfortable in recommending using {{event}} equals gtm.dom for all your tags. If you want to use gtm.load as the trigger, you\u0026rsquo;ll have to be aware that you will lose a lot more hits, even if the rate is still around just 2 percent. But that\u0026rsquo;s just with my lightweight setup.\nWhether or not race conditions had anything to do with missed hits, since my adjusted bounce rate script also fires on gtm.dom, I don\u0026rsquo;t know. A huge site with dozens of tags all firing on the same triggers might exhibit more variation in how accurate gtm.dom and gtm.load are as firing rules.\nTo play it safe, I still recommend having all your critical, independent tags firing as early as possible, i.e. after gtm.js has been pushed into the data layer. However, there\u0026rsquo;s no reason not not to use gtm.dom and gtm.load as trigger rules as well. You\u0026rsquo;ll just have to be aware that you might be missing some hits.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/form-tracking-google-tag-manager/",
	"title": "Advanced Form Tracking In Google Tag Manager",
	"tags": ["forms", "Google Tag Manager", "Guide", "macros"],
	"description": "How to track web forms using Google Tag Manager.",
	"content": " There is a new, updated version of this article for the new version of Google Tag Manager. I strongly suggest you read that as well!\nI really enjoy the ad hoc Q\u0026amp;A sessions my blog posts have inspired. I haven\u0026rsquo;t said this enough, but I am really, REALLY grateful to people who take their time to comment on my posts, even if it\u0026rsquo;s just say a quick \u0026ldquo;Hi!\u0026rdquo;. The main reason I enjoy getting blog comments is because they often turn into blog posts. Seriously, if you\u0026rsquo;re a blogger suffering from writer\u0026rsquo;s block, take a look at your comments. There\u0026rsquo;s a wealth of content ideas right there.\nI\u0026rsquo;m often asked about form tracking and Google Tag Manager. This is a recurring theme in the Google+ GTM community as well. Part of me (the pretentious part) wants to credit this to the fact that I neglected to add a section for the Form Submit Listener tag in my auto-event tracking post. This is when the rational me kicks in and says that it\u0026rsquo;s actually because tracking forms is pretty darn difficult. There are so many things that can go wrong, so many variables to look at, so many different things to track, so many different forms on a single page, so many different technologies creating the forms, so many\u0026hellip; you get the drift.\nSo this guide is meant to cover some of the more advanced use cases for form tracking in GTM, while still providing relevant examples of GTM macros and rules to make the tips actionable.\n1. Form tracking: the basics To track a form in Google Tag Manager, your best bet is to create a Form Submit Listener tag. This will then listen for form submit events (provided that they aren\u0026rsquo;t prevented by conflicting scripts), and push an {{event}} equals gtm.formSubmit event into the data layer for you to work with.\nIf you\u0026rsquo;re feeling a little confused, you should first read up on the basics: auto-event tracking, macros, and rules. Justin Cutroni has an excellent post on auto-event tracking, and it covers form tracking basics as well.\nSo let\u0026rsquo;s get started. Before we do anything, let\u0026rsquo;s create the Form Submit Listener tag.\n Create a new tag of type Form Submit Listener\n Set the firing rule to fire on all pages\n    Now, you have some room to improvise here. First of all, it isn\u0026rsquo;t at all necessary to have the tag fire on all pages. If you want to optimize things, you could only have it fire on pages with forms.\nAlso, as you can see there are two checkboxes that you can check, if you so choose:\n Wait for tags - This introduces a timeout of X milliseconds (2000 by default) to the submit event. This is to allow all tags that use the form submit event as a trigger to fire. If the timeout elapses before the dependent tags have fired, the form submit event will complete, and there\u0026rsquo;s a risk that you\u0026rsquo;ll miss some hits. Still, I do not recommend that you increase this timeout, because if your dependent tags don\u0026rsquo;t fire within 2 seconds, the fault is with them, not with GTM or your form.\n Check for validation - Basically, if the form doesn\u0026rsquo;t validate (i.e. the submission event is interrupted by a validation function), the tag will not fire. This would be smart to check, unless you know there are event propagation issues involved, such as when a custom submit handler is used.\n  The Form Submit Listener waits for a form submit event on the page. Once a form is successfully submitted, a GTM data layer event gtm.formSubmit is pushed into the data layer. If you have the \u0026ldquo;Wait for tags\u0026rdquo; option checked, any tags using this event as a trigger will be first fired (if they fire within the delay time specified), and only then will the submission be completed. After this, you can use the rule {{event}} equals gtm.formSubmit for any tags that should be fired when a form is submitted.\nSo this is the starting point for our journey. A lonely form submit listener, its meager existence reduced to waiting for a form to submit, ready to fulfill the duties it was assigned by a sadistic GTM admin.\n2. Useful macros As always, a sleek and functional GTM setup is dependent on how you use macros. For the purposes of this post, here\u0026rsquo;s a bunch of macros you\u0026rsquo;ll find useful.\n{{element}}\nMacro Type: Auto-Event Variable\nVariable Type: Element\nDescription: Captures the submitted form object\n{{element id}}\nMacro Type: Auto-Event Variable\nVariable Type: Element ID\nDescription: Captures the ID attribute value of the submitted from\n{{element url}}\nMacro Type: Auto-Event Variable\nVariable Type: Element URL\nDescription: Captures the ACTION attribute value of the submitted form\n{{field value}}\nMacro Type: Custom JavaScript\nJavaScript:\nfunction() { var inputField = document.getElementById(\u0026#34;myFormField\u0026#34;); return inputField.value || \u0026#34;\u0026#34;; }  Description: Returns the value of the element whose ID is myFormField (change this to your liking)\n{{selected item}}\nMacro Type: Custom JavaScript\nJavaScript:\nfunction() { var selectId = document.getElementById(\u0026#34;mySelectList\u0026#34;); try { var options = selectId.options; for (var i = 0;i \u0026lt; options.length;i++){ if(options[i].selected) { return options[i].value; } } } catch(e) {} return \u0026#34;\u0026#34;; }  Description: Returns the VALUE of the selected item in the select list whose ID you specify with the variable selectId\n{{checked button}}\nMacro Type: Custom JavaScript\nJavaScript:\nfunction() { var radioName = \u0026#34;myRadioButtons\u0026#34;; try { var buttons = document.getElementsByName(radioName); for (var i = 0;i \u0026lt; buttons.length;i++){ if(buttons[i].checked) { return buttons[i].value; } } } catch(e) {} return \u0026#34;\u0026#34;; }  Description: Returns the VALUE of the checked element out of the radio buttons whose NAME attribute is specified in the variable radioName\n{{string of checked buttons}}\nMacro Type: Custom JavaScript\nJavaScript:\nfunction() { var inputs = document.getElementsByTagName(\u0026#34;input\u0026#34;), selectedRadios = \u0026#34;\u0026#34;; for (var i = 0;i \u0026lt; inputs.length;i++) { if(inputs[i].type===\u0026#34;radio\u0026#34; \u0026amp;\u0026amp; inputs[i].checked) { selectedRadios += inputs[i].value +\u0026#34; \u0026#34;; } } return selectedRadios.replace(/\\s$/,\u0026#34;\u0026#34;); }  Description: Returns a concatenated string of all the values of checked radio buttons on the page\n{{array of checked buttons}}\nMacro Type: Custom JavaScript\nJavaScript:\nfunction() { var inputs = document.getElementsByTagName(\u0026#34;input\u0026#34;), selectedRadios = []; for (var i = 0;i \u0026lt; inputs.length;i++) { if(inputs[i].type===\u0026#34;radio\u0026#34; \u0026amp;\u0026amp; inputs[i].checked) { selectedRadios.push(inputs[i].value); } } return selectedRadios; }  Description: Returns an array of all the values of checked radio buttons on the page\nYou can apply the previous two macros to checkboxes as well by changing inputs[i].type===\u0026ldquo;radio\u0026rdquo; to inputs[i].type===\u0026ldquo;checkbox\u0026rdquo;.\n3. Capture field value Often you have a situation where you want to send the value of some field with your Google Analytics hit. Perhaps you want to segment your events between people who submitted value1 and those who submitted value2. Or you might want to use a specific field value as a firing or blocking rule for your other tags.\n  Whatever the case, here\u0026rsquo;s how you retrieve the value from a specific field in your form. Remember, you are not allowed to send personally identifiable information such as names, e-mail addresses or phone numbers to Google Analytics!.\nThe easy method:\nThe easy way to do it is to create the {{field value}} macro I introduced in the previous chapter. This requires that the field for which you want to retrieve the value has an ID attribute, e.g. \u0026lt;input type=\u0026quot;text\u0026quot; id=\u0026quot;lunch\u0026quot;\u0026gt;.\nYou\u0026rsquo;d then add this macro to your Event tag (or rule or pageview tag or similar), and when the tag fires upon {{event}} equals gtm.formSubmit, the macro will return the value of the form element whose ID you specified earlier.\nThe PRO method:\nIf you have many forms, each with a unique field (with a unique ID) that you want to track, you don\u0026rsquo;t need to create a separate macro for each form. Just change the variable declaration in the macro to var inputField = document.getElementById({{field ID lookup}});. Next, create a new Lookup Table macro, where you return the ID of the field whose value you want to retrieve, depending on if the user is on a specific page, if the form has a specific ID or something similar. Here\u0026rsquo;s an example, where the field ID depends on the form element ID:\n  If you don\u0026rsquo;t have an ID attribute to access, you\u0026rsquo;ll need to get creative. Usually this also means that you\u0026rsquo;ll need to resort to error-prone scripts, so I really suggest that you get your developers to introduce ID attributes to your fields. However, here are some ideas (these replace the variable declaration in the original {{field value}} macro). Note that the [0] after the functions refers to the first index of the array. So if you want the second input element, you\u0026rsquo;d use [1], for the third you\u0026rsquo;d use [2] and so on.\nGet first input element of submitted form:\nvar inputField = {{element}}.getElementsByTagName(\u0026quot;input\u0026quot;)[0];\nGet first input element with \u0026ldquo;myInput\u0026rdquo; as the NAME attribute (\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;myInput\u0026quot;\u0026gt;):\nvar inputField = document.getElementsByName(\u0026quot;myInput\u0026quot;)[0];\nGet first input element with \u0026ldquo;myInput\u0026rdquo; as the CLASS attribute (\u0026lt;input type=\u0026quot;text\u0026quot; class=\u0026quot;myInput\u0026quot;\u0026gt;):\nvar inputField = document.getElementsByClassName(\u0026quot;myInput\u0026quot;)[0];\nAnd so on. Feel free to get creative with JavaScript.\n4. Capture drop-down list value To get the selected value of a drop-down list (SELECT element), you\u0026rsquo;ll need to use a macro which goes through all the OPTION elements in your SELECT list, and returns the one that is selected. The macro used here was introduced earlier in this post ({{selected item}}).\n  The easy method:\nThe easy method, again, utilizes the ID attribute of the SELECT element. For example, you might have a list such as:\n\u0026lt;select id=\u0026#34;myList\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;home\u0026#34;\u0026gt;Home\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;work\u0026#34;\u0026gt;Work\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; You\u0026rsquo;d change the variable declaration in the {{selected item}} macro to var selectId = document.getElementById(\u0026ldquo;myList\u0026rdquo;);. Next, the script goes through all the OPTION elements within this SELECT structure, and it returns the value of the option that was selected.\nThe PRO method:\nNaturally, you can apply the same Lookup Table magic as with the field value method above. If your SELECT element doesn\u0026rsquo;t have an ID attribute, you\u0026rsquo;ll need to get creative. Here are some ideas for the variable declaration.\nAccess the first SELECT list on the page:\nvar selectId = document.getElementsByTagName(\u0026quot;select\u0026quot;)[0];\nAccess the first SELECT list of the submitted form:\nvar selectId = {{element}}.getElementsByTagName(\u0026quot;select\u0026quot;)[0];\n5. Capture selected radio button value(s) A very solid case for value retrieval is when you have a choice of radio buttons. For example, in the example below, you might want to fire a different tag (with different custom dimensions) depending on whether the user chose Home or Health insurance.\n  The trick with the radio button element is a consistent (and unique) use of the NAME attribute. If you specify each group of radio buttons with their own, unique NAME attribute, this script will work beautifully.\nThe easy method:\nUse the {{checked button}} from before, and substitute \u0026ldquo;myRadioButtons\u0026rdquo; with the NAME attribute value of the group of radio buttons you want to analyze.\nThis script goes through all the radio buttons with the given NAME attribute and returns the value of the button that is checked. As you can see, this will only work if your button groups have unique NAME attributes.\nThe PRO method:\nSometimes you have several radio button groups on your form, and you want to send or process the selected buttons from each of these in a single tag. Here\u0026rsquo;s how:\nConcatenate a string of all the selected radio button values (Custom JavaScript macro)\nfunction() { var inputs = document.getElementsByTagName(\u0026#34;input\u0026#34;), selectedRadios = \u0026#34;\u0026#34;; for (var i = 0;i \u0026lt; inputs.length;i++) { if(inputs[i].type===\u0026#34;radio\u0026#34; \u0026amp;\u0026amp; inputs[i].checked) { selectedRadios += inputs[i].value +\u0026#34; \u0026#34;; } } return selectedRadios.replace(/\\s$/,\u0026#34;\u0026#34;); }  This script goes through ALL the radio buttons on the form, and returns a concatenated string of the checked button values, e.g. \u0026ldquo;male 30 home\u0026rdquo; for three radio button groups.\nSave the values in an object for later processing (Custom JavaScript macro)\nfunction() { var inputs = document.getElementsByTagName(\u0026#34;input\u0026#34;), selectedRadios = []; for (var i = 0;i \u0026lt; inputs.length;i++) { if(inputs[i].type===\u0026#34;radio\u0026#34; \u0026amp;\u0026amp; inputs[i].checked) { selectedRadios.push(inputs[i].value); } } return selectedRadios; }  This returns an array of values, grabbed from each checked radio button found on the page. You can then process this array in another macro (or this same one), or do other magic to it. I prefer this over the concatenated string method, because you have more to work with when you utilize JavaScript array structures.\n6. Capture selected checkbox value(s) The trick with checkboxes is that you almost always have multiple, checked values. This means that if you want to send information in your event on what boxes were checked, you\u0026rsquo;ll always have to resort to methods such as those introduced above for the radio button (the PRO method). So to retrieve the values of your checked checkboxes, use the script(s) from above, but instead of\nif(inputs[i].type===\u0026quot;radio\u0026quot;...)\nyou\u0026rsquo;ll need to use\nif(inputs[i].type===\u0026quot;checkbox\u0026quot;...)\nto access your checkboxes.\nThe other method:\nHow about if you just want to make a value lookup? For example, if you wanted to fire a tag if the form includes the opt-in for spam\u0026hellip; I mean the occasional promotional e-mail?\n  In this case, you\u0026rsquo;d create a Custom JavaScript macro that looks like this:\nfunction() { var checkbox = document.getElementById(\u0026#34;spamReq\u0026#34;); return checkbox.checked || false; }  This macro returns \u0026ldquo;true\u0026rdquo; if the checkbox is checked, and \u0026ldquo;false\u0026rdquo; if it isn\u0026rsquo;t or if the script encounters an error.\nThe PRO other method:\nWhat about if you don\u0026rsquo;t have an ID attribute to access (you fool)? Well, there are many ways you can identify the correct checkbox. You can look for the nth input element on a form (e.g. 15th element of the submitted form is the checkbox) with something like:\nvar checkbox = {{element}}.getElementsByTagName(\u0026#34;input\u0026#34;)[14];  If it\u0026rsquo;s the ONLY checkbox on the form, you could get its check status (true/false) with something like this:\nfunction() { var inputs = {{element}}.getElementsByTagName(\u0026#34;input\u0026#34;); for(var i = 0;i \u0026lt; inputs.length;i++) { if(inputs[i].type===\u0026#34;checkbox\u0026#34;) { return inputs[i].checked; } } return false; }  Note that you can also leverage the querySelector() method like this (browser support isn\u0026rsquo;t as good as with getElementsByTagName()):\nfunction() { var check = document.querySelector(\u0026#39;input[type=\u0026#34;checkbox\u0026#34;]\u0026#39;); return check ? check.checked : undefined; }  The ultimate desperation method would be to use the more flimsy properties of the DOM element, such as previousSibling.innerText || previousSibling.textContent to see what text directly preceded the checkbox (such as \u0026ldquo;Yes\u0026rdquo; in the example from before). However, I won\u0026rsquo;t tell you how to do that here because I don\u0026rsquo;t think it\u0026rsquo;s a very clean or robust method. You\u0026rsquo;ll run into a lot of trouble if you try to latch onto something as frail as text content.\n7. One form element - multiple forms (ASP.NET) Oh man, oh MAN, do I hate working with ASPX pages. Microsoft\u0026rsquo;s technology stack makes it often very frustrating to work with HTML pages, since the dynamically created pages depend largely on the quality of the master page template.\nOften you\u0026rsquo;ll come across a situation where the entire page is wrapped in a FORM element. This is the form wrapper of an ASPX page, and it\u0026rsquo;s used to create the dynamic content you see fully rendered in your browser. However, for GTM this is problematic. If there\u0026rsquo;s more than one form on the page, which is very often the case, you\u0026rsquo;ll find it hard to determine just which form was sent when a submit button is clicked. You see, gtm.formSubmit is fired when the form wrapper is sent, and the submissions could have been initiated from any one of the actual forms on the page. How will you ever know if the submission originated from the site search box, the contact form, or the newsletter subscription field?\n  The workarounds aren\u0026rsquo;t ideal, but they\u0026rsquo;ll have to do for now. At some point I\u0026rsquo;d like to have the option of going through the {{event}} macro\u0026rsquo;s history. Heck, I want to access historical versions of ALL data layer variables! Until then, I\u0026rsquo;ll have to resort to the methods outlined below.\nIdentify correct form using a click listener:\nThis method uses the click listener to identify which submit button was clicked, and then uses this information as a firing / blocking rule in the tag which reacts to the form submission. To help me here, I\u0026rsquo;m using information I collected in my GTM listener firing order test. There I noticed that in the event of race conditions, gtm.click is always activated before gtm.formSubmit.\nIn this example, I have two forms on the page: a site search box with submit button ID siteSearchButton, and a contact form with submit button ID contactSubmitButton.\nFirst, you\u0026rsquo;ll need to create a Custom HTML tag which is set to fire upon {{event}} equals gtm.click. Yes, you\u0026rsquo;ll need an active click listener. Add the following code within:\n\u0026lt;script\u0026gt; dataLayer.push({\u0026#39;clickedButton\u0026#39;: {{element id}}}); \u0026lt;/script\u0026gt; This pushes the ID of the clicked button into the data layer. So if someone does a site search, the pushed value would be siteSearchButton, and if someone sends a contact form, the pushed value would be contactSubmitButton.\nNext, I\u0026rsquo;ll need a Data Layer Variable macro to access this value. So create one:\n  Finally, in your event tag for the site search submission, you\u0026rsquo;ll need the following rule:\n{{event}} equals gtm.formSubmit\n{{Clicked Button ID}} equals siteSearchButton\nConversely, in your event tag for the contact form submission, you\u0026rsquo;ll need a rule like:\n{{event}} equals gtm.formSubmit\n{{Clicked Button ID}} equals contactSubmitButton\nThis works, but I\u0026rsquo;m not sure how reliable it is. There\u0026rsquo;s always the possibility that only the gtm.click tag fires or only the form submission tag fires (due to lag or whatever), but so far I haven\u0026rsquo;t really had trouble with this solution. The major downside is that it\u0026rsquo;s really ugly. You need an intermediate tag to handle your main tag firing, and that really sucks. I\u0026rsquo;d want to operate this whole event taxonomy using just the main tags, without having to resort to \u0026ldquo;helpers\u0026rdquo;.\nIdentify correct form using {{field value}}:\nAnother method I\u0026rsquo;ve used to circumvent the form wrapper problem is to check if a form field has text within. If it does, I can assume that the form that was submitted was the one with the text. I mean, you wouldn\u0026rsquo;t start filling one form, and then jump to another and send that one, would you? WOULD YOU? (Please say no.)\nSo here\u0026rsquo;s a situation where I have two forms on the page (with just one form wrapper). The first form is the site search box, and the search field has an ID of siteSearch. I also have a contact form on the page, and one of its fields requires an e-mail address, and its ID is email.\nI then have a Custom JavaScript macro (named {{submitted form}}) that looks like this:\nfunction() { var search = document.getElementById(\u0026#34;siteSearch\u0026#34;), contactEmail = document.getElementById(\u0026#34;email\u0026#34;); if(search \u0026amp;\u0026amp; search.value != \u0026#34;\u0026#34;) { return \u0026#34;search\u0026#34;; } else if (contactEmail \u0026amp;\u0026amp; contactEmail.value != \u0026#34;\u0026#34;) { return \u0026#34;contact\u0026#34;; } return \u0026#34;\u0026#34;; }  If there\u0026rsquo;s a value in the site search field, this script returns the string \u0026ldquo;search\u0026rdquo;. If there\u0026rsquo;s a value in the e-mail field of the contact form, this script returns the string \u0026ldquo;contact\u0026rdquo;. If neither is found, the script returns an empty string.\nFinally, I can create two rules. This rule fires a tag when the site search field has text:\n{{event}} equals gtm.formSubmit\n{{submitted form}} equals search\nThis rule fires a tag when the contact form e-mail address field has text:\n{{event}} equals gtm.formSubmit\n{{submitted form}} equals contact\nI don\u0026rsquo;t really like this method, since its pretty difficult to keep up-to-date, and there\u0026rsquo;s not a shred of robustness left in the implementation.\nTo conclude, let\u0026rsquo;s just say that for ASPX pages, it\u0026rsquo;s still pretty difficult to get reliable results with GTM\u0026rsquo;s form submit listener. \u0026ldquo;Luckily\u0026rdquo;, whenever I have to work with an ASPX website, the form handlers are the least of my problems.\n8. Conclusions In this post I outlined some advanced ways to use GTM\u0026rsquo;s form submit listener. Value retrieval is something that\u0026rsquo;s been asked around a lot, so I focused mainly on that aspect of data collection.\nI didn\u0026rsquo;t wander into the murky woods of custom submit handlers, jQuery validators, event propagation problems and such, because these problems are usually pretty restricted to a certain script, implementation, or page. Suffice to say, if you do use custom submit handlers, for example, you\u0026rsquo;ll probably have to get your developers to edit these scripts so that the form submit event has a chance to reach GTM\u0026rsquo;s listeners (see my post on event delegation problems).\nSometimes the form on your page isn\u0026rsquo;t a form at all (in its HTML sense), and it\u0026rsquo;s been created entirely with some JavaScript framework (or, gasp, Flash). In these situations, just having the form submit listener won\u0026rsquo;t work, because no actual submit event is every fired. In these cases you might have to talk to your developers about manually creating the gtm.formSubmit event push. For information on how to do this, check out Doug Hall\u0026rsquo;s excellent post on extending GTM\u0026rsquo;s auto-event tracking.\nDid you miss something in this post? Is there some aspect of form tracking that you\u0026rsquo;d want more information on? Drop me a line in the comments, and let\u0026rsquo;s see what we can come up with!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/macro-magic-google-tag-manager/",
	"title": "Macro Magic For Google Tag Manager",
	"tags": ["Google Tag Manager", "macros"],
	"description": "A bunch of Google Tag Manager macros that you might find useful when working with GTM.",
	"content": " (Last updated June 2014) This post is an attempt at a whole new level of interaction. These words will transcend the barriers of time and space, bridging together the physical world and its digital counterpart. You see, in an undisclosed number of hours after the publishing of this blog post, I will be talking at the MeasureCamp unconference on this very subject. Or, I hope I will. The whole unconference thing is somewhat confusing, and it involves lighting-fast reflexes and street smarts for slot selection; traits which I sadly lack.\n  However, if you DO see me speak at MeasureCamp, this post is meant as a companion to that talk. And if you do not (or did not, this transcendental approach is really confusing), perhaps this post will inspire you with some ideas for your own day-to-day Google Tag Manager use.\nIn this post, my fair friends, I\u0026rsquo;ve outlined a number of cool ways in which you can use macros to make your data collection woes a thing of the past. If you don\u0026rsquo;t know what macros are or how they operate, be sure to check my macro guide. Almost all of my Google Tag Manager posts in this blog revolve around macros in one way or another, so while you\u0026rsquo;re at it, check out some of my other GTM articles as well. And sorry for this shameless self-promotion, I can\u0026rsquo;t help it.\nIntroducing Macro Magic   So what is Macro Magic? Well, to put it simply, it\u0026rsquo;s what follows when you accept that macros, not tags, are what make GTM the time- and effort-saver that it is. Sometimes macros make your tag setups a lot sleeker and leaner, since the flexibility that they introduce to tags greatly reduces the need to capture every single variation of tracking in its own, unique tag. Sometimes they open doors to data collection methods you didn\u0026rsquo;t think were possible with traditional, on-page tracking. And sometimes they\u0026rsquo;re just little helper functions, which make operating GTM so much easier.\nThe examples below fall into these categories nicely, and I\u0026rsquo;m sure there\u0026rsquo;s something for everyone.\nBy the way, I am really, really looking forward to a Google Tag Manager which is accompanied by a resource library similar to Google Analytics\u0026rsquo; solution gallery. Just imagine how cool it would be to have a library of tags and macros you can just download and insert into your container? Well, as long as it\u0026rsquo;s just a utopian dream of mine, posts like this will probably be in demand.\nNote that not all of these are my own inventions. It would be ridiculous to claim intellectual property for some of the macros, but where prudent, I\u0026rsquo;ve added a link to the source of the macro. If you feel like I\u0026rsquo;ve stolen your ideas, please let me know and I\u0026rsquo;ll see if I can pass credit where it is due.\n1. Client time Macro Type: Custom JavaScript\nUse for: To get local time of client as opposed to the the time of the web server hosting the site.\nExample return value: 11\nInstructions and description:\n Create new Custom JavaScript Macro\n Add the following code:\n  function() { var now = new Date(); return now.getHours(); }  Well it\u0026rsquo;s easy to credit where I got the idea for this one. Google uses a version of this as an example of the Custom JavaScript Macro:\n  The idea behind this macro is that it returns the time (hours) of the client as opposed to the time of the website (i.e. server), which is what\u0026rsquo;s measured by default.\nSo if you\u0026rsquo;re interested in what the local time (in hours) is of the visitor, use this macro and store it as a custom dimension, for example.\n2. Random number for sampling Macro Type: Random Number\nUse for: To fire a tag only for every 10th visitor, for example\nExample return value: 647156\nInstructions and description:\n Create Random Number Macro  OK, so the macro isn\u0026rsquo;t difficult at all to create, nor is it anything magical (YET!). But this is a beautiful scenario for something as simple as the Random Number macro (which, I\u0026rsquo;m sure, is often very neglected). This idea comes directly from Dan Russell, and you can read about this in his original blog post\nSampling a percentage of your users with Google Tag Manager.\nThe sweetness is not in the macro but in the rule which you\u0026rsquo;ll use to fire your tags. If you want to fire a tag for every 10th visitor, you\u0026rsquo;d add a rule with the following condition:\n{{Random Number Macro}} ends with 3\nIf you want to fire a tag for every 100th visitor, you\u0026rsquo;d edit the rule so that it\u0026rsquo;s:\n{{Random Number Macro}} ends with 01\nIt\u0026rsquo;s so simple and beautiful. Because the Random Number macro returns a random number, you can assume that there\u0026rsquo;s roughly a 1\u0026frasl;10 chance that the number will end in 3, and roughly a 1\u0026frasl;100 chance that it will end in 01.\nHow\u0026rsquo;s that for pre-sampling your data before Google Analytics gets to work on it with its brutal thresholds?\n3. Return file extension of clicked link Macro Type: Custom JavaScript\nOther requirements: Macro for Auto-Event Variable of type Element (named {{element}} in this example)\nUse for: Rules, event fields\nExample return value: pdf\nInstructions and description:\n Create Custom JavaScript Macro\n Add following code:\n  function() { var ext = {{element}}.pathname.split(\u0026#34;.\u0026#34;); return ext.length \u0026gt; 1?ext.pop():\u0026#39;html\u0026#39;; }  This macro came from Stéphane Hamel, in another inspiring, \u0026ldquo;crowd-sourced\u0026rdquo; Google+ discussion. The idea is that when a Link Click Listener is activated, this macro will return the file extension of the clicked link, and if one doesn\u0026rsquo;t exist, it returns just html. So if the link was to http://www.mydomain.com/brochure.pdf, this macro will return pdf.\nYou can use this in your tags either as a rule or as a value for a specific field. For example, here\u0026rsquo;s an event tag which sends the extension of the clicked link as one of the parameters:\n  If the link were to http://www.mydomain.com/brochure.pdf, this tag would fire with:\nEvent Category \u0026ldquo;pdf link click\u0026rdquo;\nEvent Action \u0026ldquo;brochure.pdf\u0026rdquo; (more on this in the next chapter)\nEvent Label \u0026ldquo;url of page where brochure.pdf was downloaded from\u0026ldquo;\n4. Return file name of clicked link Macro Type: Custom JavaScript Other requirements: Macro for Auto-Event Variable of type Element (named {{element}} in this example)\nUse for: Event fields\nExample return value: brochure.pdf\nInstructions and description:\n Create Custom JavaScript Macro\n Add following code:\n  function() { var filepath = {{element}}.pathname.split(\u0026#34;/\u0026#34;); var filename = filepath.pop(); return filename.indexOf(\u0026#34;.\u0026#34;) \u0026gt; -1?filename:\u0026#39;n/a\u0026#39;; }  This macro is very similar to the previous one, except now it returns the whole file name. If the downloaded link is not an asset with a file extension, the script returns the ambiguous \u0026ldquo;n/a\u0026rdquo; string, which can be used in blocking rules, for example.\nUse this macro to make your link click event tags more dynamic. In the best case scenario, you\u0026rsquo;ll just need one event tag for all your link clicks, because variable value macros like this are what make your tags the dynamic vessels they should be.\n5. Check if clicked link is internal Macro Type: Custom JavaScript\nOther requirements: Macro for Auto-Event Variable of type Element URL (named {{element url}} in this example), macro for URL of type URL Hostname (named {{url hostname}} in this example)\nUse for: Firing rules\nExample return value: true\nInstructions and description:\n Create Custom JavaScript macro\n Add following code within:\n  function() { return {{element url}}.indexOf({{url hostname}}) \u0026gt; -1; }  This returns true if the clicked element URL contains the hostname of the current page, and false, if the clicked element URL contains some other hostname.\nYou can use this in your firing rules, e.g. fire an \u0026ldquo;Outbound link\u0026rdquo; event only when the clicked link is not internal:\n  6. Get clientID using _ga cookie Macro Type: 1st Party Cookie, Custom JavaScript\nOther requirements: Universal Analytics property\nUse for: Offline measurement, stitching client data\nExample return value: 475226310.1380715146\nInstructions and description:\n Create 1st Party Cookie macro\n Set cookie name to _ga\n Create Custom JavaScript macro\n Add following code within:\n  function() { try { var cookie = {{ga cookie}}.split(\u0026#34;.\u0026#34;); return cookie[2] + \u0026#34;.\u0026#34; + cookie[3]; } catch(e) { console.log(\u0026#34;No Universal Analytics cookie found\u0026#34;); } }  First you create a new 1st Party Cookie macro, which returns the value of the _ga cookie. It might be something like GA1.2.475226310.1380715146. Next, the Custom JavaScript macro parses this string, and returns the third (client ID) and fourth (timestamp) elements of the cookie value (475226310.1380715146), which combine to make the complete clientID of the user.\nYou can then add this as a session-level custom dimension, for example, to identify which clientID committed to what actions on your site during their session. You could then use the Measurement Protocol to work all sorts of offline-online data stitching magic with your database tools!\nNote that I use a very rudimentary try-catch block for error handling. Feel free to handle errors in any way you want (as long as you do handle them!).\n7. Get clientID using ga.getAll() Macro Type: Custom JavaScript\nOther requirements: Universal Analytics property\nUse for: Offline measurement, stitching client data\nExample return value: 475226310.1380715146\nInstructions and description:\n Create Custom JavaScript macro\n Add following code within:\n  function() { try { var tracker = ga.getAll()[0]; return tracker.get(\u0026#39;clientId\u0026#39;); } catch(e) { console.log(\u0026#34;Error fetching clientId\u0026#34;); } }  This is Google\u0026rsquo;s recommendation for fetching the client ID (rather than parsing the cookie). You basically access the ga object using the function getAll(). This would normally retrieve all named trackers, but you\u0026rsquo;re only interested in the first one (which is the one GTM sets). Finally, it uses the get method of the tracker object to retrieve the value of the property clientId, which is, coincidentally, the clientId.\nNOTE! This macro will not work if it fires before a page view is sent. The tracker is created during the page view call, so you\u0026rsquo;ll either have to use a callback function (see the next section) or have the tag which fetches the client ID fire upon {{event}} equals gtm.load.\n8. hitCallback with a Universal Analytics tag Macro Type: Custom JavaScript\nUse for: Imposing a tag firing order\nInstructions and description:\n Create Custom JavaScript macro\n Add following code within:\n  function() { return function(){dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;pageViewFired\u0026#39;});} }  The Universal Analytics tag doesn\u0026rsquo;t have a callback field that you can use (yet). So you\u0026rsquo;ll have to resort to the \u0026ldquo;Fields to set\u0026rdquo; option, and add the callback function manually.\nAnyway, the idea with hitCallback is to do something as soon as the tag has fired. In my example, I push an event called \u0026lsquo;pageViewFired\u0026rsquo;, which I can then use in some other tag to make sure it fires only after the page view has been sent. You\u0026rsquo;d need to add the macro to your tag like this:\n  The field to set is called hitCallback and its value should be the macro you just created.\nIf you look at the code, you\u0026rsquo;ll see a funny thing. You\u0026rsquo;re returning the function which does all the work. Why, you wonder? Simple. When the event tag is fired, it will go through all the fields that have been set for the tag, performing all the actions within. If you didn\u0026rsquo;t have the function returning another function, the callback would fire twice: first when the event tag\u0026rsquo;s firing begins, and again when the tag has completed (when the callback function is actually called).\nThis might be a bit difficult to fathom, but it\u0026rsquo;s just how GTM and JavaScript work. hitCallback is expecting a function, so the function in your callback tag has to return a function, because macros need to always return something.\nMessy. But it works!\n9. Return URL path + query string Macro Type: Custom JavaScript\nUse for: Working with the query string\nExample return value: /analytics/?internal=true\nInstructions and description:\n Create Custom JavaScript macro\n Add following code within:\n  function() { return location.pathname+location.search; }  This is a very simple macro. There\u0026rsquo;s no predefined macro for you to use if you want to return the url pathname with query parameters. This macro does just that.\n10. Property ID lookup with hostname Macro Type: Lookup Table\nOther requirements: Macro for URL of type URL Hostname (named {{url hostname}} in this example)\nUse for: To have the same tracking tag for different property IDs on different domains\nExample return value: UA-12345-1\nInstructions and description:\n Create a Lookup Table macro\n Add some tracking code as the Default Value (optional)\n In the first column, choose {{url hostname}} as the macro that is evaluated\n In the first column, add all the different hostnames you want to assign a property ID to\n In the second column, add the respective property ID for each hostname\n  This is a very useful macro if you have multiple domains with different property IDs tracked by the same container. Whenever you have the same tags running on all the different domains, using a lookup like this means you don\u0026rsquo;t have to create a separate tag for each ID.\nThe macro should look like this:\n  This macro will return the correct property ID depending on which domain the user is browsing on.\n11. Track debug hits to different property ID Macro Type: Lookup Table, Debug Mode\nUse for: When using GTM\u0026rsquo;s debug mode, track your hits to a different property ID (e.g. test account)\nExample return value: UA-12345-1\nInstructions and description:\n Create a Debug Mode macro (named {{debug mode}} in this example)\n Create a Lookup Table macro\n Add some tracking code as the Default Value (optional)\n In the first column, choose {{debug mode}} as the macro that is evaluated\n In the first column, add rows for true and false\n In the second column, add the respective property ID for when debug mode is true and when it is false\n  This is very similar to the previous macro, but it uses the Debug Mode macro as well. Sometimes you\u0026rsquo;ll notice yourself doing so much debug work that you\u0026rsquo;ll want to track these hits on a different account altogether. This is a really simple way to do it.\n  The Debug Mode macro returns \u0026ldquo;true\u0026rdquo; if debug mode is on, and \u0026ldquo;false\u0026rdquo; if it\u0026rsquo;s off. Use these values to assign a different property ID as the return value of the Lookup Table macro.\n12. Get title attribute of document Macro Type: JavaScript Variable\nUse for: Retrieving and using the document title attribute\nExample return value: Macro Magic For Google Tag Manager - Simo Ahava\u0026rsquo;s Blog\nInstructions and description:\n Create JavaScript Variable macro\n Set field Global Variable Name to document.title\n  This macro retrieves the HTML title attribute of your document. A great use case for this is if you want to process tags on a 404 page differently. You\u0026rsquo;d then create a rule like this:\n  Another use case could be for content grouping. Use the title macro to group your content logically in your tags.\n13. Check if browser has cookies enabled Macro Type: JavaScript Variable\nUse for: Checking if user has cookies enabled, filter some bot traffic\nExample return value: true\nInstructions and description:\n Create JavaScript Variable macro\n Set field Global Variable Name to navigator.cookieEnabled\n  The navigator.cookieEnabled property returns a boolean value (true/false) determined by whether or not the browser allows websites to write cookies. You can use this in your rules to make sure tags only fire for browsers with cookies, or to filter non-cookie data to a different view.\nYou could also use this to block tags from firing for search engine bots, since there\u0026rsquo;s some consensus that a majority of them do not accept or use cookies (see this test for Googlebot from February 2013).\n14. A bunch of useful Auto-Event Variable extensions Macro Type: Data Layer Variable Use for: Making the most of auto-event tracking\nHere\u0026rsquo;s a list of extensions for your auto-event tracking. By creating Data Layer Variable macros, you can use them in your rules to make your event tracking and whatnot even more detailed. In the \u0026ldquo;What it does\u0026rdquo; sections, the element refers always to the element which was clicked / submitted and thus stored in dataLayer as gtm.element.\nData Layer Variable Name: gtm.element.nodeName\nExample return value: IMG\nWhat it does: Returns the tag name of the element (well, strictly node name but in most cases it\u0026rsquo;s the same thing)\nData Layer Variable Name: gtm.element.value\nExample return value: Simo Ahava\nWhat it does: Returns the value of the element. This is useful if you\u0026rsquo;re tracking input elements on your forms (with e.g. blur, focus, or change), and you want to send an event every time a form field has been filled.\nData Layer Variable Name: gtm.element.hash\nExample return value: #chapter1\nWhat it does: Returns the hash (if any) of the element href. So if the link was to /this-page/?internal=true#chapter1, gtm.element.hash would return #chapter1\nData Layer Variable Name: gtm.element.pathname\nExample return value: /this-page/\nWhat it does: Returns the path in the element href. If the link was to /this-page/?internal=true#chapter1, gtm.element.pathname would return /this-page/\nData Layer Variable Name: gtm.element.search\nExample return value: ?internal=true\nWhat it does: Returns the full query string of the element. If the link was to /this-page/?internal=true#chapter1, gtm.element.search would return ?internal=true\nData Layer Variable Name: gtm.element.parentElement\nExample return value: (object), extend further with some property of the parent element\nWhat it does: Returns the direct parent of the element, and you should extend this macro further to access its properties (e.g. gtm.element.parentElement.id returns the value stored in the ID attribute of the parent tag)\nData Layer Variable Name: gtm.element.firstChild\nExample return value: (object), extend further with some property of the child element\nWhat it does: Returns the first direct descendant of the element, and you should extend this macro further to access its properties (e.g. gtm.element.firstChild.className returns value stored in the CLASS attribute of the child tag)\nData Layer Variable Name: gtm.element.nextSibling\nExample return value: (object), extend further with some property of the sibling element\nWhat it does: Returns the next element in the DOM tree which is on the same hierarchical level as the element, and you should extend this macro further to access its properties (e.g. gtm.element.nextSibling.nodeName returns the tag name of the sibling tag)\nSo here\u0026rsquo;s a bunch of extensions for you to play with. There\u0026rsquo;s still a huge amount of stuff out there you can try, especially with forms, so I suggest that you set up a click listener on your site and play around with the DOM.\n15. Detect mobile browser Macro Type: Custom JavaScript\nUse for: Mobile-specific tracking\nExample return value: true\nInstructions and description:\n Create Custom JavaScript macro\n Copy-paste the code from the attached TXT file\n  I had to add the code in an attachment, because it\u0026rsquo;s such a long and ugly piece of RegEx that it makes my eyes water. Sorry about that.\n  It\u0026rsquo;s dirty, I know. This script checks the browser user agent string and returns true if it matches a mobile device user agent. If it doesn\u0026rsquo;t, the script returns false.\nThis script is provided by (with slight modifications to fit GTM infrastructure) detectmobilebrowsers.com.\nConclusions There\u0026rsquo;s so much you can do with macros. I truly believe that the goal of all GTM implementations should be to achieve the elusive compromise between complexity and eye candy. It\u0026rsquo;s important to keep a clean house when tag management is concerned, especially since Google Tag Manager doesn\u0026rsquo;t, as of yet, provide us with too much to work with in terms of taxonomies, hierarchies and categories.\nI wasn\u0026rsquo;t kidding when I wrote in the beginning how I really want to see a solution gallery for GTM. I appreciate the fact that it will make posts like this obsolete (unless you enjoy my banter or the educational twist I hopefully succeed in conveying). Nevertheless, being able to share, store, and search for the amazing tags and macros that our vibrant community has produced would be the best thing since sliced bread.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/container-snippet-gtm-secrets-revealed/",
	"title": "The Container Snippet: GTM Secrets Revealed",
	"tags": ["container snippet", "Google Tag Manager", "JavaScript"],
	"description": "Deciphering the Google Tag Manager JavaScript container snippet. This guide will show you row-by-row what the container snippet does.",
	"content": " First of all, I\u0026rsquo;m sorry for the wacky title. Sometimes I just want to amuse myself. Nevertheless, this post is about the Google Tag Manager container snippet. There\u0026rsquo;s nothing secretive about it, but I\u0026rsquo;m betting many people have no clue what the snippet really does. That\u0026rsquo;s the revelatory part.\nIf you\u0026rsquo;ve never wondered what the snippet does, then shame on you! Remember, you own your page template. It\u0026rsquo;s yours. Any code that you write there is your responsibility. You wouldn\u0026rsquo;t let a complete stranger come to your house and paint your walls without permission, would you? So why copy-paste some code that you have no idea what it does? Because Google told you to?\n  Well, you can trust Google (stop laughing!). There\u0026rsquo;s nothing nefarious about the container snippet. Regardless, I wrote this post to tell you what it does, so that you can sleep better at night. Or you might learn something new about JavaScript (never a bad thing).\nNote that this text should be understandable to JavaScript novices as well, but if you feel daunted at any time, you can just skip ahead to the last chapter. Within is a short recap of what the container snippet does.\nSo sit back (but lean forward), and enjoy another one of life\u0026rsquo;s great mysteries unravelled.\nThe container snippet You should know what the container snippet is by now. It\u0026rsquo;s the piece of code that Google Tag Manager requires that you add to your page template, right after the opening \u0026lt;body\u0026gt; tag. You know, this (from my site):\n  (I left out the \u0026lt;noscript\u0026gt; part, because this post is just about the JavaScript snippet.)\nLet\u0026rsquo;s face it, the snippet code looks gibberish. This is because the JavaScript (that\u0026rsquo;s right, it\u0026rsquo;s JavaScript) is minified. Minification is the process of truncating the script to the smallest possible size without losing any data. This means removing whitespace (spaces and line breaks), and reducing variable and function names to single- or double-character length. Minification is done because every single character adds to the page size, and thus to the page load time. The benefit with something as small as the container snippet is negligible, but it is still observed as a best practice.\nBecause I want this post to add some value, allow me to perform a little makeover to the snippet.\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; (function (w, d, s, l, i) { w[l] = w[l] || []; w[l].push({ \u0026#39;gtm.start\u0026#39;: new Date().getTime(), event: \u0026#39;gtm.js\u0026#39; }); var f = d.getElementsByTagName(s)[0], j = d.createElement(s), dl = l != \u0026#39;dataLayer\u0026#39; ? \u0026#39;\u0026amp;l=\u0026#39; + l : \u0026#39;\u0026#39;; j.async = true; j.src = \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39; + i + dl; f.parentNode.insertBefore(j, f); })(window, document, \u0026#39;script\u0026#39;, \u0026#39;dataLayer\u0026#39;, \u0026#39;GTM-P8XR\u0026#39;); \u0026lt;/script\u0026gt; That\u0026rsquo;s better! It\u0026rsquo;s the same code but with some basic formatting. Much easier to read and understand, right?\nPositioning the container snippet You might have wondered why Google so forcefully recommends that you place the container snippet just after the opening \u0026lt;body\u0026gt; tag. There are two good reasons to do so.\nFirst, if you add the \u0026lt;noscript/\u0026gt; tag as well (as you should), this should always be in the body of the document. The tag (which is shown for browsers without JavaScript enabled) contains an iFrame which loads the GTM library. If you add the \u0026lt;noscript/\u0026gt; tag into the head of your document, it can perform pretty wildly with some browsers. You could experiment with leaving the \u0026lt;noscript/\u0026gt; in the body, and placing the JavaScript in the , but I haven\u0026rsquo;t tested it and certainly don\u0026rsquo;t recommend it.\nThe second reason is simple: to maximize data collection, the snippet should be the first thing loaded when the body of the page is rendered. Because the library is loaded asynchronously, there\u0026rsquo;s no reason to delay it at all. So have it load as the first thing when the body is rendered, so that you don\u0026rsquo;t risk losing any data due to sluggish DOM elements delaying the page load.\nLines 2 and 15 We can skip lines 1 and 16, since they\u0026rsquo;re just the HTML SCRIPT tag, wrapping the JavaScript block.\n(function (w, d, s, l, i) { ... })(window, document, \u0026#39;script\u0026#39;, \u0026#39;dataLayer\u0026#39;, \u0026#39;GTM-P8XR\u0026#39;);  To understand the first line, we have to look at the last line as well. This is an example of a self-invoking / self-executing anonymous function, or immediately-invoked function expression. There\u0026rsquo;s some debate on the semantics of which term you should choose, but for this purpose it\u0026rsquo;s just that: semantics.\nBasically, line 2 of the snippet declares an anonymous function (it has no name) with five parameters. These parameters are served via the function call at the end of the function block, which has, as it should, five arguments.\nThe whole idea behind an immediately-invoked function expression is to call the function as soon as it has been declared. That\u0026rsquo;s what lines 2 and 15 of the snippet are about. Line 2 declares a function which is called in line 15, as soon as the function code has been parsed by your browser.\nThe arguments that are sent with the function call, and turned into parameters in the declaration (the parameters are in parentheses), are as follows:\n window (w) - the window object represents the open window in the user\u0026rsquo;s browser and everything in it (the document object model, or DOM, for example)\n document (d) - the document object is the top node in the DOM tree; it contains the entire HTML document\n \u0026lsquo;script\u0026rsquo; (s) - this string is used to load the gtm.js library (more on this later)\n \u0026lsquo;dataLayer\u0026rsquo; (l) - this string is used to give a name to the dataLayer object; you can rename the object used by GTM by changing this value\n \u0026lsquo;GTM-P8XR\u0026rsquo; (i) - this is your container ID, which you\u0026rsquo;ll get from Google Tag Manager\n  Line 3 w[l] = w[l] || [];  If you remember what the parameters and arguments were, this line translates to:\nwindow[\u0026#39;dataLayer\u0026#39;] = window[\u0026#39;dataLayer\u0026#39;] || [];  Here, the function looks for an object named dataLayer (or something else if you renamed it in the function arguments) in the window object, which contains all the objects on the page. If it finds one, it leaves it be. If it doesn\u0026rsquo;t find one, it declares it as an empty array.\nThis is important, because sometimes you\u0026rsquo;ll see this explicit declaration of the dataLayer object in the page template before the container snippet:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; dataLayer = []; \u0026lt;/script\u0026gt; Explicit declaration of dataLayer is useful if you need some dataLayer variables to be available at the earliest possible moment in your GTM tags. For example, if your page view tag requires some dataLayer variable to exist (for a custom dimension, perhaps), it\u0026rsquo;s better to declare it in the page template before the container snippet:\n\u0026lt;script\u0026gt; dataLayer = [{\u0026#39;author\u0026#39;: \u0026#39;Simo Ahava\u0026#39;}]; \u0026lt;/script\u0026gt; This explicit declaration is what the code on line 3 of the container snippet is looking for. If the explicit declaration is found, it is left as it is. If it hasn\u0026rsquo;t been declared, the container snippet creates the dataLayer object for you.\nThis brings me to an important point.\nIf you do not declare the dataLayer object explicitly, do NOT declare it in your GTM tags or after the container snippet. The container creates the dataLayer array for you, and if you try to declare it later on, you\u0026rsquo;ll end up erasing the original dataLayer, created and used by GTM. After dataLayer has been created, your only interaction with it should be by using the push() method of the array (dataLayer.push({\u0026lsquo;property\u0026rsquo;: \u0026lsquo;value\u0026rsquo;});).\nLines 4 through 7 w[l].push({ \u0026#39;gtm.start\u0026#39;: new Date().getTime(), event: \u0026#39;gtm.js\u0026#39; });  This is a very important part of the container snippet functionality.\nWhen the code reaches this point, a dataLayer.push() call is done. Within the curly brackets is an object literal. Object literals are JavaScript objects, which contain any number of key-value (or property-value or variable-value) pairs, often in JSON (JavaScript Object Notation). These objects are wrapped in curly brackets, and pushed to the end of the dataLayer array.\nIf most of the previous paragraph is gibberish to you, I don\u0026rsquo;t blame you.\nTo put it simply, with a dataLayer.push(), you\u0026rsquo;re pushing an object with properties to the end of the dataLayer queue. These properties can then be accessed in GTM.\nThis first push, on lines 4 through 7 of the container snippet, contains an object with the following properties:\n Key 1: \u0026lsquo;gtm.start\u0026rsquo; - Value 1: New Date.getTime()\n Key 2: event - Value 2: \u0026lsquo;gtm.js\u0026rsquo;\n  So if you\u0026rsquo;ve ever wondered when tags with {{event}} equals gtm.js or {{url}} matches regex .* get fired, it\u0026rsquo;s at this point.\nThe gtm.start property receives the current time (in milliseconds since Jan 1, 1970) as its value. Brian Kuhn of Google explained that this is used for calculating gtm.js load time and the cache hit rate of the request, so don\u0026rsquo;t worry about it.\nLines 8 through 10 var f = d.getElementsByTagName(s)[0], j = d.createElement(s), dl = l != \u0026#39;dataLayer\u0026#39; ? \u0026#39;\u0026amp;ampamp;l=\u0026#39; + l : \u0026#39;\u0026#39;;  Let\u0026rsquo;s open this up again, using the parameters and arguments we\u0026rsquo;re already familiar with:\nvar f = document.getElementsByTagName(\u0026#39;script\u0026#39;)[0], j = document.createElement(\u0026#39;script\u0026#39;), dl = \u0026#39;dataLayer\u0026#39; != \u0026#39;dataLayer\u0026#39; ? \u0026#39;\u0026amp;ampamp;l=\u0026#39; + \u0026#39;newDataLayer\u0026#39; : \u0026#39;\u0026#39;;  The first line stores the first SCRIPT element on the page in variable f.\nThe second line creates a new SCRIPT element, and stores it in variable j.\nThe third line does one of two possible things. If you haven\u0026rsquo;t touched the default name of the dataLayer object (i.e. \u0026lsquo;dataLayer\u0026rsquo;), just an empty string is stored in variable dl. However, if you\u0026rsquo;ve chosen to rename the dataLayer (e.g. \u0026lsquo;newDataLayer\u0026rsquo;), the string \u0026lsquo;\u0026ampamp;l=newDataLayer\u0026rsquo; is stored in variable dl. \u0026ampamp; is the same as the ampersand (\u0026amp;), but it has been encoded because some platforms can\u0026rsquo;t process non-encoded ASCII characters.\nThese variables will be used in the next lines.\nLines 11 through 13 j.async = true; j.src = \u0026#39;//www.googletagmanager.com/gtm.js?id=\u0026#39; + i + dl;  And let\u0026rsquo;s beautify this one as well:\nj.async = true; j.src = \u0026#39;//www.googletagmanager.com/gtm.js?id=GTM-P8XR\u0026#39;;  Remember, in the last chapter you just created a new SCRIPT element and stored it in variable j? In these lines you add some attributes to it. The container ID is retrieved from function parameter i, and it was originally passed as an argument in the self-invoking function call (you remember this!). Go look if you don\u0026rsquo;t believe me.\nNote that the last line might look different if you chose to rename your dataLayer. In that case, it would actually be the equivalent of this:\nj.src = \u0026#39;//www.googletagmanager.com/gtm.js?id=GTM-P8XR\u0026amp;l=newDataLayer\u0026#39;;  This means that if you renamed your dataLayer object, this new name is passed as the value of query parameter l with the request to load the gtm.js library from GTM servers.\nAnyway, the whole point of these lines is to make the SCRIPT element you stored into variable j look something like this:\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34; async src=\u0026#34;//www.googletagmanager.com/gtm.js?id=GTM-P8XR\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; So basically you\u0026rsquo;ve just created a SCRIPT tag which loads the external gtm.js library with your container ID (and your renamed dataLayer, if you did so) as query parameters.\nLine 14 f.parentNode.insertBefore(j, f);  Remember a few chapters back when variable f was defined as the first SCRIPT tag of the document? This line does the following:\n Look for the first SCRIPT tag on the page\n Just before that, insert the new SCRIPT tag which loads gtm.js (from the previous chapter)\n  So the code on line 14 of the container snippet makes sure that the GTM loader is the first SCRIPT tag on the page.\nAnd there you go! Read ahead for a short summary of what just happened.\nConclusions Here\u0026rsquo;s a short recap of what the container snippet does:\n Declares an anonymous function with five parameters (the name of the dataLayer object and your container ID, among others)\n Creates the dataLayer array, if you didn\u0026rsquo;t do so explicitly before the container snippet\n Pushes the first event, gtm.js, into dataLayer, along with the time the push was done\n Creates a new SCRIPT tag, which loads the external gtm.js JavaScript library with your container ID (and custom dataLayer object name) as parameters\n Adds this new SCRIPT to the page template, so that it\u0026rsquo;s the first SCRIPT tag on the page\n After the function is declared, the function is automatically executed\n  In the end, it\u0026rsquo;s a pretty simple piece of code. All it actually does is create (or verify) the dataLayer object, push the first event (named \u0026lsquo;gtm.js\u0026rsquo;) into dataLayer, and load the external gtm.js library which processes your container.\nAnd that\u0026rsquo;s the story of the container snippet.\nNext up: reverse engineering the entire gtm.js library (JUST KIDDING!).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/block-internal-traffic-gtm/",
	"title": "Block Internal Traffic With Google Tag Manager",
	"tags": ["api", "custom html", "Google Tag Manager", "internal traffic", "ip", "macros"],
	"description": "Guide and tips for how to block internal traffic from Google Analytics using Google Tag Manager.",
	"content": " You\u0026rsquo;ve probably come across a number of guides or posts talking about why it\u0026rsquo;s necessary to block so-called internal traffic from your web analytics reports. The reasons are pretty solid: internal traffic does not emulate normal visitor behavior, it rarely contributes to conversions (skewing up your conversion rate), it inflates page views, and it wreaks havoc on your granular, page-by-page data.\nInternal traffic is vaguely described as \u0026ldquo;your employees\u0026rdquo;, \u0026ldquo;people really close to your brand\u0026rdquo;, \u0026ldquo;your marketing department\u0026rdquo;, \u0026ldquo;your web editors\u0026rdquo;, and so on. Basically, it should be a term which covers traffic that does not adequately represent trending visitor behavior on your site. Most often, this is \u0026ldquo;internal\u0026rdquo;, in that it is traffic by people who generate the content. It can also be your proof-readers (wives, husbands, best friends), beta testers (wives, husbands, best friends), outreach marketers (wives, husb\u0026hellip; you get my drift).\nIn this post, I\u0026rsquo;ll introduce two methods to annotate this kind of internal traffic using (mostly) Google Tag Manager. The underlying premise is that your internal traffic comes from such a diverse number of sources that it\u0026rsquo;s impossible to filter it using Google Analytics\u0026rsquo; own filters. Another possibility is that you\u0026rsquo;ve decided to anonymize IP data sent to Google Analytics servers, which means that even if you\u0026rsquo;d just have a certain range of IPs, you couldn\u0026rsquo;t use Google Analytics\u0026rsquo; filters, since the last octet has been censored (more about this later).\nBy the way, I use the term annotate instead of block (except in the search engine friendly title, GUILTY!), because whether or not you actually want to block the data or just segment it is up to you. You could also follow Lunametrics\u0026rsquo; excellent guide on preventing the data from being sent to Google Analytics in the first place, but I wanted to follow a more reconciliatory route, offering a way for you to still incorporate internal traffic in your reports, if you so choose. And this route is, of course, a custom dimension.\nThe premise I will introduce two methods: 1) Visit to URL, and 2) IP extraction. Both have their pros and cons.\nIf the people you want included in your internal traffic are constantly on the move, use a variety of devices on the road, or are hard to pin down just by using an IP address range, you should use the first method. This way you\u0026rsquo;ll also leave these people an out. You see, sometimes your employees are also your customers or normal site visitors, which means that their behavior should be included in your actual traffic reports.\nIP extraction requires that you have specific IP address ranges in mind which you want to block. This is best for traffic which originates from stationary places, like office buildings or office networks.\nWhichever you choose, you\u0026rsquo;ll need to set up a custom dimension first, which will store your data. It\u0026rsquo;s really simple, and Google has a great guide on how to get started.\nIf you want to provide your internal traffic an out, you should create a session-scope custom dimension. This way internal traffic is annotated separately from one session to the next.\n  If, however, you want the annotation to stick \u0026ldquo;for life\u0026rdquo;, you should create a user-scope custom dimension (user is the same as device). This way the annotation will persist from session to session, even if the IP extraction fails or the user doesn\u0026rsquo;t visit your designated \u0026ldquo;internal traffic\u0026rdquo; URL.\nMethod 1: Visit to URL I really like this method, since it\u0026rsquo;s completely client-side, it doesn\u0026rsquo;t require any custom functions or external API calls to retrieve the IP address, and it provides an out for your employees or users, if they wish to be treated as external traffic.\nOne thing that it does require, however, is that your internal traffic remembers to use the URL every single time they visit your site (unless they don\u0026rsquo;t want to be treated separately). Since you\u0026rsquo;re using a session-scope dimension here, it\u0026rsquo;s ok if the internal traffic URL is not the landing page of the visit. A session-scope custom dimension hit is applied retroactively to all hits in the session, so as long as the custom dimension is sent with a single hit during the session, it will suffice to annotate all hits in the session.\nI prefer to use a URL query parameter as the trigger that tags the visitor as internal traffic. This means that:\n You need to make sure that your server accepts query parameters in URL addresses\n You should canonicalize all pages to the parameter-less version, so that search engines won\u0026rsquo;t index your internal traffic page by accident (use \u0026lt;link rel=\u0026quot;canonical\u0026quot; href=\u0026quot;http://url-of-page-without-query-parameters\u0026quot;/\u0026gt;)\n You should configure your Google Analytics view so that this query parameter is stripped from reports (because it doesn\u0026rsquo;t add any value content-wise)\n  For this example, I\u0026rsquo;ve chosen the query internal=true as the trigger. So if you navigate to the homepage, you\u0026rsquo;d need to use http://www.mydomain.com/?internal=true to be tagged as internal traffic.\nHere\u0026rsquo;s how you use the query parameter as a custom dimension in your tags.\n Create a new macro (Macro Name: Internal URL, Macro Type: URL, Component Type: Query)\n In the field Query Key, add internal\n    When called, this macro looks at your URL, tries to find the query parameter \u0026ldquo;internal\u0026rdquo;, and if it does, it returns its value (\u0026ldquo;true\u0026rdquo;). If no parameter is found, it returns an undefined which suits us just fine.\nNext, you\u0026rsquo;ll need to send this along with your page view tag.\n Open your page tracking tag\n Go to More Settings \u0026gt;\u0026gt; Custom Dimensions\n Add the index number of your custom dimension in the appropriate slot\n Add {{Internal URL}} into the Dimension field\n    And that\u0026rsquo;s it! The beauty of Google Tag Manager macros is that you don\u0026rsquo;t need a separate page view tag for undefined custom dimensions. You can just use this one macro. If the query parameter \u0026ldquo;internal\u0026rdquo; is found, its value (\u0026ldquo;true\u0026rdquo;) is sent as a custom dimension along with your page view hit. However, if no such parameter is found, no custom dimension is sent, so you don\u0026rsquo;t have to worry about overwriting your data with an empty custom dimension or something.\nFinally, check with a debugger like WASP that your custom dimension is actually being sent over.\nPro tip, use a URL rewrite If you or your internal traffic users find that using a URL query parameter is tedious, you should set up a 301 server-side redirection, and use either a vanity URL or a subdomain to handle the redirection. So if http://www.mydomain.com/?internal=true is just too difficult to manage, make it so that http://www.mydomain.com/office or office.mydomain.com redirect the user to the home page with the query parameter in place (or both!). If you have an Apache server, you could try something like this for the subdomain redirect (check with IT first!):\nRewriteEngine on RewriteCond %{HTTP_HOST} ^office\\.mydomain\\.com$ RewriteRule ^$ http://www.mydomain.com/?internal=true [R=301,L] Method 2: IP extraction A popular way to separate internal traffic from external traffic is to use the client\u0026rsquo;s IP address. The most common method is to use Google Analytics\u0026rsquo; standard features to filter out any IP addresses that are within a specified range. Because this is so \u0026ldquo;standard\u0026rdquo;, I won\u0026rsquo;t go into it (you can read the official words here).\nThis guide is for annotating internal traffic, not for filtering it, so you\u0026rsquo;ll be checking the client\u0026rsquo;s IP address against a specified range, and if there\u0026rsquo;s a match, you\u0026rsquo;ll send this information via custom dimension.\n(Pro tip: This is especially useful if you have IP anonymization set up. In Google Analytics, IP anonymization censors the last octet of the client\u0026rsquo;s IP (111.222.333.XXX) and sets it to 0 (111.222.333.0). This is what\u0026rsquo;s sent to Google Analytics servers, ensuring a higher level of security, if you don\u0026rsquo;t want the geeks at Mountain View looking at your visitors\u0026rsquo; IP addresses.)\nTo extract the client IP, you have a number of choices. The accuracy will vary greatly, since if the visitor is using a proxy, for example, it\u0026rsquo;s not really their IP that\u0026rsquo;s retrieved but the proxy\u0026rsquo;s. In this guide, I\u0026rsquo;ll introduce you to a simple PHP value retrieval, and also how to retrieve the IP with JavaScript using an external API call.\nRetrieve and process the IP with PHP This is one way to do it, and it should work if you have a site which is parsed with PHP (WordPress, Drupal, etc.). In your page template, before your container snippet, you create the dataLayer object with window.dataLayer = window.dataLayer || [];. Use this to enter the client IP into the dataLayer object as it is created. This way it will be ready when the container is set up and your page views are sent:\nwindow.dataLayer = window.dataLayer || []; window.dataLayer.push({ \u0026#34;ipaddress\u0026#34;: \u0026#34;\u0026lt;?php echo $IPADDRESS ?\u0026gt;\u0026#34; });  This will retrieve the IP address using the designated PHP variable, and it will store it in the data layer variable ipaddress.\nThis is a great way to extract the IP address, since you don\u0026rsquo;t have to wait for an external API to resolve the address. Here\u0026rsquo;s a more thorough guide on retrieving the IP with a PHP call.\nNext, create a Data Layer Variable Macro through which you can process the IP:\n Create new macro (Macro Name: Retrieve IP, Macro Type: Data Layer Variable)\n Set ipaddress as the Data Layer Variable Name\n Set none as the Default Value\n    (Why the default value, you ask? Well I like dealing with declared entities, so that I won\u0026rsquo;t have to check for undefined every single time I want to process a variable.)\nNext, you\u0026rsquo;ll need a Custom HTML tag in which you\u0026rsquo;ll process the IP address. The aim is to push a data layer variable \u0026ldquo;internal\u0026rdquo;: \u0026ldquo;true\u0026rdquo;, if the IP matches a given address or range.\n Create new Custom HTML Tag\n Add the following code within:\n  \u0026lt;script\u0026gt; var ipaddress = {{Retrieve IP}}; // Retrieves the IP from the data layer  // Comment following three lines if you want to use the IP range method  if (ipaddress == \u0026#34;111.222.333.444\u0026#34;) { dataLayer.push({\u0026#34;internal\u0026#34;: \u0026#34;true\u0026#34;}); } // To use the following IP range check, comment the previous three lines  // of code and uncomment the following lines  //  // var ipRange = ipaddress.split(\u0026#34;.\u0026#34;);  // var lastOctet = parseInt(ipRange.pop());  // if(lastOctet \u0026gt;= 1 \u0026amp;\u0026amp; lastOctet \u0026lt;= 100) {  // dataLayer.push({\u0026#34;internal\u0026#34;: \u0026#34;true\u0026#34;});  // }  dataLayer.push({\u0026#34;event\u0026#34;: \u0026#34;ipComplete\u0026#34;}); \u0026lt;/script\u0026gt;  Add Firing Rule to tag: {{event}} equals gtm.js  You have two choices in the code above. Either you do an exact match (if your office has just one IP address), or you check against a range. In the range check, I check if the last octet (111.222.333.XXX) is between 1 and 100, so remember to modify this to match the range you want to check for. And if you have multiple IP addresses you want to include in the check, just modify the if-clause to your liking. You can (and should) also use regular expression pattern matching, if the variations get more diverse.\nWhatever you do, this should push the data layer variable \u0026ldquo;internal\u0026rdquo;: \u0026ldquo;true\u0026rdquo; if the IP address matches a given pattern. Finally, you push a trigger event \u0026ldquo;ipComplete\u0026rdquo;, which is what will fire your page view tag, with which the custom dimension is also passed along.\nThe Firing Rule here is {{event}} equals gtm.js to ensure that the code is run at the earliest possible opportunity, to avoid delaying the page view call any more than necessary.\nRetrieve and process the IP with JavaScript If you can\u0026rsquo;t use PHP or server-side scripting, you can use JavaScript. Well, you can\u0026rsquo;t technically resolve the client IP using just JavaScript. You need to request the IP from an external resource such as Hostip.info or GeoPlugin. This means that this approach is a bit more suspect, because you have to trust the request endpoint to serve you with the correct data every time. Nevertheless, if you can\u0026rsquo;t retrieve the IP server-side, this is what you should try.\nI use Hostip.info in my example, but there are a number of APIs out there that you can use. I suggest you find an API that allows you to retrieve the data with an asynchronous AJAX request (you could also use an XMLHttpRequest), and which returns the data as a JSON object that you can then parse. This way your contraption won\u0026rsquo;t go up in flames, taking most of your website along in its carnival of destruction, if the endpoint chooses to change the way it distributes.\nI\u0026rsquo;ve added the AJAX call to the Custom HTML Tag where I\u0026rsquo;ll be doing the pattern matching as well.\nNOTE! This script requires that you have loaded jQuery before this script is run. So make sure the library is loaded first.\n Create new Custom HTML Tag\n Add the following code in the tag:\n  \u0026lt;script\u0026gt; function matchIP(ipaddress) { // Comment following three lines if you want to use the IP range method  if (ipaddress == \u0026#34;111.222.333.444\u0026#34;) { dataLayer.push({\u0026#34;internal\u0026#34;: \u0026#34;true\u0026#34;}); } // To use the following IP range check, comment the previous three lines  // of code and uncomment the following lines  //  // var ipRange = ipaddress.split(\u0026#34;.\u0026#34;);  // var lastOctet = parseInt(ipRange.pop());  // if(lastOctet \u0026gt;= 1 \u0026amp;\u0026amp; lastOctet \u0026lt;= 100) {  // dataLayer.push({\u0026#34;internal\u0026#34;: \u0026#34;true\u0026#34;});  // }  } var ipaddress = \u0026#34;\u0026#34;; try { jQuery.ajax({ type : \u0026#34;GET\u0026#34;, dataType : \u0026#34;json\u0026#34;, url : \u0026#34;http://api.hostip.info/get_json.php\u0026#34;, async : true, success : function(data) { ipaddress = data.ip; },error : function(errorData) { ipaddress = \u0026#34;none\u0026#34;; },complete : function() { matchIP(ipaddress); } }); } catch(e) { console.log(\u0026#34;Oops, something went wrong: \u0026#34; + e.message); } dataLayer.push({\u0026#34;event\u0026#34;: \u0026#34;ipComplete\u0026#34;}); \u0026lt;/script\u0026gt;  Set Firing Rule for tag {{event}} equals gtm.js  Phew!\nIn this tag, you send an asynchronous HTTP POST request to the endpoint at hostip.info. The request returns a JSON script, which you parse for the node \u0026ldquo;ip\u0026rdquo;. The value stored in this node is then stored in the data layer variable ipaddress. Finally, as soon as the request is complete, you call a function called matchIP(), where the actual parsing takes place.\nThe parsing is identical to what we did in the PHP IP retrieval script, so you can either evaluate an exact match or a range of IP addresses. With small modifications you can check versus multiple addresses and ranges, if you so choose.\nAgain, the desired end result is a new data layer variable \u0026ldquo;internal\u0026rdquo;, which should have the value \u0026ldquo;true\u0026rdquo;, if traffic is internal. It should remain undefined if traffic is not internal, or if an error crops up in your AJAX request.\nAnd again, there\u0026rsquo;s the trigger event \u0026ldquo;ipComplete\u0026rdquo;, which is the firing rule for your page view, which will be the vessel for your custom dimension.\nThe firing rule for this Custom HTML Tag is {{event}} equals gtm.js, because you want to make sure that the script is run at the earliest possible moment to avoid delaying your page view call any more than necessary.\nSend custom dimension with page view tag And, finally, we are about to reach the end of this arduous journey. It\u0026rsquo;s time to modify your page view tag, so that it includes information about the traffic type in a custom dimension.\nFirst, create a Data Layer Variable Macro for your internal traffic.\n Macro Name: Internal IP\n Macro Type: Data Layer Variable\n Data Layer Variable Name: internal\n    Now we\u0026rsquo;re ready to edit the page view tag.\n Open your page view tag\n Go to More Settings \u0026gt;\u0026gt; Custom Dimensions\n Add a new Custom Dimension, and give it the correct index number\n In the Dimension slot, add your new data layer variable macro ({{Internal IP}})\n Add Firing Rule: {{event}} equals ipComplete\n    That\u0026rsquo;s it! Your page view tag obediently waits for the IP check to complete. Once the check is made, if traffic was internal, the value \u0026ldquo;true\u0026rdquo; is sent as a custom dimension with the page view tag.\nNOTE! Making your page view tag wait for any scripts (especially external API calls) is a bit dangerous, since if there\u0026rsquo;s a significantly long load time, your page view might not get sent at all. You might want to leave your page view tag as it is, and send the custom dimension with a non-interaction event instead.\nConclusions I didn\u0026rsquo;t intend this post to be a be-all and end-all to All Internal Traffic Exclusion Guides on the web, so I\u0026rsquo;m a bit confused why this ended up being such a long post.\nRegardless of my verbosity, I hope this post served to highlight some of Google Tag Manager\u0026rsquo;s amazing versatility. The combination of macros, tags, and defined / undefined custom dimensions creates opportunities for really complex tagging with a really simple setup.\nWith the help of this post, you can now segment (or filter) your internal traffic in Google Analytics by looking for \u0026ldquo;true\u0026rdquo; in your Internal Traffic custom dimension.\nWhat other ways have you discovered to identify internal traffic (with or without GTM)? I\u0026rsquo;d love to add a third method to this tutorial, even though then this will really be a bloated guide.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/gtm-listener-firing-order-test/",
	"title": "GTM Listener Firing Order Test",
	"tags": ["Google Tag Manager", "listeners", "tags"],
	"description": "Quick test to see in what order Google Tag Manager&#39;s click and form triggers fire when competing for the same user action.",
	"content": " Because I was bored, I did a quick test to sort out the firing order of competing GTM listeners. If you\u0026rsquo;ve done your homework (i.e. read my article on GTM listeners), you\u0026rsquo;ll remember that GTM listeners are set up on the document node of the document object model (DOM). I wanted to test what the firing order is if you have multiple competing listeners on the same page.\nI tested with the following listeners (make sure you read up on auto-event tracking if you are completely baffled at this point):\n Form Submit Listener - listens for a submit event on a form\n Click Listener - listens for a click event on any element\n Link Click Listener - listens for a click event on a link element\n History Listener - listens for changes in browser history\n  The premise I had a very simple HTML page, with just two buttons. One was the submit button of an empty form, the other an HTML5 button element, wrapped in a link.\n  To make things more interesting, I wrapped the submit button of the form in a link as well, because I wanted to see what happens. It\u0026rsquo;s not like you\u0026rsquo;ll ever come across a silly implementation like that in real life. I hope.\nHere\u0026rsquo;s what the code looked like:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Just testing\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- GOOGLE TAG MANAGER CONTAINER WAS HERE --\u0026gt; \u0026lt;form action=\u0026#34;#form\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;?formlink\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Form test\u0026#34;/\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;a href=\u0026#34;?buttonlink\u0026#34;\u0026gt; \u0026lt;button\u0026gt;Link test\u0026lt;/button\u0026gt; \u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Very simple, right? I used query parameters in links simply because I wanted to see what happened to the {{url}} macro when different listeners fired.\nI created a Custom HTML tag for each listener, with just a simple alert dialogue. Here\u0026rsquo;s what my click tag looked like:\n\u0026lt;script\u0026gt; alert(\u0026#34;Click occurred on \u0026#34; + {{url}}); \u0026lt;/script\u0026gt;   And ditto for all the other listeners. So every time a listener fires, an alert is shown. Just by following the sequence of these alerts, I should always see what the firing order is.\nOutcome Here\u0026rsquo;s what happened on Chrome and Safari:\nClick on \u0026ldquo;Form test\u0026rdquo;  Alert: Link click occurred on (current URL)\n Alert: Click occurred on (current URL)\n Alert: Form submit occurred on (current URL)\n Alert: History event occurred on (current URL + ?#form)\n  So the order is:\nLink Click -\u0026gt; Click -\u0026gt; Form Submit\nThe History Listener fires because the form transports me to the URL ?#form (it\u0026rsquo;s in the action attribute of the form element), and in Chrome and Safari this triggers a popstate event.\nClick on \u0026ldquo;Link test\u0026rdquo;  Alert: Link click occurred on (current URL)\n Alert: Click occurred on (current URL)\n Alert: History event occurred on (current URL + ?buttonlink)\n  And the order is:\nLink Click -\u0026gt; Click\nThe History Listener fires this time as well upon popstate, because the active history entry is changed to ?buttonlink thanks to the link\u0026rsquo;s default action.\nWith Firefox, the History Listener won\u0026rsquo;t fire upon page load, so you won\u0026rsquo;t get an alert for the history event changes. Otherwise, the sequence is the same.\nConclusions The result of this simple test is that your GTM listeners fire in the following order:\nLink Click -\u0026gt; Click -\u0026gt; Form Submit\nRemember that any other listeners you might have set up on the element nodes themselves (e.g. onClick) will be fired first. For example, if you have a pushState() call sent upon clicking a navigation link, this will change the URL (if you pass it as a parameter) before your link click listener fires. This, in turn, means that if you have an event sent to GA with gtm.linkClick as the event firing rule, you will see the URL set in pushState() as the page where the link click occurred!\nMake sure that you understand how listeners compete with each other. GMT listeners are last of the line because they\u0026rsquo;re set up on the document node, not the elements themselves.\nI haven\u0026rsquo;t come across a single case yet where having multiple GTM listeners active at the same time would cause any problems in data collection. However, it\u0026rsquo;s not inconceivable, and you should really try to keep things simple with your listener tags (among other things).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-history-listener/",
	"title": "Google Tag Manager: The History Listener",
	"tags": ["Google Tag Manager", "history listener", "listeners", "tags"],
	"description": "Guide to the History Listener in Google Tag Manager. Today, this is known as the History Change trigger.",
	"content": " There\u0026rsquo;s a new listener in town! It\u0026rsquo;s a few days now since the Google Tag Manager team unleashed the History Listener, and the time has come for me to tell you what this baby can do.\nThe History Listener is designed to be used on websites where content is loaded dynamically. Typically, these websites make heavy use of AJAX (Asynchronous JavaScript and XML), which is designed for loading content in the background and serving it dynamically without having to reload the page.\n  Because I don\u0026rsquo;t want to go too deep into how a dynamic website works, this tutorial should be pretty simple. The key is to understand what events trigger the History Listener, and how you can track your page views in a website without static URLs bound to static content.\nBackground A site which loads content dynamically is usually incompatible with certain default browser events. For example, if you have a site which dynamically loads its content without any change in the URL of the page (nothing happens in the address bar), what do you think happens when a visitor navigates away from your site and then clicks the browser Back button? I can give you a hint, they won\u0026rsquo;t see whatever dynamic state the page was in just before they left.\nThis is, of course, a problem for search engines as well, since they want to index pages with unique URL addresses, which each return a static, unique piece of content. This is why URL fragments (AKA anchors AKA hashes) were introduced to solve the problems with browser history. If you loaded content clicking an \u0026ldquo;About Us\u0026rdquo; link, your URL would have looked like https://www.simoahava.com/main#aboutus.\nThis fixed the problem with browser history, since now you could detect changes in the URL fragment and serve appropriate content again, even if the user used the Back button. However, this wasn\u0026rsquo;t good enough for search engines or for Google Analytics, which have a hard time dealing with URL fragments.\nEnter the hashbang (coolest name to be ever given to anything anywhere). The hashbang is a hash followed by an exclamation mark: #!. It\u0026rsquo;s an old invention, having existed in UNIX systems to facilitate script loading. Google adopted it as a schema to signify an AJAX site with crawlable content. When search crawlers came across the hashbang sequence, they translated it to a proper URL query parameter (_escaped_fragment=the-original-fragment). A query parameter meant that the page could be crawled and indexed for search engine users to find.\nHowever, the hashbang isn\u0026rsquo;t the easiest solution to implement, it looks absolutely horrible, and it\u0026rsquo;s just not how you should treat your URLs.\nThe final chapter of the story, and the most relevant one for the History Listener, is brought about by the HTML5 standard. HTML5 introduced the window.history API, which can be used to manually manipulate browser history when loading content dynamically. You can now manually push a state into the browser history, and when someone navigates with the browser\u0026rsquo;s Back button to your page, you can look for stored states and load them in order, just like the default behavior of a static website.\nThe History Listener listens for changes in browser history. If it detects such a change event, it will tell you what happened, whether there\u0026rsquo;s a state object stored in history, and if there was a URL fragment change involved. You can use this information to send virtual page views, prevent certain tags from firing again, serve dynamic tags, and basically anything that you\u0026rsquo;d normally do when a page is loaded.\nSet up the History Listener You set up the History Listener like you would any other listener.\n Create a new tag\n Name it wisely\n Set Tag Type to Event Listener \u0026gt; History Listener\n Set firing rule to All pages ({{url}} matches regex .*)\n    And that\u0026rsquo;s it. This will set your listener up on all pages to wait for the triggers that activate it.\nYou\u0026rsquo;ll also notice that a bunch of new auto-event variables have been provided. You can use these to access properties of the history event change after the History Listener has fired. Read more about these in my Macro Guide.\nThe triggers The History Listener will activate every time one of the following occurs:\n Call to the window.history.pushState() method\n Call to the window.history.replaceState() method\n A popstate event is detected\n The URL fragment (hash) changes\n  window.history.pushState() is used to add a state into the browser history stack. pushState() takes three arguments: a state object, a title, and a URL.\nThe state object is where you store details about the content, which you can use later to serve the same content to the returning visitor. The title is just a way to name the history entry, though it can be used with popstate to set the page title. The URL is what will appear in the address bar of your browser after the pushState() csll is completed. This is especially useful, because your site visitors can share this \u0026ldquo;virtual\u0026rdquo; URL, which can be then used to serve the correct content to visitors arriving via this link.\nwindow.history.replaceState() is pretty much the same as pushState(), except that it replaces the current history state with the new state.\npopstate is what occurs every time the active history entry changes. For example, the browser\u0026rsquo;s Back and Forward buttons trigger popstate. If the history entry which is activated upon popstate was created by pushState() or replaceState(), the popstate event will have the stored state object as a property. You can use this object to serve the same content to people navigating through browser history to your AJAX site.\nNote! There are some differences as to how and when browsers send the popstate. Chrome and Safari, for example, fire a popstate with every page load (since that\u0026rsquo;s when the active history entry changes), but Firefox doesn\u0026rsquo;t. Firefox requires a history entry that was created by a pushState() or replaceState() call.\nURL fragment changes are remnants of the hashbang era, but fragments are still widely used on websites. For example, if you have internal anchor links, you\u0026rsquo;ll trigger a fragment change event every time the visitor jumps to an anchor on your page. In AJAX sites, you can listen for fragment change events, and use these to send a page view or fire a tag of your choosing.\n{{event}} equals gtm.historyChange When the History Listener is running, and any of the events described in the previous chapter occur, a gtm.historyChange is pushed into the data layer. Most of the properties in this event can be accessed by the auto-event macros, but it\u0026rsquo;s good to know what the data layer entry looks like.\nHere\u0026rsquo;s what your dataLayer object looks like after a pushState() event. Here, the state object I push is very simple. It contains just a single key-value pair, page: \u0026ldquo;About Us\u0026rdquo;.\n  Here\u0026rsquo;s what you dataLayer looks like after a replaceState() event. The parameters are the same as in pushState(). Note that I fired replaceState() just after pushState(), so you\u0026rsquo;ll see the previous state object stored in the gtm.oldHistoryState property!\n  Now, if I navigate away from the page and return with the browser Back button, a popstate event occurs with my state object neatly stored within:\n  As you can see, the old state and the new state are the same, because I navigated away from the Contact page and arrived on the same page after clicking Back in my browser. When popstate occurs, I can look into the history state object and send the correct page view for the dynamic content. In this case, I can see that the visitor returned to the Contact page.\nFinally, here\u0026rsquo;s me navigating from one URL fragment to another:\n  As you can see, I first went to the bottom of the page via URL fragment #bottom. This triggers a popstate event, with #bottom as gtm.newUrlFragment. After that, I clicked \u0026ldquo;Back to top\u0026rdquo;, which transported me to URL #backtotop, and this is reflected in the screenshot above.\nExample of use I\u0026rsquo;ll show a quick example, expanding the idea of navigating to the \u0026ldquo;Contact\u0026rdquo; page, where the page details are stored in a state object, created using pushState().\nThe premise is that when your visitor clicks a link to the \u0026ldquo;Contact\u0026rdquo; page, the contents are loaded dynamically. To account for history changes, the pushState() method is called with something like:\nvar page = {page:\u0026#34;Contact\u0026#34;}; history.pushState(page,\u0026#39;Contact\u0026#39;,\u0026#39;contact.html\u0026#39;);  This pushes a new entry into your browser history stack, with a single property within the state object. This property is the one we\u0026rsquo;ll want to access in a popstate instance, i.e. when someone returns to the contact page via a history event (browser Back, for example).\n Make sure your History Listener is running\n Create a new Data Layer Variable macro to identify what history event took place:\n     Create a new Data Layer Variable macro to get the page property of the new history state:     Create a new rule for your page view tag:    And that\u0026rsquo;s it. You can attach this sequence to your page view tag, for example, ensuring that the page view is sent every time someone navigates back to your Contact content via browser history (see below for how to make sure the page view properties are in order).\nThe firing rule is important. You\u0026rsquo;re looking for a gtm.historyChange event. This is pushed into the data layer when the History Listener is triggered. After that, you\u0026rsquo;ll want to make sure that the event was popstate (the macro in (2)), and that the page property of the new history state has value \u0026ldquo;Contact\u0026rdquo;.\nNow when you send a page view, the URL will be correctly contact.html (since you provide that in the pushState() call). However, your document title might be off, unless you explicitly set it in your AJAX logic. A nice way to send the page title is to use the Document Path setting in your page view tag, and populate it with the value of a Lookup Table macro, which in turn evaluates the page property again. Allow me to demonstrate:\n  That\u0026rsquo;s your page view tag. In the Document Title field, you\u0026rsquo;re retrieving the value from a Lookup Table macro, which I\u0026rsquo;ve named {{ AJAX - Page Title }}.\n  This sets the page title depending on the page property, pushed into the data layer when the history listener is fired. You could set a default value to the Lookup Table macro, but on the other hand, if it doesn\u0026rsquo;t return a value, the tag will just send whatever is found in the document.title property.\nConclusions Phew! This turned into a monster of a tutorial. But that\u0026rsquo;s to be expected. Working with AJAX and dynamic content is not easy, as there are so many things to factor in. Not only are there usability and browser compatibility issues involved, you\u0026rsquo;ll also need to take search engines into account, and you\u0026rsquo;ll need to understand how history events work.\nAs always, I highly recommend that you brush up on your JavaScript before you start working with the History Listener. There\u0026rsquo;s no damage to be done, but you don\u0026rsquo;t want to screw your tracking by not understanding how state objects work, for example. Also, it\u0026rsquo;s very likely that you\u0026rsquo;ll have to return to your AJAX setup to make sure that pushState() calls and replaceState() calls provide all the necessary data for you to use.\nUsing the History Listener on a dynamic site is so much better than resorting to Link Click Listeners. More often than not, you\u0026rsquo;ll come across event propagation problems with your listeners, since most of AJAX navigation is designed to prevent the default behavior of links. With the History Listener, you\u0026rsquo;re only listening for browser history events, so on-page conflicts won\u0026rsquo;t affect the listener\u0026rsquo;s basic functionality.\nYou\u0026rsquo;ll need to be careful and precise with your rules. Make use of all the properties of the gtm.historyChange event, because you\u0026rsquo;ll want to do different things upon pushState() and popstate, for example.\nAnd if you have any questions, drop me a mail or leave a comment below!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-playing-rules/",
	"title": "Google Tag Manager: Playing By The Rules",
	"tags": ["Google Tag Manager", "Guide", "rules"],
	"description": "Guide for Google Tag Manager&#39;s version 1 and its system of rules to fire tags. These have later been superceded by triggers.",
	"content": " There is a new version of this guide for GTM V2 here.\n(Last updated April 2014) I see Google Tag Manager\u0026rsquo;s operational model as an analogy of Montesquieu\u0026rsquo;s three-branched government theory (don\u0026rsquo;t leave just yet, I\u0026rsquo;m getting somewhere with this). We have the legislative power of tags (what should be done), the judiciary power of macros (explore the context and circumstance of each tag), and the executive power of rules (make the tag happen). Not one of these would work without the others, so checks and balances are in place as well.\nGoogle\u0026rsquo;s own documentation on firing and blocking rules is pretty clear and comprehensive, but as always, I think it could be better.\nSo here are a couple of refreshers for you concerning Google Tag Manager rules, and some special cases which have caused headaches for many.\nRules and conditions You can have many rules on a single tag, and your single rule can have many conditions. The difference between these is that if your tag has multiple rules attached to it, they operate in an either-or relationship, so it\u0026rsquo;s enough if just one of the rules is met for the tag to fire.\nNote! If you have multiple rules, operating in an either-or-relationship, your tag can fire multiple times, if all the rules match at different times. So if you have the following rules on your tag: {{event}} equals gtm.js OR {{event}} equals gtm.dom OR {{event}} equals gtm.dom, your tag will fire THREE times per page, when each of these events occur in the GTM loading process.\n  However, if your rule has multiple conditions, all of these conditions must be met at the same time for the tag to fire.\nAllow me to illustrate.\nLet\u0026rsquo;s say you have a tag that you only want to fire on your Thank you page, and you want to make sure that the entire DOM has loaded first. Maybe you have some custom variables that you want to pass along, and they\u0026rsquo;re written on the bottom of the page template.\nHere\u0026rsquo;s how not to do it:\n  In this example, you have two different firing rules set on the tag. The thing is, if you have multiple rules on a tag, it\u0026rsquo;s enough if just one of them checks out. The other doesn\u0026rsquo;t need to. So in this case, your tag will actually fire on every single page, because every page that has the GTM container snippet will also push the event gtm.dom into the data layer to signify that the DOM has loaded.\nHere\u0026rsquo;s how you should do it:\n  So here you have just one rule with two conditions. The difference is huge: when you have conditions on a rule, every single one of these conditions must be met for the rule to work.\nKEY TAKEAWAYS:\n If you have multiple rules, it\u0026rsquo;s enough that just one of them is met for the tag to fire\n If you have multiple rules, the tag can fire on each one, so be careful\n If you have multiple conditions in a single rule, all conditions must be fulfilled for the rule to work\n  {{url}} and {{event}} There are two easy ways to make a tag fire as soon as possible. Either\n{{url}} matches regex .*\nor\n{{event}} equals gtm.js\nYou see, the earliest possible moment that you can query for either of these two rules is when the container is setup and macros are enabled.\nThe reason these two rules do the same thing is that GTM implicitly adds the rule {{event}} equals gtm.js to every rule that doesn\u0026rsquo;t check the {{event}} macro. This is because if there is no event evaluated, a rule such as {{url}} matches regex .* would fire every single time an event is pushed into the data layer. Due to this implicit behavior, a rule like {{url}} matches regex .* has actually two conditions, one which is \u0026ldquo;hidden\u0026rdquo;: {{url}} matches regex .* AND {{event}} equals gtm.js. (Thanks Brian Kuhn for this detail).\nAnother thing to observe is that\n{{event}} can only be one thing at a time.\nThis is really important. So let\u0026rsquo;s say you want to fire a tag after the DOM has loaded AND after the event \u0026ldquo;readyToFire\u0026rdquo; has been pushed to the data layer. The first thing you\u0026rsquo;d probably try is a single rule with the following two conditions:\n{{event}} equals gtm.dom\n{{event}} equals readyToFire\nThe problem here is that {{event}} is a data layer variable, and you can\u0026rsquo;t have a variable with multiple values at any given time (unless it\u0026rsquo;s an array, which {{event}} is not).\nIf you really must wait for gtm.dom first, you\u0026rsquo;ll need to make sure that the code which pushes \u0026ldquo;readyToFire\u0026rdquo; into the data layer is run after {{event}} equals gtm.dom. This way you\u0026rsquo;ll just need to add the rule {{event}} equals readyToFire in your tag, since it\u0026rsquo;s already run after the DOM has loaded.\nKEY TAKEAWAYS:\n If your rule doesn\u0026rsquo;t check the {{event}} macro, GTM implicitly adds the condition {{event}} equals gtm.js to the rule\n This is why {{url}} matches regex .* and {{event}} equals gtm.js are pretty much the same thing\n {{event}} can only ever be one thing at any given time\n  Load order of GTM events This is run-of-the-mill stuff, but good to reiterate. When the GTM container is loaded, during the process three different events are pushed into the data layer, which you can use as triggers for your tags. The order is:\n{{event}} equals\u0026hellip;\n\u0026hellip;gtm.js\u0026hellip; \u0026gt; \u0026hellip;gtm.dom\u0026hellip; \u0026gt; \u0026hellip;gtm.load\nHere\u0026rsquo;s how they look (in order) in the data layer:\n  If you want your tags to fire on the earliest possible moment, use either {{event}} equals gtm.js or {{url}} matches regex .*.\nIf you want your tags to fire after the DOM has loaded, for example if you know you have important variables processed at the very bottom of your page template, use {{event}} equals gtm.dom.\nIf you want to wait for the window to load, meaning all initial requests have to be processed first, use {{event}} equals gtm.load.\nNote! I strongly recommend against leaving any critical tags to wait for gtm.load, since any hitches or timeouts in loading your page might lead to the tag never firing.\nKEY TAKEAWAYS:\n The automatically created GTM events are, in order, gtm.js \u0026gt; gtm.dom \u0026gt; gtm.load\n Use them to align your tags with their dependencies in the DOM or in external assets\n  Firing and blocking rules In GTM, you can have two kinds of rules: firing rules, which are required for a tag to fire, and blocking rules which can be used to signify when a tag must not fire.\nBlocking rules take precedence, so if you have competing conditions, the blocking rule will always win.\nFor example, in the very first chapter of this tutorial, we had a tag which only fires on the Thank You page. Now let\u0026rsquo;s say I want to exclude the Thank You page from the normal tracking tag, so that double hits are not recorded. I\u0026rsquo;ll have to add the following blocking rule to the tracking tag:\n{{url}} contains thankyou.html\nThis means that even though the tracking tag has a firing rule of {{url}} matches regex .*, it will not fire on the Thank You page, because the blocking rule denies it when {{url}} contains thankyou.html.\n  Blocking rules are an excellent way to reduce clutter in your tags. With a blocking rule, you won\u0026rsquo;t need complicated firing rules, macros or multiple tags to enact a simple IF x THEN y EXCEPT z scenario.\nKEY TAKEAWAYS\n Firing rules tell the tag when to fire, blocking rules tell the tag when not to fire\n If there is a conflict, the blocking rule will always win\n  Some useful rules Here\u0026rsquo;s a bunch of rules which might come in handy during your work with GTM.\n {{url}} matches regex .* - Fire tag on all pages at the earliest possible moment\n {{event}} equals gtm.js - Fire tag at the earliest possible moment\n {{event}} equals gtm.dom - Fire tag after the DOM has loaded\n {{event}} equals gtm.load - Fire tag after the page has loaded\n {{event}} equals gtm.click - Fire tag when a GTM Click Listener records a click\n {{event}} equals gtm.linkClick - Fire tag when a GTM Link Click Listener records a link click\n {{event}} equals gtm.formSubmit - Fire tag when a GTM Form Submit Listener records a form submission\n  Conclusions Google Tag Manager rules are just as important as tags and macros in making your tag setup work. The problem is that rules can get really complicated really soon. When this happens, it\u0026rsquo;s really important to understand things like loading order, GTM events, firing and blocking rules, and so forth.\nThe thing about rules is that you need a good understanding of macros as well, since rules evaluate macro values on runtime. If you need a refresher on macros, don\u0026rsquo;t forget to check my macro guide.\nDo you have any other examples of trouble you\u0026rsquo;ve had with rules? Or have you come up with ingenious ways to use firing and blocking rules to simplify your tag setup?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/tag-management-make-redundant/",
	"title": "Tag Management Does Not Make IT Redundant",
	"tags": ["Google Tag Manager", "it department", "tag management solution"],
	"description": "Just by the virtue of adding a tag management system like GTM, you do not have the right to circumvent your organization&#39;s IT processes. Successfuly tag management incorporates the IT into the development work.",
	"content": " Here are a few quotes I found on the web regarding tag management and IT departments:\nRelief of IT department bottlenecks – once the Tag Manager is deployed, new tags can be implemented directly by Marketing with no IT department involvement. This is a huge benefit for large websites, where IT is oftentimes a bottleneck. Original text here\nIT Issues - when you use a TMS like 'Google Tag Manager' you are bypassing the IT department. If anything goes wrong, they can/will put all the blame on you. Original text here\nMost solutions that require some form of tag management will likely fall within the jurisdiction of the marketing department. By decoupling the tag management process from the IT department greater control is handed to the specifically to the (digital) marketer which is logically where its should be in relation to this process. Original text here\nTag management saves money as marketers can swiftly make changes to vital assets without enlisting the help of the IT department. Less people and less time means less cost. Original text here\nAnd of course there\u0026rsquo;s the home page of the Google Tag Manager website itself:\n  The problem in all these quotes is in the rhetoric. Don\u0026rsquo;t get me wrong, all of them make a valid point, but they also do their best to antagonize IT as a slow, antiquated, process-driven, bureaucratic, revenue-hating, nerd-monster, whose sole objective is to make life difficult for marketers.\nThe all-knowing marketer   Here\u0026rsquo;s how it goes. Marketer finds Tag Management Solution. Marketer finds out s/he can \u0026ldquo;create code\u0026rdquo; using fields and a graphical user interface. Marketer questions the need to ever again consult IT, because marketer knows now how to code. Marketer learns of jQuery. Marketer copy-pastes a bunch of jQuery into a custom tag. Marketer breaks website. IT nerds laugh in glee.\nTag Management Solutions (TMS) are, as I see them, in the gray area between the marketer and the IT department. Sure, they\u0026rsquo;re self-contained solutions for manipulating tags which the solution creates, and thus there\u0026rsquo;s usually little cause for concern, if the user doesn\u0026rsquo;t stray beyond the standard features. A marketer with a basic understanding of page templates, front-end logic, and JavaScript can work magic with a TMS.\nAt the same time, these solutions inject front-end code onto the site, they manipulate DOM elements, they make use of global variables, and they are often very tightly bound with server-side logic as well (e.g. with complicated eCommerce setups).\nAn operational scale this huge for any solution cannot and must not make the solution the sole property of any one party. There are many stakeholders involved in any tag management solution setup, and the process should not be botched by some misguided preconception of ownership (\u0026ldquo;this is my solution, and you are not allowed to touch it!\u0026ldquo;).\nStop antagonizing IT The key is to stop thinking of IT as a bottleneck, or as something you have to fight against in your day-to-day work. There\u0026rsquo;s a reason they are process-driven and take a long time to deliberate.\nQuality assurance. A word unfamiliar to many marketers. Every large web infrastructure has a QA process in place, and it usually involves parallel environments (development, staging, live), a vigorous routine of testing (automated, unit, manual), diligent documentation, agile methods, punctual reporting, and a maintenance process.\nIf the marketer does not respect this, even I wouldn\u0026rsquo;t want them anywhere near the systems I am in charge of. Stéphane Hamel\u0026rsquo;s post Data Quality: Making It Simpler Doesn\u0026rsquo;t Mean It\u0026rsquo;s Simple touches upon this topic, and he makes many important and educational points about the inept marketer.\nThe important thing is to find common ground, to extend the IT processes to cover the TMS as well, and to work together in improving the usability, tracking, and performance of the website. This is not a one-team job, and with large websites it necessary involves IT as well.\nChange the rhetoric Here are my ten suggestions for making the deployment and use of a TMS more manageable to both the marketer and the IT department. These suggestions involve both parties.\n Stop using antagonizing terminology (\u0026ldquo;disregard\u0026rdquo;, \u0026ldquo;circumvent\u0026rdquo;, \u0026ldquo;make redundant\u0026rdquo;), and switch to a more communicative and collaborative lingo (\u0026ldquo;complement\u0026rdquo;, \u0026ldquo;facilitate\u0026rdquo;, \u0026ldquo;cooperate\u0026rdquo;)\n Extend quality assurance to the TMS as well, though it might be prudent to adopt a \u0026ldquo;lite\u0026rdquo; version to make things more manageable\n Train the IT to understand how the TMS works\n Train the marketer to understand how the IT process works\n If necessary, make use of tag black- and whitelisting\n Plan ahead, test and debug thoroughly, document diligently, and if you fail, make sure you fail early\n Draft a process for going beyond standard features of the solution (DOM manipulation, using global variables, setting and reading cookies)\n Periodically document and review changes to the website, so that your TMS won\u0026rsquo;t break if e.g. global libraries are updated\n Run performance tests periodically on the front-end infrastructure, and fix any bottlenecks caused by the TMS\n Keep up-to-date on the TMS development\n BONUS: Have a beer together. Be friends.\n  As I see it, a good TMS doesn\u0026rsquo;t replace IT. It complements and facilitates their work, so that the often over-burdened department can focus on more critical things. However, a good TMS also needs a marketer who understands what the TMS is capable of, in good and in bad.\nOf course, a change in mindset isn\u0026rsquo;t warranted solely from the marketer. The IT department must become more sensitive to the fast-moving pace of the marketer\u0026rsquo;s world, where changes to tagging might have to be done on a daily basis. This necessarily requires a level of compromise in QA, or the adoption of a lighter, more agile version of the front-end development process.\nWhat are your thoughts on this dichotomy between the marketer and the IT department? Do you think a TMS should be solely in the marketer\u0026rsquo;s domain, or are you empathetic to the IT\u0026rsquo;s situation as well?\n"
},
{
	"uri": "https://www.simoahava.com/analytics/awesome-google-tag-manager-resources/",
	"title": "Some Awesome Google Tag Manager Resources",
	"tags": ["Google Tag Manager", "Guide", "JavaScript", "macros", "tags"],
	"description": "Here is a list of a  bunch of extremely useful Google Tag Manager resources found around the web.",
	"content": " When push comes to shove, I\u0026rsquo;m a pretty lazy guy. I enjoy nothing more than just to stretch my legs on a couch, pick up my iPad, and read what\u0026rsquo;s going on in the world. I skip the news, since they\u0026rsquo;re just full of depressing stories. Instead, I head over to my favorite Google+ communities to see what\u0026rsquo;s new in the blogosphere.\n  This approach has led me to some pretty amazing individuals, whom I follow like a suckerfish. These people have written a bunch of great articles, which have helped countless people with their Google Tag Manager installations. Or they might be really active in the online communities which people turn to for advice.\nAs you might have noticed, Google\u0026rsquo;s own documentation is often pretty scarce. That\u0026rsquo;s why so many amazing people do such an incredible job in making the often complicated details behind tag management a bit easier to comprehend.\nWithout too much further ado, I think the time is ripe to reveal my favorite Google Tag Manager resources, so that you can get on your way to becoming a Grand Tag Master.\nI\u0026rsquo;ve added a short description under each link, along with a difficulty level (my own subjective analysis). The difficulty level has nothing to do with the quality of writing. Rather, I use it to denote how difficult it is to understand the concept the article focuses on.\nIf you feel like an essential article or individual is missing from these lists, drop me a line with a link and description, and I\u0026rsquo;ll see if they belong here!\nFollow These People First and foremost, here\u0026rsquo;s my Follow These People list. I consider these people to be top contributors in Google Tag Manager related posts. I\u0026rsquo;ve chosen them partly because I really think that they write a lot of great stuff either in the forums or on their blogs, and partly because they exhibit a quality I enjoy most about a good writer: they don\u0026rsquo;t brag about themselves or their companies, nor do they exhibit (too much) self-promotion.\nSeriously, we\u0026rsquo;re all taking part in a huge knowledge transfer experiment here. Leave your ego at the door.\n  And yes, I\u0026rsquo;m aware that I\u0026rsquo;ve added myself to the picture of my favorite GTM superstars, and also that I\u0026rsquo;ve linked to a number of my own posts in the latter sections. I claim the right to do so under editorial privileges :)\nAlso, don\u0026rsquo;t forget to visit the Google Tag Manager community in Google+ on a regular basis. That\u0026rsquo;s where most of these people hang out.\nLukas Bergstrom, Product Manager for GTM at Google\nTwitter\nJulien Coquet, Senior Digital Analytics Consultant at Hub\u0026rsquo;Scan\nGoogle+, Twitter\nYehoshua Coren, CEO at Analytics Ninja\nGoogle+, Twitter\nJustin Cutroni, Analytics Evangelist at Google\nGoogle+, Twitter\nDoug Hall, Head of Internet Marketing at Conversion Works\nGoogle+, Twitter\nStéphane Hamel, Director of Innovation at Cardinal Path\nGoogle+, Twitter\nClaudia Kosny, Web Analytics Expert at Knewledge\nGoogle+\nBrian Kuhn, Software Engineer at Google\nGoogle+, Twitter\nAndré Mafei, Founder and Web Analytics Consultant at Upmize\nGoogle+\nCarmen Mardiros, Entrepreneur\nGoogle+, Twitter\nPhil Pearce, Freelancer\nGoogle+, Twitter\nJeff Sauer, President at Jeffalytics\nGoogle+, Twitter\nDaniel Waisberg, Analytics Advocate at Google\nGoogle+, Twitter\nGeneral GTM Guides These guides should help you with deploying GTM. There\u0026rsquo;s a lot of things to keep in mind when adopting a tag management system. You\u0026rsquo;d best start with Julien Coquet\u0026rsquo;s excellent slide show on what tag management is, and, more importantly, what it isn\u0026rsquo;t.\nJulien Coquet - Tag Management Is Not A Miracle Cure\nEASY - Essential reading before you go along and implement Google Tag Manager on your website.\nDaniel Waisberg - Google Tag Manager: A Step-By-Step Guide\nEASY - A basic introduction to the tool itself.\nDave Fimek - The Google Tag Manager Datalayer Explained\nEASY - A nice, simple post explaining what the dataLayer object actually is.\nDoug Hall - Google Tag Manager: Coding \u0026amp; Naming Conventions\nEASY - Best practices for Google Tag Manager deployment, naming \u0026amp; extending via custom code.\nSimo Ahava - Macro Guide For Google Tag Manager\nEASY - A guide to macro use in Google Tag Manager by yours truly.\nJeff Sauer - 5 Ways To Troubleshoot Your Google Tag Manager Installation\nEASY - Jeff goes over different ways to make sure your GTM installation is running smoothly.\nGoogle - Developer Guide - Google Tag Manager\nINTERMEDIATE - Google\u0026rsquo;s own developer guide for Google Tag Manager. Essential reading.\nKristoffer Olofsson - A Guide to Google Tag Manager for Mobile Apps\nINTERMEDIATE - Implementation guide for mobile app tracking with Google Tag Manager.\nDorcas Alexander - Unlock the Data Layer: A Non-Developer\u0026rsquo;s Guide to Google Tag Manager\nINTERMEDIATE - A nice guide to the dataLayer object in Google Tag Manager.\nPhil Pearce - Google Tag Manager Development Guide\nADVANCED - A very long and complex guide by Phil about GTM development.\nTracking Guides Tracking is why people install Google Tag Manager. There are so many different ways to track efficiently (and inefficiently) with GTM, and these guides will get you on your way to making sure you collect all the relevant data from your visitors.\nJulius Fedorovicius - 30+ Google Tag Manager Recipes\nEASY - A handy list of Google Tag Manager tracking solutions in a well-presented, easily implementable format.\nJustin Cutroni - Auto Event Tracking With Google Tag Manager\nEASY - An excellent tutorial by Justin on tracking events in GTM.\nPier-Yves C. Valade - A Guide To E-Commerce Conversion Tracking Using Google Tag Manager\nEASY - How to setup your tags and your data layer to send eCommerce transactions to GA using GTM. This example uses Magento as the backend.\nNicholas Blexrud - Google Tag Manager: Configuring Content Grouping\nEASY - Getting content grouping data sent with your hits is dead simple with Google Tag Manager.\nYehoshua Coren - Universal Analytics and Google Tag Manager\nINTERMEDIATE - Excellent slide presentation on Universal Analytics and Google Tag Manager.\nAlex Moore - Classify your Blog Posts in Analytics Using Content Groupings\nINTERMEDIATE - Another great guide for using content groupings with Google Tag Manager.\nClaudia Kosny - Google Analytics Cross-Domain Tracking with Google Tag Manager\nINTERMEDIATE - Excellent three-part guide to cross-domain tracking in Google Tag Manager.\nJim Gianoglio - Cross-Domain Tracking with Google Tag Manager\nINTERMEDIATE - Jim\u0026rsquo;s great tutorial for tracking cross-domain traffic with GTM and Google Analytics.\nSimo Ahava - Google Tag Manager: Track Social Interactions\nINTERMEDIATE - Track social interactions in Google Analytics using GTM.\nGoogle - AdWords Dynamic Remarketing - Tag Manager Help\nINTERMEDIATE - Google\u0026rsquo;s guide to deploying the AdWords remarketing tag on a website.\nSimo Ahava - Why Don\u0026rsquo;t My GTM Listeners Work?\nINTERMEDIATE - Guide to event listeners and conflicts.\nGTM Extensions This is where the real meat of GTM is. Since it\u0026rsquo;s basically run-of-the-mill client-side scripting, you can do some crazy JavaScript magic to collect data in ways you wouldn\u0026rsquo;t have thought possible. Of course, best practices must be observed, which is why you shouldn\u0026rsquo;t try your hand at these before understanding the basics of client-side programming and markup languages.\nShay Sharon - Using Google Tag Manager to Enable Visitors to Opt-Out of Being Tracked\nINTERMEDIATE - How to make your data layer persist using cookies, and how to use this to provide an opt-out of tracking for your visitors.\nSimo Ahava - Universal Analytics: Weather As A Custom Dimension\nINTERMEDIATE - Pull weather data from an external API, and send it to GA with your visit hits.\nJon Meck - Make Phone Numbers Clickable (and Trackable!) Across Mobile Devices with JavaScript\nINTERMEDIATE - Nice extension for tracking on-site phone number clicks.\nAlex Moore - How To Upgrade To Universal Analytics: A Survival Guide\nINTERMEDIATE - A great read on how you should use GTM to upgrade to Universal Analytics.\nDoug Hall - Extending Auto Event Tracking in Google tag Manager\nADVANCED - Not satisfied with the listeners that GTM provides? Create your own! Doug will show you how.\nStéphane Hamel - YouTube Video Tracking with GTM and UA: A Step-By-Step Guide\nADVANCED - Track embedded YouTube videos on your site with GTM and Universal Analytics.\nExternal Resources Finally, here\u0026rsquo;s a bunch of resources you can download or use online to make using and debugging GTM installations so much easier. I use almost all of these on a regular basis.\nWASP: Browser extension for debugging your tags.\nGA Checker: Online tool to check what tags are installed on your website pages.\nTag Inspector: A more robust tool for tag crawling on your pages.\nJSFiddle: Test your JavaScript and your markup before adding it to your site.\nFirebug: Debugger extension for Firefox.\nGoogle Analytics Debugger: Google Analytics debugger extension for Google Chrome.\nTag Assistant (by Google): On-site tag debugger extension for Google Chrome.\nCode Editor for GTM: Replaces GTM\u0026rsquo;s native editor interface with a much more useful one.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/dont-gtm-listeners-work/",
	"title": "Why Don&#39;t My GTM Listeners Work?",
	"tags": ["Google Tag Manager", "JavaScript", "listeners"],
	"description": "Tips and tricks to identify and fix problems with Google Tag Manager&#39;s triggers. Typically the issue is conflicting JavaScript running on the site.",
	"content": " Ever so often I come across a Google Tag Manager setup where GTM\u0026rsquo;s own auto-event listeners don\u0026rsquo;t perform the task they were supposed to. Listener problems seem to be a hot topic in Google+ and the Product Forums as well.\nThere may be many reasons why your listeners don\u0026rsquo;t work, but a very common trend is that you have conflicting JavaScript libraries or scripts running on your page.\nLet\u0026rsquo;s explore how listeners work before tackling the problem. You see, when you attach an event listener to an element in your Document Object Model (the collection of all elements on your page), the listener waits for the element to produce the action it is listening for.\n With a link click listener, the handler waits for a link (\u0026lt;a/\u0026gt;) element to fire a click event.\n With a click listener, the handler waits for any element to fire a click event.\n With a form submit listener, the handler waits for a form (\u0026lt;form/\u0026gt;) element to fire a submit event.\n  Now this should still be easy to follow. You set up a link click listener, and when someone clicks a link, the listener pushes the event gtm.linkClick into the dataLayer object. Run-of-the-mill stuff.\nCompeting listeners Here\u0026rsquo;s the gist. If you have another listener ALSO waiting for the same event, there\u0026rsquo;s a chance that it will interrupt the event from ever reaching the GTM listener, meaning that your link click listener never fires.\nHow is this possible?\nWell, a GTM link click listener, for example, is not actually primed on every single link element on your page. Rather, it\u0026rsquo;s attached to the highest possible DOM element node: the document itself. It utilizes a JavaScript feature called event delegation. This means that when a click event occurs on a link, the event starts to bubble (yes, that\u0026rsquo;s an official term) up the DOM tree, until it reaches the topmost node. Any elements along this bubbly path with listeners attached to them will fire when the event reaches them. This is also called event propagation.\nThe picture below clarifies the difference between a listener on the link node and a listener on the document node. In the example, I have a single link element with a classic onClick=\u0026ldquo;\u0026rdquo; attribute. In reality, this attribute is also an event listener. It waits for a click event on this specific tag. Also, I have GTM\u0026rsquo;s own click listener primed and ready. As you can see, the onClick listener is attached to the link node itself, whereas the click listener is attached to the document node.\n  A practical example Let\u0026rsquo;s say you have a very simple page with a source code that looks something like this:\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;My Page\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Google Tag Manager Container here --\u0026gt; \u0026lt;div id=\u0026#34;main\u0026#34;\u0026gt; \u0026lt;a href=\u0026#34;http://www.google.com\u0026#34;\u0026gt;Google\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; If I now add a link click listener to my GTM container, it will be attached to the document node, which is a top-level parent to all the elements you see in the code above.\nNow, when someone clicks the link, the following happens:\n Any listener attached to the \u0026lt;a/\u0026gt; element itself (e.g. onClick) will be fired first, because it is closest to the event occurrence\n Any listener attached to the \u0026lt;div/\u0026gt; element will fire next, because it is the immediate parent to the element where the event occurred\n And so on until the event bubbles up all the way to the top of the DOM tree and reaches the document node where GTM\u0026rsquo;s link click listener is waiting\n  Here\u0026rsquo;s the thing. If at any point during the event\u0026rsquo;s bubbly journey to the top of the mountain its process is halted by a conflicting script, for example, the event will never reach GTM\u0026rsquo;s listener!\nThe most common culprit is a competing jQuery listener which contains the following, ominous line of code:\nreturn false;\nThis effectively halts the progress of the event listener, and returns the action to the link element with a \u0026ldquo;don\u0026rsquo;t do what you were supposed to do in the first place\u0026rdquo; type of statement.\nA very common occurrence is when you are using jQuery to animate in-page scrolling to anchor links (i.e. smooth scrolling). I\u0026rsquo;ve seen a bunch of scripts which hijack the link click event, animate the transition to the correct part of the page, and return false;, because, naturally, they don\u0026rsquo;t want the link to perform its default action of instantly transporting you to the correct part of the page.\nWhat\u0026rsquo;s the cure? You\u0026rsquo;ll have to talk to your developers about this. Tell them that you need event propagation to work all the way up to the document node. Usually this can be done by replacing\nreturn false;\nwith\nevent.preventDefault();\nOf course, you\u0026rsquo;ll need to pass the click event to the handler function as a parameter (event in event.preventDefault();) for this to work. There might also be cross-browser concerns, so do some research before making any changes.\n.preventDefault() also prevents the default action of the link click event, but it doesn\u0026rsquo;t stop event propagation from continuing up the DOM tree. You\u0026rsquo;ll have to test it, of course, since replacing the code might disrupt the functionality of your script.\nNOTE! If you use event.preventDefault(); OR return false;, you\u0026rsquo;ll need to uncheck the Check validation option in your link click listener. If this is left checked, the listener won\u0026rsquo;t fire even if the event bubbles up all the way to the document node.\n  Conclusions Understanding event propagation and how GTM\u0026rsquo;s listeners work is one of the things you should not have to worry about when using GTM. After all, tag managers are advertised as a be-all and end-all solution to all your data collection woes with punchlines like: \u0026ldquo;Forget IT\u0026rdquo; or \u0026ldquo;No more development needed\u0026rdquo;.\nThe harsh reality is that a tag manager like GTM is just one more library in the client\u0026rsquo;s often congested resource jungle. Conflicts are bound to happen, especially when external resources like jQuery are used to add functionality to the site.\nFor one, whenever I work with a complex website, I will never, EVER, disregard the client\u0026rsquo;s development or IT unit. Rather, I will talk to them about GTM, and work together with them to come up with the best possible implementation plan, without compromising the current front-end deployment.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/macro-guide-google-tag-manager/",
	"title": "Macro Guide For Google Tag Manager",
	"tags": ["Google Tag Manager", "Guide", "macros"],
	"description": "Guide to Google Tag Manager macros. This is a comprehensive guide for macros, but has been superceded by variables in the latest Google Tag Manager version.",
	"content": " I\u0026rsquo;ve written a new Variable Guide for Google Tag Manager, which covers the new GTM UI. This guide is for the old UI.\nYou might be vaguely familiar with macros if you\u0026rsquo;ve ever used a computer. Basically, whenever you perform a complicated task with a simple gesture, or reuse complex code with a simple input mechanism, you\u0026rsquo;re using macros. Think keyboard shortcuts.\nIn Google Tag Manager, this is the essence of macros. You can do away with a lot of complexity by resorting to macros, especially if you ever find that you need the same piece of code or the same operation over and over again.\nThis guide will first take a cursory look at what macros really are, before going through the (current) list of available macros. I\u0026rsquo;ll add short examples and use cases for each, but there\u0026rsquo;s a whole lot more to be found online.\nWhat is a macro In Google Tag Manager, a macro is a construct that you can set up in the UI. However, it\u0026rsquo;s not a tag in the sense that it would be something you\u0026rsquo;d tag your page with. Rather, macros are turned into a function of the _google_tagmanager object (more on this later), and they return a value when called.\n  So a macro is, in essence, a placeholder for some value that you might need in your tags. Most common uses for macros would be to:\n Retrieve a constant string (e.g. your tracking code)\n Retrieve a variable string (e.g. the href attribute of a clicked element)\n Retrieve the result of some simple function (e.g. the date and time of the current visit)\n  Macros are thus used to call for and to retrieve certain values. You can surely see how they facilitate your day-to-day GTM use, can\u0026rsquo;t you? It\u0026rsquo;s much easier to just refer to a macro name rather than having to write the value-retrieving function over and over again.\n  Without macros, whenever you rewrite your hard-coded functions or variables, you have to remember to change them wherever they were used. It\u0026rsquo;s much easier to just have a macro refer to the original location.\nTechnical details DISCLAIMER: Note that the following analysis is my own and only for illustrative purposes. Don't attempt to use the DOM functions uncovered here in your own code, since they are liable to change without notice. Use macros only via the GTM UI using the syntax required by the tool. Well my skills at reverse engineering minified JavaScript code are pretty sparse, but you can uncover a lot just by going through the DOM (Document Object Model) tree of a page where macros are active. You can do this by using a JavaScript console in your browser\u0026rsquo;s developer tools. Just type window and click enter.\nFor example, if you go through the DOM, you\u0026rsquo;ll find an object called google_tag_manager:\n  Here you can see the google_tag_manager array and its contents. There\u0026rsquo;s an index for your container ID (GTM-XXXX), under which you\u0026rsquo;ll find the macro function. The function is actually defined in gtm.js, which you load in the GTM container snippet.\nThe macro function accepts a single parameter and returns something else.\nIt appears that the parameter is a numeral value which refers to a certain macro that you\u0026rsquo;ve set up in GTM. I didn\u0026rsquo;t find any way to actually identify which number returns which macro value, but just by testing you can find a lot of stuff. For example, I have a macro which stores the number of images on the page. Twiddling around with the macro function I finally found the correct index:\n  So as you can see, when you refer to a macro in your tag setup, e.g. {{number_of_images}}, it actually translates to a JavaScript function call that returns the value.\nThis is also the reason why your macros don\u0026rsquo;t accept parameters. The macro itself is a function call which only takes the index number of the macro as its parameter. Runtime evaluation is done on the spot with only elements found in the Document Object Model to work with.\nThis is why you\u0026rsquo;ll see undefined for those indices which expect a value in the data layer that hasn\u0026rsquo;t been pushed yet. As soon as the value is pushed into the data layer, you\u0026rsquo;ll find that the macro index returns the appropriate value.\nHow to use macros To use a macro, you refer to it in GTM with its name between two sets of curly brackets:\n{{macro name}}\nNote that this is case-sensitive, so {{macro name}} and {{Macro name}} refer to different things.\nYou can use macros in any GTM fields which accept a text string, e.g.:\n  On top of that (and this is really cool), you can refer to macros in your custom HTML tags:\n  Here, I check whether or not the clicked link href contained the text \u0026ldquo;.pdf\u0026rdquo;. Since it\u0026rsquo;s an auto-event macro I\u0026rsquo;m using, the macro won\u0026rsquo;t return a proper value until the auto-event variable is pushed into the data layer. So upon page load the macro {{element url}} would return undefined, but after I click a link, it would return the href attribute of the link. This means that in order for this tag to work like it should, I need a firing rule which prevents it from firing until after the auto-event variable is pushed into the data layer. Runtime evaluation, remember?\nYou can also, and this is really REALLY cool, refer to macros in other macros!\n  This returns the tag name of the first child of the clicked element.\nThere\u0026rsquo;s a small point to make about using macros and JavaScript. You can only treat a macro as a JavaScript object in the context of a script. This means that you can freely access macro properties with dot notion, e.g. {{element}}.innerText, in Custom HTML tags and Custom JavaScript macros. However, this won\u0026rsquo;t work in other GTM fields where you can use macros (e.g. Event Category), because these fields do not run JavaScript functions. So if you want to access a property of a macro in a tag field, for example, you will need to create a separate macro for this property.\n  You\u0026rsquo;ll also use macros a lot in your firing and blocking rules:\n  This rule would fire only when visits are tracked to my GA debug account.\nHere\u0026rsquo;s the key takeaway:\nUse a macro whenever you need to reuse a certain value or value-returning function.\nI won\u0026rsquo;t add a separate section for when not to use a macro, but suffice to say, if you only need a certain value once or you have a function which you know won\u0026rsquo;t be reused, don\u0026rsquo;t bother creating a macro for it. Just hard-code it into your custom HTML tag or use the value directly in your tags. A macro is always, after all, another function call, which does increase the complexity of your code.\nRules are a bit different, since you must use macros in rules. You can\u0026rsquo;t write an ad hoc function into your rule; you must have a macro which you evaluate on runtime.\nThe different macro types in GTM Here, I\u0026rsquo;ve listed all the different macro types you can create in Google Tag Manager (at the time of writing). I\u0026rsquo;ve added a short description, and an example use case for each.\nAll macros need a name, which you refer to (case-sensitive) using two sets of curly brackets, e.g. {{macro name}}.\nAlso, you can give a default value to some of the macros. It\u0026rsquo;s a good practice to use a default value, because you can use that as a blocking rule (e.g. {{macro}} equals \u0026ldquo;default\u0026rdquo;) in your tags, and you can avoid getting the pesky undefined as a return value.\nNote also that there\u0026rsquo;s a difference between macro type and macro instance. Below, I list all the different macro types you can use to create different macro instances. You can have as many instances of a macro type as you want (as long as they have different names). Macro types are provided by GTM, and you can\u0026rsquo;t edit or create new macro types.\n  When you create a new container, you get the following pre-populated macro instances. Encased in brackets is the type of macro the pre-populated macro is an instance of:\n element (Auto-Event Variable / Element)\n element classes (Auto-Event Variable / Element Classes)\n element id (Auto-Event Variable / Element ID)\n element target (Auto-Event Variable / Element Target)\n element url (Auto-Event Variable / Element URL)\n event (Custom Event)\n referrer (HTTP Referrer)\n url (URL / URL)\n url hostname (URL / Host Name)\n url path (URL / Path)\n  So you might be a bit confused at first, since you have these pre-populated macros which are named the same as the macro types they are instances of. But you\u0026rsquo;ll get the hang of it soon enough, don\u0026rsquo;t worry.\n1. 1st Party Cookie   DESCRIPTION\nThe 1st Party Cookie macro returns the value of the cookie whose name you indicate in the Cookie Name field. For example, if you set up a cookie named \u0026ldquo;front-page-visits\u0026rdquo; which increases by one every time the visitor visits your front page, you can set up this macro to return the value (i.e. number of visits) every time the macro is used.\nUSE CASE\nCheck my previous article on the session cookie for a nice use case for this macro.\nBasically this macro can be used to replace any code you used to have for retrieving cookie values.\n2. Auto-Event Variable   DESCRIPTION\nWhen you set up an event listener using GTM, you can use the auto-event variable macros to return the value of various attributes of the element you were listening to.\nYou need to specify the variable type of the auto-event variable you want to use. Here are the different types.\nElement: This returns the element that was clicked. Note that the macro returns an object, not a string, so the best use of it is for traversing the DOM tree of the clicked element (e.g. {{Element}}.children[0].tagName returns the tag name of the first child of the clicked element).\nElement classes: This returns the class attribute of the element that was clicked. For example, if the element was \u0026lt;div class=\u0026quot;mainBanner\u0026quot;\u0026gt;, you\u0026rsquo;d get \u0026ldquo;mainBanner\u0026rdquo; as the return value.\nElement ID: This returns the ID attribute of the element that was clicked. For example, if the element was \u0026lt;a href=\u0026quot;/home\u0026quot; id=\u0026quot;home-link\u0026quot;/\u0026gt;, the macro would return \u0026ldquo;home-link\u0026rdquo;.\nElement target: This returns the target attribute of the element that was clicked. For example, if the element was \u0026lt;a href=\u0026quot;/home\u0026quot; target=\u0026quot;blank\u0026quot;/\u0026gt;, the macro would return \u0026ldquo;blank\u0026rdquo;.\nElement text: This returns the text content (if any) of the element that was clicked. It returns either the innerText or the textContent property (depending on what browser the visitor uses).\nElement URL: This returns the href (in e.g. links) or action (in e.g. forms) attribute of the clicked (or submitted) element. For example, if the element was \u0026lt;form action=\u0026quot;/process-form\u0026quot; id=\u0026quot;myForm\u0026quot;\u0026gt;, the macro would return \u0026ldquo;/process-form\u0026rdquo;. You can also choose which URL component is returned by the Element URL macro (see the chapter on URL macros for a description of component types).\nHistory New URL Fragment: The History macros are populated by the History Listener. History New URL Fragment returns the URL fragment set in the current history state. You can use this to fire your tags (e.g. pageview) when a certain URL fragment is in the URL.\nHistory Old URL Fragment: Returns the URL fragment set in the previous history change event. For example, if you first navigate to #aboutus then to #contact, History New URL Fragment will return \u0026ldquo;aboutus\u0026rdquo; and History Old URL Fragment will return \u0026ldquo;contact\u0026rdquo;.\nHistory New State: History New State returns the state object stored in the current history entry (if any). You can access the properties of this object to set up your content and fire your dynamic tags. Note that it\u0026rsquo;s an object that is returned, so you can\u0026rsquo;t use it directly in any GTM fields. You\u0026rsquo;ll need to use some programming logic to access the properties of this object if you want to send them as strings with your tags.\nHistory Old State: The previous state stored in browser history (if any). You can use this to determine what the previous browser history state was, for example if navigation patterns determine the tags you want to fire.\nUSE CASE\nThere\u0026rsquo;s a million different things you can use auto-event variables for. The variables are most frequently used to refer to certain aspects of the element in event descriptions. You could, for example, add {{element url}} as the action of a GA event which measures link clicks on your different pages.\nCheck my tutorial on auto-event tracking to see how the different auto-event variables can be used to improve your site measurement.\n3. Constant String   DESCRIPTION\nThis macro can be used to store a string you\u0026rsquo;d use over and over again. In other words, it\u0026rsquo;s a time-saver.\nUSE CASE\nStore your GA tracking code in this, so you don\u0026rsquo;t have to remember it in every single tag. Just add the UA-XXXXXXX-X into the \u0026ldquo;Value\u0026rdquo; field, and name the macro \u0026ldquo;GA Tracking Code\u0026rdquo; or something similar. After that, whenever your tracking code is required (e.g. in tags), you can just use the macro {{GA Tracking Code}}.\n4. Container Version Number   DESCRIPTION\nThis returns your GTM container version number. If you\u0026rsquo;re in the Preview mode (as you should be whenever you\u0026rsquo;re testing), this returns the preview container version number.\nUSE CASE\nA nice way to use it is to output the version number into the console using console.log({{container version}}); in your Custom HTML tag. This way you can always check the console if you\u0026rsquo;re unsure which version you\u0026rsquo;re currently running. It\u0026rsquo;s a good way to debug your live implementation.\n5. Custom Event   DESCRIPTION\nThis macro returns the data layer \u0026ldquo;event\u0026rdquo; value of the last event that was pushed into the array. So if you\u0026rsquo;ve just executed dataLayer.push({\u0026ldquo;event\u0026rdquo;: \u0026ldquo;myEvent\u0026rdquo;});, this macro will return \u0026ldquo;myEvent\u0026rdquo;.\nUSE CASE\nThis should be one of your most familiar macros. It comes with every container setup under the name {{event}}. There are about a zillion use cases for this, most notably in firing and blocking rules. For example, if you only want a tag to fire when the event \u0026ldquo;fireNow\u0026rdquo; has been pushed into the data layer, you can add the rule {{event}} equals fireNow to your tag. Then, as soon as you execute dataLayer.push({\u0026ldquo;event\u0026rdquo;: \u0026ldquo;fireNow\u0026rdquo;}); the event macro will be populated with the value \u0026ldquo;fireNow\u0026rdquo; and your firing rule will trigger.\n6. Custom JavaScript   DESCRIPTION\nUse this macro to perform a simple JavaScript function using either ad hoc values or elements in the DOM tree. The JavaScript function has to be encased in a function structure, it has to return a value and it can\u0026rsquo;t take parameters of its own.\nUSE CASE\nYou could use it with auto-event tracking to return the value \u0026ldquo;Outbound link\u0026rdquo; for all outbound links and \u0026ldquo;In-site link\u0026rdquo; for all in-site links. You can then use these as your Event Category in the event where you send information about the link that was clicked. The function would look like this:\nfunction() { if({{element url}}.indexOf(\u0026#34;http://www.my-domain.com\u0026#34;) \u0026gt;= 0) { return \u0026#34;In-site link\u0026#34;; } else { return \u0026#34;Outbound link\u0026#34;; } }  See how I\u0026rsquo;m referring to another macro within this macro? :) \u0026ldquo;www.my-domain.com/\u0026rdquo; would naturally need to be replaced with your hostname.\nAnother neat trick is to use a Custom JavaScript macro to retrieve the file extension of the link that was clicked. You can use this to create more dynamic tags. Check out the tip on this Google+ post.\n7. Data Layer Variable   DESCRIPTION\nUse this macro to refer to the variables you push into the data layer. Remember, you do the push with dataLayer.push({\u0026ldquo;Variable_Name\u0026rdquo;: \u0026ldquo;Some value\u0026rdquo;});. If you set this macro to look for \u0026ldquo;Variable Name\u0026rdquo;, the return value will be \u0026ldquo;Some value\u0026rdquo;.\nWith \u0026ldquo;version 2\u0026rdquo; (now default), you can refer to nested values using dot notation. For example, if you\u0026rsquo;ve pushed dataLayer.push({\u0026ldquo;Products\u0026rdquo;: {\u0026ldquo;Product_1\u0026rdquo;: \u0026ldquo;Lawn mower\u0026rdquo;}});, by referring to Data Layer Variable Name Products.Product_1, you\u0026rsquo;ll get \u0026ldquo;Lawn mower\u0026rdquo; as the return value.\nUSE CASE\nYou can use it nicely in conjunction with auto-event tracking. When you click an element, the data layer is updated with the object gtm.element, which can be traversed like any DOM object. For example, to get the tag name of the object that was clicked, you\u0026rsquo;d create a data layer variable macro for gtm.element.tagName. Clicking an image would then return \u0026ldquo;IMG\u0026rdquo;.\n8. Debug Mode   DESCRIPTION\nThis returns \u0026ldquo;true\u0026rdquo; if you\u0026rsquo;re in Google Tag Manager Debug mode, and \u0026ldquo;false\u0026rdquo; if you aren\u0026rsquo;t.\nUSE CASE\nSee Lookup Table Macro below for a nice use case.\n9. DOM Element   DESCRIPTION\nUse this macro to refer to any element that can be found in the Document Object Model. The element needs a unique ID identifier. You can even specify the attribute whose value you want to get in return. If you don\u0026rsquo;t specify an attribute, you get the text content of the element (if any).\nUSE CASE\nLet\u0026rsquo;s say I want a certain tag to only fire on pages where the text \u0026ldquo;By Simo Ahava\u0026rdquo; can be found in the \u0026lt;div id=\u0026quot;author\u0026quot;\u0026gt; element. A good use case for just my article pages. For this to work, I\u0026rsquo;d create a DOM Element macro called \u0026ldquo;Author\u0026rdquo; with Element ID \u0026ldquo;author\u0026rdquo;. After that, I can create a firing rule {{Author}} contains \u0026ldquo;By Simo Ahava\u0026rdquo; for the tag that only fires on my article pages.\n10. HTTP Referrer   DESCRIPTION\nThis returns the HTTP referrer (i.e. the previous page URL). You can also choose which URL component is returned by the HTTP Referrer macro (see the chapter on URL macros for a description of component types).\nUSE CASE\nYou can use it to check if this is the first page of the visit or not. Create the macro and then use it like:\nif ({{referrer}}.indexOf(\u0026#34;http://www.mydomain.com\u0026#34;) \u0026gt;= 0) { alert(\u0026#34;Yay, not the landing page!\u0026#34;); } else { alert(\u0026#34;Aww, this is the landing page\u0026#34;); }  11. JavaScript Variable   DESCRIPTION\nThis returns the value of a globally defined JavaScript variable.\nYou can use dot notation to refer to nested variables, e.g. document.doctype to get the doctype declaration of the current document. (Thanks +Brian Kuhn for pointing this out).\nUSE CASE\nIf you haven\u0026rsquo;t (or can\u0026rsquo;t) push the value into the data layer (preferred), or if you can\u0026rsquo;t find the variable in the DOM, you can use this macro to refer to it. A simple use case would be if you define a global variable (e.g. var myName=\u0026ldquo;Simo\u0026rdquo;;) in a Custom HTML Tag, you can use this macro to get the content of this variable in other tags as well. Sure, you could just use \u0026ldquo;myName\u0026rdquo; to refer to the global variable, but reusability is the key here. If you find that you need to change the variable reference, you just need to change it once in the variable definition and once in the macro, rather than many times in all the tags where you refer to the variable.\n12. Lookup Table DESCRIPTION\nMy favorite macro, by far. Check my five-star review of the lookup table macro for specifics. The lookup table macro is basically a simple runtime evaluation, where you assign value Y to variable Z if X is something.\nUSE CASE\nHere\u0026rsquo;s a really nice use case (originally on Google+). If you use GTM Preview \u0026amp; Debug mode a lot (AND YOU SHOULD!), you might be annoyed at all the debug hits in your GA account (unless, of course, you filter yourself out). You can use a combination of Lookup Table and Debug Mode macros to make sure that debug mode hits are sent to your test account:\n  Here the macro {{GA Tracking Code}} is assigned a variable value depending on the value returned by the {{Debug Mode}} macro.\nRemember that lookup tables only accept simple runtime evaluation of \u0026ldquo;when X equals Y\u0026rdquo;, so you can\u0026rsquo;t do calculations (e.g. \u0026ldquo;when X \u0026lt; 10\u0026rdquo;).\n13. Random Number   DESCRIPTION\nReturns a random number between 0 and 2147483647.\nUSE CASE\nYou can use it to create a random hash for your URLs (for cache-busting) OR you can follow this example of using the random number to fire a tag for only a certain percentage of your visitors.\n14. URL   DESCRIPTION\nReturns the URL or a specific component thereof. The various component types are:\nURL: Returns the entire URL minus fragment (fragment begins with a #).\nProtocol: Returns the protocol of the URL address (i.e. http or https).\nHost Name: Returns the full hostname of the URL (e.g. www.google.com) or you can choose to strip the www-prefix.\nPort: Returns the port number of the hostname. If no port number is specified, the return value is either 80 or 443 (for http and https, respectively).\nPath: Returns the URI of the URL address, i.e. the structure immediately following the hostname. You can also specify \u0026ldquo;default pages\u0026rdquo;, which are stripped out of the return value if found.\nQuery: Returns the query string of the URL address (without leading question mark and possible fragment). You can also specify a query key for the macro, after which only the value of the key is returned if found in the URL.\nFragment: Returns the fragment of the URL without the leading #.\nUSE CASE\nYou could query for only email campaign traffic by creating a URL of component type Query. Set \u0026ldquo;utm_medium\u0026rdquo; as the Query Key. Then you can employ a firing rule for only those visits which came via email with {{URL Query}} equals email.\nConclusions Macros are a really powerful way of making a complicated setup simple. You can use macros to dramatically reduce the amount of code AND separate tags in your Google Tag Manager container.\nWhen using macros, a bunch of best practices should be observed:\n Name your macros so that you\u0026rsquo;ll instantly identify them (e.g. \u0026ldquo;Name - Macro Type\u0026rdquo;)\n Only use macros when they facilitate either coding or maintenance; don\u0026rsquo;t use them as replacements for one-off functions or variables\n Document your macro use somewhere so that you\u0026rsquo;ll know what repercussions changes might have\n  The last is especially important in large implementations, where dozens and dozens of macros are used in dozens and dozens of tags.\nDo you have any questions about macros? Drop a comment on this post if you didn\u0026rsquo;t find what you were looking for above.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-lookup-table-macro/",
	"title": "Google Tag Manager: The Lookup Table Macro",
	"tags": ["Google Tag Manager", "lookup table", "macros"],
	"description": "Introducing the Lookup Table macro in Google Tag Manager.",
	"content": " Having just come hot of the press with my latest article on GTM and Content Grouping which, to my delight, LunaMetrics had written an amazing tutorial on earlier, Brian Kuhn and the amazing Google Tag Manager development team came out with another incredible new feature: The Lookup Table Macro.\nIn software engineering, a lookup table is an array which takes away a layer of complexity in runtime computation, and replaces it with a simple value assignment based on array indexing. To put it simply, a lookup table looks through an array of source values, and assigns a value to the target depending on what the source value is. Well, maybe it\u0026rsquo;s easiest to show it in an image:\n  This is probably the most simple use case for the lookup table. The range of source values is derived from the custom JavaScript macro _{{post_publish_datemonth}}, which returns the month when the article the visitor is browsing was published. The lookup table goes through the possible values of the source macro, and it uses these values to assign the literal month name to the target macro, {{Post publish month}}.\nNOTE! The source value (i.e. \u0026ldquo;When {{macro}} equals\u0026rdquo;) is case-sensitive!\nWhy use lookup tables So why resort to a lookup table, when you can just add simple predicate logic to your custom JavaScript, and have it return the month name directly? Well, sure, you could do that, and in most cases it would be just fine.\nHowever.\nA lookup table, just like macros in general, removes a layer of complexity from your code and replaces it with increased flexibility. Because you take away a transformation from the source (i.e. transliteration of the numerical month to the written month name), you are free to use the numerical month elsewhere in your computations.\nAlso, a lookup table is an indexing operation and not strictly a calculation, so the runtime processing power it requires is significantly reduced when compared to having your scripts do all the work. With a large setup, where lookup tables might go through a huge number of source and target operations, you\u0026rsquo;ll end up with less code, less computation, and a nice and flexible framework for value assignment in your macros.\nTo keep the operation as light as possible, you can only check for equation, e.g. \u0026ldquo;if {{target macro}} equals something, then\u0026hellip;\u0026ldquo;. I actually asked Brian about this, and he replied:\n  So if you want to see some other ways of evaluating the source value before assigning a target value, you\u0026rsquo;ll have to wait and see what the GTM team come up with. I guess it will be some combination of rule + lookup table to keep the setup as simple as possible.\nNaturally, you can refer to your lookup table macros in Custom HTML tags and Custom JavaScript macros as well, so you\u0026rsquo;ll increase the modularity of your code.\nUse cases Let\u0026rsquo;s put it this way. Any time you need to do a simple \u0026ldquo;if X is Y then Z\u0026rdquo; evaluation based on a range of values, you could do so with a lookup table. Let\u0026rsquo;s start with a simple one.\nMulti-account or multi-property container If you have a single container deployed across many Google Analytics accounts or properties, you\u0026rsquo;ll come across the problem of assigning the correct tracking code to your tags. You could do it with a unique tag for each deployment, a unique rule for each tag, and a bunch of macros and custom HTML code to check the correct account, but that will soon turn into a veritable noodle-o-rama of a setup.\nRelax. Use a lookup table:\n  Filetype defines event category This is an example of using macros in the lookup table itself. I have a custom JavaScript macro, which checks the filetype of the link that was clicked. It uses the gtm.element auto-event variables used in auto-event tracking. See how I use a macro in the target value field? That\u0026rsquo;s how flexible this is. You can create a framework or infrastructure of macros, and come up with something really complex with very simple processing.\nBe sure to follow the great Carmen Mardiros from Clear Clues to find out (hopefully soon) about applications of complex indexing logic using macro-based syntax.\n  More auto-event madness Another nice use case for auto-event tracking is to set your event parameters depending on what type of auto-event interaction took place. For example, if a link was clicked, I\u0026rsquo;d want my event action to be the URL of the clicked link. If any click occurred, I want my event action to be the tag type (i.e. DIV or IMG or SPAN etc.) of the clicked element. And if a form was submitted, I\u0026rsquo;d want my event action to be the ID of the form. Like so:\n  Then you can just use a single event tag to send your different auto-event hits, with a trigger rule like \u0026ldquo;{{event}} equals gtm.click OR {{event}} equals gtm.linkClick OR {{event}} equals gtm.formSubmit\u0026rdquo;.\nConclusions The lookup table macro is designed to help you actually create a logical infrastructure for your GTM deployment. It also increases flexibility, since you can cross-reference lookup macros in your tags and other macros. I\u0026rsquo;m a huge advocate of macros in general, because the less you hard-code into your custom tags the better.\nThere\u0026rsquo;s no limit to the number of rows in a lookup table (other than general GTM data set limitations). I know that there\u0026rsquo;s also an import feature on the roadmap, so you can import your own, pre-defined lookup tables into the system. Mapping classifications from one data set to another will be something that especially large GTM implementations will benefit from.\nFinally, I couldn\u0026rsquo;t agree more with Eric Erlebacher:\n  The GTM dev team is on a roll right now, and I hope it doesn\u0026rsquo;t stop anytime soon.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-content-grouping/",
	"title": "Google Tag Manager: Content Grouping",
	"tags": ["content grouping", "custom html", "google analytics", "Google Tag Manager"],
	"description": "Introducing content groupings in Universal Analytics to logically sort your content in the Google Analytics user interface.",
	"content": " Content Grouping is a nice new feature from the good folks at Google Analytics. Basically, it allows you to group your content according to a logical structure. You can create up to five Content Groupings, and you can have as many Content Groups within these groupings as you like. The difference between a Content Grouping and Content Group is hierarchy. The second is a member of the first. Read Justin Cutroni\u0026rsquo;s post on Content Groupings to get you started.\nIt\u0026rsquo;s still obviously in some kind of beta mode, and I saw a number of bugs with the feature when testing for this article. Nevertheless, it\u0026rsquo;s nice to see Content Groupings as a built-in feature of Google Tag Manager now as well.\nWhat you get In some content reports (e.g. Behavior -\u0026gt; Site content -\u0026gt; All pages), you\u0026rsquo;ll see the new Content Grouping selector among the primary dimensions:\n  Once you select an existing grouping, you can drill down in the data and compare how different groups fare among the selected grouping.\nTo be honest, I kind of wish that you could use content groupings to actually filter data on the view level. When I first heard of this feature, I instantly thought of a use case I had with a client. They have two language versions (Finnish and Swedish) running on the same domain, and no folder structure to separate the two, so Finnish URLs and Swedish URLs all mixed together. Content grouping would be a great way to have a separate view for the Swedish pages and for the Finnish pages. For now, I didn\u0026rsquo;t see content grouping as something you can filter your view data with, nor did I see it as something you can even segment your data with. It\u0026rsquo;s just a fancy way of grouping and comparing your content.\nIt didn\u0026rsquo;t take long for the amazing Google Tag Manager development team to make sure that Content Grouping is doable through the GTM UI as well. Here\u0026rsquo;s a brief walkthrough of how to do it. In my example, I created one Content Grouping for all my articles. Under this grouping, I want to measure the efficiency of my various articles by category. For this example, I\u0026rsquo;ll create Content Groups for just my SEO and Analytics articles, but I could just as well extend them to cover all my articles.\nI do have a clear URL hierarchy on my website, so I could just as well use Content Drilldown reports to achieve the same thing, but I beg of you to use your imagination here, oh good reader. There are many (much better) applications for this new feature than what I explore here as a demonstration.\nSetting up Content Groupings in GA First, you need to create the Content Grouping for your view in Google Analytics Admin.\n Go to Admin\n Under the View of your choice, select Content Grouping\n     Select Create New Content Grouping\n Give a name for your Grouping\n Choose + Enable Tracking Code (required for the GTM setup)\n Choose an index from 1 to 5 (you can only create 5 Content Groupings!)\n     Click Done and Save  So now you\u0026rsquo;ve created a Content Grouping. Make note of the index number you chose, you\u0026rsquo;ll need it in GTM. I named my new Content Grouping imaginatively \u0026ldquo;Articles\u0026rdquo;. The other grouping in the screenshot below can be disregarded, as I don\u0026rsquo;t use it in this example.\n  Modifying your Google Tag Manager tags To send the Content Grouping data, you need to annotate a pageview tag with the Content Grouping index and group name that you want the pageview to belong to.\nIn my case, I created two new pageview tags. One that fires only on Analytics article pages ({{url path}} matches regex ^/analytic/) and one that fires only on my SEO article pages ({{url path}} matches regex ^/seo/). I naturally had to modify my \u0026ldquo;all pages\u0026rdquo; tracking tag to exclude SEO and Analytics pages, so that I don\u0026rsquo;t get double pageviews.\nTo decorate your pageview with a Content Grouping annotation, you need to do the following.\n Edit your Pageview tag\n Click More settings / Content Groups / Add Content Group\n Here, you need to add the index number of your Content Grouping into the Index field, and the name you want for your Content Group in the Content Group field\n Make sure you have a rule in place to only fire the pageview on pages which you want to have in the Content Group\n     Save tag, Preview \u0026amp; Debug  So remember, the index number refers to the Content Grouping you set up in Google Analytics Admin. Content Group is the arbitrary name of the sub-group you want to appear in your reports, when you drill down through the (maximum of 5) Content Groupings you created.\nSo Index 1 is my Articles Content Grouping, and then the Content Group is either SEO Articles or Analytics Articles, depending on the folder the page is in. Both Content Groups require a separate pageview tag, naturally.\nTest and review Finally, it\u0026rsquo;s prudent to test your setup. Always, always use the brilliant Preview \u0026amp; Debug mode of Google Tag Manager to verify your changes. If you\u0026rsquo;ve done everything correctly, you should see your new pageview firing on a page which matches the rule you set.\n  Then I use WASP and Chrome Developer Tools to verify that the data is sent correctly. In the screenshot below, you can see the correct parameter (cg1 for Content Grouping 1, and Analytics Articles for Content Group) being sent with the pageview.\n  And you saw the end result at the beginning of the post.\nConclusions It\u0026rsquo;s a nice feature, to be sure. If you don\u0026rsquo;t have a logical folder structure in your site, or if you want to thematically group content without being able to do so in any other way, Content Groupings just might save the day. They\u0026rsquo;re easy to set up, and you can add a created Content Grouping as a dimension in your favorite custom reports as well!\nWishlist / feature request list / gripes\n Fix the bugs!  I tested the above process twice, and on both times it assigned the content to wrong Groupings, even though I double-checked the Index numbers and what I had set in GTM. So for some reason, content for grouping 1 was put under grouping 2 and vice versa The \u0026ldquo;Choose Content Grouping\u0026rdquo; primary dimension appeared on a whim. Sometimes I saw nothing there, on other times I saw just Test as the name of the menu, and once I saw Page Group 1 instead of the Content Grouping name  Make it possible to filter data on the view level by Content Grouping Make it possible to create advanced segments with Content Groupings Improve the tips next to the Content Grouping selector when adding a custom grouping as primary dimension in custom reports. Some of the labels just said Error  Other than that, thanks for another cool feature!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/context-king-measure-everything/",
	"title": "Context Is King: Measure Everything!",
	"tags": ["analytics", "big data", "clickstream", "context"],
	"description": "Why it&#39;s difficult to decided a priori what to measure on a website, and why aggregate tracking can sometimes be beneficial.",
	"content": " Have you ever stopped to think about what the chain of events was that led you to a particular decision? Maybe not, but in web analytics it is something that should be considered. After all, there is something counter-intuitive about analytics tools such as Google Analytics, which require us to think in terms of clicks and recorded events that occur on the website, during the visit.\nThankfully, we have evolved as a species, and we no longer place too much emphasis on last click attribution. In short, last click attribution is a model where success of a particular goal is attributed to the conditions underlying the active session. So if a person visits a page via bookmark and downloads a PDF file on that page, the direct visit channel (which covers, by default, bookmarked visits) is the only one which receives the kudos for the file download. Nothing is attributed to other channels, which might have exposed the user to the brand, the product, and the file itself. Ridiculous, right? R.I.P. last click attribution!\nNow, if you read the first paragraph, then continued onto the second paragraph, and you\u0026rsquo;ve respected the basic tenets of literacy by moving onto this, the third paragraph, you might already know where I\u0026rsquo;m going with this preamble. We have entered the age of attribution modeling, where we try to right the wrongs inherent in these tools by affording a certain slice of the attribution pie to all the channels that participated in the conversion. This is vital, since it approaches a more acceptable level of realism, as it models actual human interaction with all the various channels which bring traffic to your site. Check Avinash Kaushik\u0026rsquo;s nice introduction to the topic here.\nHowever, this post is not about attribution modeling, at least in the sense we\u0026rsquo;ve come to learn by using these tools. No, this goes deeper into the murky depths of web analytics.\nClickstream context In web analytics, the clickstream is what we measure. It\u0026rsquo;s the collection of hits, events, variables, pageviews, transactions, etc. that make up the traffic of a website. Data for the clickstream is traditionally collected by adding client-side code (JavaScript, most often) to the website, tagging elements which produce added value to the analysis, and annotating each visit with custom variables and such.\nI tell you, this is a flawed approach. Are you familiar with the Observer\u0026rsquo;s Paradox, outlined by William Labov?\nThe aim of linguistic research in the community must be to find out how people talk when they are not being systematically observed; yet we can only obtain this data by systematic observation. Now transport this idea into the realm of clickstream analytics. Here\u0026rsquo;s the gist: when we tag our website, we are injecting our own, a priori hypotheses into the analysis, thus making it less an objective observation of traffic and more a filtered, premeditated peek through a keyhole. Conversely, we should be expanding our horizons to the infinite mass of possibility that each visit entails. How do we know that tagging contact form X is the best possible dimension to measure, when thinking of business goals? Actually, how do we ever know what to tag?\n  Image courtesy of minifig\nThe problem lies in context. We have absolutely no idea what brought the visitor to make a specific decision. Sure, we can look at our tags and surmise that visitor A visited landing page B via channel C and brought a conversion to goal D. Once we have enough As, Bs, Cs and Ds, we can hypothesize that this is a recurring trend. Emphasis on enough and hypothesize.\nToo few marketing professionals and analysts really question the fact that we are working with samples, and all we ever can do is hypothesize. Not respecting this point can lead to terrible decisions. Being too lazy to look beyond standard reports of a web analytics tool is another thing that\u0026rsquo;s killing creativity in analytics, and creativity is the very thing that\u0026rsquo;s called for here.\nUncovering context There\u0026rsquo;s so much buzz out there around Big Data these days. The buzz is there for a reason. We have the capacity, the processing power, and the insight to work with copious amounts of data, so all we need to do is extend this to traditional web analytics as well.\nMeasure everything! That\u0026rsquo;s the dream. Observe the clickstream as an unfiltered mesh of all the measurable actions performed by an identified visitor. No more a priori tagging, no more injecting your own notions of a successful visit into data collection, no more messing with the data before it reaches you. Server logs are already out there, with all the requests made to the server during each visit. Spice the data with information on mouse movement, scroll depth and speed, heat charts, empty clicks (i.e. clicks that didn\u0026rsquo;t result in an action, such as clicking an image you thought was a link but wasn\u0026rsquo;t), browser controls (such as clicking the back-button or adding a bookmark), etc. That\u0026rsquo;s what I call data!\nWhen we have access to the raw performance of a website, we can then use the tools to dissect it, analyze it, observe it (in real time as well), play with it, filter it, integrate it, export it, and make actual, informed decisions with it.\nBeyond the clickstream Let\u0026rsquo;s go back to the very first sentence of this post.\nHave you ever stopped to think about what the chain of events was that led you to a particular decision? A wise reader has undoubtedly already grumbled about the fact that I only focus on on-site clicks and hits in all of the above. And you are right.\nContext is not just something that can be measured on-site. There\u0026rsquo;s a world out there, if you haven\u0026rsquo;t noticed, full of stimulation. Any number of things might affect your decision to make a purchase in an eCommerce store: You might have just broken your phone and you need a new one, you might win the lottery, or there might be some nasty weather outside and you want to fly somewhere warm.\nIn traditional tagging, creativity was most often channeled to the question of \u0026ldquo;What on-site element should I tag next?\u0026rdquo;. If we measure everything in our clickstream, we can divert our creativity to the wealth of external context that underlies our on-site decisions. Want to understand why so many people are visiting your investor site at odd times? Tap into a financial API and use your stock price fluctuation as the trigger. Want to know if weather affects visitors\u0026rsquo; decisions in your eCommerce store? Annotate the visits with the weather conditions of the visitor\u0026rsquo;s location! There are so many things you can measure out there. You are only limited by your creativity and available technology to support your needs.\nWhere to next I\u0026rsquo;d love to hear if there are solutions for measuring everything out there.\nMeanwhile, there\u0026rsquo;s so much of this \u0026ldquo;external\u0026rdquo; context that you can start measuring. Take a long look through this API Directory, and see if you can find something that you want to measure.\nAnd remember this mantra: Context is King! Measure Everything!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/universal-analytics-send-custom-dimension-event/",
	"title": "Universal Analytics: Send Custom Dimension With Event",
	"tags": ["custom dimension", "event", "google analytics"],
	"description": "To make the most of your Google Analytics tracking, you can send Custom Dimensions with non-interaction events simply to add session- and user-scoped custom dimensions to your data.",
	"content": " (Last updated March 2014) This post is the final chapter of a trilogy. The ultimate refinement, if you will. It all started with my foray into the murky waters of context, when I tested how weather data could be used to provide extra information about site visits. When I wrote that post, I had two trepidations: 1) does sending the API call with every single page view affect site performance negatively, and 2) does forcing the page view call to wait for the API call to complete affect the quality of visit metrics.\nI fixed (1) to my satisfaction in a later post on utilizing a custom cookie to make the API call just once per session. This meant that site performance improved, since the API call (which might take up to 500ms) is done just once per visit. Also, it has a positive effect on visit calculation, since the possibility of the page view call failing to complete due to problems in the chain of events is minimized.\nHowever, I was still not happy with having any code executed before the page view, because page views are something you don\u0026rsquo;t want to compromise due to, for example, problems with a third-party API (such as the weather API).\nSo I did what I should have been doing all along.\nCustom dimensions can be sent with events as well Here\u0026rsquo;s a little background. I have a script which polls a weather API, with the visitor\u0026rsquo;s location as the parameter. The script collects the weather conditions of said location, and passes them to a visit-scope custom dimension, which is then sent to Google Analytics.\nA custom dimension scoped for visits (or sessions) means that you just have to send it once per visit. All subsequent and previous hits (page views, events, transactions) of the visit are annotated with the dimension as well. Naturally, it\u0026rsquo;s a no-brainer to thus send the dimension just once per session, hence the need for a custom cookie (again, see this post).\nAlso, since you can send the same custom dimension with an event, why even use a page view? A non-interaction event does the same thing PLUS you can compare the number of weather events and visits from the same time period to see if there are discrepancies which indicate problems with the API call.\nAnother perk, if using GTM, is that you don\u0026rsquo;t need separate, confusing page view tags (one with the weather dimension, one without), but rather you can have your basic page view tag for tracking and an event tag for sending the weather data (which fires only when the API call is made).\nImplementation Well, I need to refer back to the code from my previous two posts. Here\u0026rsquo;s what the NEW custom HTML tag should look like (remember, you need to load jQuery and the geoPlugin service for this to work).\n\u0026lt;script\u0026gt; if (typeof({{Session alive}}) == \u0026#34;undefined\u0026#34;) { var lat = geoplugin_latitude(); var lon = geoplugin_longitude(); var weather = \u0026#34;\u0026#34;; var weatherAPI = \u0026#34;http://api.openweathermap.org/data/2.5/weather?lat=\u0026#34;+lat+\u0026#34;\u0026amp;lon=\u0026#34;+lon; $.ajax({ type : \u0026#34;POST\u0026#34;, dataType : \u0026#34;jsonp\u0026#34;, url : weatherAPI + \u0026#34;\u0026amp;units=metric\u0026amp;callback=?\u0026#34;, async : true, success : function(data) { weather = data.weather[0].main ; dataLayer.push({\u0026#34;weather\u0026#34;: weather}); },error : function(errorData) { console.log(\u0026#34;Error while getting weather data :: \u0026#34;+errorData.status); dataLayer.push({\u0026#34;weather\u0026#34;: \u0026#34;Undefined\u0026#34;}); },complete : function() { dataLayer.push({\u0026#34;event\u0026#34;: \u0026#34;weatherDone\u0026#34;}); } }); } var d = new Date(); d.setTime(d.getTime()+1800000); var expires = \u0026#34;expires=\u0026#34;+d.toGMTString(); document.cookie = \u0026#34;session=1; \u0026#34;+expires+\u0026#34;; path=/\u0026#34;; \u0026lt;/script\u0026gt; Here\u0026rsquo;s the order of events:\n Check if a cookie named \u0026ldquo;session\u0026rdquo; exists\n If cookie doesn\u0026rsquo;t exist, use the visitor\u0026rsquo;s location to query the weather conditions at said location\n Save weather conditions in data layer variable \u0026ldquo;weather\u0026rdquo;\n Push event \u0026ldquo;weatherDone\u0026rdquo; to data layer whether or not the API call is successful\n Finally (regardless of whether the cookie existed or not) reset the \u0026ldquo;session\u0026rdquo; cookie to expire in 30 minutes\n  So no need for a second event \u0026ldquo;noWeather\u0026rdquo; for the weatherless page view. You can just have the normal page view sent with every page load, and then use \u0026ldquo;weatherDone\u0026rdquo; as the trigger rule for the event (remember to make it a non-interaction hit) which sends the \u0026ldquo;weather\u0026rdquo; variable as a custom dimension. Dead simple.\nFinally, you\u0026rsquo;ll need to set up your event tag. Remember, you need to create the custom dimension in Google Analytics\u0026rsquo; admin section (see here for a guide). Make note of the index number assigned to your new, session-level custom dimension.\nNext, create a new event tag. Now, you can have whatever you want as your event fields, but make sure that Non-Interaction Hit is set to True. In this example, I send my custom weather type and temperature (they\u0026rsquo;re data layer variable macros), but as you can see, Non-Interaction Hit is True. This is important, because then this weather event won\u0026rsquo;t affect bounce rate calculation (because it doesn\u0026rsquo;t tell anything about engagement now, does it?).\n   And here\u0026rsquo;s what the custom dimension settings look like. You set them in the end of the tag, under More settings.\n  Conclusion I think I\u0026rsquo;ve got the whole thing pinned down now. I have come up with a method to\n poll external APIs for contextual information\n send this information just once per visit\n use a non-interaction event to annotate the visit hits with this dimension\n  Next steps would be to make sure the API is reliable and fast. Also, maybe some sort of timeout trigger for the API call should be in place, with a \u0026ldquo;weather\u0026rdquo;: \u0026ldquo;Undefined\u0026rdquo; value sent if the API call doesn\u0026rsquo;t complete.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/universal-analytics-fire-script-just-per-session/",
	"title": "Universal Analytics: Fire Script Just Once Per Session",
	"tags": ["cookie", "google analytics", "Google Tag Manager", "JavaScript", "universal analytics"],
	"description": "Guide for creating a cookie that emulates Google Analytics sessions. The purpose is to use it to delimit specific Google Tag Manager tags to fire only once per GA session.",
	"content": " There is a new version of this post for GTM V2 here.\nWhile going over my previous post about using weather conditions to segment data in Google Analytics, I started thinking about performance issues. Since I\u0026rsquo;m using a visit-scope custom dimension, it seems futile to have it send the weather details with every single page load. The odds of the weather changing drastically during one visit are slim (unless you live in the UK), and I have yet to come up with a good reason to change my on-site behavior because the weather changed from a drizzle to a downpour.\nWith Universal Analytics, it\u0026rsquo;s not possible to mine session data from the cookie set by the service. This is because the custom client ID set by the cookie is \u0026ldquo;later used by Google Analytics servers to calculate visitor, session, and campaign data.\u0026rdquo; (emphasis mine; see the developer guide). This is relevant because I want my custom JavaScript to only fire once, at the beginning of a session (visit). I have no way to use the _ga-cookie since, as stated above, it calculates session data in the bowels of Google Analytics servers.\nTo overcome this problem, I create a custom session cookie, which mimics the default properties of the Google Analytics cookie mainly in that it expires after 30 minutes of inactivity as well.\nDo note that this is not a 100 % accurate emulation of how Google Analytics calculates sessions. The cookie doesn\u0026rsquo;t take into account changing campaign sources which, by default, always initiate a new session in Google Analytics. Preliminary research shows that the accuracy is around 95 %, though I\u0026rsquo;m getting some missed hits to the Open Weather API as well, which means that the cookie is actually even more accurate.\nHow it works I\u0026rsquo;m trying to be generic here, but I will use a real-life example from the weather script I created previously.\nHere\u0026rsquo;s how the implementation basically works:\n When the visitor comes to the site, my script searches for a cookie named \u0026ldquo;session\u0026rdquo; using Google Tag Manager\u0026rsquo;s Session macro\n If the cookie exists, it means that a session is still active and no code is executed but for a reset of the cookie expiration time\n If the cookie doesn\u0026rsquo;t exist, it means that the session has expired, and in this case I run the weather code and then create the cookie\n  If you try to create a cookie which already exists, it overwrites the original cookie. This is why I can use the same cookie setup code for both (2) and (3) above.\nSince it\u0026rsquo;s a first-party cookie, and since it\u0026rsquo;s set on the root path of the site (/), there\u0026rsquo;s no risk of overwriting any other cookies (unless some other site plugin has a cookie named \u0026ldquo;session\u0026rdquo;).\nThe cookie code My original weather tracking solution fired on every single page load. This creates quite a burden on the API as well as site performance (since it might take almost half a second for the API script to fire). My new code looks like this:\n\u0026lt;script\u0026gt; if (typeof({{Session alive}}) == \u0026#34;undefined\u0026#34;) { // Weather tracking code here  } var d = new Date(); d.setTime(d.getTime()+1800000); var expires = \u0026#34;expires=\u0026#34;+d.toGMTString(); document.cookie = \u0026#34;session=1; \u0026#34;+expires+\u0026#34;; path=/\u0026#34;; \u0026lt;/script\u0026gt; As you can see, the old code is only run if the macro {{Session alive}} is undefined, i.e. the cookie doesn\u0026rsquo;t exist.\nCreating the macro is dead simple:\n Create new macro called \u0026ldquo;Session alive\u0026rdquo;\n Set Macro Type 1st Party Cookie\n Set Cookie Name \u0026ldquo;session\u0026rdquo;\n    So what you do here is create a macro which returns the \u0026ldquo;session\u0026rdquo; cookie value. Whenever this macro is referenced to in code, you are actually using the cookie value.\nWhen I poll for this cookie in the code above, I\u0026rsquo;m actually only interested in whether this cookie exists or not. That is why I use the if(typeof({{Session alive}}) == \u0026ldquo;undefined\u0026rdquo;) structure. If the cookie doesn\u0026rsquo;t exist, the macro has no reference, which means that it is an undefined structure.\nFinally, regardless of whether the cookie was found or not, a cookie named \u0026ldquo;session\u0026rdquo; is created with an expiration date 30 minutes in the future (1 800 000 milliseconds later).\nPros and cons Well obviously, having the cumbersome API call fire just once per session is a victory for site performance and for \u0026ldquo;best practices\u0026rdquo; analytics. Because I already have a visit-scoped dimension, it would be counter-intuitive to send it with every single page view hit.\nThe main problems, as I see them, have to do with maintenance. If you have a custom expiration time for the GA session, you need to remember to modify the expiration date (now 1800000 milliseconds) in the \u0026ldquo;session\u0026rdquo; cookie as well, if you want it to mimic Google Analytics performance. Also, if you already have a cookie named \u0026ldquo;session\u0026rdquo; firing on your site, you need to change this one\u0026rsquo;s name.\nOne more problem was discussed in the opening paragraphs of this post. This is not a 100 % accurate emulation of Google Analytics session computation, so you will have a slight margin of error in the number of visits with weather as a dimension vs. the number of visits to your site. Feel free to explore how to make calculating a GA session even more accurate, and drop me a line if you find something interesting :)\nI would really like it if I could bind my code to the actual _ga-cookie, but as far as I know, that\u0026rsquo;s not possible.\nEDIT: See this post on sending custom dimensions with events for a smarter implementation of the idea above.\n"
},
{
	"uri": "https://www.simoahava.com/web-design/how-to-not-make-a-splash/",
	"title": "How To (Not) Make A Splash",
	"tags": ["analytics", "JavaScript", "SEO", "splash page"],
	"description": "Rant about splash pages and the how they can be done so extremely poorly.",
	"content": " A word of warning. This is not a developers\u0026rsquo; post, a guide, or a thought experiment. This is a bona fide rant. Sometimes we just need to vent.\nA couple of weeks ago, I checked one of our (inactive) client\u0026rsquo;s Google Analytics accounts I still had access to. What I saw in the acquisition report was this:\n  See how direct traffic gobbles up a great big share of organic traffic in late October?\nAs my fingers tingled with the anticipation of yet another web analytics mystery (the fuel that keeps my engines going), I was overcome with a feeling of dread. I knew for a fact that there had been a site redesign at the time (which is part of the reason I checked the account), and I had originally had some concerns with the technical implementation.\nAnyway, when one metric falls and another rises with an observable correlation, there\u0026rsquo;s usually something very wrong with site tracking. On top of that, if the fluctuation involves direct traffic, the problem is usually related to referral data being overwritten for some reason.\nWhen I went to take a look at their site, the problem became too apparent. A splash page was present. And, to make matters worse, some shoddy JavaScript reared its ugly head.\nThe problem with the splash A splash page is a screen that the visitor sees prior to entering the website. It\u0026rsquo;s been a pain for SEO and usability for a long time (see e.g. this splash page rant from 2010, or this more recent one). It introduces an unnecessary step into the conversion path, it usually caters to the wrong crowd for all the wrong reasons, and if there\u0026rsquo;s any kind of variable visibility involved (like checking for cookies or language settings), the JavaScript redirection might just be done in the wrong way.\nI know this rant is about the splash page, but I just can\u0026rsquo;t help myself. Why is JavaScript a free-for-all programming ride, where there really are no consequences for shoddy workmanship? What\u0026rsquo;s wrong with quality assurance even with major companies, where the code that gets published is riddled with performance problems, security issues, and over-complicated syntax? Global variables are being overwritten with abandon, errors are not caught and handled, references are outdated, and pushing all this crap into a library just makes the issue exponentially worse when the library is pushed to public repositories.\nIn the case of the client\u0026rsquo;s account, the splash page was used as a country / language selector. Now, I consider that to be a moderately acceptable reason for hijacking the visit, but I\u0026rsquo;m willing to bet there\u0026rsquo;s a better way to do it. Instead of imposing a selection screen, which in itself is a turn-off for anyone who just wants to get to the site, why not do an IP redirection based on geolocation, with a visible but unobtrusive way of indicating why the visitor was transported to the version they\u0026rsquo;re seeing? Maybe a small banner at the top of the page, which can be closed with a click. Of course, the banner should also have a quick link menu, with which the visitor can go to the correct version, if they were redirected wrong.\nSo what was wrong with the example? Why yes, I sidetracked a little. The problem was that upon entering the main page of the global site, a JavaScript function checked whether or not the user had a country cookie in their browser. This cookie is downloaded once the user chooses a country from the country selector, or visits a local site directly. If the cookie is not in place, they are redirected (with JavaScript again) to the splash page.\nThat\u0026rsquo;s right. A JavaScript redirection. Anyone with even the slightest knowledge of SEO and web analytics best practices is now permitted to shudder. Here\u0026rsquo;s the kicker:\nIf you do a JavaScript redirection before GA has a time to write the visit cookie, you lose the original referral information.\nYou see, because the GA tracking code doesn\u0026rsquo;t have time to load before the redirection is fired, the referral information is not written to the session cookie. This means that the first time the referral information is recorded is after the redirection, when the user enters the splash page (if it has tracking enabled). Because the original referral information is lost, the session is recorded as originating from direct traffic. Direct traffic is notorious for being the dumping ground for all sorts of undefined traffic sources. In essence, a JavaScript redirection which does not include the referral information throws away a key ingredient of understanding how your traffic channels perform.\nHow to avoid the problem If you want the redirection, your best bet is to let Google write the session cookie on the front page before the redirection. Note! If the redirection is to another domain, you will need to implement cross-domain decoration for the redirect URL!\nThe best solution, by far, is to redesign your site structure so that a splash page is not needed. Here are some ideas:\n IP redirection based on geolocation. Just remember to help those out who are redirected wrongly, or you\u0026rsquo;ll have an even bigger problem on your hands Integrate the country selector into the flow of your main site without a splash page Optimize your country sites so that people find them without having to go through your global site  "
},
{
	"uri": "https://www.simoahava.com/analytics/google-tag-manager-track-social-interactions/",
	"title": "Google Tag Manager: Track Social Interactions",
	"tags": ["custom html", "Google Tag Manager", "social interactions", "universal analytics"],
	"description": "Use social plugins&#39; own APIs to track social interactions in Universal Analytics.",
	"content": " (Last updated June 2014) Google Analytics provides us with a nifty way of tracking social interactions. With a simple plugin, you can track how many +1s and Likes your pages accumulate.\nThis guide shows you how to activate social interaction tagging with Google Tag Manager and Universal Analytics. The instructions are for Facebook Likes, Google+ +1s (now deprecated since Google Analytics tracks +1s automatically), Twitter Tweets and Pinterest Pins.\nNote that if you use a third-party API (e.g. AddThis) these tricks probably won\u0026rsquo;t work. You\u0026rsquo;ll need to use the API functions themselves to enable tracking.\nSetting up social interaction macros Well, first of all, you\u0026rsquo;ll need a bunch of macros to collect the data from your social actions.\nSo let\u0026rsquo;s start with Google Tag Manager.\nSteps:\n Create a new container version Create a new macro of the Data Layer Variable persuasion, and name it Social network Add socialNetwork as the variable name Save the macro     Create a new Data Layer Variable macro, and name it Social action Add socialAction as the variable name Save the macro Create a new Data Layer Variable macro, and name it Social target Add socialTarget as the variable name Save the macro  So now you created three important macros, all making it easier for to track social interactions via Google Tag Manager. Network will pass the name of the social network the action belongs to (e.g. Facebook), Action will pass the name of the action performed (e.g. Like), and Target will pass the name of the page the action occurred on (e.g. http://www.example.com/post1).\nSetting up the send tag For social interaction events to appear in Google Analytics, they need to be sent (d\u0026rsquo;oh again). To send a social interaction, you need to create a tag which will have the macros we just created as its arguments. This tag is then set to fire upon a social action.\n Create a new Universal Analytics tag Give it a name (such as Send social) Add your tracking ID (it\u0026rsquo;s best to store it as a macro) Choose Social as the Track Type Add your macros as the arguments (see image below for clues) Set {{event}} equals socialInt as the firing rule (we\u0026rsquo;ll come back to this soon) Save tag    Here we create a new tag which houses the arguments the social interaction will have. The firing rule is primed to wait for an event called socialInt, which we\u0026rsquo;ll send from our social action tags.\nSet up Facebook like   I will not go into how to add a Facebook like button to your page, you\u0026rsquo;ll have to do that yourself. Facebook has a great guide and tool behind this link which will help you create the necessary code.\nHowever, once you have your button in place, you need to somehow track the clicks. This is done by using a callback function. A callback is a function which is run immediately after an event has completed.\nHere\u0026rsquo;s how to create the callback function in GTM.\nSteps:\n Create a new Custom HTML tag (or use a single tag for all your social share callbacks) Give it a name (e.g. Social Shares) Add the following code:  \u0026lt;script\u0026gt; if (typeof FB !== \u0026#39;undefined\u0026#39;){ FB.Event.subscribe(\u0026#39;edge.create\u0026#39;, function(href) { dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;socialInt\u0026#39;, \u0026#39;socialNetwork\u0026#39;: \u0026#39;Facebook\u0026#39;, \u0026#39;socialAction\u0026#39;: \u0026#39;Like\u0026#39;, \u0026#39;socialTarget\u0026#39;: href }); } ); } \u0026lt;/script\u0026gt;  Set to fire after DOM has been loaded ({{event}} equals gtm.dom) Save tag  OK, so here\u0026rsquo;s your Facebook Like callback function. Upon clicking the Like button, this function is called. Before control is returned to the page, the trigger event for the Send Social tag (socialInt) is pushed into the data layer. After that, the three required arguments are passed along as well. The value for socialTarget is href, which is one of the parameters of the callback function, and it represents the URL of the page the event occurred on.\nBy using FB.Event.Subscribe, you can listen to a number of different events (e.g. message send, login). Check the available options in the Facebook dev guide.\nSet up Google +1   UPDATE: Note that this is pretty much obsolete now, since Google Analytics and Universal Analytics both track +1s automatically.\nAgain, I\u0026rsquo;m not going to tell you how to add the button to your page. It\u0026rsquo;s dead simple, and you can find a good guide here.\nWith Google+, you need to specify the callback as an argument in the button tag. With Facebook this was automated. Note that there are a number of events for which you can specify a callback: clicks, interaction starts (when someone hovers or clicks the button) and interaction ends (when someone closes the +1 bubble). I just chose the click since it\u0026rsquo;s the simplest way to track (though a tad inaccurate).\nI chose sendPlus as the callback function name. A sample button code would then be:\n\u0026lt;g:plusone href=\u0026#34;http://example.com\u0026#34; size=\u0026#34;standard\u0026#34; annotation=\u0026#34;none\u0026#34; callback=\u0026#34;sendPlus\u0026#34;\u0026gt;\u0026lt;/g:plusone\u0026gt; Note that the developers\u0026rsquo; reference has the callback as data-callback, but this seems to work as well.\nNow to set up the callback function.\n Create a new Custom HTML tag (or use a single tag for all your social callbacks) Give it a name (e.g. Google Plus One) Add the following code:  \u0026lt;script\u0026gt; function sendPlus(g) { dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;socialInt\u0026#39;, \u0026#39;socialNetwork\u0026#39;: \u0026#39;Google\u0026#39;, \u0026#39;socialAction\u0026#39;: \u0026#39;+1\u0026#39;, \u0026#39;socialTarget\u0026#39;: g.href }); }; \u0026lt;/script\u0026gt;  Set to fire on all pages ({{url}} matches RegEx .*) Save tag  It\u0026rsquo;s basically the same as with Facebook.\nThis callback function hijacks the +1 button click and sends the necessary stuff to datalayer before returning control back to the page.\nSet up tweets   To set up a Tweet callback function, you\u0026rsquo;ll need to make use of web intent events. They add additional JavaScript functionality (such as the option to declare a callback function) to your Tweet button.\nInitialize the Twitter widgets with the following code in your HEAD element:\nwindow.twttr = (function (d,s,id) { var t, js, fjs = d.getElementsByTagName(s)[0]; if (d.getElementById(id)) return; js=d.createElement(s); js.id=id; js.src=\u0026#34;https://platform.twitter.com/widgets.js\u0026#34;; fjs.parentNode.insertBefore(js, fjs); return window.twttr || (t = { _e: [], ready: function(f){ t._e.push(f) } }); }(document, \u0026#34;script\u0026#34;, \u0026#34;twitter-wjs\u0026#34;));  You don\u0026rsquo;t have to make any modifications to your Tweet button code (providing it\u0026rsquo;s not implemented via a third-party API, such as AddThis.\nIn your social share Custom HTML tag, add the following code:\nif (typeof twttr !== \u0026#39;undefined\u0026#39;) { twttr.ready(function (twttr) { twttr.events.bind(\u0026#39;click\u0026#39;, clickEventToAnalytics); }); } function clickEventToAnalytics() { dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;socialInt\u0026#39;, \u0026#39;socialNetwork\u0026#39;: \u0026#39;Twitter\u0026#39;, \u0026#39;socialAction\u0026#39;: \u0026#39;tweet\u0026#39;, \u0026#39;socialTarget\u0026#39;: window.location.href }); }  Here you bind the CLICK event to function clickEventToAnalytics. There are a bunch of different events at your disposal, and you can find them in the developers\u0026rsquo; documentation.\nNote how I use the global JavaScript variable window.location.href as the target this time.\nSet up Pinterest Pin It Pinterest is a bit problematic, since when you load the pinit.js script, it replaces any code you may have used in the link tags. This is problematic because Pinterest doesn\u0026rsquo;t provide any callback functions, so the social share push would need to be added directly to the link code. With pinit.js, any modifications you do are erased upon page load.\nHowever, you can get your pins tracked using auto-event tracking. With a Link Click Listener in place, create a Custom HTML Tag with the following content:\n\u0026lt;script\u0026gt; dataLayer.push({\u0026#39;event\u0026#39;: \u0026#39;socialInt\u0026#39;, \u0026#39;socialNetwork\u0026#39;: \u0026#39;Pinterest\u0026#39;, \u0026#39;socialAction\u0026#39;: \u0026#39;Pin It\u0026#39;, \u0026#39;socialTarget\u0026#39;: window.location.href}); \u0026lt;/script\u0026gt; The firing rule for this is:\n{{event}} equals gtm.linkClick\n{{element classes}} contains pin_it_button\nSo once the Pin It button is clicked (the link has \u0026ldquo;pin_it_button\u0026rdquo; in its long list of class names), this custom HTML tag pushes the event into the data layer, after which your social share event tag is fired.\nTest implementation So now you have your callback functions which provide the data, the macros which store the data, and the Universal Analytics tag which sends the data. Wonderful!\nSave your container version and publish it.\nNow go to a page on your site where the buttons can be found. Use a debugger like Firebug, or Chrome\u0026rsquo;s Developer Tools, and load the page. Pay attention to the Network tab in your debugger, and click Like or +1. You should see something happening, namely a GET request to www.google-analytics.com. Check out the headers of this request, and you should see something like this:\n  Here you can see the query parameters.\nsa is Social Action (Like)\nsn is Social Network (Facebook)\nst is Social Target (URL of the page)\nOf course, don\u0026rsquo;t forget to check Google Analytics itself (it might take some time for the data to appear).\n  "
},
{
	"uri": "https://www.simoahava.com/analytics/universal-analytics-grab-offline-data-excel/",
	"title": "Universal Analytics: Grab Offline Data From Excel",
	"tags": ["excel", "universal analytics"],
	"description": "Script and tools to send offline data from your Excel report to Universal Analytics.",
	"content": " UPDATE 9 Oct 2013 - This works in Google Spreadsheets now as well! Feel free to make a copy of the sheet and work with the code. It\u0026rsquo;s still just a prototype, but I\u0026rsquo;m happy to see data bouncing from spreadsheets to Google Analytics.\nView the Google Spreadsheet here\nORIGINAL POST Inspired by Daniel Waisberg\u0026rsquo;s excellent post detailing the use of Google Web Forms to send data to your Analytics account, I decided to create something similar.\nIf you didn\u0026rsquo;t know already, Universal Analytics is the new version of Google Analytics, and the Measurement Protocol is its heart and soul. The protocol serves as an endpoint for raw visit data, which can be pushed from any service, application, or interface equipped to send HTTP requests. In this post, I\u0026rsquo;ll introduce you to a prototype of a Microsoft Excel extension I\u0026rsquo;ve been working on. With the extension, you can push data from Excel back to your account. By using carefully labelled events and by extracting the client ID from the online visit, you can combine offline and online data together in Google Analytics.\nWithout further ado, I give you: the journey of the coupon.\nThe premise Let\u0026rsquo;s say we have a traditional brick-and-mortar store, which wants to award its regular customers with something special. So they send an e-mail with a link to a page, where the user can download a special coupon, with which they can get a pack of coffee for 5 euros. Incredible deal!\nSo the user goes to the page and sees this on the phone (of course they used a mobile device!).\n  Yes, I know it looks like phlegm, but like I said, this is a prototype!\nWhen they press the button, this happens:\n  And, as the button is pressed, this happens in Google Analytics:\n  So what happened?\nWhen the user clicks the button, they receive the coupon code. In reality, the coupon code is the user\u0026rsquo;s client ID, which is a variable Universal Analytics uses to identify the client. In essence, all events, transactions, pageviews etc. done by this client ID are always registered to the same unique visitor. Because it\u0026rsquo;s so easy to get (just a simple function), I chose the variable to anchor the data.\nAfter the button is clicked, an event is sent to Google Analytics with the label get-coupon. The action is always the coupon code (the client ID), which can then be used to categorize the events nicely.\nTrip to the store So now the user has the coupon code on their mobile phone. Next, she heads on down to the store.\nShe chooses two cans of Coffee Java (a delicious brand), which each cost just 5 euros each, thanks to the coupon.\nShe goes to the checkout, gives the coupon, thanks, and leaves.\nWhen registering the sale, the cashier types down the coupon code the customer showed.\nAt the end of the day, the cashier fills the obligatory Microsoft Excel worksheet with the transaction details for the day.\nI have no idea what these systems look like in reality, but in my wicked dreams I saw something like this:\n  Here you have basic information, which can be exported from any backend system. We have the transaction details for each transaction (just one for the day, how sad!). Under each transaction are the items that were purchased in that one transaction.\nEach transaction can have a coupon code attached to it.\nThere\u0026rsquo;s also the basic information required for Universal Analytics (namely, the tracking ID).\nUpon checking the details and clicking the Big Blue Button, these three message boxes pop up one after another:\n      I\u0026rsquo;ve actually bound the button to a custom macro, which sends the HTTP POST request to Google Analytics. First, an event is sent, to link the coupon use to the coupon download that was processed earlier. Next, the transaction details are sent, and finally, the item is pushed through the API to Google Analytics.\nThe end result First of all, we can see that the coupon code has both get-coupon and use-coupon events attached to it:\n  Also, we can see that the transaction was registered as well:\n  And finally, with a custom report, we can display a number of things. First, each coupon is associated with just one unique visitor, so the client ID really works! Also, we can quickly see whether some coupons were used in transactions by looking at the Revenue column:\n  Conclusions This was, and I hope I made it clear, just a prototype. But it shows the power of the Measurement Protocol. You can send visit data (pageviews, events, transactions, you name it) from almost any digital source equipped with some scripting language which supports sending HTTP POST requests!\nUsing the client ID has its pros and cons. Basically, with the one device, only one coupon can ever be downloaded and used, since the client ID is always the same. But the user only has to switch to another device, and a new client ID is generated. So some other checks need to be in place to make sure that the system is not abused.\nAlso, and this is a major problem with the Measurement Protocol:\nYou can\u0026rsquo;t attach a custom timestamp to hits!\nThis means that in order to preserve at least some level of accuracy, the events should be sent from Microsoft Excel at the end of the day the transaction occurred. This is the only way to make sure that the transactions are registered on the correct date. I see this as a major shortcoming, and I hope a timestamping feature is introduced in a future version.\n(Queue Time will not do, as it can only introduce a time lag which stretches no further than four hour past midnight of the day when the event is sent)\nI\u0026rsquo;m looking forward to expanding the features of the Excel extension. It should be possible to send heaps of transaction data with one button press, as now the macro only supports one item, one transaction, and one coupon event.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/troubleshoot-google-analytics-9-step-program/",
	"title": "Troubleshoot Google Analytics: 9-Step Program",
	"tags": ["google analytics", "Guide", "troubleshoot"],
	"description": "A step-by-step process for troubleshooting Google Analytics implementations.",
	"content": " I\u0026rsquo;ve had such a blast in the Google+ Google Analytics community. Not only are the people super-duper-nice, but I have the wonderful opportunity of helping people with their Google Analytics problems without feeling obligated to invoice them or ask for compensation for my troubles. I do it because I love to help, because I feel like I have a lot to share with the community, and because I\u0026rsquo;ve always believed that the more knowledge you share the more you accumulate.\nInspired by the sheer range of problems people have with Google Analytics, which is, in reality, a very complex tool, I decided to write a general guide where I reveal some of my own methods on how to troubleshoot Google Analytics. I almost always follow these steps, and if you give this data rehab program a try, chances are you\u0026rsquo;ll be more secure with your data in the future.\n  Before we begin Remember a few things:\n1. GA displays symptoms, not actual problems.\nWeb analytics tools measure data in your marketing channels. They don\u0026rsquo;t create data, nor do they feed anything back into the site. This means that when your boss comes storming into your room screaming “What the f*** is the problem with this report?” you\u0026rsquo;ll need to tell the boss that the report just visualizes the problem, and you need time to get to the bottom of it.\n2. Every account is unique, every problem is unique\nI\u0026rsquo;ve tried to be as comprehensive as possible, while still being as generic as possible. The thing is that most problems, if not purely technical in nature, have something to do with the business area you operate in. Fluctuations in your market segment, media exposure, new product launch, viral content are all possible causes behind the things you see in your reports. In those cases, remember to approach the data as the business expert. Don\u0026rsquo;t just trust any crazy blogger who gives you tips on how to fix everything.\n3. Be careful with your data.\nTROUBLESHOOT GOOGLE ANALYTICS ASSESS\nStep 1: Evaluate the problem Step 2: Gather data\nACT\nStep 3: Cover your bases Step 4: Test and release\nVALIDATE\nStep 5: Check the DOM Step 6: Check requests Step 7: Check Real-Time\nMONITOR\nStep 8: Assess Step 9: Optimize\nBONUS Step 10: When all else fails\nASSESS During assessment, you gather as much data on the problem and its symptoms as possible. Be thorough, and make sure you look at the problem from all angles, not just the ones you\u0026rsquo;re used to.\nStep 1: Evaluate the problem\nFirst thing you have to do is narrow the problem down.\n  In this example, conversions fell dramatically in July, and they never got back up. You already know the symptoms, so start following the chain backwards. For example, if your conversion rate is down,\n Look at the channels which drive conversions\n When looking at the channels, focus on engagement and visitor behavior: has something changed in how people use your site at the same time the conversion rate has gone down?\n Once you know the behavior, look at traffic sources\n Finally you should be able to draw a line from traffic sources, through behavior, all the way to conversions\n  So if the symptom is a gradual change in your data, make sure you understand the visitor journey completely.\nHowever, if the symptoms are more drastic (traffic cut off completely, for example), there\u0026rsquo;s bound to be some technical issues involved.\nAll in all, try to narrow the issue down so that you can describe it with one sentence, e.g.\nThe symptom is that conversion rate for Goal X has fallen dramatically while traffic has stayed the same Here are a couple of leads to follow:\nVery little or no incoming data at all\n Troubleshoot your tracking code\n Make sure you migrated to Universal Analytics properly\n Check if there\u0026rsquo;s a bug in Google Analytics\n Determine if you\u0026rsquo;re accidentally running traditional Google Analytics code (search for “_gaq”) with Universal Analytics in place (search for “analytics.js”, though this doesn\u0026rsquo;t apply with Google Tag Manager)\n  Abnormal data\n Determine if it\u0026rsquo;s a sampling issue\n Identify bounce rate problems with this helpful article\n If the problem is in your organic search traffic, make sure you\u0026rsquo;re not being penalized\n Check if it\u0026rsquo;s a trend question, and people are just searching less for your services these days\n  Step 2: Gather data\nOnce you have an understanding of where the problem might be, start gathering data.\nNote that if the problem is minor and easily identified, you can pretty much skip this step.\nBy data gathering I mean the following:\n Write down the specific date/time the symptoms first occurred\n Take screenshots or write down the reports which display the symptoms\n Take screenshots or write down the (relevant) reports which do NOT display the symptoms\n Make sure you have a step-by-step guide of how to display the symptoms in Google Analytics – this is invaluable in convincing management\n Gather intel about changes in your environment.\n  Remember, you have to link the symptoms to a problem. You can\u0026rsquo;t just look at a plummeting conversion rate and expect to fix it in the Google Analytics UI (though sometimes the problem is in your Google Analytics settings).\nIf some metric has suddenly dropped, for example, you should identify who the stakeholder is.\nIf the problem is in your tracking code implementation, you need to contact whomever manages your page templates.\nIf the problem is that your servers are unresponsive, you need to contact your IT management.\nIf the problem is that you\u0026rsquo;ve been penalized, you need to contact your SEO consultant. And so on.\nLook for clues and changes in your environment that could be causing the data problem. Without instigating a witch hunt, try to find whoever or whatever is responsible for the problem.\nNote that sometimes (especially when the symptom is a gradual shift in a metric), the problem might be a combination of factors. The more problems there are, the more focus you need.\nTo apply this knowledge to the problem above (falling conversion rate), my data intel would look like this:\nThe symptoms began to appear in early **July 2013**. Since visit metrics are stable (see screenshot), the conversion rate hasn't fallen to zero (see screenshot), and we're still receiving conversions along every other marketing channel, the problem is probably in the fact that pageviews for this goal completion are not being sent in every visit to the goal completion destination   ACT When you\u0026rsquo;ve reached this point, you know the symptoms, you know the problem, and you\u0026rsquo;ve gathered enough data to warrant action.\nWhen making changes to your code, your site, your environment, or your Google Analytics account, just remember one thing: a single error can be fatal. Think of yourself as a neurosurgeon operating on Stephen Hawking\u0026rsquo;s brain. You really, really, don\u0026rsquo;t want to make a mistake.\nStep 3: Cover your bases\nBefore you do anything drastic, make sure your data is secure.\n Backup your page templates and JavaScript code\n Make sure you have an unfiltered Analytics profile (a few good words on Google Analytics profiles)\n  It\u0026rsquo;s so incredibly important to have a raw Analytics profile where all data is secure. If you make the beginner mistake of creating a filtered profile, with no master profile to get back to, you\u0026rsquo;re losing potentially heaps and heaps of data.\nRemember to back up your templates and code before you make any changes. Of course, if problems have cropped up because of faulty code, you should look at previous revisions (so you should already have backups of your code to roll back to).\nBecause some data might take from hours (e.g. new pageviews) to days (e.g. eCommerce) to collect, it\u0026rsquo;s important to have a clear implementation plan.\nI always, always, record every change I make to JavaScript code with version control. Sometimes it\u0026rsquo;s overkill, but I always get a fuzzy feeling of accomplishment afterwards.\nGoogle Tag Manager automatically saves versions of your containers, which is another brilliant reason to start using it.\nIn this stage, I had determined that the problem was indeed with JavaScript. A JavaScript redirection was set to fire upon page load, which meant that sometimes it fired before the pageview was sent. I wrote new code to make sure the pageview is fired first. Step 4: Test and release\nAnother hugely important thing.\nTo test the change perfectly, you need:\n A staging environment with a copy of your site templates the way they are in the live environment\n A web property in Google Analytics dedicated solely to gathering data from the staging environment\n  Check Daniel Weisberg\u0026rsquo;s guide to building a bulletproof Analytics implementation for ideas.\nIf the change is something that needs to be tested on real data, you might want to shift to a higher gear and just take the change live instantly. In this case, you need to place extra focus on steps 5–7.\nWhen testing, validate the test with the instructions in the following steps. Make sure the changes you made are actually registered in Analytics.\nNote that with some problems, only time will tell if the change was for the better. That\u0026rsquo;s why it\u0026rsquo;s even more important to have a raw profile to fall back to if you happened to mess up your implementation.\nI would advise going through the following checks with any new code:\n Check that your code is good with JSFiddle\n Check that your HTML is valid with W3C Validator\n Download the Google Analytics Debugger extension for Chrome and use it to debug the implementation\n  When testing, make sure you do what your visitors would do. Your code should have enough try…catch blocks to make sure that errors don\u0026rsquo;t decimate your site, but you really need to follow actual use cases when testing the implementation.\nIf testing a sales funnel, for example, remember to drop out from each stage of the funnel. This way you can see if the funnel has been correctly configured.\nWhen testing a new event, test it with multiple browsers and devices. There are so many browser and device incompatibilities, and you need to be aware of these when analyzing your data.\nHere I tested the JavaScript with a number of browsers and a number of devices. I tried to make it as performance-intensive as I could, with multiple page loads concurrently. None of the tests failed, so I was happy with the results When you\u0026rsquo;re all done with your testing, and you\u0026rsquo;re happy with the results, you can publish the changes to your live environment. Just remember to update the tracking code from the test property to the actual live property.\nVALIDATE During testing and immediately after you\u0026rsquo;ve updated your live environment, you need to make sure that the changes are being recorded in Google Analytics.\nDue to some delay in data refresh, you might not see anything for some time in the standard reports. This is why knowing how to use debugging tools and Real-Time reports is really important.\nYou can find a nice list of debugging tools on the Google Developer pages.\nStep 5: Check requests\nThe first thing to do is go the page where the implemented code changes are running. Use a network debugger to monitor the requests that are sent to the server when loading the page. Firebug, Chrome Developer Tools and IE Developer Tools all have tabs for Network debugging.\nYou might have to reload the page for data to appear in the Network tab.\nWhen looking at the requests, try to locate any requests for GIF files that are done to Google. You can identify these by looking for the domain “google-analytics.com” in the path or domain information.\nIf you see no requests, then the tracking code isn\u0026rsquo;t working and you need to go right back to your code.\nFor each page, you need to find one request which includes the pageview, and one request for every event that you fire on the page.\nYou can identify what type of request you\u0026rsquo;re dealing with by looking at the parameters sent with the request. So first choose the request and then click on Params (Firefox) or Headers (Chrome). With IE it looks like there\u0026rsquo;s no default option to view parameters, so you have to look at the URL call instead.\nIn the image below you\u0026rsquo;ll see what a Universal Analytics pageview in Chrome vs. a Universal Analytics event in Firebug look like.\n  Here are the GIF parameters for Google Analytics and for Universal Analytics.\nStep 6: Check the DOM\nThe DOM, or the Document Object Model, represents all the objects that can be accessed client-side in your web page. This means that if some data is stored in a variable (for example to be sent to Google Analytics), you\u0026rsquo;ll find it in the DOM.\nCheck the DOM to verify that your custom functions and variables work. So if data is sent to Google, but it\u0026rsquo;s not right or the strings are empty, check your DOM to validate at which point you mess things up. Use also the Console tab in your developer tools to look for JavaScript errors.\nI really recommend using Firebug, since it has a very intuitive UI for DOM and console inspection.\nHere\u0026rsquo;s an example of what the DOM would look for a couple of custom Universal Analytics variables, which have been pushed into the data layer:\n  Familiarize yourself with the DOM profile of your pages, so you\u0026rsquo;ll know where to look for information in the future.\nStep 7: Check Real-Time\nOne of the incredible features of Google Analytics are the Real-Time reports. Seriously, I could spend hours just looking at the traffic come and go.\nReal-Time reports show data as it passes through the Google Analytics API. You\u0026rsquo;ll see visits, visitors, events and so forth, all in a nice graphical interface with a number of segments you can play around with.\nSo if the GIF requests are passed correctly, and if the DOM is healthy, open Real-Time in the GA interface to make sure that data is actually being collected, labelled, and processed correctly.\n  Test it by going on different pages of the site with different browsers. Go to pages where there used to be problems, and check that pageviews and events are fired correctly.\nUse Real-Time until you\u0026rsquo;re bored, and then use it some more. It\u0026rsquo;s a really powerful debugging tool.\nMONITOR Monitoring is crucial if the change you\u0026rsquo;ve implemented has a gradual effect.\nSometimes the changes you make are realized only after enough traffic passes through your site. This might mean that you don\u0026rsquo;t know for days, or even weeks, whether or not the change was for the better.\nThis is why you have to monitor your site effectively, especially in the days following the update.\nStep 8: Assess (again)\nGo back to the reports you gathered in the first stage of the rehab program. Follow the step-by-step guide of reproducing the symptoms, and verify whether or not the symptoms have subsided.\nIdentify, locate, and follow any collateral symptoms that might arise due to the changes you made to fix the previous problems. Make sure you have enough evidence to support the fact that the changes you made were necessary, and any further fluctuation in the data is the result of the update you did. It might be that what you did was effectively a lose-lose situation, where you just chose the lesser of two evils.\nSo when monitoring the data in the few weeks following the changes, look for\n Traces of the symptoms you fixed\n Related metrics, dimensions, graphs, data that could have been affected by the change\n  Be prepared to act on your findings, since the relationship between traffic on your website and your Analytics account can be very fragile. Smallest changes in the system might have big ripple effects on the quality of the data you collect.\nStep 9: Optimize\nEspecially after writing new code or making changes in the templates, you might need to go back to your code and optimize it.\nTake a look at load times and site performance. Did they change for the worse after your implementation? Are you losing traffic data because you don\u0026rsquo;t understand (a)synchronicity of JavaScript?\nEspecially if you\u0026rsquo;re chaining events or making stuff happen before the pageview is called, you might see problems in the future. If the pageview is not sent, you might be seeing “ghost” visitors, who add to conversions, but who don\u0026rsquo;t count towards visits. This will have an adverse effect on your conversion rate.\nSimilarly, if you\u0026rsquo;re chaining events, you might come across a situation where the previous event hasn\u0026rsquo;t completed once the next event is already firing. This is a sure-fire way to get events with empty parameters.\nI would seriously recommend you to familiarize yourself with Google Tag Manager. It handles event chaining like a charm, and debugging, testing, and implementing code changes is really simple and handy.\nBONUS Step 10: When all else fails\nIf all else fails, contact me and I\u0026rsquo;ll help you.\n My Google+ page\n My Twitter account\n My LinkedIn profile\n My e-mail: simo (at) simoahava.com\n  Seriously, I love to help. As long as we\u0026rsquo;re just talking about simple consultation (helping with the steps in this guide, for example), I\u0026rsquo;m sure I can help. If we\u0026rsquo;re talking about bigger stuff (such as new implementations, writing custom code, managing your accounts, etc.), you\u0026rsquo;ll have to contact me through my agency, NetBooster Finland.\nAlso, remember to check the wonderful Google Analytics Google+ group for help as well.\nConclusion\nTo sum it all up, here are the key action points in my 9-step data rehab program:\n Google Analytics shows symptoms of a problem, not the problem itself\n Make sure you have enough data gathered before taking action (for benchmarking as well)\n Have a staging environment handy, where you can test development work\n During testing and after you go live, make sure you spend a lot of time validating the update\n Keep monitoring for a period of time after the update\n  Google Analytics is a wonderful, complex tool, with so many opportunities for analysing your online presence. However, due to the complexity, there\u0026rsquo;s a very high probability that you\u0026rsquo;ll come across problems with your Google Analytics implementation.\nJust be methodical in your approach, make sure you record what you\u0026rsquo;re doing (for further use), Google furiously if you come across any problems, and you should be fine.\nAnd if you just have to remember one thing:\nDon\u0026rsquo;t forget to have a raw data profile for each of your Google Analytics web properties!\n"
},
{
	"uri": "https://www.simoahava.com/analytics/auto-event-tracking-google-tag-manager/",
	"title": "Auto-Event Tracking In Google Tag Manager",
	"tags": ["auto-event tracking", "Google Tag Manager", "listeners", "macros", "tags", "universal analytics"],
	"description": "Introducing the amazing auto-event tracking feature in Google Tag Manager.",
	"content": " There is a new version of this post for GTM V2 here.\nThe Google Analytics Summit came and went, and thanks to the Live Stream, everyone could participate. We were treated to a rapid-fire selection of Google Analytics\u0026rsquo; new features, and this post sheds light on one of these in particular: automated event tracking in Google Tag Manager.\nAuto-event tracking introduces a nice feature, which does what tag managers ought to do: it provides functionality without HTML template editing. This isn\u0026rsquo;t always a good thing, since automation is usually generic and only works for a couple of viable scenarios, but especially for these generic use cases, this new feature is a great addition to GTM\u0026rsquo;s already impressive feature list.\nAuto-event tracking has four different types of event listeners you can create:\n Click listener Link Click listener Timer listener Form Submit listener  A listener is a function which operates in the background. When creating the listener, you tell what operations it should wait for, and once these operations take place, the listener activates and fires any code within.\nIn this short tutorial, I take a look at the first three listeners. I\u0026rsquo;ll return to Form Submit listeners as soon as I have a functioning form I can work with.\nNote that all these tutorials use Universal Analytics, but it\u0026rsquo;s easy to do the same in Google Analytics (the only difference is which tag you use to send the event to your account).\nTimer Listener This is the easiest, so I\u0026rsquo;ll start with it. If you\u0026rsquo;ve read my previous posts, it makes the whole concept of \u0026ldquo;Dwell time\u0026rdquo; a whole lot simpler, without having to employ custom HTML tags (the whole point of auto-event tracking).\nWhat it does is set off a timer for X milliseconds. After the timer reaches the end, an event is pushed to the data layer, which you can then use as a firing rule for your Analytics event.\nSteps:\n Create a new Tag with the following settings:     Create a new Universal Analytics tag with the following settings; remember to add your tracking code to the \u0026ldquo;Tracking ID\u0026rdquo; field, and if you want the event to count as a hit, set \u0026ldquo;Non-interaction\u0026rdquo; as False:     Make sure you have a rule in place to fire this UA tag:     Save container version Publish container  Here you create a Timer Listener, which starts the countdown upon DOM load. As soon as the timer hits 30 seconds, the event gtm.timer is pushed to the data layer.\nThe Universal Analytics tag you created is set to launch as soon as the event gtm.timer is pushed to the data layer, so as soon as the timer goes off, the event is sent to your Analytics account.\nAnd no custom HTML editing was involved. Just some tags and rules.\nRemember to check that the implementation works by looking, for example, at the Network tab in Firebug:\n  Link Click listener This is a bit more complex than the Timer listener, but it\u0026rsquo;s still much easier than what you had to do before with custom HTML code.\nThe scenario here is that I have a \u0026ldquo;Back to top\u0026rdquo; link on my site, and I want to track its clicks. This way I\u0026rsquo;ll know a) do people actually read my pages to the very bottom and b) do they have an urge to get quickly back to the top of the page.\nThis feature makes use of the Auto-Event Variable, which is essentially a macro that can be used to refer to, for example, the DOM element where a click occurred.\nSteps:\n Create a new tag which listens to link clicks on your site:     Create a macro which identifies all element IDs on your site (by using the Auto-Event Variable):     Create a new Universal Analytics tag     Make sure you have the correct rule in place:     Save container version Publish container  Here you first create the link click listener. When set up to fire on all pages, it listens to all link clicks throughout your site. As soon as a link click occurs, it pushes the gtm.linkClick event into the data layer.\nIn the Analytics tag, the important part is the firing rule. See how you\u0026rsquo;re waiting both for the gtm.linkClick event and for the element ID macro to match a certain DOM element? This is to prevent the event firing when all links are clicked. Instead, now it identifies the DOM element ID (using the Auto-Event Variable of the macro) where the click event occurred (#backtotoplink).\nSo now you have an event sent each time the Back to top link is clicked. Remember, again, to check the Network data:\n  Click listener This is pretty much the same as the previous tutorial, but the crucial difference is that the Click listener listens to all click events on your page.\nThe scenario is classic landing page optimization: I have a (fictional) blog home page, where article headings are just plain text, not actual links to the articles themselves. I want to employ the click listener to check how many people try to click the heading in vain.\nSteps:\n Create a new click listener tag:     Create a macro for all classes (we use this to identify the headings):     Create a rule which waits for a click to the .title DOM element:     Create a new Universal Analytics tag:     Save container version Publish container  Here the important thing is to create a rule which waits for the gtm.click event (which means that a click has occurred, thanks to the Click listener) and which requires that the click occur on a DOM element with the class of title, which happens to be the class of the headings on the home page.\nCheck the implementation in Firebug:\n  Auto-event tracking conclusions Well it\u0026rsquo;s a nice feature, that\u0026rsquo;s for sure.\nAt the moment, implementing listeners requires the following general steps:\n Create a tag which acts as the listener and pushes the appropriate gtm event into the data layer as soon as the operation occurs Create a tag which fires as soon as the gtm event occurs and sends the data to Analytics  If you want to be more specific, i.e. wait for clicks on specific DOM elements, you need to create a macro which binds the auto-event variable in the data layer.\nI\u0026rsquo;d also like to see the auto-event variables as default macros (similar to {{url}}) in the system.\nAuto-event tracking is a good addition to Google Tag Manager, and it removes a lot of hassle with custom HTML code. However, it\u0026rsquo;s no a be-all and end-all solution, and there\u0026rsquo;s still a lot of manual work involved if you want to do anything more complicated (cross-event dependencies, complex chaining of events and so forth).\n"
},
{
	"uri": "https://www.simoahava.com/analytics/track-adjusted-bounce-rate-universal-analytics/",
	"title": "Track Adjusted Bounce Rate In Universal Analytics",
	"tags": ["bounce rate", "custom html", "Google Tag Manager", "universal analytics"],
	"description": "Guide for tracking adjusted bounce rate in Google Analytics. This solution takes into account the time spent on the page and the amount scrolled.",
	"content": " So here we are again. Universal Analytics and Google Tag Manager, the dynamic duo, ready to strike again.\nFirst, remember to check my previous two tips for UA and GTM use in custom scenarios:\n Weather as a custom dimension Tracking page load time  In this post, I visit the idea of adjusted bounce rate, which I came across a year ago in the Google Analytics blog.\nAdjusted bounce rate basically refers to tweaking the traditional bounce rate collection method (single engagement hits / total visits) so that visits which only included a single page view would not count towards a bounce, as long as they met some qualitative requirements.\nBy the way, check this great post on bounce rate by Yehoshua Coren if you need a refresher on what the term means.\nFor these custom events, I use the generic event container I created in my previous post.\nThe easy method: visit duration This is the easiest to implement. It\u0026rsquo;s also the one in the Google Analytics blog post I referred to above.\nWhat it does is fire a setTimeout() method as soon as the page has loaded. If the timer runs out (the time is 30 seconds in this script), an interaction event is fired, meaning the visit is not counted as a bounce.\nThe end result is this:\n  And here\u0026rsquo;s how to do it.\nSteps:\n Create a new custom tag called \u0026ldquo;Dwell time\u0026rdquo; Set Tag Type as Custom HTML tag Add the following code in the HTML field:  \u0026lt;script\u0026gt; setTimeout(\u0026#34;dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39;: \u0026#39;NoBounce\u0026#39;, \u0026#39;eventAction\u0026#39;: \u0026#39;Over 30 seconds\u0026#39; })\u0026#34;, 30000); \u0026lt;/script\u0026gt;  Add {{event}} equals gtm.dom as the firing rule Save tag Save container and publish  See, I told you it was easy. What happens here is that after the DOM has loaded (the firing rule), a timer starts. If the user stays on the page when the timer goes off, the event is fired. Remember, you need the generic event container for this to work. So remember to check my previous post for instructions how to build it (it\u0026rsquo;s easy, I promise!).\nThe intermediate method: measure scrolling This method was inspired by a Google+ post I came across by Avinash Kaushik, where he detailed a script written by Nick Mihailovski. This script is used here extensively, with just the event call in a different format (to support UA and GTM).\nWhat happens here is that the event listener waits for a scroll event (so you actually scroll the page down), and fires the no-bounce event after that. Interesting! The statement is that if you scroll, you read, and if you read, you\u0026rsquo;re engaged (with the content).\nSteps:\n Create a new tag \u0026ldquo;Scroll the page\u0026rdquo; Set Tag Type as Custom HTML tag Add the following code in the HTML field  \u0026lt;script\u0026gt; window.addEventListener ? window.addEventListener(\u0026#39;scroll\u0026#39;, testScroll, false) : window.attachEvent(\u0026#39;onScroll\u0026#39;, testScroll); var scrollCount = 0; function testScroll() { ++scrollCount; if (scrollCount == 2) { dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39;: \u0026#39;NoBounce\u0026#39;, \u0026#39;eventAction\u0026#39;: \u0026#39;Scrolled the page\u0026#39; }); } } \u0026lt;/script\u0026gt;  Set {{event}} equals gtm.dom as the firing rule Save tag Save container and publish  And you\u0026rsquo;re done. So what the script does is measure if a scroll event occurs during your page view. If it does, the event is fired. Note that it won\u0026rsquo;t fire the event with every subsequent scroll, so you don\u0026rsquo;t have to worry about clogging your 500 events per session quotas.\nThis isn\u0026rsquo;t fool-proof, of course. It just checks whether the user scrolls. What this DOES prevent is the miscalculation of page visit duration if the user just opens the page in a separate tab and leaves it be. Now you actually need interaction, albeit a very minimal one, to produce an engagement and neutralize the bounce.\nThe advanced method: page load AND scroll So what about measuring whether there was a scroll event and the visit duration on the page was over 30 seconds? Wouldn\u0026rsquo;t that be an even better way to calculate engagement? I think so. So here\u0026rsquo;s what you do. First, make sure the two tags you just created are not active any more (otherwise you\u0026rsquo;ll be sending multiple bounce-wrecking events).\nSteps:\n Create new tag \u0026ldquo;Dwell and scroll\u0026rdquo; Set Tag Type as Custom HTML Tag Add the following code in the HTML field:  \u0026lt;script\u0026gt; (function() { var visitTookTime = false; var didScroll = false; var bounceSent = false; var scrollCount = 0; setTimeout(timeElapsed, 30000); window.addEventListener ? window.addEventListener(\u0026#39;scroll\u0026#39;, testScroll, false) : window.attachEvent(\u0026#39;onScroll\u0026#39;, testScroll); function testScroll() { ++scrollCount; if (scrollCount == 2) { didScroll = true }; sendNoBounce(); } function timeElapsed() { visitTookTime = true; sendNoBounce(); } function sendNoBounce() { if ((didScroll) \u0026amp;\u0026amp; (visitTookTime) \u0026amp;\u0026amp; !(bounceSent)) { bounceSent = true; dataLayer.push({ \u0026#39;event\u0026#39;: \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39;: \u0026#39;NoBounce\u0026#39;, \u0026#39;eventAction\u0026#39;: \u0026#39;Time spent and page scrolled\u0026#39; }); } } })(); \u0026lt;/script\u0026gt;  Set {{event}} equals gtm.dom as the firing rule Save tag Save container version and publish  Here the timer starts first. As soon as it hits 30 seconds, it calls the sendBounce() method. This method checks if the user has also scrolled, and if they have, the event is fired. Note that I also make sure that the event is sent only once with the boolean variable bounceSent.\nWhen the user scrolls, the same method is called and the same check is made.\nSo there are four different scenarios resulting from this script:\n The user doesn\u0026rsquo;t scroll, but stays on the page for 0-to-infinite seconds, and the event is not fired (visit is a bounce) The user scrolls, but the timer hasn\u0026rsquo;t gone off, and the event is not fired (visit is a bounce) The timer goes off, and the user has already scrolled, and the event is fired (visit is not a bounce) The user scrolls, and the timer goes off, and the event is fired (visit is not a bounce)  A much healthier way of calculating adjusted bounce rate, in my opinion.\nConclusion The way you measure bounce rate should always be in relation to the goals you set for a page or for your site. If engagement is important, remember to add clear calls-to-action, so that you don\u0026rsquo;t have to resort to artificial adjustments like those depicted in this post.\nHowever, for a simple blog like this, measuring engagement by a combination of visit time and scrolling interaction is probably a pretty good way of getting a more realistic metric for tracking visit quality.\nAn even more advanced (and qualitative) method would be to see just where the user scrolls to. Is it to the end of the post or just the first paragraph? In other words, does the user read or just skim. That\u0026rsquo;s a crucial question, and I might just return to the issue in a later post.\n"
},
{
	"uri": "https://www.simoahava.com/analytics/page-load-time-universal-analytics/",
	"title": "Page Load Time In Universal Analytics",
	"tags": ["custom html", "Google Tag Manager", "page load time", "universal analytics"],
	"description": "Send all page load timings into Google Analytics with events. This way you&#39;ll avoid sampling issues with automatic page sample collection.",
	"content": " In Google Analytics, you can monitor your site speed and get a decent overview of what pages are contributing positively and negatively to site speed. The problem with page load time metric is that it\u0026rsquo;s an average based on a sample. You can modify the sample rate with setSiteSpeedSampleRate(), but for me that\u0026rsquo;s not bloody well good enough.\n(UPDATE 28.3.2014: This post is still valid, but an implementation with User Timings is a much smarter way to measure actual page load time. I\u0026rsquo;ll be doing a short update at some point in the near future.)\nSo in this post I continue exploring the beautiful combination that is Universal Analytics and Google Tag Manager. Be sure to check out my earlier post on using Universal Analytics to send weather as a custom dimension.\nThe end result This is what you get:\n  What you see is an event, sent along with each page view, telling you how long it took to load the page. The reason I\u0026rsquo;m using events, and not, say, custom dimensions, is just convenience. With events, I have a nice set of standrad reports, which means I don\u0026rsquo;t have to mess around with custom reports.\nI would have liked to use absolute values (in milliseconds) as a custom metric, but the problem is that you can\u0026rsquo;t calculate with custom metrics, so recording all-important averages would be impossible. This is why I chose the scheme of converting the milliseconds to a string which approximates the page load time.\nDISCLAIMER: As with Google Analytics site speed, this whole thing only works if the visitor\u0026rsquo;s browser supports the Navigation Timing (window.performance.timing) API.\nCreate some macros in GTM We\u0026rsquo;re soon creating a generic event processor, so create some macros for it.\nSteps:\n Create a macro \u0026ldquo;Event category\u0026rdquo;, with Macro Type: Data Layer Variable and Data Layer Variable Name: eventCategory     Create a macro \u0026ldquo;Event action\u0026rdquo;, with Macro Type: Data Layer Variable and Data Layer Variable Name: eventAction Create a macro \u0026ldquo;Non-interaction\u0026rdquo;, with Macro Type: Data Layer Variable and Data Layer Variable Name: nonInteraction  You could create macros for Event label and Event value as well (which would make this even more generic), but for this project I only need these.\nBy creating these macros, you\u0026rsquo;re making it possible to send variable data through the data layer into the tag, whose contents are eventually passed on to Google Analytics.\nCreate a generic event container This is nice. I can just create a generic event processor, which uses the macros I just created, and use it in the future for all events I want to send to GA.\n Create a new tag called \u0026ldquo;Send event\u0026rdquo; Choose Universal Analytics (beta) as the Tag Type Add you GA tracking ID to the appropriate slot Choose Event as the Track Type Add {{Event category}} as the macro for, duh, Category Add {{Event action}} as the macro for, that\u0026rsquo;s right, Action Add {{Non-interaction}} as the macro for Non-interaction hit Create a firing rule \u0026ldquo;GA Event\u0026rdquo; with the condition \u0026ldquo;{{event}} equals GAEvent\u0026rdquo; Save your new tag    So here you create a container for all your events. Now you have your macros and your container. In the future, to send a new event, you just need to push an event named \u0026ldquo;GAEvent\u0026rdquo; to the data layer, which fires the tag you just created. And that\u0026rsquo;s what we\u0026rsquo;re doing next.\nCoding the page load time script  Create a new tag \u0026ldquo;Page load time\u0026rdquo; Set Custom HTML Tag as the Tag Type Add the following code within the HTML field:  \u0026lt;script\u0026gt; var perfData = window.performance.timing; var pageLoadTime = perfData.domComplete - perfData.navigationStart; var loadTime = \u0026#34;\u0026#34;; if (pageLoadTime \u0026lt; 1000) { loadTime = \u0026#34;0-1 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 2000) { loadTime = \u0026#34;1-2 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 3000) { loadTime = \u0026#34;2-3 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 4000) { loadTime = \u0026#34;3-4 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 5000) { loadTime = \u0026#34;4-5 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 6000) { loadTime = \u0026#34;5-6 seconds\u0026#34;; } else if (pageLoadTime \u0026lt; 10000) { loadTime = \u0026#34;6-10 seconds\u0026#34;; } else { loadTime = \u0026#34;10+ seconds\u0026#34;; } dataLayer.push ({ \u0026#39;event\u0026#39;: \u0026#39;GAEvent\u0026#39;, \u0026#39;eventCategory\u0026#39;: \u0026#39;Page Load Time\u0026#39;, \u0026#39;eventAction\u0026#39;: loadTime, \u0026#39;nonInteraction\u0026#39;: 1 }); \u0026lt;/script\u0026gt;  Add a firing rule which waits for the page to load: {{event}} matches gtm.load Save the new tag  What happens here is that after the document has loaded, the script counts the time from the moment the rendering of the page began to the moment the DOM was completely loaded. I tried having loadEventEnd as the end point, but for some reason the tag was fired before this was reached, so I got ridiculous results.\nFor more information on the Navigation Timing API, be sure to check Navigation Timing Overview.\nOnce I get the time (in milliseconds), I use quick and dirty if\u0026hellip;else statement to approximate the load time to a string.\nFinally, I push the data in the dataLayer. In the push, I signify GAEvent as the event name, which was the trigger for the Send Event tag to fire. It\u0026rsquo;s important to signify this event as a non-interaction event (nonInteraction: 1), since otherwise you\u0026rsquo;d start getting 0% bounce rate on all your pages.\nSave the container version and publish And that\u0026rsquo;s all there is to it. To sum up, here\u0026rsquo;s what happens:\n When the visitor starts loading a page, the load time is calculated This information is passed into a generic event container, with category and action names in place to make sure the event is recorded clearly in Analytics The container tag is fired as soon as the data is passed, since the trigger is the event name (which is passed with the data) You can verify that you did things correctly by looking at the Network log in Firebug:    Final words This might seem a bit overkill (tracking every single load time of every single page load), but I like the idea of looking at page load time on a more detailed level. Now I can use the Event reports to see what browsers were used with the slowest visits, what countries had the lowest page load times, etc. It\u0026rsquo;s all data, baby.\nSure, I know, by upping the sampling rate you can get similar results in the Site Speed report, but hey, it\u0026rsquo;s more fun when you can code the stuff yourself!\nI\u0026rsquo;m still waiting for the possibility to start doing calculations with custom metrics. It would be so cool to see what the average page load time was during a set day, with a certain browser, with visits from a specific country, etc.\n"
},
{
	"uri": "https://www.simoahava.com/web-development/universal-analytics-weather-custom-dimension/",
	"title": "Universal Analytics: Weather As A Custom Dimension",
	"tags": ["api", "custom html", "google analytics", "Google Tag Manager", "JavaScript", "universal analytics", "Web development"],
	"description": "Use Universal Analytics and some free (or cheap) APIs to collect data on weather conditions when the user visited the site.",
	"content": " There is a new version of this post for GTM V2 here.\n[Last updated June 2014] I\u0026rsquo;ve fallen in love with Universal Analytics and Google Tag Manager. Together they form an incredibly powerful tool for marketing professionals. In most cases, I no longer need to post recommendations to my client for yet another page template revision, since with the tag manager in place, I can just add custom code via the admin panel. Add to that the power of Universal Analytics with its ultra-sensitive Measurement Protocol, and the ability to craft custom dimensions and metrics, and voila! I\u0026rsquo;m in a happy place.\nIn this post, I take you through a short JavaScript dev journey of utilizing weather data as a custom dimension in your site\u0026rsquo;s Analytics. You only need to have Universal Analytics and Google Tag Manager installed on your site.\nThe end result This is what you get:\n  As you can see, I\u0026rsquo;ve created a custom report which shows visits, pageviews and conversion rates (Pages / Visit \u0026gt; 2) for various weather conditions. This report unequivocally, with a plain-as-day-without-a-doubt display of causality, proves that when it rains, people are more likely to convert. I should do more targeting to British audiences\u0026hellip;\nCreate a new tag in GTM  Name the tag \u0026ldquo;Weather API\u0026rdquo; Choose Custom HTML Tag as the tag type Enter the following code into the HTML field (Note! You need to load jQuery for this to work! See here for more information):  \u0026lt;script\u0026gt; var lat = geoplugin_latitude(); var lon = geoplugin_longitude(); var weather = \u0026#34;\u0026#34;; var weatherAPI = \u0026#34;http://api.openweathermap.org/data/2.5/weather?lat=\u0026#34;+lat+\u0026#34;\u0026amp;lon=\u0026#34;+lon; $.ajax({ type : \u0026#34;POST\u0026#34;, dataType : \u0026#34;jsonp\u0026#34;, url : weatherAPI+\u0026#34;\u0026amp;units=metric\u0026amp;callback=?\u0026#34;, async : true, success : function(data) { weather = data.weather[0].main; dataLayer.push({\u0026#34;weather\u0026#34;: weather}); }, error : function(errorData) { console.log(\u0026#34;Error while getting weather data :: \u0026#34;+errorData.status); }, complete : function() { dataLayer.push({\u0026#34;event\u0026#34;: \u0026#34;weatherDone\u0026#34;}); } }); \u0026lt;/script\u0026gt;  Add rule to fire tag on every page ({{url}} matches RegEx .*)  Here\u0026rsquo;s what\u0026rsquo;s going on.\nFirst, a couple of external JavaScript functions are called to retrieve the longitude and latitude of the visitor by using their IP addresses. I\u0026rsquo;m using the free geoPlugin service. You can load it on your site by adding \u0026lt;script src=\u0026quot;http://www.geoplugin.net/javascript.gp\u0026quot;\u0026gt;\u0026lt;/script\u0026gt; in your template.\nRemember to load this script BEFORE the weather API runs. It\u0026rsquo;s best to put it in the \u0026lt;head/\u0026gt; of your page template. If you want, you can also put the script load as the first line of the custom HTML tag you just created.\nNext, I use the API of OpenWeatherMap to retrieve the weather data for the latitude and longitude I got in the previous step. Matt Aster modified my solution so that it works with the Weather Underground API.\nIn the AJAX call, I make an asynchronous call to the API, requesting the data in JSONP (since it originates from a different domain than mine). If the call is successful, I look for the /weather/main/ node, as it has a nice, short description of the weather in the area (e.g. \u0026ldquo;Clear\u0026rdquo;). I then push the string into the data layer.\nFinally, whether the API call is a success or not, I push an event \u0026ldquo;weatherDone\u0026rdquo; into the data layer. This is used to make sure the API call is done before the Universal Analytics tag is fired (see below).\nCreate new custom dimension in GA  Go to the admin panel of your Google Analytics site Under Property, choose Custom Definitions / Custom Dimensions     Create a new Custom Dimension with the name \u0026ldquo;Weather\u0026rdquo; Scope the new dimension to Session Set the dimension as Active Click Save Make note of the index of the new dimension  Here you create a new dimension in Google Analytics and set it active. You need to make note of the dimension index, since you will be referring to this in a short while.\nCreate new macro in GTM  In Google Tag Manager, go to your container and click New Macro\n     Name the macro \u0026ldquo;Weather\u0026rdquo;\n Set Macro Type as Data Layer Variable\n Type \u0026ldquo;weather\u0026rdquo; in Data Layer Variable Name\n Click Save\n  You create the macro to access the weather string you pushed into the data layer a couple of steps ago.\nEdit your GA tag (NOTE! I suggest you take a look at this post for details on sending the weather data using a non-interaction event instead. This way your precious pageviews will never be compromised if the weather script fails to work.)\nSteps:\n Go to the tag that tracks your pageviews and sends them to GA Choose More Settings Choose Custom Dimensions Add the index number of your new dimension in the Index field In the Dimension field, click {{+macro}} and choose the macro you just created     Edit the firing rule and add condition {{event}} equals weatherDone     Save the tag Create a new container version Publish the new container version  Here you send a new custom dimension with the pageview, and it gets its content from the data layer variable you pushed into the data layer during the weather API call. Since the calls are asynchronous, you\u0026rsquo;ll need to make sure the UA tag is fired only after the weather API call has been made. This is done by waiting for the event weatherDone to be pushed into the data layer.\nMake sure everything works  Visit your site Take a look at the requests your site sends by using Firebug or something similar    Enjoy I created a new custom report in GA, with visits, pageviews and conversion rate as metrics, and my new custom dimension as the dimension.\nNote that it might take some time for the new dimension to start pulling in data. If Firebug tells you that the weather data is sent along with your pageview data, you\u0026rsquo;re fine.\nThis could be done in so many different ways, but I chose JavaScript simply for this quick prototype. I\u0026rsquo;m pretty pleased with the result, and even though I make a couple of external calls, page load speed is not an issue. There\u0026rsquo;s always a risk with asynchronous scripting that the user is quick enough to interact with the site before the pageview is sent, but I don\u0026rsquo;t think that will be an issue with this light-weight scripting.\nI can think of a number of cool applications for this weather API, but I\u0026rsquo;ll leave those to your imagination.\nGoogle Tag Manager and Universal Analytics do a terrific job of providing high value for marketing professionals. I love the fact that you don\u0026rsquo;t need to mess with the page template, and you can test and preview your tags as much as you want before publishing them.\nEDIT: I edited the firing rules so that the UA tag occurs only after the weather API call has completed.\nEDIT II: Note that you need to load jQuery for this to work! The $.ajax call is a jQuery function! So either load the jQuery resource in the \u0026lt;head/\u0026gt; of your page method (so that it gets loaded before the GTM container) OR have the following as the first line of the custom HTML tag:\n\u0026lt;script src=\u0026#34;//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; EDIT III: Be sure to check my post on how to make sure the weather API is polled just once per visit. This will improve site performance, and decrease the burden on the external API.\nEDIT IV: Finally, see this post on sending custom dimensions with events rather than pageviews for the optimal version of the code above.\n"
},
{
	"uri": "https://www.simoahava.com/seo/seo-for-sales-making-the-pitch/",
	"title": "SEO For Sales: Making The Pitch",
	"tags": ["marketing", "pitch", "sales", "SEO"],
	"description": "Helping sales teams understand search engine optimization.",
	"content": " My days as a freewheeling, unrestrained, happy-go-lucky, gung-ho city cowboy are over. As of 31 August 2013, I\u0026rsquo;m a married man, and for the rest of my life, I will dedicate myself to optimizing my relationship to my beautiful wife. The old ball-and-chain. But before I bury myself in the bosom of our blessèd alliance, I\u0026rsquo;ll continue to blog about the dark and murky undergrowth of digital marketing that SEO is. Specifically, this post will be all about SEO for sales: how to prepare yourself for the questions your prospective client should/will be asking.\n  First, a lesson:\nDon\u0026rsquo;t sell SEO\nThat\u0026rsquo;s right! You can quote me on that. If you\u0026rsquo;re focusing on solely on SEO for sales, your chance of making the sale will diminish. Or even if you make the sale, you\u0026rsquo;re red-lighting a huge sales potential.\nYour client is not really interested in SEO, even if they seem to explicitly communicate so to you. Your client is interested in results, which might include more conversions, more brand awareness, more social media exposure, better content, a well-sculpted marketing strategy, more revenue, etc. Their goal is not to increase their visibility in organic search engine rankings, which is, as you might know, what SEO has traditionally aimed at. SEO should never be the goal of the sale (or the project), it should be one of the steps you take in helping the client understand and, eventually, reach their business goals.\nHaving said that, there are a number of questions the client should ask if you are far enough in the sales process to actually introduce the methodologies you have hand-picked in making the client\u0026rsquo;s dreams come true. I\u0026rsquo;ve listed a number of these questions here. Most are based on experience, some on common sense, and some on the faint hope that someday, someone will ask them from me in a sales meeting.\nWhat is it you actually do? Wow, straight to the point, huh? Well, when this question is asked, I like to draw the \u0026ldquo;marketing general\u0026rdquo; card. I do a lot of things in SEO, but my first and foremost task is to increase or improve the online presence of my client. This might include a whole slew of traditional SEO \u0026ldquo;tactics\u0026rdquo;, as sometimes the whole online presence of a client revolves around a website built on some nasty ass templates. Sometimes the client seems to have everything under control, with a strong website driving lots of quality traffic, a powerful social media presence, and a high-tuned understanding of digital marketing. In cases like this I sell maintenance work: \u0026ldquo;Let me take some of that burden away from you, so that you can focus on developing your business\u0026rdquo;. There\u0026rsquo;s nothing I enjoy more than taking control of a well-oiled machine, bringing my own expertise to the mix, and making sure that the wheels keep turning.\nCan you make me number one on the search engine results page with keyword X? No, I can\u0026rsquo;t! And no, it\u0026rsquo;s not because I\u0026rsquo;m bad at my job, it\u0026rsquo;s because the search engine results page (SERP) as it used to be is no more. Searches are personalized, localized, embellished, enriched, and made as flexible as possible without hurting the relevance of the results. This is a great thing for the business owners, as they have a chance of reaching an even wider audience. This is a terrible thing for SEO micro-managers, since keyword rankings mean next to nothing these days. Actually, it\u0026rsquo;s actually a good thing, since keyword rankings were a horrible KPI to begin with. Seriously, who cares about rankings when you can actually look at the traffic the keywords are driving to your site?\nHow can you do keyword research when you\u0026rsquo;re not an expert in our business? I might not be an expert in your business, but I want to be. And I have you to help me. Seriously, with your business knowledge and my ultimate SEO skills, together we\u0026rsquo;re the dynamic duo of the digital world. Let\u0026rsquo;s rock, baby! Seriously, keyword research is all about search intent, relevance, search volume, data analysis, search trends, blah blah blah. My job is to get to know your business, so that I can use that knowledge in the keyword research to find the right keyword, which drives the right visitor to the right landing page on your site.\nHow will I benefit from our partnership? Excellent question! This ties me back to the first rule (you still remember it, right?). If you don\u0026rsquo;t know them by now, this is where you dig out the goals your client has in mind. If these goals are too superficial, make them work a little to really find out why they need your help. It\u0026rsquo;s never about traffic, it\u0026rsquo;s never about organic search results, it\u0026rsquo;s never about brand awareness. There\u0026rsquo;s always a process involved, and the client is implicitly asking you to be part of it. Make sure this process is articulated, after which it is much easier to explain why you suggest SEO for this particular phase. Remember, don\u0026rsquo;t just talk about SEO. Tie your project in with an entire online marketing ecosystem, opening the door for all your other products, projects, and processes, which might complement your SEO work.\nGive this question a lot of thought, and plan ahead. If they don\u0026rsquo;t flat out ask this question, they will be thinking about it. So make sure to drive the point through. The main benefit your client will receive is your knowledge and your skills. You are there to drive business, to create or improve a marketing plan, to strategize, to increase revenue or brand awareness, etc. You\u0026rsquo;re not just looking for keywords and optimizing templates. Remember that, young padawan.\nWhat\u0026rsquo;s wrong with our current SEO? Ouch. Tread lightly, my friend. Be diplomatic and constructive. When pointing out flaws, don\u0026rsquo;t be superficial (\u0026ldquo;you\u0026rsquo;re missing a title here and a header there\u0026rdquo;), but make the client understand how they\u0026rsquo;re actually missing out on revenue because of the combined mass of mistakes weighing their website down. This is what the client wants to hear. Or well, they don\u0026rsquo;t want to hear it, but they have to hear it. As a SEO, your goal is to build the client\u0026rsquo;s business. If their current SEO work has been done shoddily, it\u0026rsquo;s your job as a consultant to rectify the situation.\nWhat\u0026rsquo;s the ROI of hiring you? Again, tread lightly. You know how much you cost, you have the means to estimate the increase in traffic, conversions, revenue, etc. But remember the elusive goal I was talking about? Sometimes return of investment is incredibly difficult to calculate. For example, if you do social media work to a client in an obscure business area with no previous exposure in social media, you\u0026rsquo;ll have a hard time estimating the worth of a single new fan, let alone a hundred. In these cases, you must help the client arrive at the right figures. Give them your numbers, how much do you cost as a consultant? How much does the client have to employ other stakeholders? After this, start looking at the obvious benefits: more traffic is more potential. Increase potential with targeted social media advertising, conversion optimization, viral content, etc. Make it clear that positive ROI is a given, since with SEO it most often is. Let the client evaluate the worth of a single, committed fan belonging to the target audience. Then multiply that by the number of new relationships you know you can deliver with your SEO magic, and you have all you need to estimate the ROI.\n  Thank you? No, thank YOU! When thinking about SEO for sales, it\u0026rsquo;s important to remember the golden rule: it\u0026rsquo;s not about marketing. It\u0026rsquo;s not about concepts, it\u0026rsquo;s not about products, it\u0026rsquo;s not about SEO. It\u0026rsquo;s about delivering the goods, understanding the client, and building the client\u0026rsquo;s business.\n"
},
{
	"uri": "https://www.simoahava.com/digital-marketing/an-optimized-haiku/",
	"title": "An Optimized Haiku",
	"tags": ["Poetry"],
	"description": "Haiku celebrating search engine optimization and digital marketing.",
	"content": "Dear client, search engine\nOptimization for you?\nOr perhaps - donuts?\nThe Web, I\u0026rsquo;m afraid,\nIs a pretty sticky maze.\nAnd you\u0026rsquo;re the trapped fly.\nWe tell you we\u0026rsquo;ll help,\nBut you will not believe us.\nYou are very wise.\nEverything we do,\nEverything we claim we do,\nYou can do yourself.\nBut if you let us\nApproach you humbly, gently,\nAs a team, we\u0026rsquo;ll rock.\nWe\u0026rsquo;ll rock Google, check!\nWe\u0026rsquo;ll rock the blogosphere, check!\nWe\u0026rsquo;ll rock Bing! (Who cares?)\nWe\u0026rsquo;ll take your ugly,\nAntediluvian site,\nAnd sex it all up.\nHowever, you must,\nReally must, believe in us,\nAnd let us help you.\nMarketing Partners,\nHow cool does that sound, my friend?\nBetter than donuts.\nPerhaps in the end\nYou\u0026rsquo;ll say \u0026ldquo;I love you\u0026rdquo;, and then,\nThen we optimize.\nourselves\n"
},
{
	"uri": "https://www.simoahava.com/content-management/after-the-click-conversion-time/",
	"title": "After The Click: Conversion Time",
	"tags": ["content management", "Conversion", "ppc", "SEO"],
	"description": "For measurement and optimization, just collecting clicks is not enough. Having a viable conversion target is of paramount importance.",
	"content": " So you\u0026rsquo;ve spent a whopping amount of money on paid search, SEO, Facebook ads, competitions, link building, and traditional marketing. You\u0026rsquo;re seeing a crazy influx of visitors to your site. Just as you\u0026rsquo;re about to call your boss to accept the promotion, you notice a worrying trend: your new visitors are barely making an impression on conversions from online traffic. What\u0026rsquo;s up with that? All your high-paid consultants told you that a high return of investment is guaranteed, since The Internet is da bomb, everything is cheap, and percentages are always in your favor!\nWell nuh-uh!\nTake a moment, if you will, to step into the visitor\u0026rsquo;s shoes: \u0026ldquo;Gee, I want to know where I can find a new lightbulb for my stove overhead lamp. Let\u0026rsquo;s Google it. \u0026lsquo;Buy stove lamp online\u0026rsquo;. Ok, here\u0026rsquo;s a bunch of colorful results, let\u0026rsquo;s click the top one and see what happens. Oh, cool, a flashin\u0026hellip;MY EYES!! MY EYES!! IT BURNS, OH IT BURNS!!!\u0026rdquo;.\n  See what happened there? You had the top result for an excellent, conversion-prone, long tail search phrase, but since your landing page looked like a half-hearted Picasso imitation, picked up from the tail end of a digestive system, you just scared this \u0026ldquo;guaranteed\u0026rdquo; customer away.\nIt\u0026rsquo;s easy to fool yourself into thinking that getting people to come to your site is all that matters. Afer all, Total Visits is a clearly defined metric, easy to set up and evaluate, and you can go a long way without any qualitative analyses.\nI blame the digital marketing industry for enforcing this misconception. There\u0026rsquo;s a lot of unhealthy stagnation going on, at least in Finland, and not only do we have to make our customers understand the holistic approach required to nurture an online presence, we also need to lobby for more follow-through, more long-term planning, more strategy, more involvement, and more commitment.\nFor starters, we need to reevaluate:\nOn-page optimization Keywords in all the right places, check. Images with descriptive and keyword-rich ALT texts, check. A coherent and well-planned information architecture, check. Top quality content, check. A cute cat video just waiting to go viral, check!\nGood, you\u0026rsquo;ve done everything your SEO guy told you to do. Now step outside your cocoon and think of the visitor. They arrive on your site through organic search by using a keyword which implicitly or explicitly outlines their information need. Now,\nDoes this page satisfy that need?\nDo you provide a clear call-to-action?\nDoes this page introduce new needs, some that the customer would be prone to subscribe to given the opportunity?\nThink about it. You want to convert the visitor into a customer. This means that you need to go all Hansel and Gretel. Give the visitors a trail to follow with a clear, delicious goal in the end. (It\u0026rsquo;s up to you and your business whether there\u0026rsquo;s a cannibalistic witch inside).\nThe clearer the path, the better your chances at conversion.\nOutreach marketing Another pitfall is over-promotion. Not only is it worth less if you get referrals or mentions in completely unrelated forums, it will hurt your conversions if you try to coax a population whose interests are, by default, as far removed from your offering as can be.\nNote that there\u0026rsquo;s nothing wrong in trying to penetrate a new interest group. It\u0026rsquo;s just that the connection needs to be established before you reach out to uncharted waters.\nIt\u0026rsquo;s best to focus on related sites, forums, and channels. Google values referrals from related authority sources. Why not focus solely on them? It\u0026rsquo;s bound to help your conversion rates if your referral traffic already has an idea what you are all about.\nDon\u0026rsquo;t cling to the past I\u0026rsquo;ve come across some cases where a desperate need to rank high with a set of keywords resulted in an even more desperate need to rank high with said keywords after the product was discontinued. Not cool.\nThis means that the search engine result would promise one thing, but the landing page would dismiss this promise with \u0026ldquo;We don\u0026rsquo;t have what you\u0026rsquo;re looking for anymore, but now we have THIS!\u0026rdquo;. And the visitor is flabbergasted since they actually only wanted the item promised to them in the search engine results.\nThere are other ways to retain this traffic, and most of them have to do with your marketing strategy in general. Before you pull the plug, you\u0026rsquo;d sure better have an idea of how to cater to those loyal customers who loved the product. In other words, you need a transition plan.\nWhatever you do, don\u0026rsquo;t retain a landing page just for the sake of traffic. A broken promise is a poor way to begin a customer relationship.\nMake sure you have a plan B For conversions, your website is just one, albeit significant, channel. Even if you can\u0026rsquo;t commit to turning your website into a super-charged conversion machine, you need to make sure that its role in assisting conversions is not diminished.\nPerhaps you have a social media channel, where each person who likes your brand is valued as much as any conversion on your website. In this case, make sure that social media is omnipresent throughout your website.\nPerhaps you haven\u0026rsquo;t jumped on the eShop bandwagon, and you still trust ye olde storefront to bring the customers in. Well, make sure your website gives your store the proper introduction, with sufficient targeting of your core group (with storefronts you\u0026rsquo;re bound to have a core group) to ensure that people actually locate it and walk through the door.\nOr perhaps your website is just a small cog in the machine of a huge, faceless organization, and the website solely exists to drive traffic away from your competition. In that case, bless your black heart, you little devil you.\nA promise is a promise is a promise I\u0026rsquo;m sorry for this sappy idealism, but I\u0026rsquo;m about to get married in two weeks, and I\u0026rsquo;m feeling all soft and fluffy inside.\nIf you want to convert, you have to keep your promises.\n(Read The READY Conversion Optimization Framework for a nice method of evaluating how well you deliver on your promises.)\nYou can\u0026rsquo;t base your business on the off chance that someone makes a purchase even though they\u0026rsquo;re disgusted by the manner in which you conduct your online marketing. Conversions are driven by satisfaction, and satisfaction is regulated by the efficiency of your marketing message.\nIf you sell stove lamps online, and if you\u0026rsquo;ve manufactured your landing page to target visitors who search for \u0026ldquo;buy stove lamp online\u0026rdquo;, providing that the purchase process has been optimized, you\u0026rsquo;ll be sure to arrive at a high conversion rate.\nNext time you\u0026rsquo;re browsing the web, using search engines \u0026lsquo;n stuff, take a look at the landing pages you are directed to. How many actually have the content you were expecting to find? Depending on your information need, the answer might vary from \u0026ldquo;none\u0026rdquo; to \u0026ldquo;some\u0026rdquo;. Hardly ever is it \u0026ldquo;all\u0026rdquo;.\n"
},
{
	"uri": "https://www.simoahava.com/seo/website-redesign-with-seo/",
	"title": "Website Redesign With SEO And Common Sense",
	"tags": ["CMS", "SEO", "website redesign"],
	"description": "Tips for redesigning a website, especially from the search engine optimization point-of-view.",
	"content": " So it\u0026rsquo;s been a while, I know. I\u0026rsquo;ve been enjoying my summer vacation, either swimming in the lush blue waters of Finland\u0026rsquo;s lakes or in the murky, greenish, (only slightly toxic) chemistry lab reject also known as the Baltic Sea. I\u0026rsquo;ve also had the pleasure of playing golf only to realize I\u0026rsquo;m roughly at the same skill level I was at when I first started.\n  I blame the fact I\u0026rsquo;ve played less than ever before due to some unexpected patellofemoral pain in my right knee (yes, I know it\u0026rsquo;s called the Runner\u0026rsquo;s Knee, but if I know words like patellofemoral, I will use them). However, now it\u0026rsquo;s time to OPTIMIZE again! And what better way to start this new season of invigorating blog posts than to tackle one of my favorite subjects: website redesign.\nFirst, let\u0026rsquo;s explore a tangent. You know (or maybe you don\u0026rsquo;t) how before every regular season of NBA basketball, there\u0026rsquo;s a ridiculous amount of trading, signing, waiving and skimming to make sure each team has the perfect lineup for the upcoming season? Sometimes the changes are really inconspicuous, like what the San Antonio Spurs have done. Just a few role players here and there to strengthen an already world-class unit. Sometimes the changes are much bigger, like Celtics trading away almost every single star in their team (coach included) and leaving Rajon Rondo feeling betrayed.\nIt\u0026rsquo;s the same with website redesign. Sometimes the redesign has a singular purpose: to update the URL structure, to change the visuals, to redo the content. And sometimes the website is on the receiving end of a complete, and often painful, overhaul.\n  The problem with the latter path is the same as with a complete revamp of a basketball team: you really have no idea how well the pieces fit together in the overall scheme of things. By changing everything, you\u0026rsquo;re taking a risk, since if something goes awry, you\u0026rsquo;ll have a hard time figuring out which of the changes you implemented is to blame.\nOops, I already uncovered my first tip, so let\u0026rsquo;s go to another patented Top 5 list.\nTop 5 things to consider in a website redesign 1. Choose a focus As I said, it\u0026rsquo;s better to choose a focus and roll out the redesign in stages. Search engines are impatient, and for some reason they are as comfortable with change as the typical Facebook user. If your redesign has a technical focus, don\u0026rsquo;t do anything else during the reindexing of your site. In other words, if you\n Redo the URL structure\n Migrate to a new domain\n  you\u0026rsquo;ll want to do these separate from new content creation. Why? Because it takes time for the new pages to be indexed in the search engines. If you add new content to the mix, you\u0026rsquo;ll risk endangering your entire web presence by not having any current pages in the index, and the pages that are indexed don\u0026rsquo;t respond to the keywords you used to rank with.\nIf your website redesign comprises new content creation or new visuals (including conversion optimization), you\u0026rsquo;ll want to do these separate of any technical upgrades you\u0026rsquo;ve been thinking of.\n2. Choose a CMS Choose your content management system wisely. At the very least, it should have the features of a modern CMS, with special focus on SEO capabilities. There simply is no excuse for any CMS to not be technically equipped for proper web design and development. And with proper I mean search engine friendly.\nMake sure your CMS caters to your needs. You don\u0026rsquo;t need to spend tens of thousands of dollars on expensive CMS licenses if WordPress is good enough for you.\n3. Think mobile In the recent years, both Finland\u0026rsquo;s largest online reseller of technology goods (www.verkkokauppa.com) and the largest online auction portal (www.huuto.net) have redesigned their websites. You want to know what sucks? Neither has been optimized for mobile visitors!\nIt\u0026rsquo;s no use trying to wave the \u0026ldquo;but no one makes mobile purchases in Finland\u0026rdquo; card any longer. That simply isn\u0026rsquo;t an excuse. A recent study showed that 10% of the respondents have made purchases online with their mobile devices. This figure would be larger if the websites would actually provide the means for mobile shopping.\nSo go responsive, create a dedicated mobile site, or create a mobile app for your website. It\u0026rsquo;s better to be prepared for the mobile storm than to be left deaf, dumb and blind in the onslaught of the I-told-you-so\u0026rsquo;s I\u0026rsquo;ll be whacking your way in a year or two.\n4. Do things the SEO way This, I\u0026rsquo;m biased enough to say, is the most important thing to consider.\nMake sure your website redesign is done with minimal impact on your site\u0026rsquo;s search engine friendliness.\nFeel free to read and re-read that sentence again and again. To make sure your redesign is done the SEO way, you\u0026rsquo;ll need to do (at least) the following:\n Make note of your \u0026ldquo;before\u0026rdquo; state (indexed pages, PageRank, domain authority, etc.)\n Create a 301 strategy to make sure that all traffic to your old pages is redirected correctly to your new pages\n Use web analytics to identify your most important content and make sure it is retained in the website redesign\n Update your sitemap.xml to make sure the search engine index is updated without delay\n Place extra focus on the first few weeks after the transition: find and fix any crawl errors without delay, make sure your 301 strategy is working, and react to any glitches in the indexing process with haste.\n  It\u0026rsquo;s so easy to botch the redesign with poorly implemented SEO-proofing, but I\u0026rsquo;ve seen it happen so many times I\u0026rsquo;m beyond cynicism.\nDon\u0026rsquo;t go for a CMS or IT supplier who won\u0026rsquo;t let you SEO-proof your website. The loss in organic search rankings and visibility can be devastating to your business.\n5. Choose a professional who can help you This is a given. There\u0026rsquo;s SO much work involved in a redesign that it\u0026rsquo;s futile for one person or one team to tackle all the aspects, even with a smallish site. Don\u0026rsquo;t hesitate to delegate your workload to professionals and consultants who can do the work for you.\nOn the other hand, the science behind the appropriate steps you need to take is sound, so it\u0026rsquo;s not difficult to find the necessary guides and instructions online. However, I know for a fact that SEO, for example, is something that just isn\u0026rsquo;t considered enough when redesigning a website. It\u0026rsquo;s easy to overlook especially if your company has very little web presence to begin with. Nevertheless, I\u0026rsquo;ve explained the virtues of SEO elsewhere, so I won\u0026rsquo;t go there now.\nConclusion A website redesign is a good thing, and you should do it every couple of years. However, don\u0026rsquo;t botch it so that you lose all credibility you ever had online. Chop the project down to a manageable size, and please, please, PLEASE:\n  Don\u0026rsquo;t use Flash.\n"
},
{
	"uri": "https://www.simoahava.com/seo/learning-seo-is-good-for-you/",
	"title": "Why Learning SEO Is (Probably) Good For You",
	"tags": ["Learning", "SEO", "Technique"],
	"description": "Argument for why learning about search engine optimization is good for anyone working in digital.",
	"content": " Before I begin, it is important to note that SEO, as any other facet of web design, covers both technique and purpose. Technique in the sense that SEO comprises a number of de facto guidelines (and accompanying tools) which help improve the search engine friendliness of your website. With purpose I mean the elusive concept of setting goals, and how to pursue them. Both are incredibly important aspects of learning SEO, and it can be argued that one cannot exist without the other.\nIn this post, I take a stand on why it\u0026rsquo;s important for all those working with web design to learn and understand the basics of search engine optimized web design. I sincerely believe that search (in one form or another) is and will be the reigning paradigm of the Internet, mainly due to the fact that the sheer amount of online content has surpassed any other means of gaining access to it. This means that as a whole, and for the good of information retrieval, tuning existing web content to be more search-accessible should be a benefit to all, especially in the near future.\n  Learning SEO techniques Most of SEO, as it stands today, is based on guesswork. That\u0026rsquo;s what it boils down to. Search engines want to promote the democratic nature of the web by keeping all parties equally misinformed about their machinations. Just imagine what would happen if search preference was afforded directly to the highest bidder? In the long run, search would be rendered useless, as money could be used to buy undeserved relevance in search results.\nThe fact that it\u0026rsquo;s guesswork doesn\u0026rsquo;t change the equally important fact that we actually know a lot about search engines. This is thanks to a vibrant community, vigorous testing, and some helpful engineers who treat us with factual knowledge, if we\u0026rsquo;ve been good.\nThat being said, there are a number of techniques, whose adoption into your everyday content management will definitely lead to good results. I\u0026rsquo;ve covered some of these techniques in an earlier post on combining accessibility and SEO requirements, and I also touched the subject in my SEO in a nutshell post.\nIf you grasp the basic ideas behind keywords, HTML templates, meta data, and web crawling, you should be well on your way to creating good, accessible, and healthy web content.\nUnderstanding the purpose of SEO But technique is not, and should not be, enough. Doing SEO for the sake of SEO will probably result in you making progress with keyword rankings, but are you also able to increase the number of conversions? Is your brand achieving more popularity? Do you have adequate presence in social media? After you create your content, do you have any idea how to market it? What is there on your website that should be found? Is your online presence justified?\nI can\u0026rsquo;t stand the idea of just selling organic search improvement. A savvy client will understand that it\u0026rsquo;s not enough, and if they don\u0026rsquo;t, it takes a scrupulous consultant to capitalize on this lack of understanding. What about the quality of visits? Does SEO maximize the potential of landing pages? Is keyword research taken beyond volume, to relevance and beyond?\nI pose all these questions because I know how this business works. SEO is an incredibly easy thing to sell, and, I\u0026rsquo;m sorry to say, most buyers are incredibly easy to fool.\nAnd this is why I\u0026rsquo;m calling for increased understanding of the purpose of SEO. Developing content strategy, for example, is actually really easy if the clients themselves see the benefit of creating good and optimized content that goes beyond \u0026ldquo;traditional SEO\u0026rdquo; deep into the realm of audience design and creativity.\nWhat to demand from SEO As a client, you should ask the difficult questions right from the get-go. Remember to go beyond the concepts and marketing jargon. Make sure you are not spoon-fed with age-old SEO tactics, which might increase visitor levels, but do nothing for the quality of these visits.\nIn the first meetings, ask at least the following questions:\n Have you understood what our business is about? How do you determine the relevance of your keyword research? How will you make sure our site\u0026rsquo;s link profile is kept clean and relevant? How will you assist us in truly making quality content and marketing it? Will you train me to use all necessary tools so that I don\u0026rsquo;t have to buy consultancy every time I want to update our site?  The last is the most important. I really REALLY believe in knowledge transfer, and I see SEO professionals as obligated to educate the masses. Doing things the right way is and should be a common undertaking, not restricted to just a few professionals.\nLearning SEO is good for you, trust me. It\u0026rsquo;s a question of doing web design and content management in a certain, unobtrusive manner.\nThis manner maximizes search engine friendliness and usability of your site content.\nAnd it makes the Internet just a little less chaotic.\n"
},
{
	"uri": "https://www.simoahava.com/digital-marketing/its-not-about-marketing/",
	"title": "It&#39;s Not About Marketing",
	"tags": ["Digital marketing", "Guide", "SEO", "Tips"],
	"description": "As it turns out, marketing is successful when it&#39;s not about marketing.",
	"content": " In a recent post, I took a short foray into the world of clumsy analogies by comparing the team work qualities (and necessities) of basketball and digital marketing. In an even earlier post, I made the claim that the single most important facet of content strategy is audience design. Well, now is the time to pull these two threads together all trilogy-like. After this, you can hail me as the Stieg Larsson of marketing.\nLet me start by repeating one of the greatest quotes to come out of professional basketball: \u0026ldquo;[The secret of basketball is that] it\u0026rsquo;s not about basketball.\u0026rdquo; This from the mouth of one of the most controversial team leaders in basketball history, but also one whose loyalty and team skills just can\u0026rsquo;t be disputed.\nIt\u0026rsquo;s not about basketball.\nThis simple quote means that as soon as players learn to disregard individual achievements, statistic-driven egoism, and isolation in the court, they will learn to look past the concepts of the game and learn to focus on the broader context of winning as a team.\nThis is what successful marketing is all about, too.\nMarketing concepts The problem is simple, and in no way unique to marketing: we sell concepts, acronyms, statistical lift, productized ideas, and clinical processes. Benefits are usually introduced as wispy afterthoughts with little regard to the eccentricities of the client in question.\nWhat\u0026rsquo;s worse is that our selling points, take SEO for example, are loaded with history. This history dictates the whats, whys, and how-tos of SEO marketing. A great many of us try to change this by choosing a different approach to SEO, but maybe the problem was never with the concept behind the acronym, but the fact that we tend to treat our products as solutions.\nWe proclaim to be experts, and therefore we take the floor during sales pitches. Well yes, we are professionals, we probably know the theory inside out, and we have a vast body of experience to back us up. But I tell you this: in marketing, we should acknowledge that the client\u0026rsquo;s business expertise is what everything else should revolve around.\nAfter all, it is their domain, their kitchen, their niche we are penetrating with our fancy marketing jargon. We are bold enough to claim that we can help them achieve a number of goals, but in the end are we really sure that these goals are even relevant? As a matter of fact, do we really know who and what we\u0026rsquo;re dealing with, before we start drafting our proposals?\nThe plan After this disjointed hodgepodge of an introduction, let me introduce you to my STOP-list. These are commandments which I believe help me (as a marketing professional) make better use of my client\u0026rsquo;s business knowledge. The client is, after all, at the receiving end of this professionalism.\nStop confusing products with solutions SEO is not a solution. SEM is not a solution. Graphical design is not a solution. Most probably the things you call solutions are not solutions. These are all tools which help you reach the solution. Solution has become synonymous with product (and vice versa) to the point where no one really understands the difference between the two.\nStop selling blindly Don\u0026rsquo;t start your pitch until you\u0026rsquo;ve heard everything about the client\u0026rsquo;s problem. If they\u0026rsquo;re not forthcoming or if they\u0026rsquo;re unable to articulate the problem, help them! And be altruistic about it. You don\u0026rsquo;t have to sell your help, because by finding the need together, you\u0026rsquo;ll form a bond with the client that will reflect upon the success of your possible cooperation. Remember, you must identify a need to focus the pitch. A pitch without an established need is worth nothing.\nStop dictating, start discussing I really believe in this one even though it might seem detrimental to my business (which, I guarantee you, it\u0026rsquo;s not!). I see my duty as educating the client. I teach them how to use the same tools as I do, I teach them the theory behind SEO, I help them understand how they are the biggest difference-makers when it comes to managing their organic search rankings. This makes the client happier, more satisfied, and more understanding of my efforts.\nStop the monotony Just because you\u0026rsquo;ve worked with similar clients before, don\u0026rsquo;t believe for a second that you can just carbon copy a process and be done with it. Each case requires a unique approach, as each business need is unique. Don\u0026rsquo;t jump to conclusions during sales, or while the project is on-going, or, most importantly, when presenting your findings. Be empathetic, find the relevance in your work, and be prepared to communicate it to your client in words that they undestand. The more you talk about their business and the less you talk about yours, the better.\nStop enforcing your recommendations Consulting is a touchy business. After all, you\u0026rsquo;re hired to consult the client. That is, you observe, you recommend, and you track. If your client says no to your recommendations, don\u0026rsquo;t have a fit, they probably have a good reason for it. The larger the client, the more complex their change management process. If this happens, it is your duty as a marketing professional to come up with something else.\nThe human factor I guess my motivation for writing this post stems from the fact that I believe there\u0026rsquo;s a huge amount of untapped potential in digital marketing.\nIn the end, it\u0026rsquo;s all about the human factor. We are proud, selfish beasts, who battle for control and refuse to compromise.\nAnd so, our greatest battle in self-development is not against the unstoppable influx of new information, nor is it against the ever changing business needs of our clients. No, the greatest battle is fought within, against our own flaws and the restrictions we impose upon ourselves.\nLuckily, these flaws are usually enhanced by stagnated processes, expired concepts, and poorly designed products. This can be remedied.\nBe flexible and make your processes flexible, so that they can accommodate the diverse spectrum of you clients\u0026rsquo; business requirements. This way you will be able to take your professionalism to another level.\n"
},
{
	"uri": "https://www.simoahava.com/digital-marketing/how-is-digital-marketing-like-basketball/",
	"title": "How Is Digital Marketing Like Basketball?",
	"tags": ["basketball", "creative", "Digital marketing", "SEO"],
	"description": "Drawing the obvious parallel between a digital marketing team and a professional basketball team.",
	"content": " So I was watching the 2013 NBA Eastern Conference Finals game 7 between Miami Heat and Indiana Pacers. While making note of the dozens of different ways that the lackluster Pacers were taken to the cleaners by the dominant Miami team (read: LeBron James), I started churning a funky thought in my head. This beautiful, wonderful, exciting, adrenaline-pumping, superstar-studded, tattoo-galore of a game must be an analogy of something. Something equally thought-provoking, exhilarating and life-changing. Oh! I know! Digital marketing!\n  There has to be something in common between the helter-skelter world of marketing and the organized chaos that basketball – at times – seems to be. Now, I\u0026rsquo;m making this up as I go along, so just bear with me. I\u0026rsquo;m sure you\u0026rsquo;ll either know more about basketball or more about digital marketing once I\u0026rsquo;m through, and even if not, at least you\u0026rsquo;ll have suffered with me through another unbearably hot summer evening.\nAnd just as a quick disclaimer: I apologize for the half-Freakonomics, half-Lewis-Carroll, sensationalist post title. It\u0026rsquo;s just how I roll today.\nThe premise To add some substance to my argument, my premise is simple: digital marketing is team work, where points are awarded for blasting through competition in an attempt to reach the goals we set for our clients. I know, I know, you could substitute \u0026ldquo;Digital marketing\u0026rdquo; with any other B2B or B2C business, but my motive here is as simple as my premise: Digital marketing is team work. It is team work. It is team work. Every single word in this sentence should be emphasized. There is no i in team (although this has been disproved, and there\u0026rsquo;s also \u0026lsquo;me\u0026rsquo;).\nBasketball, as you may know, is all about team work as well. The five-man-unit must play together like a seamless group in order to blast through competition in an attempt to finish the game with a higher score than the other team. A good team is one that comprises of individuals with spectacular talent, all hell-bent on winning the championship trophy. A perfect team is one that transcends the concept of individuality, and becomes more of a unit where the only thing that stands out is the team itself.\nHow\u0026rsquo;s that for a premise? Flimsy, generic and completely unsurprising. Which is why I have to go deeper. Much deeper.\nThe coach vs. the account manager I\u0026rsquo;m not going to the GM/CEO-level simply because that\u0026rsquo;s way too deep, and because that\u0026rsquo;s a world I (want to) know little about.\nHowever, a coach in basketball is very much like the account manager in digital marketing. In a well-oiled organization, the coach/account manager calls the plays. They analyze the competition and choose the team that will work on any specific goal. Usually these goals are tailored against the competition in the field. In basketball, if the other team goes big then your team goes big. In marketing, if your competition is ad agencies, you want to bring out the visually talented nerds. If your competition is Google\u0026rsquo;s algorithms, you want to bring out the SEOs. If your competition is your client\u0026rsquo;s competition, you want to bring out the big guns from all departments to find out where and how your client can stand out.\nCoaches and account managers are really important in the grand scheme of things, but in the end they should stay on the sidelines and delegate the brunt of the work to the specialists. Naturally, the world is full of coaches who meddle in the on-court action, and there are plenty of account managers who do all the work by themselves.\nAnd this is OK. Well, actually, basketball coaches shouldn\u0026rsquo;t be the go-to guys in a choked up offense, but they should participate in the action. Maybe call the referee some dirty names after a poor foul call. Maybe inconspicuously trip the other team\u0026rsquo;s players. Similarly, account managers should take an interest in the on-going projects. After all, it is their role to keep the client updated and happy.\nBut seriously. With a team bursting with talent, it\u0026rsquo;s all about delegation. Let the specialists do their magic.\nThe back court vs. the creative department The back court is the most important function of a basketball team. You can argue with me all you want, but I will not budge. Similarly, th__e creative department (especially the content managers) is the lifeline of a digital marketing organization.\n  The back court are the guards. The ball handlers. The play makers. The distributors. The sharpshooters. The fast breakers. A well-organized offense begins (the dribble, the pass or the shot) and ends (the transition to defense) with the back court. Just think of the following names and you\u0026rsquo;ll agree with me: Stockton \u0026amp; Hornacek, Isiah \u0026amp; Dumars, Magic \u0026amp; Scott, Curry \u0026amp; Thompson. Even Jordan \u0026amp; Pippen (if you stretch your imagination a little). And then the individuals like Kobe Bryant, Allen Iverson, Steve Nash, etc.\nThe content managers are the king-makers. The miracle factory. The fantastic N (where N = number of content managers). The visionaries. The illuminators. The fashionistas. They are tasked with coming up with the coolest campaigns in the world. With the viral videos. With the keywords that bring in the millions. With the content that wows, ooh-aahs, makes you cry and laugh at the same time, and makes you feel insignificant and god-like all at once. They are the gears that make the machine turn.\n\u0026ldquo;Creative department?! Hah!\u0026rdquo; I hear you scoff. Well mark my words. Even if your digital marketing team doesn\u0026rsquo;t have a designated creative department with its Don-Draper-esque content creators, you probably have someone or some people who fit the description. They are the go-to guys who get the project rolling with a crazy idea that everyone kind of fears but kind of loves at the same time.\n  If you don\u0026rsquo;t have people like this, you\u0026rsquo;ll want to, because they make the difference between a poor campaign and a good one. Wait, just like a solid back court is the difference between a poor team (e.g. 2012 Bobcats) versus a good team (e.g. San Antonio Spurs). See how it\u0026rsquo;s all working out for my analogy?\nThe forwards vs. the SEOs, the SEMs and all other specialists And then you have the forwards. These guys are the ones who, at least since the early 80s, have received most stars on the basketball walk of fame. Larry Bird, Charles Barkley, Michael Jordan (when he felt like playing a forward), Kobe Bryant (same thing), Kevin Durant, LeBron James, Kevin Love, and so on and so forth. They are the players who have the most potential to dazzle, as their roles require ridiculous amounts of athleticism (they have to juggle fluently between various roles in both ends of the court), some very specific skills (sharpshooting, post-up playing, hustling for loose balls, rebounding, defensive rotation), and chameleon-like adaption. They are often quite single-minded and thus poor as play makers, but they make up for it with pure, unadulterated skill in their preferred roles.\nTheir counterparts in the digital marketing world are the specialists of the marketing team. Do you need someone to hitch up the client\u0026rsquo;s website in organic results? Get the SEO. Do you need someone to inject the SERP with exact ad impressions? Call the SEM. Do you need someone to design some kick-ass campaigns? Go wake up the AD. Do you see where I\u0026rsquo;m going with this?\nSimilarly, in basketball, If you need someone to pick the team up and make the decisive play, you get Kobe or post-2011-LeBron or pre-2000-Jordan. If you need someone to grab the rebound and initiate a fast break, you get Rodman or Moses.\nIf you need someone for something because you are sure that that someone doing that something will take your project or your game to the next level, you choose that someone from this category.\nThe center vs. sales This was a difficult category, as I had no idea what would be the ideal digital marketing counterpart for the big men in the basketball game. But the more I thought about it, the more I thought of the sales people I\u0026rsquo;ve had the fortune of working with.\nA center dominates below the basket. In both ends of the court. They push away the other team, they make room for the driving forwards, they make all-essential screens for the back court, they tip the loose balls in, they grab the rebounds, and they swat away the pitiful shots the opposition makes.\nThe sales people dominate the end zones as well. In both ends of the project pipeline. They push away the competitors, they negotiate more work for the role-players, they make sure the content managers know what the opportunities are, they ensure continuation after the project is wrapping up, they turn whispers into leads and leads into new sales, and they do this by assuring the client that this digital marketing team is the only one that matters. There\u0026rsquo;s some overlap with account managers here, as you may notice, but sales people can be specialists as well.\nIf your sales department stands out in your company, there\u0026rsquo;s probably something wrong. You don\u0026rsquo;t want a super-efficient sales unit if your production isn\u0026rsquo;t up to par. You want equilibrium in both ends of the sales funnel.\nAnd, of course, if your center stands out in your basketball team, you\u0026rsquo;re also looking at difficulties in the near future. First of all, they usually have a very limited zone of action. Due to their height and mass, they are hardly ever good for dribbling or shooting the ball (there are exceptions). Also, because of the physical nature of their position, they are very injury-prone and thus poor candidates for picking the team up and carrying them to the championship.\nThe rest Well I know that there are so many more people involved in digital marketing, and I know I\u0026rsquo;ve insulted at least, well, no one, by not including them.\nI\u0026rsquo;d love to say that programmers are the most important people in the team, but no. They\u0026rsquo;re not on the court, they work off-screen. They lay the foundation for the team to operate. They draft the plays, they maintain them, they create new versions of them, and they teach the others how to use them. They are specialists, with specialized functions in the organization, but they are hardly the movers and shakers of a marketing team.\nI\u0026rsquo;d love to say that the analysts, the consultants, and the other managers are important, but I really don\u0026rsquo;t know what these job titles are so I won\u0026rsquo;t go there. There\u0026rsquo;s no such things as just \u0026ldquo;an analyst\u0026rdquo; or just \u0026ldquo;a consultant\u0026rdquo;, so I\u0026rsquo;m assuming that they are the same people as the ones I mentioned before. What\u0026rsquo;s funny is that the job market is overflowing with fancy but nonsensical titles like these.\nSo is digital marketing like basketball? I\u0026rsquo;m happy with how things ended. Sure, I\u0026rsquo;m being awfully generic and the analogy is stretched at times, but you know what, a basketball team really is like a digital marketing team! They are both built around pure talent, they have very specific goals, for which equally specific tactics and strategies have been devised, and they both bleed and sweat to make sure these goals are achieved (and surpassed). Everybody has a function, and everyone has the potential to make or break every single game/project.\nAt the same time, everybody is part of a unit, a team, a whole. Remember Isiah Thomas and the secret of basketball? This is what teamwork is all about.\nNBA players and marketing professionals, they\u0026rsquo;re all stars. When you drop your ego and work with your colleagues to surpass all expectations – that\u0026rsquo;s when you become superstars.\n"
},
{
	"uri": "https://www.simoahava.com/seo/what-makes-a-good-seo-report/",
	"title": "What Makes A Good SEO Report?",
	"tags": ["Audit", "Score card", "SEO", "SEO report"],
	"description": "Identifying features of a good search engine optimization report.",
	"content": " I recently started rewriting some of the templates we use for SEO reports at my company. I first thought that the task would be a simple one. Just rewrite all the SEO stuff to match the latest trends, add more diagrams, charts, and graphs, and make it more personal by increasing the number of client-specific sections. However, soon I started to question my motives (as I usually do when doing something independently). Are these reports really necessary? Who reads them? What use is the information within? Should I require that my clients fix all the issues I reported or are they just recommendations? Are SEO reports the final product of a project, or do they mark the beginning of a hopefully successful post-audit journey for the client? The questions just kept coming, and in the end I was pretty certain that I had uncovered at least some insight into the business of reporting.\nThe biggest revelation I came across was the most obvious one.\nA good report is really important.\nA good report turns data into prose, problems into opportunities, errors into fixes, troughs into peaks, and most importantly, it makes everything seem manageable. A good report doesn’t just suggest corrections, it educates and facilitates. Finally, it’s also my calling card. A good SEO report tells more about my professionalism than the results within.\nThis post contains a number questions you might want to ask yourself if you’re either a) the one who has to write the report or b) the one who has to read it. The questions might seem almost self-evident, but hey, simple revelations are usually the ones that have the biggest impact.\nAnd yes, I know there are all sorts of SEO reports out there: keyword research reports, content analysis reports, comprehensive site audits, link profile analyses etc. I’m being intentionally generic here, and the following questions should be asked regardless of the report you’re dealing with.\nFor whom is the SEO report for? A fundamental question, and one that is most often forgotten.\nI used the concept of audience design in an earlier post on content strategy. The same credo applies here: know your audience! Or preferably, know your audiences. It’s very likely that your report is written for a number of target groups: marketing directors, content managers, ICT services, art directors, etc. The likelihood increases the more complex the report is.\nStart with this question, and revisit it every time you start writing a new section. Make it obvious from the content that you’re targeting a specific audience. This way the client can distribute the report to the right recipients independently without you having to act as a mediator.\nWhat are the most pressing issues? This is something that every SEO report should begin with. Essentially you’re taking the entire body of the report and congesting it into a hit list of 5–10 most important issues which make the biggest impact with the least amount of work.\nClients will really benefit from this. It’s such a huge thing to see that there’s something you can do right away to make most of the problems go away. This is not only reassuring but also revelatory, as most clients don’t understand why traffic has plummeted or why certain keywords have lost their ranking.\nJust make sure you’re not misleading the client. It’s perfectly OK to skip this step by noting that the issues within the report require more time and effort than can be expressed in a digested format. Honesty is always valued more than any quick fix lists that don’t deliver.\nHow did the website score? I don’t like score cards which score each analyzed section from 1 to 10, since the scale is hardly ever scientifically founded, and the grades are just very, very subjective.\nI tend to go for the traffic lights: red if something is critical and requires immediate attention, yellow if something is wrong but not catastrophic, and green if something is OK. This is usually enough, and it’s nicer to look at than just a matrix of labels and grades.\n  Just remember that it’s ok to have lots of greens (or 9s and 10s). A pass is a result as well, and you shouldn’t be a harbinger of doom just because you want justify your fee.\nRemember to start each section with a look at the respective row in the score card. This provides more context for each section, and it also gives a powerful visual cue to the reader of the gravity of each problem you address.\nWhy recommend this? Why suggest that? This is something again that you should return to in every single section of the report. Don’t just write about the problem and the fix. This is your chance to educate! If you add a proper introduction to each section, you not only provide the foundation for each fix you’re recommending, you’re also telling the client how to avert the problem in the future.\nThis is in many ways the meat and bone of the report.\nStart with a description of the problem along with its symptoms. Do it academically: transition from the general to the specific. Provide the SEO context for each problem, so that the reader understands your motivation for suggesting the corrections. Then provide the details of how the problem manifests in the site you are auditing. Remember that you’ve been hired to fix problems. You can’t fix a problem without identifying its source.\nSimilarly, you shouldn’t report a cure without explaining how you came about it. You have to provide context for all the concepts, because part of your job is to consult and educate your reader.\nI know it sounds noble and highbrow, but remember why you (hopefully) got into SEO in the first place? You wanted to make the Internet a better place, right? RIGHT? I know that years of fighting Google’s algorithms has made you cynical and battle-scarred, but that’s no reason to abandon your principles.\nDoes this look good? Okay, I left the most important for last. Just kidding. But seriously, it’s important to make sure the report looks like a real SEO report. Don’t just stitch things together in a hesitant email that you send to the client in the last minute. Put some time and effort into it. This is how my ideal template looks like:\n Cover page\n Introduction (a personal note from you to the client)\n Table of contents\n Hit list of the most pressing issues\n Score card\n Report itself\n Conclusion\n Appendices\n  Presentation is important, because you don’t want to have to explain each section again and again just because of sloppy output. On the other hand, you do want to do some explaining, which brings me to the last question.\nAre you prepared to present the report? Don’t just send the report and expect that your work is done. Remember that you might be talking about a 100-page manual, detailing the heart and core of years and years of SEO research, and unraveling the infinitely complex machinations of a huge website with equally huge problems.\nCall the client an hour after sending the report. Go over the table of contents, the score card, and the hit list. If the report is large, arrange a workshop for all stakeholders and target groups.\nMake sure the message sinks in. Your report is a testament to the hard work you’ve put in. And remember: Internet. Make it a better place (for you and for me and the entire human rac\u0026hellip; sorry).\n"
},
{
	"uri": "https://www.simoahava.com/seo/seo-in-a-nutshell-and-some-tips/",
	"title": "SEO In A Nutshell (And Some Tips)",
	"tags": ["Content strategy", "SEO"],
	"description": "All-around usable tips for search engine optimization.",
	"content": " \u0026ldquo;Oh no, not another \u0026lsquo;SEO in a nutshell\u0026rsquo; post!\u0026rdquo; I hear you scream. Oh yes! And to make matters worse, I\u0026rsquo;m actually calling this SEO In A Nutshell just out of spite! But why, oh why, must I litter the otherwise so clean and orderly forum that Internet is with yet another here\u0026rsquo;s-what-something-is-in-case-you-ever-cared-post? I promise, I\u0026rsquo;m only doing this for selfish reasons. I\u0026rsquo;m not trying to buy myself into the major league by posting about something that everyone else is posting about. I\u0026rsquo;m not trying to impress those whom I work with by telling them I\u0026rsquo;m good at something I\u0026rsquo;m supposed to be good at. And I\u0026rsquo;m definitely not trying to impress you, my cynical reader, since I know you are so difficult to please.\nNo, I actually honestly believe that at this point to approach SEO with any other agenda than that of introspection and self-enlightenment would be fruitless. So that\u0026rsquo;s it. I\u0026rsquo;m writing this to get my thoughts straight and really look at what SEO is today. It\u0026rsquo;s not the same it was five years ago, hell, it\u0026rsquo;s not the same it was last week.\nSEO in a nutshell \u0026hellip; in a nutshell Well, as you might now, SEO stands for search engine optimization, or if referring to the person who does it, search engine optimizer. At least, it used to. Nowadays, partly thanks to the efforts of a community hyped up about the age-old, Bill Gatesian Content is King mantra, it\u0026rsquo;s also referred to lovingly as search experience optimization. It sounds nice, but they changed the wrong word. Optimization is too close to manipulation for my taste. I\u0026rsquo;d love it if someone could come up with a better alternative. Something to do with facilitation. Or assistance. Or community, comprehension, camraderie.\nSo SEO is search engine optimization, that\u0026rsquo;s how far I got. Great!\nTraditionally, they way SEOs approach a website (note, traditionally), is via a three-pronged attack:\n1) Technical optimization - where we make sure that the titles and metas are there, that robots.txt and XML sitemaps are in place, that all redirections are kosher etc. This is what we do to ensure that the search engines can index the site and its pages properly. Indexing means that the page can be searched for.\n2) Semantic (or keyword) optimization - where we partake in an endless tug-of-war between the popularity of a keyword versus its competition. Keywords are search queries that your preferred customers use. If you own a webstore that sells skis, you want the site to be found by people who are looking for winter sports equipment and not hammocks. This is achieved by priming your content to make use of these keywords as inconspicuously as possible.\n3) External (or link profile or inbound marketing) optimization - where we try to build the hype around the site, because we know that parts (1) and (2) are simply not enough to lure people in. You see, it matters where you appear in the search engine results page (or SERP). It\u0026rsquo;s crazy, but apparently if you\u0026rsquo;re not in the top 10, you\u0026rsquo;re screwed. And you get there by increasing your site\u0026rsquo;s popularity. And what is a better sign of popularity than people linking to your site?\nSo think of it like this:\nWithout technical optimization, the search engines won\u0026rsquo;t know your page exists.\nWithout semantic analysis, the right crowd won\u0026rsquo;t know your page exists.\nWithout link profiling, no one will know your page exists.\nAnd this is traditional SEO at its best. Doing stuff with the page template, doing stuff with keywords, and doing stuff with links.\nBut that\u0026rsquo;s not enough, is it? Hell no it isn\u0026rsquo;t! If you\u0026rsquo;re approached by SEOs who promise you the moon and stars by doing nothing but the above, you\u0026rsquo;re in for an unpleasant treat. The problem with the traditional approach is that somewhere along the way someone forgot that humans use search engines (and some very well educated apes).\nThat\u0026rsquo;s the beauty of search experience optimization as the new SEO. You\u0026rsquo;re not creating your website for search engines, you\u0026rsquo;re creating it for users! That\u0026rsquo;s what Google\u0026rsquo;s been telling you to do all along! Forget tactics, forget dirty schemes to undermine Google\u0026rsquo;s algorithms, forget buying links from the black market, just focus on content. That\u0026rsquo;s all there should be to it.\nSure, in a perfect world. Even at its easiest, creating content is bloody difficult. Some people have a talent for it, but even they have to stay on top of the latest trends and fashions of the Web. The thing about content is that you never know what really works until you try it. It\u0026rsquo;s like trying to create a hit song (not that I know anything about it). Often times the most unpredictable B-side of a failed pop tune turns into the biggest hit the artist has ever had. And that\u0026rsquo;s without trying to market it at all! Many times things that go viral in the Internet are accompanied by a bewildered eccentric who thought it would be cool to combine cat videos with pop songs in a random mayhem of laughter-inducing proc\u0026reg;a(s)tination.\nBut that\u0026rsquo;s what SEOs have to do. They have to help the customer market their content. They have to know what\u0026rsquo;s cool and what isn\u0026rsquo;t. And they have to know the right channels to promote the content in.\nSo add step number (4) to the list as an all-encompassing feature of SEO work: content strategy. It\u0026rsquo;s the most important thing by a landslide, as none of the other aspects works in the long run without a decent content strategy to back it up.\nAnd that\u0026rsquo;s all there is to it. In a nutshell, SEO is all about creating magical content to lure, charm, and convert your site visitors into loyal fans. It\u0026rsquo;s all about the buzz, the viral videos, and the annoying memes. It\u0026rsquo;s about being unique in a forum where being unique is almost impossible. It\u0026rsquo;s about finding the critical point between hype and saturation, and hanging in there for as long as you can.\nI heard there were going to be some tips? OK, but just two this time.\n1) Did you know that Google uses pixels to determine title length in SERPs? That\u0026rsquo;s right. The traditional approach in SEO has been to limit page title length to just under 70 (and over 50) characters in length. However, much longer titles are OK as long as they\u0026rsquo;re below a certain width in pixels. So what\u0026rsquo;s the length? Well, there\u0026rsquo;s some debate about that, but it appears it\u0026rsquo;s somewhere in the vicinity of 500 pixels.\n2) You can extrapolate your keyword data in Analytics to uncover your (not provided) results. Some time ago, Google hid all search queries from Google Analytics that have been made by signed in (Google) users. This is a pain for reporting SEO success, as (not provided) results can dominate the rankings. Here\u0026rsquo;s a nice tip by AJ Kohn to use the distribution of other keywords to extrapolate the distribution of (not provided) keywords.\n"
},
{
	"uri": "https://www.simoahava.com/seo/penguin-2-0-googles-next-major-update/",
	"title": "Penguin 2.0: Google&#39;s Next Major Update",
	"tags": ["google", "penguin", "SEO"],
	"description": "A brief introduction to the Penguin 2.0 Google search algorithm update.",
	"content": " When Matt Cutts speaks, the world listens. We reach out our hands to catch even the tiniest morsels that make up the bread that fills the basket that is Google. We hush in anticipation, as we know that we are about to be revealed another piece of the puzzle that is Google\u0026rsquo;s search algorithms. We want to know these dark, esoteric, technological secrets because a) as humans we are genetically coded to abhor secrets and shadow-talk, and b) as SEOs we are competing in a business where only the first place is rewarded. And now Matt Cutts has spoken a glorious 7 minutes, 24 seconds on Penguin 2.0, the next version of Google\u0026rsquo;s spam-blasting incarnation.\n  Before you pack your survival kit and head for the fox hole you dug out in the back yard, don\u0026rsquo;t fret. If you\u0026rsquo;ve been doing things by the book, you should be OK. Well, you never know with Google, but that\u0026rsquo;s what we\u0026rsquo;ve been promised. Remember, Google only wants you to do a quality website. There\u0026rsquo;s no magic to it, you just have to create good content for people who might be genuinely interested in reading it. Doing things all clean like this, your site\u0026rsquo;s link profile should have accumulated organically, without you taking part in any dirty link-scavenging schemes (black hat SEO, as the industry calls it).\nHowever, if you\u0026rsquo;ve been buying links, or if you\u0026rsquo;ve accumulated links from directories or services which exist in the periphery of good taste, you might be in trouble. You should always try to aim for links which come from domains that relate to your business. Getting links from authority sites that have direct relevance to your own is a win-win situation in SEO. You get the important link you need, and you increase the authority of the hub that linked to you, thus increasing the power of your connection.\nIf your links come from disreputable sites, or sites with low authority, you might be considered a prime candidate to target with spam-based demotion in Penguin 2.0.\nPenguin 2.0 speculation Remember that this is all still speculative. Matt Cutts can\u0026rsquo;t and won\u0026rsquo;t go into detail, because that\u0026rsquo;s just how things roll in the Googleplex. They want us to find out for ourselves, and thus keep the search engine industry blooming. However, he does have a pretty good idea on how things might turn up in Penguin 2.0, and here\u0026rsquo;s its current status:\n1. Advertorials Google are looking to punish advertorials whose sole reason is to pass PageRank. Advertorials are basically legitimate looking texts or articles, but they contain paid links back to the website where the commission originated from. Google wants to target these page links, as they do not want to permit PageRank flowing from articles whose link value is bought, and not earned through authority and relevance. In Penguin 2.0, advertorials need to be conspicuous. The readers must be aware that the text is an advert, or otherwise penalties might kick in.\n2. Spammy queries Another thing Penguin 2.0 will target are queries that are traditionally contested by spammers. Google wants to clean these queries up and provide results that are actually relevant. This is, of course, good news to porn hunters, as the adult industry is possibly one of the most spammed niches of the web. All in all, the new update will take a strong stand against link spamming and link spammers.\n3. Webmaster tools Google wants to help webmasters with better tools. One of these new tools will have to do with hacked site detection and with remedies to battle hacking. If a webmaster finds out that their site has been hacked, Google provides the tools to report this and fix the situation.\n4. Authority counts! Now\u0026rsquo;s the time to look at your link profile and start hounding for links coming from authorities in your field of business. Google is looking to increase the visibility and PageRank of authority sites. What this means is that if you are recognized (by Google\u0026rsquo;s algorithms, of course) to be an authority in your field of business or information, your site will gain momentum in the organic ranking of pages. Naturally, all sites who benefit from your generous links will enjoy this change as well.\n5. Cluster-proofing Penguin 2.0 will make changes to how we see clustered results in search queries. Have you ever noticed that when you go past page 3 or 4 in Google\u0026rsquo;s search results, you\u0026rsquo;ll find a bunch of results coming from the same host domain? This is host clustering, and it basically means that a single domain is over-represented in search results when going deeper in. The planned algorithm change will activate so that if you\u0026rsquo;ve already seen results from a domain, it will be less likely that you\u0026rsquo;ll see more hits from that domain further on down the chain.\nWhat goes around, comes around Even though this is all just speculation, and nothing is official yet, we know that Matt Cutts doesn\u0026rsquo;t waste his breath on trivialities. So my advice is this:\nLook at your link profile and clean it up if necessary. Get those suspicious looking, low-authority domains away from there, and start looking for authority websites that might spread you with link honey.\nKeep creating quality content. Nothing is more effective than doing what you should be doing. Stop looking for ways to manipulate the search engines, and start looking for ways to coexist with them. Penguin 2.0 might sound like a fluffy toy or something to do with Linux, but it will surely cause some mayhem, especially with sites boasting vast link diversity.\n"
},
{
	"uri": "https://www.simoahava.com/seo/checklist-for-optimizing-web-design/",
	"title": "Checklist For Optimizing Web Design",
	"tags": ["SEO", "WCAG", "Web design"],
	"description": "Handy checklist for comparing site accessibility, web development best practices, and search engine optimization preferences-",
	"content": " In this post, I propose that a combination of valid, accessible, and search engine friendly markup is the perfect recipe for optimal web design.\nFor markup to be valid, it needs to conform to the guidelines laid out by the \u0026ldquo;governing body\u0026rdquo; of HTML standardization: the World Wide Web Consortium, or W3C. While the Internet anxiously waits for HTML5 to shift in status from candidate to recommendation, we\u0026rsquo;re stuck with ye olde HTML 4.01 standard (est. 1999) as laid out by W3C. Naturally, HTML5 is already widely supported by all the major browsers, and it can (and should) be incorporated in web design without hesitation.\nAccessibility here means that the markup follows the recommendations in the Web Content Accessibility Guidelines (WCAG). WCAG is developed by the Web Accessilibity Initiative (WAI), also engineered by W3C. The guidelines, now matured to their 2.0 version (since 2008), provide a list of steps to consider during web design. These steps aim to make the pages accessible for users with disabilities, and also for different platforms and user agents such as mobile devices.\nFinally, search engine friendly markup follows the best practices identified by the enormous SEO community, all working to uncover the best ways to make friends with the elusive search engines that govern our daily life on the web. There is a seemingly endless supply of good SEO guides for optimizing web design, but if the topic is new to you, you might as well start with SEOmoz\u0026rsquo;s Beginner\u0026rsquo;s Guide To SEO.\nOptimal markup is good for your web design On our way to finding the best practices, i.e. the perfect combination of recommendations, let\u0026rsquo;s get one thing straight. It is a self-evident, nature-given, inalienable fact that your markup must be 100% valid. Even though the HTML standard is just a recommendation, meaning that web browsers can steer around your poor markup, it\u0026rsquo;s no reason to be lax about it.\nFor one thing, invalid markup is a sign of sloppiness. Web designers should take pride in creating markup that is clear, readable, and passes validation tests. Also, valid markup is always a requirement for accessibility and SEO. There is no such markup that is search engine friendly or accessible and not valid at the same time. So if your markup is valid, you are well on your way to optimizing it for WCAG and SEO as well.\n  Finding the optimal markup for W3C, WCAG and SEO is the holy grail of web design\nWhether you want to promote your site\u0026rsquo;s accessibility or search engine friendliness is up to you. Most of the things you do for SEO will apply for WCAG as well, and vice versa. Note that there are elements prohibited in one but accepted in the other, and there are elements which have relevance only for one but not the other. In your web design efforts, I recommend that you pay heed to the rules and make note of the recommendations. You can always try to make your website as accessible, search engine friendly, and valid as possible, but this post looks to find the minimal strategy required to find the holy grail of optimal markup.\nThe guidelines What follows is essentially a checklist for your web design needs. I have chopped it up so that first you see the recommendations that are shared by SEO and WCAG. Following that are the recommendations that are SEO- or WCAG-specific. A green bulb means that the item is a requirement. A yellow bulb means that the item is a recommendation (or has some other significance). A red bulb means that the item is prohibited, and a dash means that the item has no (significant) relevance. Note that W3C validation criteria are not listed, as I mentioned above that regardless of recommendations or guidelines, make sure that your HTML is always 100% valid.\nFor the WCAG guidelines, I use the recommendations in WebAIM\u0026rsquo;s WCAG 2.0 checklist. Kevin Vertommen has provided a wonderful SEO checklist for web designers, which I refer to here as well. Note here also that because especially SEO best practices are quite subjective and usually require context to perform well, I have used my judgment on what is most often the best practice for each recommendation. This means that you should take it with a grain of salt, and treat it as a requirement only if it\u0026rsquo;s relevant for your particular SEO case.\nDownload the entire chart in PDF format (Comparison chart for SEO and WCAG guidelines.pdf).\n  In the snippet above I only included those recommendations that apply to both SEO and WCAG guidelines, in good or in bad. The PDF contains the entire chart. Most of the recommendations put forth by WCAG and SEO are relevant to one but not the other. As you can see from the image above, I identified only three recommendations as possibly harmful, and they were only harmful to SEO. They are easily avoided, as you should really try to do without frames, and null ALT text simply has no justification. If you have images that serve no content purpose, make them background elements by using CSS.\nBecause SEO is the only thing that stands to be harmed if you follow all guidelines diligently, it would imply that you should make following SEO guidelines a priority. So when writing markup 1) make sure it is valid, 2) make sure your page conforms to all SEO best practices, and only then 3) make sure your page follows WCAG recommendations. Just be wary of using frames and null ALT text, and you\u0026rsquo;ll do fine.\nThe PDF is not comprehensive, but it does serve as a nice \u0026ldquo;checklist\u0026rdquo; for checking if your site adheres to accessibility and search optimization guidelines. It is not a bad habit to familiarize yourself with these guidelines and to make them part of your web design routine. Once you ensure that your HTML is valid, accessible, and search engine friendly, you can rest assured that you are doing your part in making the Internet a better place.\n"
},
{
	"uri": "https://www.simoahava.com/seo/content-strategy-know-your-audience/",
	"title": "Content Strategy: Know Your Audience",
	"tags": ["Audience design", "CMS", "Content management system", "Content strategy", "Search engine optimization"],
	"description": "Content strategy is the key to any successful search engine optimization effort.",
	"content": " For years and years, the one constant in the chaotic world of SEO has been a simple statement: Content is King. This statement has been the cornerstone of content strategy in SEO projects, and its validity has hardly been contested. This is not due to lack of trying. Many posts in the blogosphere have taken an opposing stand (Heidi Cohen: format is king, Carl Ocab: marketing is king, Robert Jones: traffic is king, Bernadette Coleman: trust is king). The message of the opposition is this: content cannot be king, as it is only a small part of the audience experience.\n  I agree, and I also think the metaphor is a poor one. Being king implies sovereignty. Kings inherit their power through lineage (or usurpation), and they rule supreme (well, they used to, at least). The problem with this metaphor, in terms of content strategy, is that this devalues all the other, hugely important aspects of creating a successful website. In SEO, all parts of the optimization process come together in a well-developed content strategy:\nYou need the technical groundwork to make sure the site is crawlable. Without crawled pages, your site\u0026rsquo;s standing in organic search results will be compromised. As long as you have access to a modern CMS, you won\u0026rsquo;t need to worry about this too much.\nYou need a strong keyword analysis to make sure that the right audience arrives at your site. You need to understand your audience\u0026rsquo;s needs in order to convert them to followers/fans/revenue/whatever your goals are.\nYou need jaw-dropping design to make sure that the initial impression your site gives is the one that draws your visitors in.\nYou need a good outreach plan to build hype around your site. Your marketing department must be up-to-speed with the latest online trends and fashions.\nAnd finally, you need incredible content to make sure that the audience who does arrive at your site doesn\u0026rsquo;t leave. Ever. You want your site to be the last one they look at before they go to sleep, the one they dream about in their feverish dreams, and the first thing they think of when they wake up in the morning.\nYou can focus your content strategy in many ways (see e.g James Agate\u0026rsquo;s wonderfully informative post A Guide to Producing World-Class Infographics), but the basics are always the same, and I will introduce them next.\nRight content strategy for the right audience I like to approach content strategy with the same tools and methods I used when I was a product owner in an agile development team. Everything began with a vision statement. Every product, every release, every increment, and every feature needed to adhere to this vision religiously.\nimilarly, when I think about what content to create for a single page, for example, I think of a single content statement which governs everything the page should be about. Really, it must be simple. A good content statement contains the the core message of the page, the general target group, the differentiating factor, and a goal statement. For example:\nThis page tells all about MyToolCompany's new Power Drill 2000. This information is of most interest to home owners, building crews and DIY hobbyists. This page stands out because the product is introduced in a memorable and easily accessible way. The goal of this page is to get leads and sales contacts. After I have my content statement, I can start thinking about the target groups more carefully. This aspect of content strategy requires a lot of niche knowledge about the business. If a SEO consultant has been hired to work on the content, target group analysis should be developed as a team effort.\nI call this audience design, and it should provide you with the keywords you need to work on semantic optimization. Look at search trends to make early bird calls, and home in on your competition\u0026rsquo;s tactics.\nAnother really good method of implementing audience design is to draft user stories and scenarios. Think of a few user profiles who might be typical visitors to your site, and write scenarios for them: \u0026ldquo;As a user type, I want to find out about page content so that I can statement of need or action\u0026rdquo;. Once you have a number of these, you can start writing your content.\nThe point behind all this labor is simple. Your content strategy will ensure high quality content if you ask the following questions after each paragraph you write:\n Is this paragraph in line with the content statement? If there is any content that cannot directly be related to the content statement, discard the text. You don\u0026rsquo;t want to confuse your visitors by littering your pages with irrelevant or anecdotal content.\n Does this paragraph cater to the user scenarios you wrote? Step into the shoes of the user profiles you created. Read through the text as if you were a visitor on the site. Does it work for you? Do you feel attached to the content of the paragraph, or does it leave you cold?\n Does this paragraph cover just one issue? Or do you ramble on? Focusing your writing is a good habit and increases readibility a lot. Each paragraph should cover just one issue related to the topic of the page, and each page should have just one topic.\n  As long as each paragraph you write scores well on the questions above, you should be well on your way to creating amazing content.\nThe most important thing is to really, REALLY, suck up to your audience. Your content strategy is not king-like. Its power is not self-derived, it doesn\u0026rsquo;t have the means to dictate, and it can\u0026rsquo;t overrule the masses. It\u0026rsquo;s more like a democratically elected president: It has a lot of power, but the minute the people are dissatisfied is the minute they abandon the fruit of all your hard work.\nSo content really isn\u0026rsquo;t king? That\u0026rsquo;s right it isn\u0026rsquo;t. Content is not and should not be the sole reason your site is successful. And here\u0026rsquo;s the kicker: your content strategy should not just create quality content. Your website design should not just create beautiful and accessible visuals. Your forms, plugins and widgets should not just provide fluent interaction with your site visitors. No.\nEverything you do should be geared towards eliciting an emotional response from your guest.\nRead that again. You are competing against a gazillion of similar sites in the web. You must know who your visitors are, and you must model your content strategy after their needs.\nIn other words: Remember your audience and they will remember you.\n"
},
{
	"uri": "https://www.simoahava.com/content-management/modern-cms-top-5-features/",
	"title": "Modern CMS: Top 5 Features",
	"tags": ["CMS", "Content management system", "Modern CMS", "Modular architecture", "OWASP", "Security"],
	"description": "Listing top 5 features that any modern content management system (CMS) should have.",
	"content": " You are right now enjoying the fruits of a very popular content management system, or CMS, whether you know it or not. This blog is published via WordPress, a modern CMS if there ever was one. In fact, if you add a comment to this post with the form below (hint, hint), you will be participating in content creation, using tools that come out-of-the-box in this particular platform.\n  But what makes a modern CMS? Is WordPress the perfect choice for you or your business? Well, I\u0026rsquo;m not going to review the products on the market, so I\u0026rsquo;ll leave the second question to you or your IT manager. However, I will take a stand on the first question, as I look at what makes a modern content management system. What are the must-have features it should boast, and what can you live without? My word is not doctrine, but I do have a long history of working with CMS\u0026rsquo;s and with clients who only want the best.\nThe top 5 must-have features of any modern CMS 5. Modularity\nUnless you have the kind of money to pay for a tailored solution created from scratch just for you and your needs, you\u0026rsquo;re going to want a modular platform. Actually, even if you\u0026rsquo;re shopping around for a customized solution you\u0026rsquo;ll still want it to be modular. The reason is simple. No matter how far-sighted you think you are, your needs will change and the requirements you attach to a CMS will change as well. Lack of modularity leads to a number of problems, with cumbersome change management at the top of the list.\n  Furthermore, if the platform is modular, development will be more cost-efficient. An able version management plan for the core as well as the modules ensures that only the necessary changes are implemented in each release cycle. Trust me, you will be thankful when a new core package doesn\u0026rsquo;t automatically result in the quick and merciless incapacitation of your installation.\nIn addition to architectural modularity, where the core features and the components are separated in the code, support for dedicated and third-party plugins, widgets, apps etc. is a huge plus. To have an entire community working on the development is what a modern CMS is all about. Which brings me to the next key feature:\n4. Open source\nThis could be easily debated, as there are a number of hugely popular proprietary CMS\u0026rsquo;s out there, such as Microsoft SharePoint and EPiServer. The problem with these solutions is that their development is governed by the company who owns the software. This means that the community\u0026rsquo;s impact is diminished, since the company can usually support only a singular product vision. Furthermore, SharePoint, for example, is so much more than just a CMS. It\u0026rsquo;s a full-blown web platform for enterprises, and its development is surely not geared to making it the best web publishing solution around.\n  Open source software takes the development away from a single point-of-origin and brings the power to the community. The mark of a modern CMS is to stay up-to-date, fresh and vitalized. A vibrant user community, where everyone partakes in the design, development and support of the platform can ensure just that.\nOpen source does have its own issues, ranging from the significant (lack of a proper support process, exaggerated focus on template design) to the insignificant (unpredictability of community-driven development, uncertain platform life cycle), but the pros of having an open-source platform outweigh the cons. But as I said earlier, whether or not this point is a key feature of a CMS is debatable. What I do believe with absolute certainty is that community- and user-driven development have a far more significant impact on defining what a modern CMS is than development that is hidden behind the interfaces of a closed source application.\n3. Control over the content\nIn many ways, this is the single most important feature of any modern CMS, and will most probably affect your decision the most. There is simply no excuse for a software solution which doesn\u0026rsquo;t provide all the necessary tools for advanced content manipulation. Here are some of the features the CMS must be able to tackle:\n Quick publishing - if you are a blogger or if you update the news section of your website, you will want it to be as painless as possible. Having to click 5+ times just to get your modifications published is a turn-off\n Access to the HTML source of the template - if you are denied the possibility to edit the title, the meta tags or other markup in your website, you are in a jam, as these all have a huge impact on the accessibility of your website\n Editing the URL structure - another huge thing for accessibility and SEO, because being stuck with a garbled URL structure or one riddled with confusing parameters will make it difficult for users and search engines to identify important content\n Separation of content and design - you might think that you\u0026rsquo;d do fine with a visual, WYSIWYG editor, but trust me: you will not want the design to dictate what content you can and should publish. Rather, it should always be the other way around, where the design adapts to whatever content you feed into it.\n  2. Customizability\nThis steps somewhat into the same territory which we already covered in point #5. Where modularity covers the architectural aspects of a modern CMS, customizability has to do with how you want the platform to suit your needs. Plugins, widgets, apps, components, controls etc. exist to provide you with a number of ways to customize your solution. You can shop around for the perfect addition to your core application. If you can\u0026rsquo;t find what you\u0026rsquo;re looking for, you can always create (or pay for the creation of) the extension.\nYou need to be able to stay on top of how the software works. You should be able to choose the features that are active, and hide or deactivate the rest. You should be able to choose the theme, design, skin or template of your site, and you should be able to modify or remove it if you wish. You must be able to secure single pages or sections of your website behind restricted access, and it should be possible to edit and mass edit any resources, pages or assets within the site.\nIn short: if there\u0026rsquo;s something you can\u0026rsquo;t modify in the platform, there must be a really good reason for it. Not the other way around.\n1. Security\nThis is a no-brainer. Any modern CMS worth its salt must be secure. OWASP has listed the top 10 security concerns for 2013, and you\u0026rsquo;d be surprised how many CMS deployments I\u0026rsquo;ve come across where these concerns have surfaced.\nNaturally, especially with open source software, security problems crop up more often than not. Since users can customize the application to their liking, it doesn\u0026rsquo;t require too much imagination to see how lack of proper quality control might lead to breaches in the system.\nOnce you have your platform set up with all its extensions, customizations and most of the content, it would be a good idea to order a security audit of the solution. It\u0026rsquo;s too easy to overlook injection flaws and data exposure problems, among others.\nSo what is the best solution for you? Well, your business needs dictate which platform you should get. These five modern CMS features exist in a number of excellent software solutions out there. If you also count in the proprietary software which have all but feature #4, the list is long indeed. Most likely you already have a CMS in mind if you are reading this. I hope that these five requirements help you in your decision-making.\n"
},
{
	"uri": "https://www.simoahava.com/seo/search-trends-and-what-they-reveal/",
	"title": "Search Trends And What They Reveal",
	"tags": ["Google trends", "Search trends"],
	"description": "Research search trends to get a pulse of the world.",
	"content": " I\u0026rsquo;m hooked on Google Trends. For example, it probably won\u0026rsquo;t astound you to learn that whenever search trends peak for flu symptoms, there\u0026rsquo;s a similar peak for vaccine.\n  (See also how at some points vaccine comes first and only then do flu symptoms arise. Conspiracy theorists, the ball is in your court!)\nProbing this particular case further, I looked at the search trends for swine flu and vaccine. The former peaks in April 2009 and, to my surprise, vaccine actually declines over the following two months. However, it skyrockets during the third peak of the swine flu searches. What does this tell us? I\u0026rsquo;d like to speculate that people have become resilient to rumors, needing factual confirmation before rushing to the vaccine line. However, one thing is sure: This is a clear incentive for pharmacies and health care stations. What better time to promote their goods than the minute search trends for flu activity begin to gain statistical momentum?\n  By the way, like me, Google has tapped into Trends as a resource for identifying flu trends (see Google Flu Trends).\nSearch trends, correlations and conclusions I\u0026rsquo;m a HUGE fan of Freakonomics by Steven Levitt and Stephen J. Dubner. It\u0026rsquo;s a book on economics, correlations, causality, data mining and other boring-sounding topics, but the authors have managed to spin a yarn so delightful that it makes for a very entertaining read. Freakonomics studies trends and how they seem to correlate. They draw conclusions that might at times stray beyond the scope of credibility, but it all appears kosher enough to a layman (which is probably why it\u0026rsquo;s a bestseller). Anyway, once you get really into populist economics like this book, you start to get paranoid.\nYou start seeing correlations everywhere.\nFor example, between 2004-2013 there\u0026rsquo;s a clear decline in the search trends for war, which is a good thing, I guess. I like to think that it\u0026rsquo;s an indication of the fact that war is not the foremost thing in people\u0026rsquo;s minds. On the other hand, there\u0026rsquo;s a clear rise in queries for what to do, the motto of a very bored generation. It would be so easy to make a tale out of these two distinct search trends. Maybe it would be something like \u0026ldquo;there\u0026rsquo;s no war going on, what should we do now?\u0026rdquo;; an unhealthy, completely irresponsible statement (and factually wrong) coupled with a very popular information query (e.g. what to do in Berlin?), coming together in a correlation which might mislead the misinformed.\n  This is, of course, completely ungrounded conjecture. But seemingly unrelated correlations can be a breeding ground for some pretty amazing conclusions, as can be seen in Freakonomics. War and what to do might be an example of search trends having correlation only in the wildest imaginations of blog authors. Conversely, a study was done on the search volumes for debt, and it showed that search trends for debt were a very clear indicator of market fluctuations, thus showing that studying search queries has concrete applications.\nHow are we doing, really? What do search trends tell about the state of humanity? Can you really draw conclusions on the basis of what people type into the small input box day in, day out? I think you can, up to a point. First, you need a hypothesis before you start shuffling through the data. Just throwing in terms at random provides optimal manure for misguided conclusions based on your first interesting findings (see the comparison between war and what to do above). Second, a good quantitative analysis can go only so far without a qualitative component. In addition to crunching up the numbers, think of how the statistics relate to events around the globe during the peaks and troughs in the search volume. Think of why people did those very searches in those very months.\nOnce you accept the fact that you have no control over the quality of your informants, that your case study has little to do with ideal, clinical laboratory conditions, and that you are looking at search trends not absolutes (people do a lot more searches than just the ones you look at), you might see something of interest. Maybe this turns into a lucrative chance for you, especially if you identify something that has market value. Or maybe you\u0026rsquo;ve found something that tells you more about human nature than a single Superbowl commercial ever did.\nOr maybe you forget all about statistical significance and quality, and you see something like this, and it makes you smile just a little bit:\n  "
},
{
	"uri": "https://www.simoahava.com/tags/accelerated-mobile-pages/",
	"title": "Accelerated Mobile Pages",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/adblocker/",
	"title": "Adblocker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/add-on/",
	"title": "Add On",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/agile/",
	"title": "Agile",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/amazon/",
	"title": "Amazon",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/amp/",
	"title": "Amp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/analytics/",
	"title": "Analytics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/analytics/",
	"title": "Analytics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/api/",
	"title": "Api",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/app-engine/",
	"title": "App Engine",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/approval/",
	"title": "Approval",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/apps/",
	"title": "Apps",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/apps-script/",
	"title": "Apps Script",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/archives/",
	"title": "Archives",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/array/",
	"title": "Array",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/attribution/",
	"title": "Attribution",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/audience-design/",
	"title": "Audience Design",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/audit/",
	"title": "Audit",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/auto-event-tracking/",
	"title": "Auto Event Tracking",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/auto-link-domains/",
	"title": "Auto Link Domains",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/aws/",
	"title": "Aws",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/basketball/",
	"title": "Basketball",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/beforeunload/",
	"title": "Beforeunload",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/best-practices/",
	"title": "Best Practices",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/big-data/",
	"title": "Big Data",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/blogger/",
	"title": "Blogger",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/bounce-rate/",
	"title": "Bounce Rate",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/calculated-metrics/",
	"title": "Calculated Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/callback/",
	"title": "Callback",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/campaign-tracking/",
	"title": "Campaign Tracking",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/celebration/",
	"title": "Celebration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/change-history/",
	"title": "Change History",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/chrome/",
	"title": "Chrome",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/chrome-extension/",
	"title": "Chrome Extension",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/clickstream/",
	"title": "Clickstream",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/client-id/",
	"title": "Client Id",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cms/",
	"title": "Cms",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/container/",
	"title": "Container",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/container-snippet/",
	"title": "Container Snippet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content/",
	"title": "Content",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-blocker/",
	"title": "Content Blocker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-engagement/",
	"title": "Content Engagement",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-grouping/",
	"title": "Content Grouping",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/content-management/",
	"title": "Content Management",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-management/",
	"title": "Content Management",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-management-system/",
	"title": "Content Management System",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-security-policy/",
	"title": "Content Security Policy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/content-strategy/",
	"title": "Content Strategy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/context/",
	"title": "Context",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/conversion/",
	"title": "Conversion",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cookie/",
	"title": "Cookie",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cookiedomain/",
	"title": "Cookiedomain",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cookies/",
	"title": "Cookies",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/creative/",
	"title": "Creative",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cross-domain/",
	"title": "Cross Domain",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/cross-domain-tracking/",
	"title": "Cross Domain Tracking",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/csp/",
	"title": "Csp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/css/",
	"title": "Css",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/css-selectors/",
	"title": "Css Selectors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom/",
	"title": "Custom",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-dimension/",
	"title": "Custom Dimension",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-dimensions/",
	"title": "Custom Dimensions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-html/",
	"title": "Custom Html",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-html-tag/",
	"title": "Custom Html Tag",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-javascript/",
	"title": "Custom Javascript",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/custom-metrics/",
	"title": "Custom Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/customtask/",
	"title": "Customtask",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/dan-wilkerson/",
	"title": "Dan Wilkerson",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/dashboard/",
	"title": "Dashboard",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/data-collection/",
	"title": "Data Collection",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/data-layer/",
	"title": "Data Layer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/data-model/",
	"title": "Data Model",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/data-quality/",
	"title": "Data Quality",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/datalayer/",
	"title": "Datalayer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/debug/",
	"title": "Debug",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/debugging/",
	"title": "Debugging",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/definition-of-success/",
	"title": "Definition of Success",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/developer/",
	"title": "Developer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/development/",
	"title": "Development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/digital-marketing/",
	"title": "Digital Marketing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/digital-marketing/",
	"title": "Digital Marketing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/document.write/",
	"title": "Document.write",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/dom/",
	"title": "Dom",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/duplicate/",
	"title": "Duplicate",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/dynamic-content/",
	"title": "Dynamic Content",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/easter-egg/",
	"title": "Easter Egg",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/ecommerce/",
	"title": "Ecommerce",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/education/",
	"title": "Education",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/element-visibility/",
	"title": "Element Visibility",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/engagement/",
	"title": "Engagement",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/enhanced-ecommerce/",
	"title": "Enhanced Ecommerce",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/environments/",
	"title": "Environments",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/errors/",
	"title": "Errors",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/event/",
	"title": "Event",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/event-listener/",
	"title": "Event Listener",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/event-listeners/",
	"title": "Event Listeners",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/eventcallback/",
	"title": "Eventcallback",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/events/",
	"title": "Events",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/excel/",
	"title": "Excel",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/exceptions/",
	"title": "Exceptions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/extension/",
	"title": "Extension",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/facebook/",
	"title": "Facebook",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/fields-to-set/",
	"title": "Fields to Set",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/firing-rules/",
	"title": "Firing Rules",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/folders/",
	"title": "Folders",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/form/",
	"title": "Form",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/form-tracking/",
	"title": "Form Tracking",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/format-value/",
	"title": "Format Value",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/forms/",
	"title": "Forms",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/ga-spy/",
	"title": "Ga Spy",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gdpr/",
	"title": "Gdpr",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google/",
	"title": "Google",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-analytics/",
	"title": "Google Analytics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-analytics-settings/",
	"title": "Google Analytics Settings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-cloud/",
	"title": "Google Cloud",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-optimize/",
	"title": "Google Optimize",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-sheets/",
	"title": "Google Sheets",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-tag-manager/",
	"title": "Google Tag Manager",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/google-trends/",
	"title": "Google Trends",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/googletagmanager/",
	"title": "Googletagmanager",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/governance/",
	"title": "Governance",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gtag/",
	"title": "Gtag",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gtm-sonar/",
	"title": "Gtm Sonar",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gtm-tools/",
	"title": "Gtm Tools",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gtm360/",
	"title": "Gtm360",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/gtmtips/",
	"title": "Gtmtips",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/guide/",
	"title": "Guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/hack/",
	"title": "Hack",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/history/",
	"title": "History",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/history-change-trigger/",
	"title": "History Change Trigger",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/history-listener/",
	"title": "History Listener",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/hugo/",
	"title": "Hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/iframe/",
	"title": "Iframe",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/internal-traffic/",
	"title": "Internal Traffic",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/ios/",
	"title": "Ios",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/ip/",
	"title": "Ip",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/it-department/",
	"title": "It Department",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/javascript/",
	"title": "Javascript",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/klipfolio/",
	"title": "Klipfolio",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/learning/",
	"title": "Learning",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/links/",
	"title": "Links",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/listeners/",
	"title": "Listeners",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/local/",
	"title": "Local",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/localstorage/",
	"title": "Localstorage",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/lookup-table/",
	"title": "Lookup Table",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/macros/",
	"title": "Macros",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/marketer/",
	"title": "Marketer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/marketing/",
	"title": "Marketing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/measurement-protocol/",
	"title": "Measurement Protocol",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/meta-description/",
	"title": "Meta Description",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/migration/",
	"title": "Migration",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/mixcloud/",
	"title": "Mixcloud",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/mobile/",
	"title": "Mobile",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/modern-cms/",
	"title": "Modern Cms",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/modular-architecture/",
	"title": "Modular Architecture",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/navigation/",
	"title": "Navigation",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/netbooster/",
	"title": "Netbooster",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/new-ui/",
	"title": "New Ui",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/nodejs/",
	"title": "Nodejs",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/non-technical/",
	"title": "Non Technical",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/open-source/",
	"title": "Open Source",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/opt-out/",
	"title": "Opt Out",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/owasp/",
	"title": "Owasp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/page-load-time/",
	"title": "Page Load Time",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/page-timings/",
	"title": "Page Timings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/page/",
	"title": "Pages",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/penguin/",
	"title": "Penguin",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/performance/",
	"title": "Performance",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/permissions/",
	"title": "Permissions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/persistence/",
	"title": "Persistence",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/personal/",
	"title": "Personal",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/personal/",
	"title": "Personal",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/php/",
	"title": "Php",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/pii/",
	"title": "Pii",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/pitch/",
	"title": "Pitch",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/poetry/",
	"title": "Poetry",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/post/",
	"title": "Posts",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/ppc/",
	"title": "Ppc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/process/",
	"title": "Process",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/query-string/",
	"title": "Query String",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/race-condition/",
	"title": "Race Condition",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/reaktor/",
	"title": "Reaktor",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/referral/",
	"title": "Referral",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/regular-expression/",
	"title": "Regular Expression",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/release/",
	"title": "Release",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/resources/",
	"title": "Resources",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/rules/",
	"title": "Rules",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/sales/",
	"title": "Sales",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/schema/",
	"title": "Schema",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/score-card/",
	"title": "Score Card",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/scroll-depth/",
	"title": "Scroll Depth",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/search/",
	"title": "Search",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/search-api/",
	"title": "Search Api",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/search-engine-optimization/",
	"title": "Search Engine Optimization",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/search-trends/",
	"title": "Search Trends",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/security/",
	"title": "Security",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/selection/",
	"title": "Selection",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/seo/",
	"title": "Seo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/seo-report/",
	"title": "Seo Report",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/serp/",
	"title": "Serp",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/session/",
	"title": "Session",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/sessions/",
	"title": "Sessions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/site-search/",
	"title": "Site Search",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/site-speed/",
	"title": "Site Speed",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/snippet/",
	"title": "Snippet",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/snowplow/",
	"title": "Snowplow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/social-interactions/",
	"title": "Social Interactions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/soundcloud/",
	"title": "Soundcloud",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/spa/",
	"title": "Spa",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/splash-page/",
	"title": "Splash Page",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/static-site/",
	"title": "Static Site",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/storage/",
	"title": "Storage",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/support/",
	"title": "Support",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/swift/",
	"title": "Swift",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/syntax-highlight/",
	"title": "Syntax Highlight",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tag-management-solution/",
	"title": "Tag Management Solution",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tag-management-solutions/",
	"title": "Tag Management Solutions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tag-sequencing/",
	"title": "Tag Sequencing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tasks/",
	"title": "Tasks",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/technique/",
	"title": "Technique",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/test/",
	"title": "Test",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/testing/",
	"title": "Testing",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/timer/",
	"title": "Timer",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/timings/",
	"title": "Timings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tips/",
	"title": "Tips",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tools/",
	"title": "Tools",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tracker/",
	"title": "Tracker",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/tracker-object/",
	"title": "Tracker Object",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/trigger/",
	"title": "Trigger",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/triggers/",
	"title": "Triggers",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/troubleshoot/",
	"title": "Troubleshoot",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/undefined/",
	"title": "Undefined",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/universal-analytics/",
	"title": "Universal Analytics",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/user-id/",
	"title": "User Id",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/user-interface/",
	"title": "User Interface",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/user-permissions/",
	"title": "User Permissions",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/user-timings/",
	"title": "User Timings",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/v2/",
	"title": "V2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/variable/",
	"title": "Variable",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/variables/",
	"title": "Variables",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/videos/",
	"title": "Videos",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/visibility/",
	"title": "Visibility",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/wcag/",
	"title": "Wcag",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/weather/",
	"title": "Weather",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/web-design/",
	"title": "Web Design",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/web-design/",
	"title": "Web Design",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/categories/web-development/",
	"title": "Web Development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/web-development/",
	"title": "Web Development",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/website-redesign/",
	"title": "Website Redesign",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/workflow/",
	"title": "Workflow",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/workspaces/",
	"title": "Workspaces",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/youtube/",
	"title": "Youtube",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://www.simoahava.com/tags/zones/",
	"title": "Zones",
	"tags": [],
	"description": "",
	"content": ""
}]
