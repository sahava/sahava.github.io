<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Google Cloud on Simo Ahava&#39;s blog</title>
    <link>https://www.simoahava.com/tags/google-cloud/</link>
    <description>Recent content in Google Cloud on Simo Ahava&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Dec 2018 11:14:06 +0200</lastBuildDate>
    
	<atom:link href="https://www.simoahava.com/tags/google-cloud/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Scrape The URLs Of A Domain And Write The Results To BigQuery</title>
      <link>https://www.simoahava.com/google-cloud/scrape-domain-and-write-results-to-bigquery/</link>
      <pubDate>Mon, 31 Dec 2018 11:14:06 +0200</pubDate>
      
      <guid>https://www.simoahava.com/google-cloud/scrape-domain-and-write-results-to-bigquery/</guid>
      <description>In my intense love affair with the Google Cloud Platform, I&amp;rsquo;ve never felt more inspired to write content and try things out. After starting with a Snowplow Analytics setup guide, and continuing with a Lighthouse audit automation tutorial, I&amp;rsquo;m going to show you yet another cool thing you can do with GCP.
  In this guide, I&amp;rsquo;ll show you how to use an open-source web crawler running in a Google Compute Engine virtual machine (VM) instance to scrape all the internal and external links of a given domain, and write the results into a BigQuery table.</description>
    </item>
    
    <item>
      <title>Install Snowplow On The Google Cloud Platform</title>
      <link>https://www.simoahava.com/analytics/install-snowplow-on-the-google-cloud-platform/</link>
      <pubDate>Thu, 06 Dec 2018 07:00:22 +0200</pubDate>
      
      <guid>https://www.simoahava.com/analytics/install-snowplow-on-the-google-cloud-platform/</guid>
      <description>I&amp;rsquo;m (still) a huge fan of Snowplow Analytics. Their open-source, modular approach to DIY analytics pipelines has inspired me two write articles about them, and to host a meetup in Helsinki. In my previous Snowplow with Amazon Web Services guide, I walked you through setting up a Snowplow pipeline using Amazon Web Services. This time around, I&amp;rsquo;m looking at the wondrous Google Cloud Platform, for which Snowplow introduced support in an early 2018 release.</description>
    </item>
    
    <item>
      <title>Static Site Search With Hugo &#43; App Engine &#43; Search API &#43; Python</title>
      <link>https://www.simoahava.com/web-development/static-site-search-google-app-engine-search-api/</link>
      <pubDate>Mon, 15 Jan 2018 09:39:41 +0200</pubDate>
      
      <guid>https://www.simoahava.com/web-development/static-site-search-google-app-engine-search-api/</guid>
      <description>As the year changed to 2018, I decided to abandon WordPress, which I had been using for over 12 years as my content management system of choice. I had many reasons to do so, but the biggest motivators were the opportunity to try something new and to abandon the bloat and clutter of WordPress for a more simple, more elegant order of things. Spurred on by another adopter, Mark Edmondson, I decided to give Hugo a go (pun intended).</description>
    </item>
    
  </channel>
</rss>